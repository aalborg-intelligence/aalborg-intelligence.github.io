---
title: "Opdatering af vægte i simpelt neuralt netværk"
description-meta: 'En øvelse i at opdatere vægtene i et simpelt neuralt nætværk'
image: ""
categories:
  - A-niveau
  - Kort
---

::: {.callout-caution collapse="true" appearance="minimal"}
### Forudsætninger og tidsforbrug

+ Simple neurale netværk.
+ Sigmoid aktiveringsfunktion.
+ Gradientnedstigning.

Forudsætningerne kan f.eks. dækkes vha. [noten om simple neurale netværk](../materialer/perceptron/perceptron.qmd){target="_blank"}.

**Tidsforbrug:** Ca. 90 minutter.

:::

::: {.purpose}

### Formål

Gennem detaljerede beregninger at forstå, hvordan vægtene i et simpelt neuralt netværk opdateres med brug af sigmoid aktiveringsfunktionen og gradientnedstigning.

Dette kan ses som et skridt på vejen til at forstå, hvordan vægtene opdateres i et generelt neuralt netværk.

:::

## Et meget lille datasæt

I neurale netværk er der ofte rigtige mange features, rigtigt mange vægte og rigtige mange datapunkter. 

For bedre at forstå, hvor vægtene opdateres i et simpelt neuralt netværk, vil vi her se på et meget lille eksempel, så det mere manuelt er muligt at lave opdateringen af vægtene.

Konkret vil vi se på to features $x_1$ og $x_2$ og en targetværdi $t$ ud fra følgende 3 datapunkter.

|$x_1$ | $x_2$ | $t$ |
|:---:|:---:|:---:|
| -1 | 2 | ja = 1 |
| 0 | 4 | nej = 0 |
| 1 | 7 | ja = 1 |

Vi vælger en learning-rate på $$\eta = 0.1$$ 
*sigmoid-funktionen* som aktiveringsfunktion $$\sigma(x)=\frac{1}{1+e^{-x}}$$ 
og *squared-error* som tabsfunktion $$E(w_0, w_1, w_2) = \frac{1}{2} \sum_{m=1}^{3} \left (t^{(m)}-\sigma(w_0 + w_1 \cdot x_1^{(m)} + w_2 \cdot x_2^{(m)}) \right)^2$$ 
Endeligt vælger vi startvægtene $$w_0=0.1, w_1=0.1, w_2=0.1$$.

## Første opdatering af vægtene

Du skal nu gå gennem de enkelte beregninger, som skal til for at opdatere vægtene. Der er efterfølgende facit til hver del.

::: {.callout-note collapse="false" appearance="minimal"}
### Opgave 1: Beregn værdien af tabsfunktionen
* Udregn først $s^{(1)} = w_0 + w_1 \cdot x_1^{(1)} + w_2 \cdot x_2^{(1)}$ for det første datapunkt.
* Udregn så $o^{(1)} = \sigma (s^{(1)})$.
* Udregn derefter $e^{(1)} = (t^{(1)} - o^{(1)})^2$, hvilket giver det første punkts bidrag til tabsfunktionen.
* Gentag for hver af de 2 øvrige datapunkter.
* Læg de 3 beregnede værdier sammen og divider med 2, så $E=\frac{1}{2} \cdot (e^{(1)}+e^{(2)}+e^{(3)})$.

:::

::: {.callout-note collapse="true" appearance="minimal"}
### Løsning til opgave 1
$$
\begin{aligned}
s^{(1)}  & = 0.1 + 0.1 \cdot -1 + 0.1 \cdot 2   = 0.2 \\
o^{(1)} & = \sigma (0.2)  \approx 0.5498339973 \\
e^{(1)} & = (1 - o^{(1)})^2  \approx 0.2026494300 \\
\\
\\
s^{(2)} & = 0.1 + 0.1 \cdot 0 + 0.1 \cdot 4 = 0.5 \\
o^{(2)} & = \sigma (0.5) \approx 0.6224593311 \\
e^{(2)} & = (0 - o^{(2)})^2 = \approx 0.3874556189 \\
\\
\\
s^{(3)} & = 0.1 + 0.1 \cdot 1 + 0.1 \cdot 7 = 0.9 \\
o^{(3)} & = \sigma (0.9) \approx 0.7109495025 \\
e^{(3)} & = (1 - o^{(3)})^2 = \approx 0.08355019010 \\
\\
\\
E & = \frac {1}{2}(e^{(1)}+e^{(2)}+e^{(3)}) \approx 0.3368276195
\end{aligned}
$$
:::

::: {.callout-note collapse="false" appearance="minimal"}
### Opgave 2: Beregn de partielle afledede

* Beregn $$\frac{\partial E}{\partial w_0} = - \sum_{m=1}^{3} \left (t^{(m)}-o^{(m)} \right) \cdot o^{(m)}\cdot (1-o^{(m)}) \cdot 1$$
* Beregn $$\frac{\partial E}{\partial w_1} = - \sum_{m=1}^{3} \left (t^{(m)}-o^{(m)} \right) \cdot o^{(m)}\cdot (1-o^{(m)}) \cdot x_1^{(m)}$$
* Beregn $$\frac{\partial E}{\partial w_2} = - \sum_{m=1}^{3} \left (t^{(m)}-o^{(m)} \right) \cdot o^{(m)}\cdot (1-o^{(m)}) \cdot x_2^{(m)}$$

:::

::: {.callout-note collapse="true" appearance="minimal"}
### Løsning til opgave 2
$$
\begin{aligned}
E_0^{(1)} & = (t_1-o^{(1)}) \cdot o^{(1)} \cdot (1-o^{(1)}) \cdot 1 \\ 
       & = (1-0.5498339973) \cdot 0.5498339973 \cdot (1-0.5498339973) \cdot 1 \\
       & \approx 0.1114235461 \\
E_0^{(2)} & = (t^{(2)}-o^{(2)}) \cdot o^{(2)} \cdot (1-o^{(2)}) \cdot 1 \\
       & = (0-0.6224593311) \cdot 0.6224593311 \cdot (1-0.6224593311) \cdot 1 \\
       & \approx -0.1462802535 \\
E_0^{(3)} & = (t^{(3)}-o^{(3)}) \cdot o^{(3)} \cdot (1-o^{(3)}) \cdot 1 \\
      & = (1-0.7109495025) \cdot 0.7109495025 \cdot (1-0.7109495025) \cdot 1 \\
      & \approx 0.05939996609 \\
\frac{\partial E}{\partial w_0} & = -(E_0^{(1)}+E_0^{(2)}+E_0^{(3)}) \\
      & = - (0.1114235461-0.1462802535+0.05939996609) \\
      & \approx -0.02454325869 \\
\\
\\
E_1^{(1)} & = (t^{(1)}-o^{(1)}) \cdot o^{(1)} \cdot (1-o^{(1)}) \cdot x_1^{(1)} \\ 
       & = (1-0.5498339973) \cdot 0.5498339973 \cdot (1-0.5498339973) \cdot -1 \\
       & \approx -0.1114235461 \\
E_1^{(2)} & = (t^{(2)}-o^{(2)}) \cdot o^{(2)} \cdot (1-o^{(2)}) \cdot x_1^{(2)} \\
       & = (0-0.6224593311) \cdot 0.6224593311 \cdot (1-0.6224593311) \cdot 0 \\
       & = 0 \\
E_1^{(3)} & = (t^{(3)}-o^{(3)}) \cdot o^{(3)} \cdot (1-o^{(3)}) \cdot x_1^{(3)} \\
      & = (1-0.7109495025) \cdot 0.7109495025 \cdot (1-0.7109495025) \cdot 1 \\
      & \approx 0.05939996609 \\
\frac{\partial E}{\partial w_1} & = -(E_1^{(1)}+E_1^{(2)}+E_1^{(3)}) \\
      & = - (-0.1114235461+0+0.05939996609) \\
      & \approx 0.05202358001 \\    
\\
\\
E_2^{(1)} & = (t^{(1)}-o^{(1)}) \cdot o^{(1)} \cdot (1-o^{(1)}) \cdot x_2^{(1)} \\ 
       & = (1-0.5498339973) \cdot 0.5498339973 \cdot (1-0.5498339973) \cdot 2 \\
       & \approx 0.2228470922 \\
E_2^{(2)} & = (t^{(2)}-o^{(2)}) \cdot o^{(2)} \cdot (1-o^{(2)}) \cdot x_2^{(2)} \\
       & = (0-0.6224593311) \cdot 0.6224593311 \cdot (1-0.6224593311) \cdot 4 \\
       & = -0.5851210140 \\
E_2^{(3)} & = (t^{(3)}-o^{(3)}) \cdot o^{(3)} \cdot (1-o^{(3)}) \cdot x_2^{(3)} \\
      & = (1-0.7109495025) \cdot 0.7109495025 \cdot (1-0.7109495025) \cdot 7 \\
      & \approx 0.4157997626 \\
\frac{\partial E}{\partial w_2} & = -(E_2^{(1)}+E_2^{(2)}+E_2^{(3)}) \\
      & = - (0.2228470922-0.5851210140+0.4157997626) \\
      & \approx -0.0535258408
\end{aligned}
$$

:::

::: {.callout-note collapse="false" appearance="minimal"}
### Opgave 3: Opdater vægtene

Beregn de opdaterede vægte
$$
\begin{aligned}
w_0 \leftarrow & w_0 - \eta \cdot \frac{\partial E}{\partial w_0}   \\
w_1 \leftarrow & w_1 - \eta \cdot \frac{\partial E}{\partial w_1}  \\
w_2 \leftarrow & w_2 - \eta \cdot \frac{\partial E}{\partial w_2} 
\end{aligned}
$$

:::

::: {.callout-note collapse="true" appearance="minimal"}
### Løsning til opgave 3

Beregn de opdaterede vægte
$$
\begin{aligned}
w_0 \leftarrow & 0.1 - 0.1 \cdot (-0.02454325869) \approx 0.1024543259   \\
w_1 \leftarrow & 0.1 - 0.1 \cdot 0.05202358001 \approx 0.09479764200  \\
w_2 \leftarrow & 0.1 - 0.1 \cdot (-0.0535258408) \approx 0.1053525841 
\end{aligned}
$$
:::

## Anden opdatering af vægtene
Overvej, om du kan strømline dine beregninger, evt. i Excel eller i dit CAS værktøj, så det bliver hurtigere at opdatere vægtene en gang mere på samme måde.

::: {.callout-note collapse="false" appearance="minimal"}
### Opgave 4: Opdater vægtene anden gang

* Beregn tabsfunktionen.
* Beregn de opdaterede vægte.

:::

Bemærk, at værdien af tabsfunktionen er blevet lidt mindre. Formålet er jo netop at minimere den gennem gradientnedstigning, så som regel bør værdien bliver mindre, hver gang vægtene opdateres.

::: {.callout-note collapse="true" appearance="minimal"}
### Løsning til opgave 4
$$
\begin{aligned}
E & \approx 0.3362680478 \\
w_0 & \approx 0.1045005370 \\
w_1 & \approx 0.08949754490 \\
w_2 & \approx 0.1086460194
\end{aligned}
$$

:::

## App til simple neurale netværk
Med [perceptron app'en](../apps/perceptron_app.qmd){target="_blank"} kan du lave de samme beregninger bare automatisk.

::: {.callout-note collapse="false" appearance="minimal"}
### Opgave 5: Afprøv perceptron app'en

* Lav et Excelark med feature- og targetværdierne.
* Indlæs data fra Excelarket i perceptron app'en.
* Vælg de korrekte værdier i felterne på app'en. Herunder skal feature-skalering være slået fra.
* Se om app'en giver samme resultater for tabsfunktionen og vægtene, som du selv fik efter 1 iteration og efter 2 iterationer.

:::

## Cross-entropy som tabsfunktion.
Du kan læse om *cross-entry* i [noten om tabsfunktioner](../materialer/tabsfunktioner/tabsfunktioner.qmd#cross-entropy){target="_blank"}.

::: {.callout-note collapse="false" appearance="minimal"}
### (Ekstra) Opgave 6: Cross-entropy tabsfunktion 
* Gentag opgave 1-5 men med *cross-entropy* som tabsfunktion i stedet for *squared-error*.

:::
