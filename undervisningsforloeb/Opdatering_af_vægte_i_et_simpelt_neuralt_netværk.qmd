---
title: "Opdatering af vægte i simpelt neuralt netværk"
description-meta: 'En øvelse i at opdatere vægtene i et simpelt neuralt nætværk'
image: ""
categories:
  - A-niveau
  - Kort
---

::: {.callout-caution collapse="true" appearance="minimal"}
### Forudsætninger og tidsforbrug

+ Simple neurale netværk.
+ Sigmoid aktiveringsfunktion.
+ Gradientnedstigning.

Forudsætningerne kan f.eks. dækkes vha. [noten om simple neurale netværk](../materialer/perceptron/perceptron.qmd){target="_blank"}.

**Tidsforbrug:** Ca. 90 minutter.

:::

::: {.purpose}

### Formål

Gennem detaljerede beregninger at forstå, hvordan vægtene i et simpelt neuralt netværk opdateres med brug af sigmoid aktiveringsfunktionen og gradientnedstigning.

Dette kan ses som et skridt på vejen til at forstå, hvordan vægtene opdateres i et generelt neuralt netværk.

:::

## Et meget lille datasæt

I neurale netværk er der ofte rigtige mange features, rigtigt mange vægte og rigtige mange datapunkter. 

For bedre at forstå, hvor vægtene opdateres i et simpelt neuralt netværk, vil vi her se på et meget lille eksempel, så det mere manuelt er muligt at lave opdateringen af vægtene.

Konkret vil vi se på to features $x_1$ og $x_2$ og en targetværdi $t$ ud fra følgende 3 datapunkter.

|$x_1$ | $x_2$ | $t$ |
|:---:|:---:|:---:|
| -1 | 2 | ja = 1 |
| 0 | 4 | nej = 0 |
| 1 | 7 | ja = 1 |

Vi vælger en learning-rate på $$\eta = 0.1$$ 
*sigmoid-funktionen* som aktiveringsfunktion $$\sigma(x)=\frac{1}{1+e^{-x}}$$ 
og *squared-error* som tabsfunktion $$E(w_0, w_1, w_2) = \frac{1}{2} \sum_{m=1}^{3} \left (t_m-\sigma(w_0 + w_1 \cdot x_{m,1} + w_2 \cdot x_{m,2}) \right)^2$$ 
Endeligt vælger vi startvægtene $$w_0=0.1, w_1=0.1, w_2=0.1$$.

## Første opdatering af vægtene

Du skal nu gå gennem de enkelte beregninger, som skal til for at opdatere vægtene. Der er efterfølgende facit til hver del.

::: {.callout-note collapse="false" appearance="minimal"}
### Opgave 1: Beregn værdien af tabsfunktionen
* Udregn først $s_1 = w_0 + w_1 \cdot x_1 + w_2 \cdot x_2$ for det første datapunkt.
* Udregn så $o_1 = \sigma (s_1)$.
* Udregn derefter $e_1 = (t_1 - o_1)^2$, hvilket giver det første punkts bidrag til tabsfunktionen.
* Gentag for hver af de 2 øvrige datapunkter.
* Læg de 3 beregnede værdier sammen og divider med 2, så $E=\frac{1}{2} \cdot (e_1+e_2+e_3)$.

:::

::: {.callout-note collapse="true" appearance="minimal"}
### Løsning til opgave 1
$$
\begin{aligned}
s_1  & = 0.1 + 0.1 \cdot -1 + 0.1 \cdot 2   = 0.2 \\
\sigma_1 & = \sigma (0.2)  \approx 0.5498339973 \\
e_1 & = (1 - \sigma_1)^2  \approx 0.2026494300 \\
\\
\\
s_2 & = 0.1 + 0.1 \cdot 0 + 0.1 \cdot 4 = 0.5 \\
\sigma_2 & = \sigma (0.5) \approx 0.6224593311 \\
e_2 & = (0 - \sigma_2)^2 = \approx 0.3874556189 \\
\\
\\
s_3 & = 0.1 + 0.1 \cdot 1 + 0.1 \cdot 7 = 0.9 \\
\sigma_3 & = \sigma (0.9) \approx 0.7109495025 \\
e_3 & = (1 - \sigma_3)^2 = \approx 0.08355019010 \\
\\
\\
E & = \frac {1}{2}(e_1+e_2+e_3) \approx 0.3368276195
\end{aligned}
$$
:::

::: {.callout-note collapse="false" appearance="minimal"}
### Opgave 2: Beregn de partielle afledede

* Beregn $$\frac{\partial E}{\partial w_0} = - \sum_{m=1}^{3} \left (t_m-o_m \right) \cdot o_m\cdot (1-o_m) \cdot 1$$
* Beregn $$\frac{\partial E}{\partial w_1} = - \sum_{m=1}^{3} \left (t_m-o_m \right) \cdot o_m\cdot (1-o_m) \cdot x_{m,1}$$
* Beregn $$\frac{\partial E}{\partial w_2} = - \sum_{m=1}^{3} \left (t_m-o_m \right) \cdot o_m\cdot (1-o_m) \cdot x_{m,2}$$

:::

::: {.callout-note collapse="true" appearance="minimal"}
### Løsning til opgave 2
$$
\begin{aligned}
E_{01} & = (t_1-o_1) \cdot o_1 \cdot (1-o_1) \cdot 1 \\ 
       & = (1-0.5498339973) \cdot 0.5498339973 \cdot (1-0.5498339973) \cdot 1 \\
       & \approx 0.1114235461 \\
E_{02} & = (t_2-o_2) \cdot o_2 \cdot (1-o_2) \cdot 1 \\
       & = (1-0.6224593311) \cdot 0.0.6224593311 \cdot (1-0.6224593311) \cdot 1 \\
       & \approx -0.1462802535 \\
E_{03} & = (t_3-o_3) \cdot o_3 \cdot (1-o_3) \cdot 1 \\
      & = (1-0.7109495025) \cdot 0.7109495025 \cdot (1-0.7109495025) \cdot 1 \\
      & \approx 0.05939996609 \\
\frac{\partial E}{\partial w_0} & = -(E_{01}+E_{01}+E_{03}) \\
      & = - (0.1114235461-0.1462802535+0.05939996609) \\
      & \approx 0.02454325869 \\
\\
\\
E_{11} & = (t_1-o_1) \cdot o_1 \cdot (1-o_1) \cdot x_{11} \\ 
       & = (1-0.5498339973) \cdot 0.5498339973 \cdot (1-0.5498339973) \cdot -1 \\
       & \approx -0.1114235461 \\
E_{12} & = (t_2-o_2) \cdot o_2 \cdot (1-o_2) \cdot x_{12} \\
       & = (1-0.6224593311) \cdot 0.0.6224593311 \cdot (1-0.6224593311) \cdot 0 \\
       & = 0 \\
E_{13} & = (t_3-o_3) \cdot o_3 \cdot (1-o_3) \cdot x_{13} \\
      & = (1-0.7109495025) \cdot 0.7109495025 \cdot (1-0.7109495025) \cdot 1 \\
      & \approx 0.05939996609 \\
\frac{\partial E}{\partial w_1} & = -(E_{11}+E_{11}+E_{13}) \\
      & = - (-0.1114235461+0+0.05939996609) \\
      & \approx -0.05202358001 \\    
\\
\\
E_{21} & = (t_1-o_1) \cdot o_1 \cdot (1-o_1) \cdot x_{21} \\ 
       & = (1-0.5498339973) \cdot 0.5498339973 \cdot (1-0.5498339973) \cdot 2 \\
       & \approx 0.2228470922 \\
E_{22} & = (t_2-o_2) \cdot o_2 \cdot (1-o_2) \cdot x_{22} \\
       & = (1-0.6224593311) \cdot 0.0.6224593311 \cdot (1-0.6224593311) \cdot 4 \\
       & = -0.5851210140 \\
E_{23} & = (t_3-o_3) \cdot o_3 \cdot (1-o_3) \cdot x_{23} \\
      & = (1-0.7109495025) \cdot 0.7109495025 \cdot (1-0.7109495025) \cdot 7 \\
      & \approx 0.4157997626 \\
\frac{\partial E}{\partial w_2} & = -(E_{21}+E_{21}+E_{23}) \\
      & = - (0.2228470922-0.5851210140+0.4157997626) \\
      & \approx 0.0535258408
\end{aligned}
$$

:::

::: {.callout-note collapse="false" appearance="minimal"}
### Opgave 3: Opdater vægtene

Beregn de opdaterede vægte
$$
\begin{aligned}
w_0 \leftarrow & w_0 - \eta \cdot \frac{\partial E}{\partial w_0}   \\
w_1 \leftarrow & w_1 - \eta \cdot \frac{\partial E}{\partial w_1}  \\
w_2 \leftarrow & w_2 - \eta \cdot \frac{\partial E}{\partial w_2} 
\end{aligned}
$$

:::

::: {.callout-note collapse="true" appearance="minimal"}
### Løsning til opgave 3

Beregn de opdaterede vægte
$$
\begin{aligned}
w_0 \leftarrow & 0.1 - 0.1 \cdot (-0.02454325869) \approx 0.1024543259   \\
w_1 \leftarrow & 0.1 - 0.1 \cdot 0.05202358001 \approx 0.09479764200  \\
w_2 \leftarrow & 0.1 - 0.1 \cdot (-0.0535258408) \approx 0.1053525841 
\end{aligned}
$$
:::

## Anden opdatering af vægtene
Overvej, om du kan strømline dine beregninger, evt. i Excel eller i dit CAS værktøj, så det bliver hurtigere at opdatere vægtene en gang mere på samme måde.

::: {.callout-note collapse="false" appearance="minimal"}
### Opgave 4: Opdater vægtene anden gang

* Beregn tabsfunktionen.
* Beregn de opdaterede vægte.

:::

Bemærk, at værdien af tabsfunktionen er blevet lidt mindre. Formålet er jo netop at minimere den gennem gradientnedstigning, så som regel bør værdien bliver mindre, hver gang vægtene opdateres.

::: {.callout-note collapse="true" appearance="minimal"}
### Løsning til opgave 4
$$
\begin{aligned}
E & \approx 0.3362680478 \\
w_0 & \approx 0.1045005370 \\
w_1 & \approx 0.08949754490 \\
w_2 & \approx 0.1086460194
\end{aligned}
$$

:::

## App til simple neurale netværk
Med [perceptron app'en](../apps/perceptron_app.qmd){target="_blank"} kan du lave de samme beregninger bare automatisk.

::: {.callout-note collapse="false" appearance="minimal"}
### Opgave 5: Afprøv perceptron app'en

* Lav et Excelark med feature- og targetværdierne.
* Indlæs data fra Excelarket i perceptron app'en.
* Vælg de korrekte værdier i felterne på app'en. Herunder skal feature-skalering være slået fra.
* Se om app'en giver samme resultater for tabsfunktionen og vægtene, som du selv fik efter 1 iteration og efter 2 iterationer.

:::

## Cross-entropy som tabsfunktion.
Du kan læse om *cross-entry* i [noten om tabsfunktion](../materialer/tabsfunktioner/tabsfunktioner.qmd#cross-entropy){target="_blank"}.

::: {.callout-note collapse="false" appearance="minimal"}
### (Ekstra) Opgave 6: Cross-entropy tabsfunktion 
* Gentag opgave 1-5 men med *cross-entropy* som tabsfunktion i stedet for *square-error*.

:::

NB: Ege skal have tilføjet en mulighed for at slå feature-skalering fra i appen, før det fungerer efter hensigten.
