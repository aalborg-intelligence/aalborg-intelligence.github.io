---
title: "Facit til forløb om opdatering af vægte i et simpelt neuralt netværk med to skjulte lag"
description-meta: ''
image: ""
categories:
---


```{r, include = FALSE}

# Definer sigmoid-funktionen
sigmoid <- function(x) {
  1 / (1 + exp(-x))
}

# Input og output data
X1 <- c(1,2,3)
X2 <- c(2,3,5)
t  <- c(0, 1, 0)

# Vægte og bias
k <- 0.5
r1 <- k; r2 <- k; r0 <- k
v1 <- k; v0 <- k
w1 <- k; w0 <- k

# Læringsrate
eta <- 0.1


  # Forløb fremad
  Y <- sigmoid(r1 * X1 + r2 * X2 + r0)
  Z <- sigmoid(v1 * Y + v0)
  o <- sigmoid(w1 * Z + w0)
  
  # Baglæns forløb (backpropagation)
  dw <- (t - o) * o * (1 - o)
  dv <- dw * w1 * Z * (1 - Z)
  dr <- dv * v1 * Y * (1 - Y)
  
  # Opdater vægtene og bias
  w0 <- w0 + eta * sum(dw)
  w1 <- w1 + eta * sum(dw * Z)

  v0 <- v0 + eta * sum(dv)  
  v1 <- v1 + eta * sum(dv * Y)

  r0 <- r0 + eta * sum(dr)
  r1 <- r1 + eta * sum(dr * X1)
  r2 <- r2 + eta * sum(dr * X2)

```  

::: {.callout-note collapse="true" appearance="minimal"}
### Facit til opgave 1
$y$-værdierne er

`r Y`

:::

::: {.callout-note collapse="true" appearance="minimal"}
### Facit til opgave 2
$z$-værdierne er 

`r Z`
:::

::: {.callout-note collapse="true" appearance="minimal"}
### Facit til opgave 3
$o$-værdierne er

`r o`
:::

::: {.callout-note collapse="true" appearance="minimal"}
### Facit til opgave 4
* $\delta_w$-værdierne er 

   `r dw`


* Summen 

   $\sum_{m=1}^3 \delta_w^{(m)} =$ `r sum(dw)`


* $w_0$-vægten opdateres til

   $w_{0}^{ny}=$ `r w0` 


* Summen 

   $\sum_{m=1}^{3} \delta_w^{(m)} \cdot z^{(m)} =$ `r sum(dw*Z)`


* $w_1$-vægten opdateres til

   $w_{1}^{ny}=$ `r w1` 
   
:::

::: {.callout-note collapse="true" appearance="minimal"}
### Facit til opgave 5

* $\delta_v$-værdierne er 
  
  `r dv`

* Summen 

   $\sum_{m=1}^{3} \delta_v^{(m)} =$ `r sum(dv)`

* $v_0$-vægten opdateres til
   
   $v_{0}^{ny}=$ `r v0` 

* Summen 
   
   $\sum_{m=1}^{3} \delta_v^{(m)}\cdot y^{(m)} =$ `r sum(dv*Y)`

* $v_1$-vægten opdateres til
   
   $v_{1}^{ny}=$ `r v1` 
   
:::

::: {.callout-note collapse="true" appearance="minimal"}
### Facit til opgave 6

* $\delta_r$-værdierne er 

   `r formatC(dr,format="f",digits=7)`

* Summen 

   $\sum_{m=1}^3 \delta_r^{(m)} =$ `r formatC(sum(dr),format="f",digits=7)`

* $r_0$-vægten opdateres til 

   $r_{0}^{ny}=$ `r r0` 

* Summen 

   $\sum_{m=1}^3 \delta_r^{(m)} \cdot x_1^{(m)} =$ `r formatC(sum(dr*X1),format="f",digits=7)`

* $r_1$-vægten opdateres til 
   
   $r_{1}^{ny}=$ `r r1`

* Summen 

   $\sum_{m=1}^3 \delta_r^{(m)} \cdot x_2^{(m)} =$ `r sum(dr*X2)`

* $r_2$-vægten opdateres til 
   
   $r_{2}^{ny}=$ `r r2`
:::


::: {.callout-note collapse="true" appearance="minimal"}
### Facit til opgave 7
Tabsfunktionen giver ca. $24.8$
:::

::: {.callout-note collapse="true" appearance="minimal"}
### Facit til opgave 8
Vurderingen af tabsfunktion er $24.99$, så $24.8$ fra opgave 7 er næppe godt.
:::

::: {.callout-note collapse="true" appearance="minimal"}
### Facit til opgave 9
Værdien af tabsfunktionen er faldet meget betydeligt til i nærheden af $2$.

Når grafen ikke ser pæn ud, er det nok fordi learning-rate er for stor, så opdateringerne "hopper" hen over minimum. Løsningen er at bruge en lavere learning rate.
:::

::: {.callout-note collapse="true" appearance="minimal"}
### Facit til opgave 10
Værdien af tabsfunktionen er faldet yderligere til i nærheden af $0.5$. Om den kan blive endnu lavere, vides naturligvis ikke.

Grafen ser også betydeligt pænere ud.
:::