---
title: "Del 3: Tekstgenerering med neurale netværk"
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

::: {.estimeret_tid}

Forventet tid ca. 60 min.

:::

{{< include ../space.qmd >}}


## Aktivitet 1 - Antal parametre i modellen {.aimat}

Læs det første afsnit i noten [Tekstgenerering med neurale netværk](../../materialer/sprogmodeller/tekstgenerering.qmd). 


::: {.callout-note collapse="false" appearance="minimal"}

### Opgave 1: Antal parametre i det neurale netværk

Vi betragter det kunstige neurale netværk med ét skjult lag, som skal bruges til tekstgenerering:

![](../../materialer/sprogmodeller/images/NN_tekstgenerering.png){width=50% fig-align='center'}

* Hvad angiver $m$, $d$ og $V$ i figuren?

* Undersøg, hvor mange ord der cirka er i det danske sprog.

Antag, at alle ord repræsenteres ved en 3-dimensional vektor og at $d=50$. 

* Hvor mange vægte indgår da i det neurale net?

* Hvis alle ord repræsenteres ved en 100-dimensional vektor, hvor mange vægte skal så estimeres?

* Undersøg hvor mange vægte (eller parametre, som de også kaldes) de store sprogmodeller har i dag (det præcise antal er en forretningshemmelighed, så du kan ikke finde det præcise svar!).

:::


{{< include ../space.qmd >}}

::: {.callout-note collapse="false" appearance="minimal"}

### Opgave 2 -  Et lille neuralt netværk {.aimat}

Vi forestiller os, at vi har trænet et lille neuralt netværk, der kan beregne sandsynligheden for næste ord baseret på de to foregående ord. For at gøre eksemplet simpelt tillader vi kun to mulige næste ord, nemlig "spinder" og "danser". Inputordene respræsenteres ved to-dimensionale vektorer. Netværket har følgende struktur, hvor outputtet $z_1$ er sandsynligheden for "spinder", og $z_2$ er sandsynligheden for "danser":

![](images/opgave_nn1.png){width=75% fig-align='center'}

Vægtene, der indgår, i første lag er 

 |$w_{1,0}$ | $w_{1,1}$  |$w_{1,2}$ |$w_{1,3}$ |$w_{1,4}$ | $w_{2,0}$ | $w_{2,1}$  |$w_{2,2}$ |$w_{2,3}$ |$w_{2,4}$ | 
   |:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
   | 1 | 0  | 1 | 1 | 5  | 2  | 4 | 2 | -1 | 3 |
: {.bordered}

Vægtene i andet lag er 

 |$u_{1,0}$ | $u_{1,1}$  |$u_{1,2}$ |$u_{2,0}$ |$u_{2,1}$ | $u_{2,2}$ |  
   |:---:|:---:|:---:|:---:|:---:|:---:|
   | 0.5 | 1 | 2 | 0.2 | 0 | -4 | 
: {.bordered}


Vægtene er delvist illustreret i figuren her:

![](images/opgave_nn2.png){width=75% fig-align='center'}


Lad os sige, at vi som input har sætningen "En kat" og skal beregne sandsynligheden for næste ord. Ordene "en" og "kat" har vektorrepræsentationerne
$$\vec{v}_{\text{en}} = \begin{pmatrix} 1\\-2\end{pmatrix}, \qquad \vec{v}_{\text{kat}} = \begin{pmatrix} 3\\0 \end{pmatrix}$$
Vi vil bruge det neurale netværk til at beregne sandsynligheden for næste ord. 

- Beregn den 4-dimensionale vektor $\vec{x}$, der skal bruges som input til netværket, ved at sætte vektorerne $\vec{v}_{\text{en}}$ og $\vec{v}_{\text{kat}}$ oven på hinanden.

- Beregn $h_1$ og $h_2$ ved formlerne 
 $$
 \begin{aligned}
 &h_1= f(w_{1,0} + w_{1,1}x_1 + w_{1,2}x_2 + w_{1,3}x_3 + w_{1,4 } x_4)\\
 &h_2= f(w_{2,0} + w_{2,1}x_1 + w_{2,2}x_2 + w_{2,3}x_3 + w_{2,4} x_4)
 \end{aligned}
 $$
hvor $f(x)=\frac{1}{1+e^{-x}}$ er den logistiske funktion.

- Beregn $y_1$ og $y_2$ ved hjælp af formlerne
 $$
 \begin{aligned}
 &y_1= u_{1,0} + u_{1,1}h_1 + u_{1,2}h_2 \\
 &y_2= u_{2,0} + u_{2,1}h_1 + u_{2,2}h_2 
 \end{aligned}
 $$
- Anvend softmax på $y_1$ og $y_2$ for at beregne $z_1$ og $z_2$. Det vil sige, beregn
$$
\begin{aligned}
z_1 &= \frac{e^{y_1}}{e^{y_1} + e^{y_2}}\\
z_2 &= \frac{e^{y_2}}{e^{y_1} + e^{y_2}}
\end{aligned}
$$
- Hvilket af ordene er det mest sandsynlige næste ord?

:::

## Aktivitet 3 -  Træning af netværk {.aimat}

Læs afsnittet [Træning af netværk](../../materialer/sprogmodeller/tekstgenerering.qmd#træning-af-netværket). 


::: {.callout-note collapse="false" appearance="minimal"}

### Opgave 3: Cross-entropy

Vi forstiller os, at vi har ordnet ordene i vores ordforråd på denne måde:

$$
\begin{pmatrix}
\vdots
\\
\textrm{solen}
\\
\textrm{månen}
\\
\textrm{himlen}
\\
\vdots
\end{pmatrix}
$$

Et sted i vores tekstkorpus står der 

::: {.llm_saetninger}
\"jeg ser på månen\"
:::

og en række i træningsdata vil derfor være

| Input 1 | Input 2 | Input 3 | Target |
|:---:|:---:|:---:|:---:|
| $\vdots$ | $\vdots$ | $\vdots$ | $\vdots$ |
| jeg | ser | på | månen |
| $\vdots$ | $\vdots$ | $\vdots$ | $\vdots$ |

Targetvektoren $\vec t$ for denne række er da

$$
\vec t = 
\begin{pmatrix}
\vdots
\\
0
\\
1
\\
0
\\
\vdots
\end{pmatrix}
$$
hvor der står $0$ på alle de øvrige pladser.

Vi har trænet to netværk, som for dette træningseksempel har givet følgende outputvektor (på alle andre koordinater i vektoren står der $0$)

$$
\textrm{Netværk 1:} \quad \vec z =
\begin{pmatrix}
\vdots
\\
P(\text{solen } |\text{ "jeg ser på" })
\\
P(\text{månen } |\text{ "jeg ser på" })
\\
P(\text{himlen } |\text{ "jeg ser på" })
\\
\vdots
\end{pmatrix} =
\begin{pmatrix}
\vdots
\\
0.25
\\
0.61
\\
0.14
\\
\vdots
\end{pmatrix}
$$

og

$$
\textrm{Netværk 2:} \quad \vec z =
\begin{pmatrix}
\vdots
\\
P(\text{solen } |\text{ "jeg ser på" })
\\
P(\text{månen } |\text{ "jeg ser på" })
\\
P(\text{himlen } |\text{ "jeg ser på" })
\\
\vdots
\end{pmatrix} =
\begin{pmatrix}
\vdots
\\
0.32
\\
0.59
\\
0.29
\\
\vdots
\end{pmatrix}
$$

* Vis, at alle koordinater i $\vec z$ kan fortolkes som sandsynligheder, og at summen af sandsynlighederne er 1.

* Udregn bidraget til *cross-entropy* tabsfunktionen $CE(\vec z, \vec t)$ for begge netværk.

* Hvilket netværk ville du på baggrund af dette ene træningseksempel vælge? Stemmer det overens med sandsynlighederne?

::::

{{< include ../space.qmd >}}


## Aktivitet 3 -  Tekstgenerering {.aimat}

Læs afsnittet [Tekstgenerering](../../materialer/sprogmodeller/tekstgenerering.qmd#tekstgenerering). 


::: {.callout-note collapse="false" appearance="minimal"}

### Opgave 4: Prædiktion af næste ord

En opgave hvor et netværk er trænet på det lille tekstkorpus fra Simple-noten:

::: {.llm_saetninger}
\" En hund løber efter en kat. \
Løber en hund efter en kat? \
En kat løber ikke efter en hund. \
Efter en kat løber en hund.\"
:::

og hvor elever så igen starter med \"En hund\" og skal danne en sætning ud fra det... Eller måske noget sjovere...!

:::

{{< include ../space.qmd >}}

[$\leftarrow$ Forrige](sprogmodeller_del2.qmd){.prev}
[Næste $\rightarrow$](sprogmodeller_del4.qmd){.next}

