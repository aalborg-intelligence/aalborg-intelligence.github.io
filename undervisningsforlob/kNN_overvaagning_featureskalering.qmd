---
title: "Feature-skalering på data fra overvågningsforløb"
description: 'I forlængelse af forløbet om overvågning ses her på begrebet feature-skalering.'
image: "kNN_forlob_overvaagning_filer/images/feature_skalering.jpg"
categories:
  - B-niveau
  - Kort
---

::: {.callout-caution collapse="true" appearance="minimal"}
### Forudsætninger og tidsforbrug

+ Forløbet kræver, at man har gennemgået forløbet [Overvågning i Monitorbian](kNN_forlob_overvaagning.qmd).
+ Stikprøvespredning.


**Tidsforbrug:** Ca. 90 minutter.

:::

::: {.purpose}

### Formål

I dette forløb undersøges begrebet **feature-skalering** med brug af data fra forløbet om overvågning i Monitorbian.

Man kan læse mere i [noten om feature-skalering](../materialer/afstande/feature_scaling.qmd){target="_blank"}, men det er ikke en forudsætning for at arbejde med dette forløb.

:::

/
{{< video https://youtu.be/7aZHFg12Gbs >}}

## De konkrete features

I datasættet er fodarealerne målt i $cm^2$ med værdier fra 138 til 334, mens højderne er målt i $cm$ med værdier fra 62 til 155. Så variationsbredden i fodarealer uden enhed er ca. 200, mens variationsbredden i højder uden enhed er ca. 100. Så når vi med *kNN* bestemmer nærmeste naboer, vil højden ofte betyde mere end fodarealet, da højderne ligger tættere på hinanden. 

::: {.callout-note collapse="false" appearance="minimal"}
### Opgave 1: Illustration af de konkrete features

Datasæt: [Træningsdata](kNN_forlob_overvaagning_filer/data/Træningsdata.xlsx).

* Lav et punktplot, hvor datapunkterne for **Fedtmule** er røde, datapunkterne for **Anders And** er blå, og der desuden er et gråt punkt i $(240 \ cm^2, 88 \  cm)$. Dette kan f.eks. gøres ret let i GeoGebra, se evt. [denne video](https://www.youtube.com/watch?v=xdkEqfM1nsQ){target="_blank"} . Hvis du hellere vil lave i det eget CAS-værktøj, men ikke helt ved hvordan, må du spørge din lærer.
* Vurder, hvilke $6$ punkter, der ligger tættest på det grå punkt, eventuelt ved at tilføje en cirkel med centrum i det grå punkt med en radius, så $6$ af de øvrige punkter ligger i cirklen.

:::

## Enheden på data ændres

Men hvad ville der ske, hvis vi anvendte en anden enhed for eksempel for højderne. Hvad hvis vi i stedet målte højderne i $mm$? Så bliver variationsbredden i højderne ca. $1000$, mens variationsbredden for fodarealerne stadig er ca. $200$. Så vi må nu forvente, at fodarealerne betyder mere end højderne, når vi bestemmer nærmeste naboer, da fodarealerne nu ligger tættere på hinanden end højderne. Det skal vi se på i de følgende opgaver.

::: {.callout-note collapse="false" appearance="minimal"}
### Opgave 2: Illustration med højder i $mm$

* Lav samme punktplot som før, men nu skal alle $y$-koordinaterne være 10 gange så store, da de skal regnes i $mm$ (det gælder også det grå punkt).
* Vurder igen, hvilke $6$ punkter, der ligger tættest på det grå punkt, eventuelt ved hjælp af en cirkel.
* Diskuter og vurder, om det fik den betydning, at fodarealerne nu betyder mere end før i forhold til *kNN*.

:::

Det er naturligvis ikke praktisk, hvis den valgte enhed på data har betydning for, hvilke punkter der er tættest på hinanden.


## Metode til at give begge features samme vægt

Som du måske har gættet, vil det bedste nok være, at fodareal og højde betød lige meget.

Det gøres i to trin. Først \"flyttes\" data, så både værdierne for fodarealer og værdierne for højder ligger omkring $0$. På den måde vil værdier under gennemsnittet blive negative og værdier over gennemsnittet positive.

::: {.callout-note collapse="false" appearance="minimal"}
### Opgave 3: Data centreres omkring $(0, 0)$

* Beregn middelværdien af fodarealerne fra de 20 datapunkter.
* Træk middelværdien fra værdierne for fodareal for alle 20 datapunkter og det grå punkt.
* Beregn tilsvarende middelværdien af højderne fra de 20 datapunkter.
* Træk middelværdien fra værdierne for højde for alle 20 datapunkter og det grå punkt.

:::

Dernæst gøres variationsbredderne nogenlunde lige store. Man kunne dividere alle værdierne for fodarealer med variationsbredden for fodarealerne, og tilsvarende for højderne. Derved ville de to features begge få en variationsbredde på $1$, og dermed være ens. Man vælger dog at gøre noget lidt anderledes, blandt andet fordi variationsbredden kun afhænger af to af punkterne og ikke dem alle. I stedet for at dividere med variationsbredden, divideres med spredningen, hvorefter de fleste dataværdier kommer til at ligge mellem $-2$ og $2$ for begge features.

::: {.callout-note collapse="false" appearance="minimal"}
### Opgave 4: Variationsbredden gøres nogenlunde ens

* Beregn stikprøvespredning af fodarealerne fra de 20 datapunkter.
* Divider de justerede fodarealer fra opgave 3 med spredningen, også værdien for det grå punkt.
* Beregn tilsvarende stikprøvespredningen af højderne fra de 20 datapunkter.
* Divider de justerede højder fra opgave 3 med spredningen, også værdien for det grå punkt.

:::

Vi skal have set, hvordan det ser ud.

::: {.callout-note collapse="false" appearance="minimal"}
### Opgave 5: Illustration med justerede værdier for begge features

* Lav samme punktplot som tidligere, men nu med de justerede værdier.
* Vurder igen, hvilke $6$ punkter, der ligger tættest på det grå punkt, eventuelt ved hjælp af en cirkel.
* Se, om værdierne for begge features nogenlunde ligger mellem $-2$ og $2$, som forventet.
:::

Denne metode er en kendt standard til at sørge for, at begge (eller alle, hvis der er flere) features vægtes lige meget, så man undgår at den valgte enhed afgør, om den ene eller anden anden feature bliver dominerende.

For eksempel bruger programmet Orange, som du anvendte i forløbet [Overvågning i Monitorbian](kNN_forlob_overvaagning.qmd) denne form for feature-skalering.

::: {.callout-note collapse="false" appearance="minimal"}
### Opgave 6: Ekstra

* Overvej, om centreringen i opgave 3 er nødvendig.
* Overvej, hvordan punkter og cirkel vil placere sig uden justeringen i opgave 3.
* Lav illustrationen uden justeringen omkring $(0,0)$, men stadig med divisionen med spredningen for hver feature.
:::

::: {.callout-tip collapse="true" appearance="minimal"}
### Åben først efter opgave 6
Så justeringen omkring $(0,0)$ er faktisk ikke nødvendig, men indgår alligevel ofte i feature-skalering, så data som standard ligger mellem -2 og 2.
:::


