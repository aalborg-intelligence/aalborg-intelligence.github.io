[
  {
    "objectID": "apps/perceptron_app.html",
    "href": "apps/perceptron_app.html",
    "title": "ADALINE perceptron app",
    "section": "",
    "text": "Gør følgende\n\nUpload data (.xlsx eller .csv format).\nVælg den kolonne som angiver targetværdien (skal være kodet +/- 1).\nVælg de forklarende variable (feature-/input-værdier).\nÆndr eventuelt på startvægte, learning rate, stopkriterium og/eller det maksimale iterationer – eller behold default værdierne.\nVælg antal af fold i \\(k\\)-folds krydsvalidering (default er 5).\nTryk på \"Kør ADALINE!\"\n\n\n\nOutput fra algoritmen\n\nInformation om hvad du har valgt som features og targetværdi.\nVærdien af de estimerede vægte.\nEn figur, som viser, hvordan vægtene har ændret sig for hver iteration. Hvis graferne for alle vægtene er fladet ud, er det tegn på, at algoritmen er konvergeret.\nResultatet af krydsvalidering her angivet som klassifikationsnøjagtigheden (den gennemsnitlige andel som er klassificeret korrekt ved \\(k\\)-folds krydsvalidering).\nTil sidst en tabel med data."
  },
  {
    "objectID": "undervisningsforlob.html",
    "href": "undervisningsforlob.html",
    "title": "Undervisningsforløb",
    "section": "",
    "text": "Forskellige undervisningsforløb til matematik i gymnasiet, som inddrager AI. Der findes forløb til både A-, B- og C-niveau.\n\n\n\n\n\n\n\n\n\n\nHvem ligner du mest?\n\n\n\nC-niveau\n\n\nKort\n\n\n\n\n\n\n\nEvnen til at skelne mellem forskellige kategorier er helt central for os som mennesker. Vi kan langt oftest kende forskel på et æble og en pære, på en cykel og en knallert eller på om en person er en kvinde eller en mand. Men hvordan får man en computer til at gøre det samme?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAktiveringsfunktioner\n\n\n\nA-niveau\n\n\nKort\n\n\n\n\n\n\n\nI opbygningen af kunstige neurale netværk er aktiveringsfunktioner helt centrale. Og aktiveringsfunktioner skal differentieres – det handler dette forløb om.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOvervågning i Monitorbian\n\n\n\nC-niveau\n\n\nKort\n\n\n\n\n\n\n\nNogle lande overvåger deres borgere. Men hvordan gør man mon det? I dette forløb bliver I ansat af efterretningstjenesten i landet Monitorbian for at hjælpe dem med at overvåge deres borgere.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeature-skalering på data fra overvågningsforløb\n\n\n\nB-niveau\n\n\nKort\n\n\n\n\n\n\n\nI forlængelse af forløbet om overvågning ses her på begrebet feature-skalering.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScreeningsprogrammer\n\n\n\nA-niveau\n\n\nBioteknologi\n\n\nKort\n\n\n\n\n\n\n\nKan man lave screeningsprogrammer for sygdomme baseret på genetiske markører med brug af AI? Det undersøger vi i dette forløb, som med fordel kan foregå i et samarbejde med bioteknologi.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpklar et mord!\n\n\n\nA-niveau\n\n\nKort\n\n\n\n\n\n\n\nDer er blevet begået et mord på skolen i nat. Det er jeres opgave at opklare det!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAI og rødder i andengradspolynomier\n\n\n\nB-niveau\n\n\nKort\n\n\n\n\n\n\n\nEt andengradspolynomium kan have enten ingen, én eller to rødder. I skal her lære om, hvordan man kan bruge kunstig intelligens til at bestemme antallet af rødder i et andengradspolynomium.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverfitting og krydsvalidering med polynomiel regression\n\n\n\nB-niveau\n\n\nKort\n\n\n\n\n\n\n\nIntroduktion til begreberne overfitting og krydsvalidering vha. polynomiel regression. Som eksempel ses på en fiktiv sammenhæng mellem antal biografbesøg og antal venner på de sociale medier.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLogistisk regression\n\n\n\nA-niveau\n\n\nLangt\n\n\n\n\n\n\n\nEt længere forløb om logistisk regression som supplerende stof på A-niveau inklusiv spørgsmål til mundtlig eksamen\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpdatering af vægte i en kunstig neuron\n\n\n\nA-niveau\n\n\nKort\n\n\n\n\n\n\n\nEn øvelse i at opdatere vægtene i en kunstig neuron.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpdatering af vægte i et simpelt neuralt netværk med to skjulte lag\n\n\n\nA-niveau\n\n\nKort\n\n\n\n\n\n\n\nEn øvelse i at opdatere vægtene i et simpelt neuralt netværk med to skjulte lag.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpdatering af vægte i et simpelt neuralt netværk med ét skjult lag (men med cross-entropy som tabsfunktion)\n\n\n\nA-niveau\n\n\nKort\n\n\n\n\n\n\n\nEn øvelse i at opdatere vægtene i et neuralt netværk med ét skjult lag med cross-entropy som tabsfunktion.\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "materialer.html",
    "href": "materialer.html",
    "title": "Materialer",
    "section": "",
    "text": "Til en del af materialerne findes en række videoer, hvor teorien forklares. Der er linket til de relevante videoer under de respektive materialer, men en samlet liste findes også her.\n\n\n\n\n\n\n\n\n\n\nPerceptroner\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKunstige neuroner\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimple kunstige neurale netværk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKunstige neurale netværk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLogistisk regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTabsfunktioner\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverfitting, modeludvælgelse og krydsvalidering\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSensitivitet, specificitet, ROC-kurver og AUC\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFunktioner af flere variable\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGradientnedstigning\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNaiv Bayes klassifier\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClustering med K-means\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfstande og feature-skalering\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "videoer.html",
    "href": "videoer.html",
    "title": "Videoer",
    "section": "",
    "text": "Herunder finder du links til playlister om nogle af de emner, som vi har behandlet under materialer."
  },
  {
    "objectID": "videoer.html#kunstige-neurale-netværk",
    "href": "videoer.html#kunstige-neurale-netværk",
    "title": "Videoer",
    "section": "Kunstige neurale netværk",
    "text": "Kunstige neurale netværk"
  },
  {
    "objectID": "videoer.html#perceptroner",
    "href": "videoer.html#perceptroner",
    "title": "Videoer",
    "section": "Perceptroner",
    "text": "Perceptroner"
  },
  {
    "objectID": "videoer.html#logistisk-regression",
    "href": "videoer.html#logistisk-regression",
    "title": "Videoer",
    "section": "Logistisk regression",
    "text": "Logistisk regression"
  },
  {
    "objectID": "videoer.html#overfitting-modeludvælgelse-og-krydsvalidering",
    "href": "videoer.html#overfitting-modeludvælgelse-og-krydsvalidering",
    "title": "Videoer",
    "section": "Overfitting, modeludvælgelse og krydsvalidering",
    "text": "Overfitting, modeludvælgelse og krydsvalidering"
  },
  {
    "objectID": "referencer.html",
    "href": "referencer.html",
    "title": "Referencer",
    "section": "",
    "text": "Diverse referencer til andre AI materialer.\n\nWebsider\n\nDTU har lavet et undervisningsmateriale, som handler om, hvordan kunstig intelligens kan bruges til at genkende lyde: Regn lyden ud\nOnline kursus hvor man lærer helt grundlæggende om kunstig intelligens (men ikke så matematisk som materialet her på siden): Elements of AI\nDanske Gymnasier har afholdt en konference om betydningen af AI og ChatGPT. Her på siden kan man genhøre oplæg fra blandt andet Vincent Hendricks, Stefan Herman m.fl.\nDen Store Danske har skrevet lidt om, hvad kunstig intelligens er - herunder også et historisk oprids af udviklingen inden for kunstig intelligens. Kunstig intelligens\nPå siden dataekspeditioner findes en række forløb hvoraf flere omhandler AI.\n\n\n\nVideoer\n\n3Blue1Brown har lavet en række fine videoer, som forklarer, hvad et kunstigt neuralt netværk er, og hvordan det trænes (på engelsk): Neural networks\n\n\n\nBøger\n\nOnline bog om kunstige neurale netværk af Michael Nielsen (på engelsk): Neural networks and deep learning"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Om os",
    "section": "",
    "text": "Projektet Aalborg Intelligence, som er finansieret af Novo Nordisk Fonden, er forankret på Institut for Matematiske Fag på Aalborg Universitet (AAU), og inkluderer en repræsentant fra de fem STX-gymnasier i Aalborg."
  },
  {
    "objectID": "about.html#gymnasielærere",
    "href": "about.html#gymnasielærere",
    "title": "Om os",
    "section": "Gymnasielærere",
    "text": "Gymnasielærere\n\nMalene Cramer Engebjerg (Aalborghus Gymnasium)\nAllan Frendrup (Nørresundby Gymnasium)\nNikolaj Hess-Nielsen (Aalborg Katedralskole)\nMette Kristensen (Hasseris Gymnasium)\nJan B. Sørensen (Aalborg City Gymnasium)"
  },
  {
    "objectID": "about.html#kontakt",
    "href": "about.html#kontakt",
    "title": "Om os",
    "section": "Kontakt",
    "text": "Kontakt\nEmail: rubak@math.aau.dk"
  },
  {
    "objectID": "materialer/sprogmodeller/word2vec-bog.html",
    "href": "materialer/sprogmodeller/word2vec-bog.html",
    "title": "Word2vec",
    "section": "",
    "text": "https://aimat.dk/materialer/sprogmodeller/data/bog.txt"
  },
  {
    "objectID": "materialer/sprogmodeller/word2vec-bog.html#sætningerne-der-bruges-til-at-estimere-vektorerne",
    "href": "materialer/sprogmodeller/word2vec-bog.html#sætningerne-der-bruges-til-at-estimere-vektorerne",
    "title": "Word2vec",
    "section": "",
    "text": "https://aimat.dk/materialer/sprogmodeller/data/bog.txt"
  },
  {
    "objectID": "materialer/sprogmodeller/word2vec-bog.html#vægte-når-ordet-er-input",
    "href": "materialer/sprogmodeller/word2vec-bog.html#vægte-når-ordet-er-input",
    "title": "Word2vec",
    "section": "Vægte når ordet er input",
    "text": "Vægte når ordet er input\n\n\n\n\n\n\nV1\nV2\nV3\n\n\n\n\n.\n7.82\n0.93\n-29.53\n\n\næsel\n-0.36\n1.52\n1.10\n\n\nAnne\n-0.82\n19.57\n8.59\n\n\nbil\n-7.71\n-1.06\n11.59\n\n\nblå\n-2.06\n-1.27\n-0.12\n\n\nblåt\n-0.03\n0.56\n0.31\n\n\nBo\n-0.15\n7.67\n3.02\n\n\ncykel\n-3.10\n-0.04\n4.67\n\n\nen\n-2.61\n-2.68\n4.06\n\n\net\n-0.17\n0.64\n0.80\n\n\nEva\n-1.30\n32.95\n14.89\n\n\nfår\n-12.73\n2.75\n-23.80\n\n\ngrøn\n-1.11\n-0.67\n-0.06\n\n\ngrønt\n-0.06\n0.52\n0.31\n\n\nhar\n-4.01\n1.15\n-2.60\n\n\nhest\n-2.60\n-0.06\n4.00\n\n\nhus\n-0.36\n1.06\n1.06\n\n\nIb\n-0.67\n14.13\n6.50\n\n\nIda\n-0.15\n10.37\n3.98\n\n\nKim\n-0.24\n18.71\n6.97\n\n\nko\n-6.42\n0.17\n9.84\n\n\nmarsvin\n-0.36\n1.24\n1.06\n\n\nMia\n-0.44\n8.87\n4.26\n\n\nog\n-0.45\n5.83\n-3.38\n\n\nOle\n-0.42\n11.12\n4.75\n\n\nser\n-7.18\n0.10\n-5.49\n\n\nskur\n-0.71\n1.51\n1.94"
  },
  {
    "objectID": "materialer/sprogmodeller/word2vec-bog.html#vægte-når-ordet-er-kontekst",
    "href": "materialer/sprogmodeller/word2vec-bog.html#vægte-når-ordet-er-kontekst",
    "title": "Word2vec",
    "section": "Vægte når ordet er kontekst",
    "text": "Vægte når ordet er kontekst\n\n\n\n\n\n\nV1\nV2\nV3\n\n\n\n\n.\n2.61\n0.89\n2.09\n\n\næsel\n22.86\n-2.22\n5.80\n\n\nAnne\n4.57\n-3.27\n-10.31\n\n\nbil\n3.86\n-10.41\n0.52\n\n\nblå\n1.27\n-3.92\n1.20\n\n\nblåt\n13.54\n-2.68\n6.40\n\n\nBo\n0.37\n7.24\n-23.01\n\n\ncykel\n2.03\n-7.16\n-1.51\n\n\nen\n-2.81\n-2.66\n-0.35\n\n\net\n-0.28\n-0.20\n-0.01\n\n\nEva\n22.73\n10.46\n-32.10\n\n\nfår\n3.44\n-0.53\n2.10\n\n\ngrøn\n5.89\n-8.26\n4.35\n\n\ngrønt\n1.67\n-0.44\n0.56\n\n\nhar\n6.25\n-1.08\n3.67\n\n\nhest\n8.51\n-16.40\n0.85\n\n\nhus\n7.57\n-0.97\n1.84\n\n\nIb\n7.59\n4.21\n-11.83\n\n\nIda\n3.20\n2.93\n-37.90\n\n\nKim\n-0.76\n7.23\n-25.06\n\n\nko\n1.52\n-10.04\n-0.43\n\n\nmarsvin\n4.62\n-0.56\n0.67\n\n\nMia\n7.75\n4.04\n-12.33\n\n\nog\n27.00\n-1.72\n7.37\n\n\nOle\n4.31\n7.96\n-21.83\n\n\nser\n5.39\n-0.96\n3.27\n\n\nskur\n15.97\n-1.56\n4.00"
  },
  {
    "objectID": "materialer/sprogmodeller/word2vec.html",
    "href": "materialer/sprogmodeller/word2vec.html",
    "title": "Word2vec",
    "section": "",
    "text": "Lad os se på en situation, hvor vi gerne vil kunne gætte næste ord i en sætning. Lad os sige, at vi har sætningen \\[\n\\text{\"Min hund har en blød ---\"}\n\\] og vil gætte næste ord. Hvis vi har en stor mængde tekst til rådighed, et såkaldt tekstkorpus, kan vi selvfølgelig lede efter ordsekvensen \"Min hund har en blød\" og se hvilket ord, der oftest kommer efter, som beskrevet i noten om simple sprogmodeller. Men hvis sekvensen ikke forekommer i vores korpus, så har vi et problem. I stedet kunne vi lede efter en sætning med en betydning, der minder om \"Min hund har en blød\" og se, hvad der kommer efter den. Men hvordan får vi en computer til at forstå betydningen af ord?\nDen simpleste måde at repræsentere et ord på i en computer ville være ved at nummerere alle ordene i det danske sprog fra 1 til \\(V\\), hvor \\(V\\) er det samlede antal ord. Nummeret på et ord giver dog ikke megen information om ordets betydning.\nEn anden nærliggende idé kunne være at repræsentere et ord ved bogstaverne i ordet. For at en computer skal kunne forstå det, kunne man give hvert bogstav et tal ud fra bogstavets nummer i alfabetet. Så ville \"kat\" blive til \\((11,1,20)\\) og \"hund\" til \\((8,21,14,4)\\). Stavemåden fortæller dog heller ikke meget om betydningen af et ord. Ordet \"mund\" staves næsten lige som \"hund\", men har en helt anden betydning. Omvendt betyder ordet \"vovse\" næsten det samme som \"hund\", men staves helt anderledes.\nI stedet vil vi gerne repræsentere hvert ord med en vektor. Idéen er, at ord, hvis betydning ligner hinanden, skal repræsenteres med vektorer, der peger i nogenlunde samme retning og har nogenlunde samme længde, som illustreret på figur 1.\nI kender vektorer i 2 eller 3 dimensioner og ved, at de kan skrives på formen \\[\n\\begin{pmatrix}\na_1\\\\a_2\\end{pmatrix}\\text{ og } \\begin{pmatrix} a_1\\\\a_2 \\\\a_3\n\\end{pmatrix}\n\\] hvor \\(a_1, a_2\\) og (eventuelt) \\(a_3\\) er reelle tal, der kaldes vektorens koordinater. Tre koordinater er dog ikke nok til at indfange betydningen af alle ord i sproget. Derfor bruger man i stedet en \\(m\\)-dimensional vektor, som man kan tænke på som en liste af \\(m\\) koordinater \\[\n\\begin{pmatrix}\na_1\\\\a_2\\\\a_3\\\\ \\vdots \\\\ a_m\n\\end{pmatrix}\n\\] hvor \\(a_1,a_2,a_3,\\ldots,a_m\\) er reelle tal. I praksis vælger man \\(m\\) stort, for eksempel \\(m=100\\). Man kan regne med \\(m\\)-dimensionale vektorer, lige som man gør i to eller tre dimensioner. Vi kommer for eksempel til at se, hvordan man kan finde skalarprodukter. Til gengæld har man ikke mulighed for at visualisere en \\(m\\)-dimensional vektor som en pil i et koordinatsystem, men det har vi heldigvis heller ikke brug for.\nI denne note ser vi på algoritmen Word2Vec som et eksempel på, hvordan man kan oversætte ord til vektorer, der repræsenterer ordenes betydning. Mere præcist kigger vi på en version af algoritmen, der hedder skip-gram. Word2Vec blev opfundet af en gruppe medarbejdere hos Google i 2013. I dag bruges diverse forfininger af algoritmen i mange store sprogmodeller."
  },
  {
    "objectID": "materialer/sprogmodeller/word2vec.html#betydning-og-kontekst",
    "href": "materialer/sprogmodeller/word2vec.html#betydning-og-kontekst",
    "title": "Word2vec",
    "section": "Betydning og kontekst",
    "text": "Betydning og kontekst\nHvilke egenskaber skal de vektorer, der repræsenterer ord, så have? Jo, idéen er, at vektorerne skal indfange betydningen af et ord i den forstand, at ord, hvis betydning minder om hinanden, svarer til vektorer, der ligner hinanden. Hvad vi forstår ved, at vektorer ligner hinanden, det kommer vi tilbage til. Men hvordan ved vi, om to ords betydning minder om hinanden?\nSprogteoretikere, som for eksempel den danske Louis Hjelmslev (1899-1965), har fundet ud af, at vi forstår betydningen af et ord ud fra, hvilke sproglige sammenhænge det optræder i, når man kigger i rigtig mange dokumenter. Ordet “kælk” forekommer for eksempel ofte i nærheden af ord som “sne”, “leg” og “bakke”. Det giver os en idé om betydningen. Den sproglige sammenhæng, et ord indgår i, kaldes også en kontekst. Når vi skal forstå et ord med flere betydninger, kigger vi også på konteksten. Vi forstår for eksempel betydningen af ordet \"marsvin\" forskelligt alt efter, om ordet \"fisk\" eller ordet \"mælkebøtte\" optræder i nærheden af det. Det vil altså sige:\n\nBetydningen af et ord er bestemt af den kontekst, ordet indgår i.\n\n\n\nTo ord, der betyder næsten det samme, vil ofte optræde i samme kontekst. Ordene \"hund\" og \"kat\" er for eksempel forskellige, men de vil ofte optræde i sammenhænge, der ligner hinanden. Se bare på sætningerne \\[\n\\text{\"Min --- har spist af sin madskål\"}\n\\] og \\[\n\\text{\"Sikken en blød pels, din --- har\"}\n\\] Her ville der kunne stå \"hund\" eller \"kat\", men nok ikke \"kælk\" eller \"badedragt\". Betydningen af ordene \"hund\" og \"kat\" er tættere på hinanden end betydningen af \"hund\" og \"kælk\". På den anden side kunne der ikke stå \"hund\" i sætningen \\[\n\\text{\"Den lille --- har hvide knurhår\"}\n\\] mens både \"kat\" og \"mis\" ville passe ind. Ordene \"kat\" og \"hund\" er altså tætte på hinanden, men ikke så tætte som \"kat\" og \"mis\".\nVi ville jo gerne lave vores vektorer, således at ord, hvis betydning ligner hinanden, svarer til vektorer, der ligner hinanden. Mere præcist vil vi lave dem, således at ord, der ofte har samme kontekst, svarer til vektorer, der ligner hinanden. Vi vil derfor gerne have, at vektorerne for \"hund\" og \"kat\" minder mere om hinanden end vektorerne for \"hund\" og \"kælk\", men ikke så meget som \"kat\" og \"mis\". I figur 1 ses et eksempel på, hvordan det kunne se ud."
  },
  {
    "objectID": "materialer/sprogmodeller/word2vec.html#træningsdata",
    "href": "materialer/sprogmodeller/word2vec.html#træningsdata",
    "title": "Word2vec",
    "section": "Træningsdata",
    "text": "Træningsdata\nVi har altså brug for at vide, hvilken kontekst ordene indgår i. For at lære, hvilken kontekst et ord forekommer i, tager vi udgangspunkt i et stort tilgængeligt tekstkorpus. Vi kalder dette korpus for vores træningsdata.\nVed konteksten til et ord vil vi her forstå de ord, der står umiddelbart før og efter ordet. Mere præcist vælger vi et vindue, lad os sige på fem ord, hvor ordet i midten er det, vi gerne vil kende betydningen af. Vi vil kalde dette for inputordet. De to første ord og de to sidste ord i vinduet er inputordets kontekstord. Se for eksempel på sætningen\n\\[\n\\boxed{\\textrm{ Den sorte }\\textbf{hund} \\textrm{ logrer med }} \\textrm{ halen}\n\\] Boksen angiver vores 5-ords vindue. Det midterste ord \"hund\" er vores inputord, ordene \"Den\", \"sorte\", \"logrer\" og \"med\" er kontekstord til \"hund\".\nVi starter med at placere vinduet omkring det første ord i vores datasæt og noterer dets fire kontekstord (hvoraf de to vil være blanke). Vi flytter nu vinduet mod højre et ord ad gangen, og hver gang noterer vi inputordet og dets fire kontekstord. Vi gør det for al teksten i vores træningsdata og samler informationen i et datasæt som vist i tabel 2. Hver række i tabellen består af et inputord og et af dets kontekstord.1\n1 Når man vil gætte det næste ord i en sætning, har man selvfølgelig kun lov til at bruge de ord, der kommer før ordet. Det er dog ikke det, vi er ude på, når vi laver Word2Vec. Vi er ude på at forstå, hvordan et ord forholder sig til dets kontekst, altså de omkringstående ord. Derfor er der ikke noget problem i, at vinduet både indeholder ord før og efter inputordet.\n\n\n\n\n\nInput\nKontekst\n\n\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\nsorte\n\n\n\nsorte\nDen\n\n\nsorte\nhund\n\n\nsorte\nlogrer\n\n\nhund\nDen\n\n\nhund\nsorte\n\n\nhund\nlogrer\n\n\nhund\nmed\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\n\n\nTabel 1: Par af input- og kontekstord.\n\n\n\nI de næste to afsnit ser vi på, hvordan man kan bruge vektorer til at modellere sandsynligheden for, at et inputord \\(w\\) har \\(c\\) som kontekstord. Det vil vi sidenhen benytte til at vælge vektorerne, således at sandsynlighederne matcher, hvor hyppigt vi observerer \\(c\\) som kontekstord til \\(w\\) i datasættet."
  },
  {
    "objectID": "materialer/sprogmodeller/word2vec.html#input--og-kontekstvektorer",
    "href": "materialer/sprogmodeller/word2vec.html#input--og-kontekstvektorer",
    "title": "Word2vec",
    "section": "Input- og kontekstvektorer",
    "text": "Input- og kontekstvektorer\nI første omgang vil vi lade hvert ord \\(w\\) være repræsenteret af to vektorer, \\(\\vec{v}_{w}\\) og \\(\\vec{k}_{w}\\), hvor \\(\\vec{v}_{w}\\) repræsenterer ordet, når det optræder som input, mens \\(\\vec{k}_{w}\\) repræsenterer ordet, når det optræder som kontekst. Ordet \"hund\" vil altså være repræsenteret ved vektoren \\(\\vec{v}_{\\text{hund}}\\), når det optræder som input og ved vektoren \\(\\vec{k}_{\\text{hund}}\\), når det optræder som kontekst.\nBetydningen af ordet \\(w\\) afgøres som nævnt af, hvordan ordet forholder sig til konteksten. Det vil vi oversætte matematisk til, hvordan inputvektoren \\(\\vec{v}_{w}\\) forholder sig til kontekstvektorerne \\(\\vec{k}_{c}\\) for diverse kontekstord \\(c\\). Vi vil derfor tænke på \\(\\vec{v}_{w}\\) som den vektor, der repræsenterer betydningen af ordet, og altså den vi er ude på at bestemme.\nFor at måle hvordan inputvektoren \\(\\vec{v}_{w}\\) for ordet \\(w\\) forholder sig til kontekstvektoren \\(\\vec{k}_{c}\\) for ordet \\(c\\), vil vi bruge skalarproduktet \\(\\vec{v}_{w}\\cdot \\vec{k}_{c}\\). Husk på, at man finder skalarproduktet mellem to vektorer i to dimensioner ved formlen \\[\n\\begin{pmatrix}\na_1\\\\a_2\n\\end{pmatrix}\n\\cdot\n\\begin{pmatrix}\nb_1\\\\b_2\n\\end{pmatrix}\n=a_1b_1+a_2b_2\n\\] I tre dimensioner er formlen \\[\n\\begin{pmatrix}\na_1\\\\a_2\\\\a_3\n\\end{pmatrix}\n\\cdot\n\\begin{pmatrix}\nb_1\\\\b_2\\\\b_3\n\\end{pmatrix}\n=a_1b_1+a_2b_2+a_3b_3\n\\] Tilsvarende kan man definere skalarproduktet mellem to \\(m\\)-dimensionale vektorer ved \\[\n\\begin{pmatrix}\na_1\\\\a_2\\\\a_3\\\\ \\vdots\\\\a_m\n\\end{pmatrix}\n\\cdot\n\\begin{pmatrix}\nb_1\\\\b_2\\\\b_3\\\\ \\vdots \\\\b_m\n\\end{pmatrix}\n=a_1b_1+a_2b_2+a_3b_3+\\dotsm + a_mb_m\n\\] Det overordnede mål er nu:\n\nVi vil gerne have, at vores input- og kontekstvektorer skal opfylde, at hvis \\(w\\) ofte har \\(c\\) som kontekst, så er skalarproduktet \\(\\vec{v}_{w}\\cdot \\vec{k}_{c}\\) stort, mens en meget negativ værdi af \\(\\vec{v}_{w}\\cdot \\vec{k}_{c}\\) indikerer, at \\(w\\) sjældent har \\(c\\) som kontekst.\n\n\n\nHvad fortæller skalarproduktet om, hvordan to vektorer forholder sig til hinanden? I 2 og 3 dimensioner kan vi give en geometrisk fortolkning af skalarproduktet ved hjælp af formlen \\[\n\\vec{a}\\cdot\\vec{b} = |\\vec{a}|\\cdot |\\vec{b}| \\cdot \\cos(v)\n\\tag{1}\\] hvor \\(v\\) er vinklen mellem vektorerne \\(\\vec{a}\\) og \\(\\vec{b}\\), og \\(|\\vec{a}|\\) betegner længden af \\(\\vec{a}\\), som findes med formlen \\[\n|\\vec{a}|=\\sqrt{\\vec{a}\\cdot\\vec{a}}\n\\]\nI 2 dimensioner svarer det til \\[\n|\\vec{a}|=\\sqrt{a_1^2 + a_2^2}\n\\]\nCosinus er en aftagende funktion på intervallet \\([0^\\circ,180^\\circ ]\\), så jo større vinklen \\(v\\) er, desto mindre vil \\(\\cos(v)\\) være – se figur 2.\n\n\n\n\n\n\nFigur 2: Grafen for \\(cos(v)\\), hvor \\(v\\) er målt i grader.\n\n\n\nDet betyder, at \\(\\cos(v)\\) er størst når vinklen mellem \\(\\vec{a}\\) og \\(\\vec{b}\\) er \\(0^\\circ\\), svarende til at vektorerne peger samme vej. Her er \\(\\cos(v)=1\\). Den mindste værdi af \\(\\cos(v)\\) er \\(-1\\), som antages ved en vinkel på \\(180^\\circ\\), hvor vektorerne peger i modsat retning.\nDet vil sige, jo mindre vinklen mellem \\(\\vec{v}_{w}\\) og \\(\\vec{k}_{c}\\) er, desto større er deres skalarprodukt \\(\\vec{v}_{w}\\cdot \\vec{k}_{c}\\) altså, og jo oftere har ordet \\(w\\) dermed \\(c\\) som kontekst. Desuden viser (1), at lange vektorer tæller mere, både positivt og negativt, end korte vektorer. Ord, der er gode til at forudsige konteksten udfra, for eksempel \"logre\", der ofte vil forekomme i hunderelaterede kontekster, vil derfor blive repræsenteret med lange inputvektorer. Ord som \"og\" eller \"er\", der ikke indeholder megen information om konteksten, vil blive repræsenteret med kortere inputvektorer. Altså vil \\(|\\vec{v}_{\\text{logre}}|\\) være større end \\(|\\vec{v}_{\\text{og}}|\\) og \\(|\\vec{v}_{\\text{er}}|\\).\nBemærk også, at hvis to ord ofte optræder i samme kontekst, skal deres inputvektorer gerne have nogenlunde samme skalarprodukt med alle kontekstvektorer. Formlen (1) viser, at det betyder, at de dels skal have nogenlunde samme længde og dels skal have nogenlunde samme vinkel med alle kontekstvektorerne. Sidstnævnte kræver, at de selv har nogenlunde samme retning. Ord, hvis betydning ligner hinanden, kommer derfor til at svare til inputvektorer, hvis længde og retning ligner hinanden.\nI praksis bruger vi vektorer af højere dimension end 3. Det er måske ikke helt oplagt, hvad man skal forstå ved længden af en vektor eller vinklen mellem to vektorer i højere dimensioner, men det viser sig, at man stadigvæk godt kan give mening til formlen (1). Intuitionen fra to eller tre dimensioner er derfor god at have, selv om vi arbejder med højere dimensioner.\n\nEksempel 1\nLad os sige, at vi har fundet en vektorrepræsentation, der opfylder det ønskede. Det gav vektorerne \\[\n\\begin{aligned}\n&\\vec{v}_{\\text{hund}} =  \\begin{pmatrix} 3\\\\ 2\\end{pmatrix}, \\quad\n\\vec{v}_{\\text{kat}} =  \\begin{pmatrix} 2\\\\ 3\\end{pmatrix} \\\\\n&\\vec{k}_{\\text{madskål}}  =  \\begin{pmatrix} 3\\\\3\\end{pmatrix}, \\quad\n\\vec{k}_{\\text{badedragt}} =  \\begin{pmatrix} -2\\\\-1.5 \\end{pmatrix}, \\quad\n\\vec{k}_{\\text{lufte}} =  \\begin{pmatrix} 2\\\\0.5 \\end{pmatrix}\n\\end{aligned}\n\\] Vektorerne er vist i figur 3, hvor inputvektorer er lyserøde, og kontekstvektorer er blå.\n\n\n\n\n\n\nFigur 3: Repræsentanter for vektorerne i eksempel 1. Inputvektorerne er lyserøde, og kontekstvektorerne er blå.\n\n\n\nVi kan udregne skalarprodukterne \\[\n\\begin{aligned}\n&\\vec{v}_{\\text{kat}}\\cdot \\vec{k}_{\\text{madskål}} = \\begin{pmatrix} 2\\\\ 3\\end{pmatrix}  \\cdot  \\begin{pmatrix} 3\\\\ 3\\end{pmatrix} = 2\\cdot 3 +  3\\cdot 3 = 15 \\\\\n&\\vec{v}_{\\text{kat}}\\cdot \\vec{k}_{\\text{badedragt}} = \\begin{pmatrix} 2\\\\ 3\\end{pmatrix}  \\cdot  \\begin{pmatrix} -2\\\\ -1.5\\end{pmatrix} = 2\\cdot (-2) +  3\\cdot (-1.5) = -8.5\n\\end{aligned}\n\\] Vi ser, at \\(\\vec{v}_{\\text{kat}}\\cdot \\vec{k}_{\\text{madskål}}\\) er større end \\(\\vec{v}_{\\text{kat}}\\cdot \\vec{k}_{\\text{badedragt}}\\). Det svarer til, at ordet \"kat\" oftere har \"madskål\" som kontekst, end det har \"badedragt\". Det ses også ved, at \\(\\vec{k}_{\\text{madskål}}\\) peger i nogenlunde samme retning som \\(\\vec{v}_{\\text{kat}}\\), mens \\(\\vec{k}_{\\text{badedragt}}\\) peger i en helt anden retning.\nVi kan også udregne \\[\n\\begin{aligned}\n&\\vec{v}_{\\text{hund}}\\cdot \\vec{k}_{\\text{madskål}} = \\begin{pmatrix} 3\\\\ 2\\end{pmatrix}  \\cdot  \\begin{pmatrix} 3\\\\ 3\\end{pmatrix} = 3\\cdot 3 +  2\\cdot 3 = 15\n\\end{aligned}\n\\] Vi ser, at \\(\\vec{v}_{\\text{hund}}\\cdot \\vec{k}_{\\text{madskål}} =\\vec{v}_{\\text{kat}}\\cdot \\vec{k}_{\\text{madskål}} =15\\), svarende til at både \"hund\" og \"kat\" ofte har \"madskål\" som kontekst. Vi ser da også, at vektorerne \\(\\vec{v}_{hund}\\) og \\(\\vec{v}_{kat}\\) peger i nogenlunde samme retning og har nogenlunde samme længde, fordi de tit har samme kontekst. De to vektorer er dog ikke helt ens, da der også vil være nogle kontekstord, der ikke er lige hyppige for \"hund\" og \"kat\". Vi kan for eksempel udregne \\[\n\\begin{aligned}\n&\\vec{v}_{\\text{hund}}\\cdot \\vec{k}_{\\text{lufte}} = \\begin{pmatrix} 3\\\\ 2\\end{pmatrix}  \\cdot  \\begin{pmatrix} 2\\\\ 0.5\\end{pmatrix} = 3\\cdot 2 + 2\\cdot 0.5 =7\\\\\n&\\vec{v}_{\\text{kat}}\\cdot \\vec{k}_{\\text{lufte}} =\\begin{pmatrix} 2\\\\ 3\\end{pmatrix}  \\cdot  \\begin{pmatrix} 2\\\\ 0.5\\end{pmatrix} = 2\\cdot 2 + 3\\cdot 0.5 = 5.5  \n\\end{aligned}\n\\] Her er \\(\\vec{v}_{\\text{hund}}\\cdot \\vec{k}_{\\text{lufte}}\\) større end \\(\\vec{v}_{\\text{kat}}\\cdot \\vec{k}_{\\text{lufte}}\\) svarende til, at \"hund\" oftere har \"lufte\" som kontekst, end \"kat\" har.\n\n\n\n\n\n\nHvorfor to vektorer?\n\n\n\n\n\nMåske har du undret dig over, hvorfor vi har brug for to forskellige vektorer for hvert ord. Hver gang et ord er kontekst for et andet, gælder det omvendte også. For eksempel er \"logrer\" kontekst for \"hund\" i dette vindue:\n\\[\n\\boxed{\\textrm{ Den sorte }\\textbf{hund} \\textrm{ logrer med }} \\textrm{ halen}\n\\] Samtidig er \"hund\" også kontekst for \"logrer\" i vinduet:\n\\[\n\\textrm{Den } \\boxed{\\textrm{ sorte hund }\\textbf{logrer} \\textrm{ med halen}}\n\\]\nAlligevel er der ikke symmetri mellem de to ord. Når for eksempel inputordet er \"logrer\", er det ret sandsynligt, at \"hund\" er et af kontekstordene. Inputordet \"hund\" forekommer derimod i mange kontekster, der ikke involverer ordet \"logrer\". Sandsynligheden for kontekstordet afhænger derfor af, om det er \"hund\" eller \"logrer\", der er input. Hvis vi kun brugte én vektor for hvert ord, \\(\\vec{u}_{\\text{hund}}\\) og \\(\\vec{u}_{\\text{logrer}}\\), ville vi få samme skalarprodukt \\(\\vec{u}_{\\text{hund}}\\cdot \\vec{u}_{\\text{logrer}} =  \\vec{u}_{\\text{logrer}}\\cdot \\vec{u}_{\\text{hund}}\\), og dermed samme sandsynlighed, uanset hvilket ord der var input.\n\n\n\n\n\n\n\n\n\nOpgave 1\n\n\n\n\n\nAntag, at vi har lavet 4-dimensionale input- og kontekstvektorer således, at jo større skalarproduktet \\(\\vec{v}_{w}\\cdot \\vec{k}_{c}\\) er, desto mere sandsynligt er det, at ordet \\(w\\) har \\(c\\) som kontekst. Inputvektoren for \"hund\" og kontekstvektorerne for \"pels\" og \"fjer\" er \\[\n\\begin{aligned}\n\\vec{v}_{\\text{hund}}=\\begin{pmatrix} 0.5\\\\2\\\\1\\\\-1\\end{pmatrix} ,\\quad\n\\vec{k}_{\\text{pels}}=\\begin{pmatrix} 0\\\\3\\\\2\\\\-2\\end{pmatrix},\\quad\n\\vec{k}_{\\text{fjer}}=\\begin{pmatrix} 1\\\\-2\\\\1.5\\\\0.5\\end{pmatrix}\n\\end{aligned}\n\\]\n\nUdregn skalarprodukterne \\(\\vec{v}_{\\text{hund}}\\cdot \\vec{k}_{\\text{pels}}\\) og \\(\\vec{v}_{\\text{hund}}\\cdot \\vec{k}_{\\text{fjer}}\\).\nPasser det med, hvilket af ordene \"pels\" og \"fjer\" der er mest sandsynligt som kontekst til \"hund\"?\n\nAntag, at vi har lavet 3-dimensionale input- og kontekstvektorer som beskrevet i afsnittet ovenfor. Så skulle ord, der ofte har samme kontekst, gerne have inputvektorer af nogenlunde samme længde og retning, mens inputvektorerne for ord, der betyder noget helt forskelligt, kan have meget forskellig længde og retning. Antag, at inputvektorerne for \"kat\", \"hund\", \"mis\" og \"kælk\" er \\[\n\\begin{aligned}\n\\vec{v}_{\\text{kat}}=\\begin{pmatrix}0\\\\2\\\\1 \\end{pmatrix},\\quad\n\\vec{v}_{\\text{hund}}=\\begin{pmatrix}0\\\\1.2\\\\1.8\\end{pmatrix}, \\quad\n\\vec{v}_{\\text{mis}}=\\begin{pmatrix}-0.5\\\\2\\\\0.8\\end{pmatrix},\\quad\n\\vec{v}_{\\text{kælk}}=\\begin{pmatrix} 0\\\\-1\\\\-2 \\end{pmatrix}\n\\end{aligned}\n\\]\n\nFind længden af de fire vektorer.\nFind vinklen mellem \\(\\vec{v}_{\\text{kat}}\\) og de tre øvrige vektorer.\nStemmer resultatet overens med, hvilke ord der er tættest på \"kat\" i betydning?\nTegn vektorerne ind i GeoGebra. Skriv for eksempel v(0,2,1) i inputfeltet i GeoGebra og vælg derefter \"Vis\" \\(\\rightarrow\\) \"3D Grafik\"."
  },
  {
    "objectID": "materialer/sprogmodeller/word2vec.html#model-for-sandsynligheder",
    "href": "materialer/sprogmodeller/word2vec.html#model-for-sandsynligheder",
    "title": "Word2vec",
    "section": "Model for sandsynligheder",
    "text": "Model for sandsynligheder\nSom nævnt vil vi gerne have, at jo større skalarproduktet \\(\\vec{v}_{w}\\cdot \\vec{k}_{c}\\) er, desto mere sandsynligt er det, at ordet \\(w\\) har ordet \\(c\\) som kontekst. Hvis der er \\(V\\) antal ord i sproget, kan vi nummerere de mulige kontekstord som \\(\\text{ord}_1,\\text{ord}_2,\\ldots,\\text{ord}_V\\). For hvert af dem får vi et skalarprodukt \\(\\vec{v}_{w}\\cdot \\vec{k}_{\\text{ord}_i}\\) for \\(i=1,\\ldots,V\\). Hvis vi betegner sandsynligheden for, at \\(\\text{ord}_i\\) er et kontekstord til \\(w\\), med \\(P(\\text{ord}_i\\mid w)\\), så vil vi gerne have, at følgende er opfyldt:\n\nFor hvert \\(\\text{ord}_i\\) er \\[0\\leq P(\\text{ord}_i \\mid w)\\leq 1\\] da sandsynligheder skal ligge mellem 0 og 1.\nDen samlede sandsynlighed for at få et af de mulige kontekstord skal være 1, det vil sige, \\[P(\\text{ord}_1\\mid w) + P(\\text{ord}_2\\mid w) + \\dotsm + P(\\text{ord}_V\\mid w ) = 1.\\]\nJo større skalarproduktet \\(\\vec{v}_{w}\\cdot \\vec{k}_{\\text{ord}_i}\\) er, desto større er sandsynligheden \\(P(\\text{ord}_i\\mid w)\\) for at få \\(\\text{ord}_i\\) som kontekstord.\n\nSkalarprodukter kan imidlertid antage alle reelle værdier, så de egner sig ikke til at repræsentere sandsynligheder, der jo skal være tal mellem 0 og 1. Vi bruger derfor en funktion på skalarprodukterne for at få dem lavet om til sandsynligheder, der opfylder punkt 1. til 3 ovenfor. Den funktion, vi vil bruge, hedder Softmax. Hvis \\(\\vec{y}\\) er en vektor med \\(V\\) koordinater, så er \\(\\text{Softmax}\\big(\\vec{y}\\big)=\\vec{z}\\), hvor \\(\\vec{z}\\) er en ny vektor med \\(V\\) koordinater. Den \\(i\\)te koordinat i \\(\\vec{z}\\) er givet ved \\[z_i = \\frac{e^{y_i}}{e^{y_1} + \\dotsm + e^{y_V}}\\] Vi viser i boksen nedenfor, at Softmax opfylder:\n\n\\(0&lt;z_i&lt;1\\)\n\\(z_1 + z_2 + \\dotsm + z_V = 1\\)\nHvis \\(y_i &lt; y_j\\), så er \\(z_i &lt; z_j\\).\n\nLader vi \\(\\vec{y}\\) være vektoren med \\(i\\)te koordinat \\[y_i = \\vec{v}_{w}\\cdot \\vec{k}_{\\text{ord}_i}\\] og bruger Softmax på \\(\\vec{y}\\), så får vi en vektor \\(\\vec{z}=\\text{Softmax}\\big(\\vec{y}\\big)\\), der kan bruges som sandsynligheder. Mere præcist lader vi\n\\[\n\\begin{aligned}\nP(\\text{ord}_i\\mid w) &= z_i = \\frac{e^{y_i}}{e^{y_1} + \\dotsm + e^{y_V}} \\\\ &= \\frac{e^{\\vec{v}_{w}\\cdot \\vec{k}_{\\text{ord}_i}}}{e^{\\vec{v}_{w}\\cdot \\vec{k}_{\\text{ord}_1}} + \\dotsm + e^{\\vec{v}_{w}\\cdot \\vec{k}_{\\text{ord}_V}}}\n\\end{aligned}\n\\tag{2}\\]\nEgenskaberne ved softmax sikrer, at punkt 1. til 3. ovenfor er opfyldt.\n\nEksempel 2\nAntag, at vores ordforråd kun består af de tre ord \"hund\", \"pels\" og \"fjer\", og at vi har fundet vektorrepræsentationer for de tre ord.\nAntag, at inputvektoren for \"hund\" og kontekstvektorerne for \"fjer\", \"pels\" og \"hund\" er givet ved \\[\n    \\begin{aligned}\n    \\vec{v}_{\\text{hund}}=\\begin{pmatrix} 0.5\\\\2\\end{pmatrix},\\quad\n    \\vec{k}_{\\text{fjer}}=\\begin{pmatrix} 1\\\\-1 \\end{pmatrix}, \\quad\n    \\vec{k}_{\\text{pels}}=\\begin{pmatrix} 0\\\\1\\end{pmatrix},\\quad\n    \\vec{k}_{\\text{hund}}=\\begin{pmatrix} 4\\\\-1\\end{pmatrix}\n    \\end{aligned}\n    \\] Vi beregner først skalarprodukterne \\[\n\\begin{aligned}\n\\vec{v}_{\\text{hund}} \\cdot \\vec{k}_{\\text{fjer}} &= 0.5\\cdot 1 + 2\\cdot (-1)  =-1.5\\\\\n\\vec{v}_{\\text{hund}} \\cdot \\vec{k}_{\\text{pels}}&= 0.5\\cdot 0 + 2\\cdot 1  = 2\\\\\n\\vec{v}_{\\text{hund}} \\cdot \\vec{k}_{\\text{hund}} &= 0.5 \\cdot 4 + 2 \\cdot (-1) = 0\n\\end{aligned}\n\\] Derefter anvender vi Softmax for at finde sandsynlighederne \\[\n\\begin{aligned}\nP(\\text{fjer} \\mid \\text{hund}) &= \\frac{e^{\\vec{v}_{\\text{hund}} \\cdot \\vec{k}_{\\text{fjer}} }}{e^{\\vec{v}_{\\text{hund}} \\cdot \\vec{k}_{\\text{fjer}} }+e^{\\vec{v}_{\\text{hund}} \\cdot \\vec{k}_{\\text{pels}} }+e^{\\vec{v}_{\\text{hund}} \\cdot \\vec{k}_{\\text{hund}} }} \\\\ &= \\frac{e^{-1.5}}{e^{-1.5}+e^{2 }+e^{0 }} \\approx 0.026\\\\ \\\\\nP(\\text{pels} \\mid \\text{hund}) &= \\frac{e^{\\vec{v}_{\\text{hund}} \\cdot \\vec{k}_{\\text{pels}} }}{e^{\\vec{v}_{\\text{hund}} \\cdot \\vec{k}_{\\text{fjer}} }+e^{\\vec{v}_{\\text{hund}} \\cdot \\vec{k}_{\\text{pels}} }+e^{\\vec{v}_{\\text{hund}} \\cdot \\vec{k}_{\\text{hund}} }} \\\\ &= \\frac{e^{2}}{e^{-1.5}+e^{2 }+e^{0 }} \\approx 0.858\\\\ \\\\\nP(\\text{hund} \\mid \\text{hund}) &= \\frac{e^{\\vec{v}_{\\text{hund}} \\cdot \\vec{k}_{\\text{hund}} }}{e^{\\vec{v}_{\\text{hund}} \\cdot \\vec{k}_{\\text{fjer}} }+e^{\\vec{v}_{\\text{hund}} \\cdot \\vec{k}_{\\text{pels}} }+e^{\\vec{v}_{\\text{hund}} \\cdot \\vec{k}_{\\text{hund}} }} \\\\ &= \\frac{e^{0}}{e^{-1.5}+e^{2 }+e^{0 }} \\approx 0.116\n\\end{aligned}\n\\] “Pels” er altså det mest sandsynlige kontekstord til \"hund\", mens \"fjer\" sjældent er kontekst til \"hund\".\n\n\n\n\n\n\nEgenskaber ved Softmax\n\n\n\n\n\nVi viser nu de tre egenskaber ved Softmax.\nEgenskab 1: \\(0 &lt; z_i &lt; 1\\)\nHusk på at \\[z_i=\\frac{e^{y_i}}{e^{y_1} + \\dotsm + e^{y_V}} \\tag{3}\\] Da eksponentialfunktionen kun kan antage positive værdier, er både tæller og nævner positive, så \\(z_i&gt;0\\). Desuden er \\[e^{y_i} &lt; e^{y_1} + \\dotsm +e^{y_i} + \\dotsm + e^{y_V}\\] Derfor er \\[z_i=\\frac{e^{y_i}}{e^{y_1} + \\dotsm + e^{y_V}} &lt; \\frac{e^{y_1} + \\dotsm  + e^{y_V}}{e^{y_1} + \\dotsm + e^{y_V}} = 1\\]\nAlt i alt har vi altså, at\n\\[\n0 &lt; z_i &lt; 1\n\\]\nEgenskab 2: \\(z_1 + \\dotsm + z_V = 1\\)\nVed at indsætte at \\(z_i\\) er givet ved (3) og sætte på fælles brøkstreg, får vi \\[\n\\begin{aligned}\nz_1 &+ \\dotsm  + z_V  = \\\\ & \\frac{e^{y_1}}{e^{y_1} + \\dotsm + e^{y_V}} + \\dotsm + \\frac{e^{y_V}}{e^{y_1} + \\dotsm + e^{y_V}} = \\frac{e^{y_1} + \\dotsm + e^{y_V}}{e^{y_1} + \\dotsm + e^{y_V}} = 1\n\\end{aligned}\n\\]\nAltså er:\n\\[\nz_1 + \\dotsm + z_V = 1\n\\]\nEgenskab 3: Hvis \\(y_i &lt; y_j\\), så er \\(z_i &lt; z_j\\)\nHvis \\(y_i&lt; y_j\\), så er \\[e^{y_i} &lt; e^{y_j}\\] Hvis vi dividerer med \\(e^{y_1} + \\dotsm + e^{y_V}\\) på begge sider af uligheden, får vi \\[ \\frac{e^{y_i}}{e^{y_1} + \\dotsm + e^{y_V}} &lt; \\frac{e^{y_j}}{e^{y_1} + \\dotsm + e^{y_V}} \\] Det betyder netop, at \\(z_i&lt;z_j\\).\n\n\n\n\n\n\n\n\n\nOpgave 2\n\n\n\n\n\nLad \\(\\vec{y}\\) være vektoren \\[\\vec{y}= \\begin{pmatrix} 1 \\\\2 \\\\-1 \\end{pmatrix}\\]\n\nBeregn \\(\\vec{z} = \\text{Softmax}(\\vec{y})\\).\n\nAntag, at vores ordforråd består af de tre ord \"sommer\", \"sol\" og \"sne\". Vi har lavet en model for sandsynligheder for kontekstord som i (2), hvor inputvektoren for \"sommer\" og kontekstvektorerne for \"sommer\", \"sol\" og \"sne\" er givet ved \\[\n\\begin{aligned}\n\\vec{v}_{\\text{sommer}}=\\begin{pmatrix} 1\\\\1\\end{pmatrix},\\quad\n\\vec{k}_{\\text{sommer}}=\\begin{pmatrix} 1\\\\-1 \\end{pmatrix} ,\\quad\n\\vec{k}_{\\text{sol}}=\\begin{pmatrix} 0\\\\2\\end{pmatrix},\\quad\n\\vec{k}_{\\text{sne}} =\\begin{pmatrix} -1\\\\-2\\end{pmatrix}\n\\end{aligned}\n\\]\n\nHvad er sandsynligheden for, at hvert af de tre ord er kontekst til \"sommer\"?\nHvilket af de tre ord optræder oftest som kontekst til sommer?"
  },
  {
    "objectID": "materialer/sprogmodeller/word2vec.html#estimation-af-vektorrepræsentationer",
    "href": "materialer/sprogmodeller/word2vec.html#estimation-af-vektorrepræsentationer",
    "title": "Word2vec",
    "section": "Estimation af vektorrepræsentationer",
    "text": "Estimation af vektorrepræsentationer\nVi mangler stadig at bestemme vektorrepræsentationerne \\(\\vec{v}_{w}\\) og \\(\\vec{k}_{c}\\), så modellen i (2) kommer til at passe til virkelig tekst. Her får vi brug for det datasæt, som vi lavede ud fra vores træningsdata. Hver række i datasættet bestod af et inputord \\(w\\) og et kontekstord \\(c\\), som forekom i vores træningsdata. Lad os sige, at der er \\(M\\) rækker i vores træningsdata. Vi betegner data i den \\(j\\)te række med \\((w_j,c_j)\\) for \\(j=1,\\ldots,M\\). Vores datasæt har altså formen (jævnfør tabel 2):\n\n\n\n\n\n\nInput\nKontekst\n\n\n\n\n\\(w_1\\)\n\\(c_1\\)\n\n\n\\(w_2\\)\n\\(c_2\\)\n\n\n\\(w_3\\)\n\\(c_3\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\\(w_j\\)\n\\(c_j\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\n\n\nTabel 2: Eksempel på datatabel med træningsdata.\n\n\n\nVi ser nu på \\(j\\)te række. Sandsynligheden for, at \\(w_j\\) har netop \\(c_j\\) som kontekst, er \\(P(c_j\\mid w_j)\\). Vi vil nu finde den samlede sandsynlighed for, at inputordene \\(w_1,\\ldots,w_M\\) i vores datasæt har henholdsvis \\(c_1,\\ldots,c_M\\) som kontekstord. Den kalder vi \\(P(\\text{data})\\). Lad os antage, at alle vores par af input- og kontekstord er uafhængige af hinanden2. Så får vi den samlede sandsynlighed ved at gange de enkelte sandsynligheder sammen. \\[P(\\text{data})  = P(c_1\\mid w_1) \\cdot P(c_2\\mid w_2) \\dotsm P(c_M\\mid w_M) \\tag{4}\\] Hvis vores model fra (2) passer godt til datasættet, skulle denne sandsynlighed gerne være høj.\n2 I praksis er ordpar, der forekommer i nærheden af hinanden ikke helt uafhængige. Hvis for eksempel parret \\((\\text{hund},\\text{madskål})\\) forekommer, er det mere sandsynligt, at \\((\\text{hund}, \\text{fodre})\\) forekommer i nærheden, end hvis der havde stået \\((\\text{hund},\\text{hundesnor})\\).Da summer er nemmere at regne på end produkter, vælger vi at tage den naturlige logaritme på begge sider af (4). Ved at bruge logaritmeregnereglen \\(\\ln(ab) = \\ln(a) + \\ln(b)\\) får vi, at \\[\n\\begin{aligned}\n\\ln (P(\\text{data})) &= \\ln\\big(P(c_1\\mid w_1) \\cdot P(c_2\\mid w_2) \\dotsm P(c_M\\mid w_M)\\big)\\\\\n&= \\ln(P(c_1\\mid w_1)) + \\ln(P(c_2\\mid w_2)) + \\dotsm + \\ln(P(c_M\\mid w_m))\n\\end{aligned}\n\\] Da den naturlige logaritme er en voksende funktion, svarer store værdier af \\(P(\\text{data})\\) til store værdier af \\(\\ln (P(\\text{data}))\\), som igen svarer til små værdier af \\(-\\ln(P(\\text{data}))\\). Dette er illustreret på figur 4:\n\n\n\n\n\n\nFigur 4: Grafen for \\(\\ln(x)\\) og \\(-\\ln(x)\\).\n\n\n\nHvis vores model er god, skal \\[\n\\begin{aligned}\nL&= - \\ln(\\text{data}) \\\\ &= -\\ln(P(c_1\\mid w_1)) - \\ln(P(c_2\\mid w_2)) - \\dotsm - \\ln(P(c_M\\mid w_m))\n\\end{aligned}\n\\tag{5}\\]\naltså gerne være lav3. Vi kalder \\(L\\) for vores tabsfunktion. Denne tabsfunktion kaldes også nogle gange for cross-entropy.\n3 Bemærk, at da \\(P(c_j\\mid w_j)\\) er en sandsynlighed, der ligger mellem 0 og 1, er \\(\\ln (P(c_j\\mid w_j))\\) negativ. Derfor er \\(-\\ln (P(c_j\\mid w_j))\\) positiv og \\(L\\) er dermed også positiv. Når \\(L\\) gerne skal være lav, betyder det altså, at den skal være så tæt på 0 som muligt.Vi kan indsætte vores udtryk for sandsynlighederne fra (2) i (5) og få \\[\n\\begin{aligned}\nL = &-\\ln\\left(\\frac{e^{\\vec{v}_{w_1}\\cdot \\vec{k}_{c_1}}}{e^{\\vec{v}_{w_1}\\cdot \\vec{k}_{\\text{ord}_1}} + \\dotsm + e^{\\vec{v}_{w_1}\\cdot \\vec{k}_{\\text{ord}_V}}}\\right)\n\\\\ &- \\ln\\left(\\frac{e^{\\vec{v}_{w_2}\\cdot \\vec{k}_{c_2}}}{e^{\\vec{v}_{w_2}\\cdot \\vec{k}_{\\text{ord}_1}} + \\dotsm + e^{\\vec{v}_{w_2}\\cdot \\vec{k}_{\\text{ord}_V}}}\\right)\n- \\dotsm \\\\ &- \\ln\\left(\\frac{e^{\\vec{v}_{w_M}\\cdot \\vec{k}_{c_M}}}{e^{\\vec{v}_{w_M}\\cdot \\vec{k}_{\\text{ord}_1}} + \\dotsm + e^{\\vec{v}_{w_M}\\cdot \\vec{k}_{\\text{ord}_V}}}\\right)\n\\end{aligned}\n\\tag{6}\\] Bemærk her, at \\(w_j\\) og \\(c_j\\) refererer til henholdsvis input- og kontekstordet i \\(j\\)te række i datasættet, mens \\(\\text{ord}_i\\) refererer til \\(i\\)te ord i ordforrådet.\nLigning (6) viser, at \\(L\\) afhænger af, hvordan vi har valgt input- og kontekstvektorerne. Vi kan altså betragte \\(L\\) som en funktion af input- og kontekstvektorerne. Mere præcist er \\(L\\) en funktion af alle koordinaterne i disse vektorer. For at få den bedst mulige model for vores træningsdata, ønsker vi at bestemme input- og kontekstvektorerne, således at de minimerer \\(L\\). Hvordan finder man minimum for \\(L\\) i praksis? Det kan man for eksempel gøre ved hjælp af gradientnedstigning, som vi ikke vil komme nærmere ind på her.\nDer er rigtig mange ord i det danske sprog. For hvert af dem skal vi finde både en input- og en kontekstvektor, der hver har \\(m\\) koordinater. Alt i alt giver det rigtig mange koordinater, der skal bestemmes. Antallet af ord på dansk afhænger lidt af, hvad man forstår ved et ord, men 200.000 er et fornuftigt bud. Hvis vi vil repræsentere hver af dem ved to vektorer af dimension \\(m=100\\), får man brug for at bestemme 40.000.000 koordinater. For at kunne gøre det meningsfuldt, er man også nødt til at have enormt store mængder træningsdata til rådighed i form af et tekstkorpus med rigtig mange ord.\nNu har vi set, hvordan man kan repræsentere et ord \\(w\\) ved en inputvektor \\(\\vec{v}_{w}\\) og en kontekstvektor \\(\\vec{k}_{w}\\). Vektoren \\(\\vec{v}_{w}\\) er den, der viser, hvordan \\(w\\) forholder sig til sin kontekst, så det er den, der repræsenterer betydningen af \\(w\\). Normalt vil man derfor arbejde videre med \\(\\vec{v}_{w}\\), mens \\(\\vec{k}_{w}\\) smides væk. Når vektorerne \\(\\vec{v}_{w}\\) er fundet med Word2Vec, kan man bruge dem til at lave algoritmer til at generere tekst. Det ser vi på i næste afsnit.\n\n\n\n\n\n\n\n\nOpgave 3\n\n\n\n\n\nFor at finde minimum for tabsfunktionen, får man brug for at finde partielle afledte af Softmax-funktionen. Det kan man gøre smart ved hjælp af nedenstående opgave, som viser, at man ikke behøver at kende værdien af \\(\\vec{y}\\) i det punkt, hvor man differentierer, men kun funktionsværdien \\(\\vec{z}\\).\n\nVis ved at bruge udtrykket i (3) følgende egenskaber ved de partielle afledte af Softmax-funktionen:\n\n\\[\\frac{\\partial z_i}{\\partial y_i} = z_i(1-z_i),\\quad \\frac{\\partial z_i}{\\partial y_j} = -z_iz_j, \\quad i\\neq j\\]"
  },
  {
    "objectID": "materialer/sprogmodeller/word2vec.html#fra-vektorer-til-tekstgenerering",
    "href": "materialer/sprogmodeller/word2vec.html#fra-vektorer-til-tekstgenerering",
    "title": "Word2vec",
    "section": "Fra vektorer til tekstgenerering",
    "text": "Fra vektorer til tekstgenerering\nI det følgende ser vi på, hvordan vektorrepræsentationerne, som vi fandt med Word2Vec, kan bruges til at lave en algoritme, der kan generere ny tekst. De fleste tekstgenereringsalgoritmer fungerer ved, at de danner teksten et ord ad gangen. Givet den tekst der allerede er dannet, prøver algoritmen hele tiden at gætte, hvad det næste ord skal være. Det kan gøres i to trin:\n\nFørst benyttes Word2Vec til at oversætte alle ordene i sproget til vektorer.\nDernæst genereres teksten. Givet den tekst, der allerede er dannet, bruger vi en (kompliceret) funktion, der tager vektorrepræsentationerne af de hidtil genererede ord som input. Som output giver funktionen det mest sandsynlige næste ord (eller et af de mest sandsynlige).\n\nHvis vi for eksempel har genereret teksten \\[\n\\text{\"Hunden spiser sit ---\"}\n\\] så skal vi prøve at gætte, hvilket ord der kommer efter \"sit\". Vi oversætter derfor ordene \"Hunden\", \"spiser\" og \"sit\" til vektorerne \\(\\vec{v}_{\\text{Hunden}}\\), \\(\\vec{v}_{\\text{spiser}}\\) og \\(\\vec{v}_{\\text{sit}}\\). Disse tre vektorer giver vi funktionen som input, og som output får vi et nyt ord. Det kunne være \"kødben\". Den funktion, der bruges i punkt 2., kunne for eksempel være et neuralt netværk. Du kan læse mere om, hvordan det fungerer i Tekstgenerering med neurale netværk.\nDet smarte ved at bruge vektorrepræsentationerne er, hvis vi for eksempel vil generere næste ord i \\[\n\\text{\"Jeg skal huske, at katten skal have ---\"}\n\\] Det skulle gerne give \"mad\" som muligt næste ord. Men måske har sprogmodellen aldrig set sætningen \"katten skal have mad\". Hvis den til gengæld har set \"hunden skal have mad\", og modellen ved at \"hunden\" og \"katten\" tit har samme kontekst, og dermed har næsten samme vektorrepræsentation, så vil man alligevel få \"mad\" som muligt næste ord.\nBemærk, at resultatet af Word2Vec afhænger meget af, hvilket træningsdata vi har brugt. Antag for eksempel, at vi kun træner modellen på tekster skrevet af folk, der ikke kan lide hunde. Så vil \\(\\vec{v}_{\\text{hund}}\\) have en tendens til at pege i samme retning som andre negativt ladede ord, fordi de ofte optræder sammen med negative kontekstord. Når vi sidenhen genererer ny tekst, vil vi få en tendens til at danne sætninger, der omtaler hunde negativt."
  },
  {
    "objectID": "materialer/neurale_net/neurale_net.html",
    "href": "materialer/neurale_net/neurale_net.html",
    "title": "Kunstige neurale netværk",
    "section": "",
    "text": "Denne note giver en grundig gennemgang af matematikken bag kunstige neurale netværk."
  },
  {
    "objectID": "materialer/neurale_net/neurale_net.html#video-kunstige-neurale-netværk-1",
    "href": "materialer/neurale_net/neurale_net.html#video-kunstige-neurale-netværk-1",
    "title": "Kunstige neurale netværk",
    "section": "VIDEO: Kunstige neurale netværk 1",
    "text": "VIDEO: Kunstige neurale netværk 1\nI denne video forklarer vi lidt om, hvad et kunstigt neuralt netværk er samt hvilke input- og outputværdier, man kan bruge."
  },
  {
    "objectID": "materialer/neurale_net/neurale_net.html#video-kunstige-neurale-netværk-2",
    "href": "materialer/neurale_net/neurale_net.html#video-kunstige-neurale-netværk-2",
    "title": "Kunstige neurale netværk",
    "section": "VIDEO: Kunstige neurale netværk 2",
    "text": "VIDEO: Kunstige neurale netværk 2\nI denne video giver vi et eksempel på et simpelt kunstig neuralt netværk og forklarer feedforward."
  },
  {
    "objectID": "materialer/neurale_net/neurale_net.html#video-kunstige-neurale-netværk-3",
    "href": "materialer/neurale_net/neurale_net.html#video-kunstige-neurale-netværk-3",
    "title": "Kunstige neurale netværk",
    "section": "VIDEO: Kunstige neurale netværk 3",
    "text": "VIDEO: Kunstige neurale netværk 3\nI videoen her forklarer vi, hvad targetværdier er, og hvordan tabsfunktionen defineres."
  },
  {
    "objectID": "materialer/neurale_net/neurale_net.html#video-kunstige-neurale-netværk-4",
    "href": "materialer/neurale_net/neurale_net.html#video-kunstige-neurale-netværk-4",
    "title": "Kunstige neurale netværk",
    "section": "VIDEO: Kunstige neurale netværk 4",
    "text": "VIDEO: Kunstige neurale netværk 4\nI denne video bliver gradientnedstigning forklaret."
  },
  {
    "objectID": "materialer/neurale_net/neurale_net.html#sec-opdatering_w",
    "href": "materialer/neurale_net/neurale_net.html#sec-opdatering_w",
    "title": "Kunstige neurale netværk",
    "section": "Opdatering af \\(w\\)-vægtene",
    "text": "Opdatering af \\(w\\)-vægtene\nNår man bruger backpropagation, starter man med at finde de partielle afledede for de vægte, som direkte påvirker outputværdien \\(o\\). På figur 3 fremgår det, at det er vægtene \\(w_0, w_1\\) og \\(w_2\\) (husk at vi kalder vores bias for \\(w_0\\)). Lad os starte med at finde den partielle afledede for \\(w_1\\). Ved at bruge kædereglen får vi: \\[\n\\frac{\\partial E}{\\partial w_1} = \\frac{d E}{d o} \\cdot \\frac{\\partial o}{\\partial w_1}\n\\] Vi ved fra (12), at \\(E=\\frac{1}{2}(t-o)^2\\) og derfor er: \\[\n\\frac{d E}{d o} = \\frac{1}{2} \\cdot 2 \\cdot (t-o) \\cdot (-1) = -(t-o)\n\\tag{14}\\] Fra (10) har vi, at \\(o=\\sigma(w_1 \\cdot z_1 + w_2 \\cdot z_2 + w_0)\\) og derfor får vi \\[\n\\frac{\\partial o}{\\partial w_1} =\\sigma'(w_1 \\cdot z_1 + w_2 \\cdot z_2 + w_0) \\cdot z_1\n\\] Vi har tidligere vist, at \\(\\sigma'(z)=\\sigma(z)(1-\\sigma(z))\\) og derfor har vi \\[\n\\frac{\\partial o}{\\partial w_1} =\\sigma(w_1 \\cdot z_1 + w_2 \\cdot z_2 + w_0)(1-\\sigma(w_1 \\cdot z_1 + w_2 \\cdot z_2 + w_0)) \\cdot z_1\n\\] Bruger vi nu, at \\(o=\\sigma(w_1 \\cdot z_1 + w_2 \\cdot z_2 + w_0)\\) kan vi skrive ovenstående lidt mere kompakt: \\[\n\\frac{\\partial o}{\\partial w_1} =o(1-o) \\cdot z_1\n\\] Alt i alt får vi altså, at \\[\n\\frac{\\partial E}{\\partial w_1} = \\frac{d E}{d o} \\cdot \\frac{\\partial o}{\\partial w_1}\n= -(t-o) \\cdot o \\cdot (1-o) \\cdot z_1\n\\tag{15}\\] Vi kan nu udlede den første opdateringsregel for vægten \\(w_1\\) ved at bruge idéen fra (13): \\[\nw_1 \\leftarrow w_1 - \\eta  \\cdot \\frac{\\partial E}{\\partial w_1}\n\\] Indsættes udtrykket fra (15), får vi \\[\nw_1 \\leftarrow w_1 - \\eta  \\cdot (-(t-o) \\cdot o \\cdot (1-o) \\cdot z_1)\n\\] Det vil sige, at \\[\nw_1 \\leftarrow w_1 + \\eta  \\cdot (t-o) \\cdot o \\cdot (1-o) \\cdot z_1\n\\] Det er værd at dvæle lidt ved opdateringsleddet \\(\\eta  \\cdot (t-o) \\cdot o \\cdot (1-o) \\cdot z_1\\) på højresiden, fordi det faktisk giver intuitiv god mening. For det første er \\(\\eta\\), det vi som sagt kalder for vores learning rate - et lille positivt tal, som sørger for, at vi ikke tager for store skridt på vores vej ned i dalen (til det lokale minimum). Faktoren \\(t-o\\) er jo netop fejlen. Nemlig forskellen mellem det vi ønsker \\(t\\) (target), og det som netværket giver \\(o\\) (output). Jo større fejl/forskel, desto mere må vi justere vægten. Ser vi på faktoren \\(o\\cdot(1-o)\\), så vil det være sådan, at hvis outputværdien \\(o\\) er tæt på enten \\(0\\) eller \\(1\\) (man siger at neuronen er \"mættet\"), så vil \\(o\\cdot(1-o)\\) være tæt på \\(0\\). Det vil sige, at hvis outputværdien er tæt på \\(0\\) eller \\(1\\), så ændrer vi heller ikke så meget på vægten. Endelig er der faktoren \\(z_1\\), som er inputtet fra det foregående lag (se figur 3). Hvis værdien af denne er (numerisk) stor, så får det også stor betydning for opdateringsleddet (eller tænk på det omvendt: hvis \\(z_1\\) er tæt på \\(0\\), så har \\(z_1\\) alligevel ikke så stor indflydelse på outputværdien, og så giver det heller ikke mening at justere så meget på den tilhørende vægt \\(w_1\\)).\nDet viser sig faktisk, at faktoren \\((t-o) \\cdot o \\cdot (1-o)\\) kommer til at gå igen rigtige mange gange i det følgende. Det bliver i længden lidt tungt at slæbe rundt på. Derfor vælger vi at definere \\[\n\\delta = (t-o) \\cdot o \\cdot (1-o)\n\\tag{16}\\] og derfor kan opdateringsreglen for \\(w_1\\) nu også skrives: \\[\nw_1 \\leftarrow w_1 + \\eta  \\cdot \\delta \\cdot z_1\n\\tag{17}\\]\nHelt analogt med ovenstående kan man udlede opdateringsregler for \\(w_2\\) og \\(w_0\\). Resultatet er samlet her.\n\n\n\n\n\n\nOpdateringsregler for \\(w\\)-vægtene\n\n\n\n\n\n\\[\\begin{align*}\nw_0 &\\leftarrow w_0 + \\eta  \\cdot \\delta  \\\\\nw_1 &\\leftarrow w_1 + \\eta  \\cdot \\delta \\cdot z_1 \\\\\nw_2 &\\leftarrow w_2 + \\eta  \\cdot \\delta \\cdot z_2 \\\\\n\\end{align*}\\] hvor \\[\\delta = (t-o) \\cdot o \\cdot (1-o)\\]\n\n\n\nMen hvordan foregår det der med de opdateringsregler så egentligt? Jo altså vi starter med at sætte vægtene mere eller mindre tilfældigt. Så laver vi ved hjælp af vores træningseksempel \\((\\vec{x},t)\\) et feedforward i netværket, som det er beskrevet i afsnit 3. Derfor får vi beregnet outputværdien \\(o\\) samt \\(z_1\\) og \\(z_2\\) (husk at \\(z_1\\) og \\(z_2\\) bruges til at beregne \\(o\\)). Desuden kender vi jo fra vores træningsdata target-værdien \\(t\\). Og voila! Alt hvad der indgår på højresiderne i ovenstående opdateringsregler har vi nu adgang til, og vi kan derfor beregne de nye \\(w\\) vægte.\nSå mangler vi bare at finde opdateringsreglerne for de restende vægte!"
  },
  {
    "objectID": "materialer/neurale_net/neurale_net.html#video-kunstige-neurale-netværk-5",
    "href": "materialer/neurale_net/neurale_net.html#video-kunstige-neurale-netværk-5",
    "title": "Kunstige neurale netværk",
    "section": "VIDEO: Kunstige neurale netværk 5",
    "text": "VIDEO: Kunstige neurale netværk 5\nI videoen her forklarer vi hvordan \\(w\\)-vægtene opdateres."
  },
  {
    "objectID": "materialer/neurale_net/neurale_net.html#sec-opdatering_uv",
    "href": "materialer/neurale_net/neurale_net.html#sec-opdatering_uv",
    "title": "Kunstige neurale netværk",
    "section": "Opdatering af \\(u\\)- og \\(v\\)-vægtene",
    "text": "Opdatering af \\(u\\)- og \\(v\\)-vægtene\nVi går nu et trin længere tilbage i netværket - væk fra outputlaget. Her kan vi se neuronerne, som fyrer værdierne \\(z_1\\) og \\(z_2\\), som bliver påvirket af \\(u\\)- og \\(v\\)-vægtene. Lad os her starte med at bestemme opdateringsreglerne for \\(v\\)-vægtene. For at gøre det skal vi finde ud af hvordan \\(v\\)-vægtene påvirker neuronerne længere fremme i netværket. Se igen på figur 3. Her er det tydeligt, at \\(v\\)-vægtene påvirker den mørkegrønne neuron, som fyrer værdien \\(z_1\\), som igen påvirker outputværdien. Derfor kan vi bruge kædereglen på følgende måde: \\[\n\\frac{\\partial E}{\\partial v_1} = \\frac{d E}{d o} \\cdot \\frac{\\partial o}{\\partial z_1} \\cdot \\frac{\\partial z_1}{\\partial v_1}\n\\] Vi ved allerede fra (14), at \\[\n\\frac{d E}{d o} = -(t-o)\n\\] Den partielle afledede af \\(o\\) med hensyn til \\(z_1\\) finder vi ved at bruge definitionen af outputværiden \\(o\\) i (10) \\[\n\\begin{aligned}\n\\frac{\\partial o}{\\partial z_1} &= \\sigma'(w_1 \\cdot z_1+w_2 \\cdot z_2 + w_0) \\cdot w_1  \\\\\n&= \\sigma(w_1 \\cdot z_1+w_2 \\cdot z_2 + w_0) \\cdot (1-\\sigma(w_1 \\cdot z_1+w_2 \\cdot z_2 + w_0)) \\cdot w_1  \\\\\n&= o \\cdot (1-o) \\cdot w_1\n\\end{aligned}\n\\tag{18}\\] hvor vi igen har brugt sætning 1. Og endelig ved at udnytte definitionen af \\(z_1\\) i (8) får vi, at \\[\\begin{align}\n\\frac{\\partial z_1}{\\partial v_1} &= \\sigma'(v_1 \\cdot y_1+v_2 \\cdot y_2 + v_0) \\cdot y_1 \\\\\n&= \\sigma(v_1 \\cdot y_1+v_2 \\cdot y_2 + v_0) \\cdot (1-\\sigma(v_1 \\cdot y_1+v_2 \\cdot y_2 + v_0)) \\cdot y_1 \\\\\n&= z_1 \\cdot (1-z_1) \\cdot y_1\n\\end{align}\\] Sætter vi det hele sammen får vi, at \\[\n\\frac{\\partial E}{\\partial v_1} = \\underbrace{-(t-o)}_{\\frac{\\partial E}{\\partial o}}  \\cdot \\underbrace{o \\cdot (1-o) \\cdot w_1}_{\\frac{\\partial o}{\\partial z_1}} \\cdot \\underbrace{z_1 \\cdot (1-z_1) \\cdot y_1}_{\\frac{\\partial z_1}{\\partial v_1}}\n\\] og bruger vi definitionen af \\(\\delta\\) i (16) får vi et lidt mere kompakt udtryk \\[\n\\frac{\\partial E}{\\partial v_1} = -\\delta \\cdot w_1 \\cdot z_1 \\cdot (1-z_1) \\cdot y_1\n\\] Opdateringsreglen for \\(v_1\\) bliver derfor \\[\nv_1 \\leftarrow v_1 - \\eta \\cdot \\frac{\\partial E}{\\partial v_1}\n\\] og med det netop udledte udtryk for \\(\\frac{\\partial E}{\\partial v_1}\\) får vi \\[\nv_1 \\leftarrow v_1 - \\eta \\cdot (-\\delta \\cdot w_1 \\cdot z_1 \\cdot (1-z_1)\\cdot y_1)\n\\] Det vil sige, at \\[\nv_1 \\leftarrow v_1 + \\eta \\cdot \\delta \\cdot w_1 \\cdot z_1 \\cdot (1-z_1) \\cdot y_1\n\\] Læg igen mærke til, at når vi har været igennem et feedforward i netværket, så kender vi alle de størrelser, som indgår i ovenstående udtryk.\nPå helt tilsvarende vis kan man bestemme opdateringsreglerne for \\(v_0\\) og \\(v_2\\). De tre opdateringsregler for \\(v\\)-vægtene ses her:\n\n\n\n\n\n\nOpdateringsregler for \\(v\\)-vægtene\n\n\n\n\n\n\\[\\begin{align}\nv_0 &\\leftarrow v_0 + \\eta  \\cdot \\delta \\cdot w_1 \\cdot z_1 \\cdot (1-z_1) \\\\\nv_1 &\\leftarrow v_1 + \\eta  \\cdot \\delta \\cdot w_1 \\cdot z_1 \\cdot (1-z_1) \\cdot y_1 \\\\\nv_2 &\\leftarrow v_2 + \\eta  \\cdot \\delta \\cdot w_1 \\cdot z_1 \\cdot (1-z_1) \\cdot y_2 \\\\\n\\end{align}\\] hvor \\[\n\\delta = (t-o) \\cdot o \\cdot (1-o)\n\\]\n\n\n\nOpdateringsreglerne for \\(u\\)-vægtene findes på præcis samme måde. Her skal man blot se, at \\(u\\)-vægtene har indflydelse på outputtet via \\(z_2\\) (se figur 3). Derfor skal man f.eks. finde den partielle afledede af \\(E\\) med hensyn til \\(u_1\\) ved at bruge kædereglen på denne måde \\[\n\\frac{\\partial E}{\\partial u_1} = \\frac{d E}{d o} \\cdot \\frac{\\partial o}{\\partial z_2} \\cdot \\frac{\\partial z_2}{\\partial u_1}\n\\] Udregninger svarende til det netop gennemgåede giver os\n\n\n\n\n\n\nOpdateringsregler for \\(u\\)-vægtene\n\n\n\n\n\n\\[\\begin{align}\nu_0 &\\leftarrow u_0 + \\eta  \\cdot \\delta \\cdot w_2 \\cdot z_2 \\cdot (1-z_2) \\\\\nu_1 &\\leftarrow u_1 + \\eta  \\cdot \\delta \\cdot w_2 \\cdot z_2 \\cdot (1-z_2) \\cdot y_1 \\\\\nu_2 &\\leftarrow u_2 + \\eta  \\cdot \\delta \\cdot w_2 \\cdot z_2 \\cdot (1-z_2) \\cdot y_2 \\\\\n\\end{align}\\] hvor \\[\n\\delta = (t-o) \\cdot o \\cdot (1-o)\n\\]"
  },
  {
    "objectID": "materialer/neurale_net/neurale_net.html#video-kunstige-neurale-netværk-6",
    "href": "materialer/neurale_net/neurale_net.html#video-kunstige-neurale-netværk-6",
    "title": "Kunstige neurale netværk",
    "section": "VIDEO: Kunstige neurale netværk 6",
    "text": "VIDEO: Kunstige neurale netværk 6\nI videoen her forklarer vi, hvordan \\(v\\)-vægtene opdateres."
  },
  {
    "objectID": "materialer/neurale_net/neurale_net.html#sec-opdatering_rs",
    "href": "materialer/neurale_net/neurale_net.html#sec-opdatering_rs",
    "title": "Kunstige neurale netværk",
    "section": "Opdatering af \\(r\\)- og \\(s\\)-vægtene",
    "text": "Opdatering af \\(r\\)- og \\(s\\)-vægtene\nSå er vi endelig fremme ved \\(r\\)- og \\(s\\) vægtene. Start lige med at tage en dyb indånding! Nu bliver det lidt mere kompliceret. Se på figur 3. Lad os starte med at finde den partielle afledede af \\(E\\) med hensyn til \\(r_1\\). Når man ser på netværket, kan man se, at \\(r_1\\) i første omgang påvirker \\(y_1\\), \\(y_1\\) påvirker både \\(z_1\\) og \\(z_2\\), som så til sidst påvirker outputværdien \\(o\\). Det kan illustreres sådan her \\[\n\\begin{matrix}\n& & & & z_1 & & & \\\\\n& & & \\nearrow & & \\searrow & & \\\\\nr_1 & \\rightarrow & y_1 & & & & \\rightarrow & o \\\\\n& & & \\searrow & & \\nearrow & & \\\\\n& & & & z_2 & & & \\\\\n\\end{matrix}\n\\]\nBalladen er, at \\(y_1\\) både påvirker \\(z_1\\) og \\(z_2\\), og det gør det hele lidt mere kompliceret. Lad os lige starte med at se bort fra det. Ifølge kædereglen får vi så: \\[\n\\frac{\\partial E}{\\partial r_1} = \\frac{d E}{d o} \\cdot \\frac{\\partial o}{\\partial y_1}  \\cdot \\frac{\\partial y_1}{\\partial r_1}\n\\] Men så var det jo, at \\(o\\) i virkeligheden afhænger af \\(y_1\\) både via \\(z_1\\) og \\(z_2\\). Man kunne skrive det sådan her: \\[\no(z_1(y_1), z_2(y_1))\n\\] Bemærk, at \\(z_1\\) og \\(z_2\\) jo også afhænger af \\(y_2\\), men når vi skal differentiere med hensyn til \\(y_1\\), så er \\(y_2\\) at betragte som en konstant. Og når konstanter bliver differentieret, så giver det som bekendt \\(0\\).\nDerfor: For at finde den partielle afledede af \\(o\\) med hensyn til \\(y_1\\) må vi benytte kædereglen for funktioner af flere variable. Den siger, at \\[\n\\frac{\\partial o}{\\partial y_1} = \\frac{\\partial o}{\\partial z_1} \\cdot \\frac{\\partial z_1}{\\partial y_1} + \\frac{\\partial o}{\\partial z_2} \\cdot \\frac{\\partial z_2}{\\partial y_1}\n\\] Det samlede udtryk for den partielle afledede af \\(E\\) med hensyn til \\(r_1\\) bliver derfor \\[\n\\frac{\\partial E}{\\partial r_1} = \\frac{d E}{d o} \\cdot\n\\left(\n\\frac{\\partial o}{\\partial z_1} \\cdot \\frac{\\partial z_1}{\\partial y_1} + \\frac{\\partial o}{\\partial z_2} \\cdot \\frac{\\partial z_2}{\\partial y_1}\n\\right)\n\\cdot \\frac{\\partial y_1}{\\partial r_1}\n  \\tag{19}\\] Vi finder hver af de afledede, som indgår i ovenstående udtryk én ad gangen. Vi ved allerede fra (14), at \\[\n\\frac{d E}{d o} = \\frac{1}{2} \\cdot 2 \\cdot (t-o) \\cdot (-1) = -(t-o)\n\\] Vi ved også fra (18), at \\[\n\\frac{\\partial o}{\\partial z_1} = o \\cdot (1-o) \\cdot w_1\n\\] Differentieres \\(z_1\\) (se (8)) med hensyn til \\(y_1\\) får vi \\[\\begin{align}\n\\frac{\\partial z_1}{\\partial y_1} &= \\sigma'(v_1 \\cdot y_1 + v_2 \\cdot y_2 + v_0)\\cdot v_1 \\\\\n&= z_1 \\cdot (1-z_1) \\cdot v_1\n\\end{align}\\] hvor vi igen har brugt sætning 1 og definitionen af \\(z_1\\) i (8). Helt tilsvarende kan vi finde \\(\\frac{\\partial o}{\\partial z_2}\\) og \\(\\frac{\\partial z_2}{\\partial y_1}\\) (se (9)) \\[\n\\frac{\\partial o}{\\partial z_2} = o \\cdot (1-o)\\cdot w_2\n\\] og \\[\n\\frac{\\partial z_2}{\\partial y_1} = z_2 \\cdot (1-z_2)\\cdot u_1\n\\] Den sidste partielle afledede \\(\\frac{\\partial y_1}{\\partial r_1}\\) finder vi ved at differentiere udtrykket for \\(y_1\\) i (4), hvor vi endnu engang udnytter sætning 1.\nIndsætter vi nu alle de udtryk, som vi netop har udledt, i (19) får vi et temmelig langt udtryk for \\(\\frac{\\partial E}{\\partial r_1}\\): \\[\\begin{align}\n\\frac{\\partial E}{\\partial r_1} &= \\underbrace{-(t-o)}_{\\frac{dE}{do}}\\cdot \\\\ &\\Big( \\underbrace{o\\cdot(1-o)\\cdot w_1}_{\\frac{\\partial o}{\\partial z_1}} \\cdot \\underbrace{z_1\\cdot(1-z_1)\\cdot v_1}_{\\frac{\\partial z_1}{\\partial y_1}}+\\underbrace{o\\cdot(1-o)\\cdot w_2}_{\\frac{\\partial o}{\\partial z_2}}\\cdot \\underbrace{z_2\\cdot(1-z_2)\\cdot u_1}_{\\frac{\\partial z_2}{\\partial y_1}}\\Big)\\cdot \\\\ & \\qquad \\underbrace{y_1\\cdot(1-y_1)\\cdot x_1}_{\\frac{\\partial y_1}{\\partial r_1}}\n\\end{align}\\] Og sætter vi \\(o\\cdot(1-o)\\) uden for parentesen og erstatter \\((t-o)\\cdot o\\cdot (1-o)\\) med \\(\\delta\\) får vi \\[\n\\frac{\\partial E}{\\partial r_1}\n=-\\delta \\cdot \\Big(w_1 \\cdot z_1\\cdot (1-z_1)\\cdot v_1+w_2 \\cdot z_2 \\cdot (1-z_2)\\cdot  u_1 \\Big) \\cdot y_1\\cdot (1-y_1) \\cdot x_1\n\\] Helt i tråd med tidligere får vi altså følgende opdateringsregel for \\(r_1\\) \\[r_1 \\leftarrow r_1 - \\eta \\cdot \\frac{\\partial E}{\\partial r_1} \\] Det vil sige \\[\nr_1 \\leftarrow r_1 + \\eta \\cdot \\delta \\cdot \\Big(w_1 \\cdot z_1\\cdot (1-z_1)\\cdot v_1+w_2 \\cdot z_2 \\cdot (1-z_2)\\cdot  u_1 \\Big) \\cdot y_1\\cdot (1-y_1) \\cdot x_1\n\\]\nUdleder man tilsvarende opdateringsregler for \\(r_2, r_3, r_4\\) og \\(r_0\\) vil man se, at det eneste, som kommer til at ændre sig i ovenstående, er den sidste faktor \\(x_1\\), som bliver erstattet med henholdsvis \\(x_2, x_3, x_4\\) og \\(1\\). Derfor får vi samlet set\n\n\n\n\n\n\nOpdateringsregler for \\(r\\)-vægtene\n\n\n\n\n\n\\[\\begin{align}\nr_0 &\\leftarrow r_0 +  \\eta \\cdot \\delta \\cdot \\Big(w_1 \\cdot z_1\\cdot (1-z_1)\\cdot v_1+w_2 \\cdot z_2 \\cdot (1-z_2)\\cdot  u_1 \\Big) \\cdot y_1\\cdot (1-y_1) \\\\\nr_1 &\\leftarrow r_1 +  \\eta \\cdot \\delta \\cdot \\Big(w_1 \\cdot z_1\\cdot (1-z_1)\\cdot v_1+w_2 \\cdot z_2 \\cdot (1-z_2)\\cdot  u_1 \\Big) \\cdot y_1\\cdot (1-y_1) \\cdot x_1\\\\\nr_2 &\\leftarrow r_2 +  \\eta \\cdot \\delta \\cdot \\Big(w_1 \\cdot z_1\\cdot (1-z_1)\\cdot v_1+w_2 \\cdot z_2 \\cdot (1-z_2)\\cdot  u_1 \\Big) \\cdot y_1\\cdot (1-y_1) \\cdot x_2\\\\\nr_3 &\\leftarrow r_3 +  \\eta \\cdot \\delta \\cdot \\Big(w_1 \\cdot z_1\\cdot (1-z_1)\\cdot v_1+w_2 \\cdot z_2 \\cdot (1-z_2)\\cdot  u_1 \\Big) \\cdot y_1\\cdot (1-y_1) \\cdot x_3\\\\\nr_4 &\\leftarrow r_4 +  \\eta \\cdot \\delta \\cdot \\Big(w_1 \\cdot z_1\\cdot (1-z_1)\\cdot v_1+w_2 \\cdot z_2 \\cdot (1-z_2)\\cdot  u_1 \\Big) \\cdot y_1\\cdot (1-y_1) \\cdot x_4\\\\\n\\end{align}\\] hvor \\[\n\\delta = (t-o) \\cdot o \\cdot (1-o)\n\\]\n\n\n\nOpdateringen af \\(s\\)-vægtene foregår på samme måde. Hvis du ser på figur 3, kan du se, at alle \\(s\\)-vægtene påvirker \\(y_2\\), som så påvirker både \\(z_1\\) og \\(z_2\\), som i sidste ende påvirker outputtet \\(o\\). Ser vi generelt på vægten \\(s_i\\), hvor \\(i=0, 1, 2, 3\\) eller \\(4\\), har vi altså \\[\n\\begin{matrix}\n& & & & z_1 & & & \\\\\n& & & \\nearrow & & \\searrow & & \\\\\ns_i & \\rightarrow & y_2 & & & & \\rightarrow & o \\\\\n& & & \\searrow & & \\nearrow & & \\\\\n& & & & z_2 & & & \\\\\n\\end{matrix}\n\\] Som tidligere kan vi starte med at skrive \\[\n\\frac{\\partial E}{\\partial s_i} = \\frac{d E}{d o} \\cdot \\frac{\\partial o}{\\partial y_2}  \\cdot \\frac{\\partial y_2}{\\partial s_i}\n\\] og bruger vi igen kædreglen for funktioner af flere variable, får vi \\[\n\\frac{\\partial E}{\\partial s_i} = \\frac{d E}{d o} \\cdot\n\\left(\n\\frac{\\partial o}{\\partial z_1} \\cdot \\frac{\\partial z_1}{\\partial y_2} + \\frac{\\partial o}{\\partial z_2} \\cdot \\frac{\\partial z_2}{\\partial y_2}\n\\right)\n\\cdot \\frac{\\partial y_2}{\\partial s_i}\n\\] I ovenstående udtryk bliver det klart, at opdateringsreglerne vil blive ens bortset fra den sidste faktor.\nNu udledes alle de partielle afledede, fuldstændig som for \\(r\\)-vægtene og vi ender med følgende opdateringsregler for \\(s\\)-vægtene:\n\n\n\n\n\n\nOpdateringsregler for \\(s\\)-vægtene\n\n\n\n\n\n\\[\\begin{align}\ns_0 &\\leftarrow s_0 +  \\eta \\cdot \\delta \\cdot \\Big(w_1 \\cdot z_1\\cdot (1-z_1)\\cdot v_2+w_2 \\cdot z_2 \\cdot (1-z_2)\\cdot  u_2 \\Big) \\cdot y_2\\cdot (1-y_2) \\\\\ns_1 &\\leftarrow s_1 + \\eta \\cdot \\delta \\cdot \\Big(w_1 \\cdot z_1\\cdot (1-z_1)\\cdot v_2+w_2 \\cdot z_2 \\cdot (1-z_2)\\cdot  u_2 \\Big) \\cdot y_2\\cdot (1-y_2) \\cdot x_1\\\\\ns_2 &\\leftarrow s_2 + \\eta \\cdot \\delta \\cdot \\Big(w_1 \\cdot z_1\\cdot (1-z_1)\\cdot v_2+w_2 \\cdot z_2 \\cdot (1-z_2)\\cdot  u_2 \\Big) \\cdot y_2\\cdot (1-y_2)  \\cdot x_2\\\\\ns_3 &\\leftarrow s_3 + \\eta \\cdot \\delta \\cdot \\Big(w_1 \\cdot z_1\\cdot (1-z_1)\\cdot v_2+w_2 \\cdot z_2 \\cdot (1-z_2)\\cdot  u_2 \\Big) \\cdot y_2\\cdot (1-y_2)  \\cdot x_3\\\\\ns_4 &\\leftarrow s_4 + \\eta \\cdot \\delta \\cdot \\Big(w_1 \\cdot z_1\\cdot (1-z_1)\\cdot v_2+w_2 \\cdot z_2 \\cdot (1-z_2)\\cdot  u_2 \\Big) \\cdot y_2\\cdot (1-y_2)  \\cdot x_4\\\\\n\\end{align}\\] hvor \\[\n\\delta = (t-o) \\cdot o \\cdot (1-o)\n\\]\n\n\n\nDet var faktisk det! Altså det blev jo en værre omgang bogstavgymnastik, men faktum er, at vi er i mål med at udlede backpropagation algoritmen for vores simple netværk i figur 3. Hurra for det!"
  },
  {
    "objectID": "materialer/neurale_net/neurale_net.html#video-kunstige-neurale-netværk-7",
    "href": "materialer/neurale_net/neurale_net.html#video-kunstige-neurale-netværk-7",
    "title": "Kunstige neurale netværk",
    "section": "VIDEO: Kunstige neurale netværk 7",
    "text": "VIDEO: Kunstige neurale netværk 7\nI denne video forklares hvordan \\(r\\)-vægtene opdateres."
  },
  {
    "objectID": "materialer/logistisk/log-reg.html",
    "href": "materialer/logistisk/log-reg.html",
    "title": "Logistisk regression",
    "section": "",
    "text": "I denne note skal vi se på logistisk regression. Måske har du allerede hørt begrebet \"logistisk\" i gymnasieundervisningen i forbindelse med logistisk vækst. Det er et helt andet emne end logistisk regression. Det eneste, de to emner umiddelbart har til fælles, er, at den logistiske funktion spiller en rolle begge steder. I slutningen af noten vil vi dog se et eksempel, hvor der alligevel er en sammenhæng mellem logistisk regression og logistisk vækst."
  },
  {
    "objectID": "materialer/logistisk/log-reg.html#logistisk-regression-og-hjerte-kar-sygdom",
    "href": "materialer/logistisk/log-reg.html#logistisk-regression-og-hjerte-kar-sygdom",
    "title": "Logistisk regression",
    "section": "Logistisk regression og hjerte-kar-sygdom",
    "text": "Logistisk regression og hjerte-kar-sygdom\nEn helt central tankegang i mange metoder inden for kunstig intelligens er, at man på baggrund af en masse træningsdata for eksempel gerne vil afgøre om en patient er syg eller ej. En populær metode til det er at bruge et kunstigt neuralt netværk, som er en slags black-box-metode, og som du kan læse mere om her. Men hvis man lige præcis bruger et særligt slags neuralt netværk med et enkelt lag, er det faktisk ækvivalent med den meget ældre metode \"logistisk regression\", som vi gennemgår her, og som har den store fordel, at man kan forstå og fortolke modellen.\nLogistisk regression, i den betydning vi betragter i denne note, bruges, når man gerne vil modellere, hvordan en sandsynlighed afhænger af en variabel. Som et eksempel forestiller vi os, at vi vil undersøge, hvordan sandsynligheden for at lide af hjerte-kar-sygdom afhænger af det systoliske blodtryk. Vi kigger derfor på et datasæt bestående af 2000 mennesker, som har fået målt deres blodtryk. Desuden har de fået undersøgt, om de lider af hjerte-kar-sygdom. Datasættet er fiktivt, men det er lavet til at ligne virkelige data1. Vi kalder blodtrykket for \\(x\\), mens vi lader \\(y\\) være en variabel, der er \\(1\\) hvis personen lider af hjertekarsygdom og \\(0\\) ellers. På figur 1 har vi tegnet samhørende \\(x\\)- og \\(y\\)-værdier ind i et koordinatsystem for de første 200 personer i datasættet.\n1 De fleste mennesker har et systolisk blodtryk mellem 100 og 180 mmHg. I datasættet har vi genereret en masse mennesker med ekstremt højt eller lavt blodtryk for illustrationens skyld, selv om det er urealistisk i praksis.\n\n\n\n\n\n\n\nFigur 1: Her ses et plot af data med blodtryk på \\(x\\)-aksen og sygdomsstatus på \\(y\\)-aksen.\n\n\n\n\n\nDet ses på figur 1, at der er flest personer med \\(y\\)-værdien 0, altså raske personer, blandt folk med lavt blodtryk, mens der er flest med \\(y\\)-værdien 1, svarende til syge, blandt folk med højt blodtryk. Ved de fleste blodtryksværdier er der dog både syge og raske, og det er svært at få et præcist overblik ud fra figuren.\nSå hvordan kan man beskrive sammenhængen mellem \\(x\\) og \\(y\\)? I stedet for at se direkte på sammenhængen mellem \\(x\\) og \\(y\\), vil vi se på hvordan sandsynligheden for hjerte-kar-sygdom afhænger af blodtrykket. Vi vil betragte denne sandsynlighed som en funktion \\(p(x)\\) af blodtrykket \\(x\\). Vi vil nu se på, hvordan man kan modellere denne funktion.\nFor at få en idé om, hvordan \\(p(x)\\) kunne se ud, kigger vi på datasættet fra før. Vi inddeler blodtrykket i intervaller af længde 25 og tæller op, hvor mange syge og raske der er inden for hvert interval.\n\n\n\n\n\n\n\n\nBlodtryk\nRask\nSyg\nAndel syge\n\n\n\n\n(75,100]\n168\n29\n0.147\n\n\n(100,125]\n195\n45\n0.188\n\n\n(125,150]\n143\n63\n0.306\n\n\n(150,175]\n152\n105\n0.409\n\n\n(175,200]\n93\n135\n0.592\n\n\n(200,225]\n57\n136\n0.705\n\n\n(225,250]\n46\n179\n0.796\n\n\n(250,275]\n25\n204\n0.891\n\n\n(275,300]\n19\n206\n0.916\n\n\n\n\n\n\nTabel 1: Tabel over syge og raske inden for forskellige blodtryksintervaller.\n\n\n\n\nDesuden har vi beregnet, hvor stor en andel af patienterne inden for hvert interval, der lider af hjerte-kar-sygdom. Dette bruges som et estimat for sandsynligheden for hjerte-kar-sygdom i den gruppe. For eksempel er der 195 raske og 45 syge personer med et blodtryk i intervallet (100,125]. Sammenlagt er der \\(195+45 = 240\\) personer i dette interval. Andelen af syge i denne gruppe er derfor \\[\n\\frac{45}{240} \\approx 0.188.\n\\] På figur 2 har vi tegnet disse andele ind i et koordinatsystem. For hvert blodtryksinterval er midtpunktet for intervallet indtegnet som \\(x\\)-værdien, og andelen af syge er indtegnet som den tilhørende \\(y\\)-værdi2.\n2 Det er klart, at vælger man nogle andre intervaller, så vil man få et lidt andet resultat. Bemærk også, at vi her bruger midtpunktet af intervallet i figur 2. Det er i modsætning til, når vi tegner sumkurver, hvor højre intervalendepunkt benyttes.\n\n\n\n\n\n\n\nFigur 2: Andel syge inden for hvert blodtryksinterval.\n\n\n\n\n\nUmiddelbart kunne det være fristende at lave lineær regression. Vi forestiller os altså en forskrift \\[\n    p(x) = ax + b.\n\\] På figur 3 har vi indtegnet den bedste rette linje i figur 2.\n\n\n\n\n\n\n\n\nFigur 3: Grafen for \\(p(x)\\) tilnærmet med en ret linje.\n\n\n\n\n\nDer er et problem her: En sandsynlighed ligger altid mellem 0 og 1, men regressionslinjen ovenfor skærer \\(x\\)-aksen ved blodtryksværdier omkring 70. Det betyder, at sandsynligheden er negativ for blodtryk under 70. Tilsvarende får vi sandsynligheder, der er større end 1 ved blodtryk over 300. Det giver selvfølgelig ikke mening.\nHvis vi kigger på figur 3 igen, ser sammenhængen da heller ikke lineær ud, men snarere S-formet. I stedet for en ret linje, ville det give mening at lade \\(p\\) være en funktion med en S-formet graf som indtegnet i figur 4.\n\n\n\n\n\n\n\n\nFigur 4: Graf for \\(p(x)\\) tilnærmet med en S-formet kurve.\n\n\n\n\n\nFor at komme nærmere hvordan funktionsforskriften for \\(p\\) skal se ud, viser det sig, at være smart at se på oddsene for sygdom i stedet for sandsynligheden3.\n3 Du kender måske begrebet odds fra sportsgambling. Det er dog en anden betydning af ordet, end det vi bruger her. Inden for gambling angiver odds, hvor mange gange man får pengene igen, hvis en bestemt hændelse indtræffer(for eksempel at et bestemt hold vinder). Gambling odds er naturligvis også udregnet ud fra sandsynligheden for hændelsen, men de er altid justeret for at sikre, at bookmakeren vinder i det lange løb.\nVIDEO: Dataeksemplet\nI denne video præsenteres dataeksemplet."
  },
  {
    "objectID": "materialer/logistisk/log-reg.html#odds",
    "href": "materialer/logistisk/log-reg.html#odds",
    "title": "Logistisk regression",
    "section": "Odds",
    "text": "Odds\nOddsene \\(O\\) for en hændelse er defineret som sandsynligheden \\(p\\) for hændelsen divideret med sandsynligheden for, at hændelsen ikke indtræffer (det kaldes også for komplementærhændelsen), som er \\(1-p\\). Altså er \\[\n    O=\\frac{p}{1-p}.\n\\] Odds måler således, hvor mange gange mere sandsynlig en hændelse er i forhold til komplementærhændelsen. Hvis for eksempel sandsynligheden for hjerte-kar-sygdom er \\(p=\\frac{4}{5}\\), så er odds for sygdom \\[\n    O=\\frac{\\frac{4}{5}}{\\frac{1}{5}} = 4.\n\\] Det er altså fire gange så sandsynligt at være syg som at være rask.\nFor at få en lidt bedre fornemmelse for, hvordan odds fungerer, kan vi lave en tabel, der viser odds svarende til forskellige værdier af \\(p\\):\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(p\\)\n\\(\\frac{1}{5}\\)\n\\(\\frac{1}{4}\\)\n\\(\\frac{1}{3}\\)\n\\(\\frac{1}{2}\\)\n\\(\\frac{2}{3}\\)\n\\(\\frac{3}{4}\\)\n\\(\\frac{4}{5}\\)\n\n\n\n\n\\(O\\)\n\\(\\frac{1}{4}\\)\n\\(\\frac{1}{3}\\)\n\\(\\frac{1}{2}\\)\n1\n2\n3\n4\n\n\n\nLæg her mærke til at jo større \\(p\\) bliver, desto større bliver odds \\(O\\) også.\nFunktionen, der omdanner sandsynligheder til odds, har forskriften \\[\nO(p) = \\frac{p}{1-p}.\n\\] Definitionsmængden for \\(O\\) er \\(]0,1[\\). Bemærk, at \\(1\\) ikke er med i definitionsmængden, fordi vi så vil komme til at dividere med \\(0\\) i ovenstående udtryk. Vi tillader heller ikke, at \\(0\\) er med i definitionsmængden. Der er ikke noget i vejen for at udregne odds til \\(0\\) (det vil bare give \\(0\\)), men det hænger sammen med, at vi senere gerne vil tage logaritmen til odds, og logaritmen er som bekendt kun defineret for positive tal og altså ikke for \\(0\\).\nGrafen for \\(O\\) er vist på figur 5.\n\n\n\n\n\n\n\n\nFigur 5: Grafen for odds-funktionen.\n\n\n\n\n\nVi kan se på figur 5, at odds-funktionen \\(O\\) er voksende. Det kan også bevises ved at vise, at \\(O'(p)&gt;0\\) for alle værdier af \\(p\\). Vi ser desuden, at \\(O(p)\\) altid er positiv, da både tæller og nævner er positive. Når \\(p\\) nærmer sig \\(0\\), nærmer tælleren sig \\(0\\), mens nævneren nærmer sig \\(1\\), så \\(O(p)\\) går mod \\(0\\). Når \\(p\\) nærmer sig \\(1\\), nærmer tælleren sig \\(1\\), og nævneren nærmer sig \\(0\\), så hele brøken \\(O(p)\\) går mod uendelig. Værdimængden for \\(O\\) består derfor af alle de positive reelle tal.\n\nVIDEO: Odds\nVi giver her en introduktion til begrebet odds."
  },
  {
    "objectID": "materialer/logistisk/log-reg.html#den-logistiske-regressionsmodel",
    "href": "materialer/logistisk/log-reg.html#den-logistiske-regressionsmodel",
    "title": "Logistisk regression",
    "section": "Den logistiske regressionsmodel",
    "text": "Den logistiske regressionsmodel\nI vores dataeksempel, hvor sandsynligheden for hjerte-kar-sygdom er en funktion \\(p(x)\\), bliver oddsene for hjerte-kar-sygdom også en funktion af \\(x\\) \\[\nO(p(x)) = \\frac{p(x)}{1-p(x)},\n\\] hvor \\(x\\) er blodtrykket.\nPå figur 6 vises dataeksemplet fra før, men nu har vi oddsene \\(O(p(x))\\) på \\(y\\)-aksen.\n\n\n\n\n\n\n\n\nFigur 6: Odds for hjerte-kar-sygdom inden for de forskellige blodtryksintervaller.\n\n\n\n\n\nVi ser, at oddsene for sygdom stiger med blodtrykket. Det betyder derfor også, at sandsynligheden for sygdom stiger med blodtrykket. Kigger vi på grafen, ser tendensen ikke lineær ud. Det kunne derimod ligne en eksponentiel vækst. For at bekræfte dette, laver vi samme plot på figur 7, men nu med den naturlige logaritme til oddsene \\(\\ln (O(p(x)))\\) på \\(y\\)-aksen4.\n4 Man kan nemlig vise, at hvis \\(y\\) afhænger eksponentielt af \\(x\\), så vil \\(\\ln(y)\\) afhænge lineært af \\(x\\).\n\n\n\n\n\n\n\nFigur 7: Den naturlige logaritme til odds for hjerte-kar-sygdom inden for de forskellige blodtryksintervaller.\n\n\n\n\n\nDer ser nu ud til at være en lineær sammenhæng! Det kunne altså tyde på, at ln-oddsene afhænger lineært af \\(x\\). Det leder os frem til følgende model for ln-oddsene: \\[\n\\ln (O(p(x))) = ax  + b.\n\\tag{1}\\] Denne model kaldes den logistiske regressionsmodel. Virkelige data følger ofte en logistisk regressionsmodel.\nI næste afsnit ser vi på, hvordan man kan finde et funktionsudtryk for \\(p(x)\\) i den logistiske regressionsmodel."
  },
  {
    "objectID": "materialer/logistisk/log-reg.html#logit-funktionen-og-den-logistiske-funktion",
    "href": "materialer/logistisk/log-reg.html#logit-funktionen-og-den-logistiske-funktion",
    "title": "Logistisk regression",
    "section": "Logit-funktionen og den logistiske funktion",
    "text": "Logit-funktionen og den logistiske funktion\nNår vi tager den naturlige logaritme til oddsene, får vi \\[\n\\ln (O(p)) = \\ln\\left(\\frac{p}{1-p}\\right).\n\\] Funktionen på højresiden kaldes \\(\\text{logit}\\) og er altså givet ved \\[\n\\text{logit}(p) = \\ln\\left(\\frac{p}{1-p}\\right).\n\\] Definitionsmængden for \\(\\text{logit}\\)-funktionen er ligesom for oddsene \\(]0,1[\\). Vi fandt tidligere, at værdimængden for oddsene består af alle de positive reelle tal. Dette er netop definitionsmængden for \\(\\ln\\). Værdimængden for \\(\\text{logit}\\) bliver derfor den samme som for \\(\\ln\\), nemlig alle de reelle tal. Grafen for \\(\\text{logit}\\) er vist på figur 8.\n\n\n\n\n\n\n\n\nFigur 8: Grafen for logit-funktionen.\n\n\n\n\n\nDen logistiske regressionsmodel i (1) kan skrives ved hjælp at \\(\\text{logit}\\)-funtionen som \\[\n\\text{logit}(p(x)) = \\ln (O(p(x))) = ax  + b.\n\\tag{2}\\] Egentlig var vi jo ude på at finde et udtryk for sandsynligheden \\(p(x)\\) som funktion af \\(x\\). Vi prøver derfor at isolere \\(p(x)\\) i (2). For at gøre det, finder vi først den omvendte (eller inverse) funktion til \\(\\text{logit}\\). Vi antager derfor, at \\[\ny = \\text{logit(p)} = \\ln\\left( \\frac{p}{1-p} \\right).\n\\] Vi skal så isolere \\(p\\) for at udtrykke \\(p\\) som funktion af \\(y\\). Vi tager først eksponentialfunktionen på begge sider af udtrykket og får \\[\ne^y =  \\frac{p}{1-p}.\n\\] Så ganger vi med \\((1-p)\\) på begge sider. Det giver \\[\ne^y(1-p) =p.\n\\] Hvis parentesen ophæves, får vi \\[\ne^y - p\\cdot e^y =p.\n\\]\nVi kan så lægge \\(p\\cdot e^y\\) til på begge sider og sætte \\(p\\) uden for parantes. Det giver \\[\\begin{align*}\ne^y &= p \\cdot e^y+p  \\\\\ne^y &= p\\cdot (e^y+1).\n\\end{align*}\\] Endelig kan vi isolere \\(p\\) og få \\[\n\\frac{e^y}{e^y+1} =p.\n\\] Her er \\(p\\) egentlig isoleret, men vi kan vælge at forkorte brøken med \\(e^y\\) for at få et andet udtryk for \\(p\\) \\[\np=\\frac{\\frac{e^y}{e^y}}{\\frac{e^y+1}{e^y}}=\\frac{\\frac{e^y}{e^y}}{\\frac{e^y}{e^y}+\\frac{1}{e^y}}    =\\frac{1}{1+e^{-y}} .\n\\]\nSammenlagt har vi vist, at den inverse funktion til logit er den standard logistiske funktion (også nogle gange kaldet sigmoid-funktionen) \\[\nf(y) = \\frac{1}{1+e^{-y}}.\n\\] Grafen for den standard logistiske funktion er indtegnet i figur 9. Vi ser, at grafen har en karakteristisk S-form, som vokser fra \\(0\\) mod \\(1\\).\n\n\n\n\n\n\n\n\nFigur 9: Grafen for den standard logistiske funktion\n\n\n\n\n\nBruger vi den inverse til \\(\\text{logit}\\) på begge sider af lighedstegnet i den logistiske regressionsmodel i (2), får vi isoleret \\(p(x)\\) \\[\np(x) = \\frac{1}{1+e^{-(ax+b)}}.\n\\tag{3}\\] Det ligner altså den standard logistiske funktion, men med \\((ax+b)\\) indsat på \\(y\\)’s plads. Denne funktion kaldes den generelle logistiske funktion.\n\nVIDEO: Den logistiske regressionsmodel og den logistiske funktion\nEn gennemgang af den logistiske regressionsmodel samt den logistiske funktion finder du i videoen her:"
  },
  {
    "objectID": "materialer/logistisk/log-reg.html#fortolkning-af-parametrene-i-den-logistiske-regressionsmodel",
    "href": "materialer/logistisk/log-reg.html#fortolkning-af-parametrene-i-den-logistiske-regressionsmodel",
    "title": "Logistisk regression",
    "section": "Fortolkning af parametrene i den logistiske regressionsmodel",
    "text": "Fortolkning af parametrene i den logistiske regressionsmodel\nHvordan skal vi forstå betydningen af konstanterne \\(a\\) og \\(b\\) i den logistiske regressionsmodel? Hvis man har en funktion \\(f\\), så svarer funktionen \\(f(ax)\\) til, at væksthastigheden er blevet sat op med en faktor \\(a\\). Alternativt kan man forestille sig, at \\(x\\)-aksen er blevet skaleret med en faktor \\(1/a\\). Grafen for \\(f(x-k)\\) svarer til, at man har forskudt grafen med \\(k\\) enheder i \\(x\\)-aksens retning. Hvis man kombinerer disse, kan man indse, at \\(f(ax+b)\\) svarer til først at øge væksthastigheden med en faktor \\(a\\) og derefter forskyde grafen med \\(k=\\frac{-b}{a}\\) i \\(x\\)-aksens retning, idet \\[\nf(ax+b)=f\\Big(a\\cdot \\Big(x-\\Big(\\frac{-b}{a}\\Big)\\Big)\\Big).\n\\]\nHvis man gør dette for den standard logistiske funktion, får man netop den generelle logistiske funktion \\[\nf(ax+b)= \\frac{1}{1+e^{-(ax+b)}}.\n\\] Sammenlignet med den standard logistiske funktion får man altså en \\(S\\)-formet kurve, der vokser \\(a\\) gange så hurtigt og er forskudt med \\(\\frac{-b}{a}\\).\nI app’en herunder ser du grafen for \\(f(x)=\\frac{1}{1+e^{-(ax+b)}}\\). Hvis du trækker i skyderne for \\(a\\) og \\(b\\), kan du se, hvordan kurven ændrer form. Den stiplede linje har ligning \\(x=\\frac{-b}{a}\\) og svarer altså til den vandrette forskydning af grafen for den standard logistiske funktion. På figuren er der desuden 9 punkter, som du kan få grafen til at passe bedst muligt med.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigur 10: Eksperimenter med a og b for at forstå deres betydning for grafen. Når du har klikket på en skyder med musen, kan værdien også ændres med piletasterne, hvilket kan ske mere præcist.\n\n\n\nI den logistiske regressionsmodel (3) er \\(p(x)\\) givet ved en generel logistisk funktion. Det var en generel logistisk funktion, der blev brugt til at lave den S-formede kurve på figur 4.\nEn anden måde at fortolke konstanterne \\(a\\) og \\(b\\) på er ved at gå tilbage til at se på oddsene. For at få et udtryk for oddsene i den logistiske regressionsmodel, kan vi anvende eksponentialfunktionen på begge sider i (1) og få \\[\nO(x) = e^{ax + b} = e^b \\cdot e^{ax}=e^b \\cdot (e^{a})^x.\n\\] Hvis \\(e^b\\) kaldes \\(b_{ny}\\), og \\(e^{a}\\) kaldes \\(a_{ny}\\), ses at \\[\nO(x)=b_{ny}\\cdot a_{ny}^x\n\\] er en eksponentiel udvikling med fremskrivningsfaktor \\(a_{ny}=e^a\\). Derved vil odds for sygdom stige med \\(r=e^a-1\\) procent, hver gang blodtrykket stiger med \\(1\\)mmHg. Hvis \\(a\\) er positiv, er \\(e^a&gt;1\\), og oddsene vokser altså eksponentielt. Hvis derimod \\(a\\) er negativ, er \\(e^a&lt;1\\), og dermed aftager oddsene eksponentielt.\nHar vi f.eks. en logit model \\[\n\\text{logit}(p(x))= -2 + 0.2x.\n\\] så er den procentvist vækst i odds, når \\(x\\) vokser med 1 \\[\nr = e^a-1 = e^{0.2}-1 \\approx 0.2214028.\n\\] Altså vokser odds med ca. 22%, når \\(x\\) vokser med 1 i modellen.\nI forbindelse med logistisk regression kaldes \\(e^a\\) også for odds-ratioen. For at forstå hvorfor, kan vi forestille os to patienter, en med blodtryk \\(x_1\\) og en med blodtryk \\(x_2\\). De har dermed oddsene \\[\\begin{align*}\nO(x_1) &= e^b \\cdot e^{ax_1}\\\\\nO(x_2) &= e^b \\cdot e^{ax_2}.\n\\end{align*}\\] Lad os se på forholdet (ratioen) mellem de to personers odds: \\[\n\\frac{O(x_1)}{O(x_2)} = \\frac{e^b \\cdot e^{ax_1}}{ e^b \\cdot e^{ax_2}} = \\frac{e^{ax_1}}{e^{ax_2}} = e^{ax_1 - ax_2} = e^{a(x_1 - x_2)} = (e^{a} )^{x_1-x_2}.\n\\] Forholdet mellem oddsene afhænger altså kun af forskellen \\(x_1 - x_2\\) mellem de to personers blodtryk. Hvis person 1 er har et blodtryk, der er 1mmHg højere end person 2, bliver forholdet (ratioen) mellem oddsene lige præcis \\(e^a\\).\n\nVIDEO: Fortolkning af parametrene i modellen\nI videoen her forklarer vi, hvordan parametrene i den logistiske regressionsmodel kan fortolkes.\n\nHvordan man bestemmer \\(a\\) og \\(b\\) ud fra data forklares i det følgende."
  },
  {
    "objectID": "materialer/logistisk/log-reg.html#maksimum-likelihood-estimation",
    "href": "materialer/logistisk/log-reg.html#maksimum-likelihood-estimation",
    "title": "Logistisk regression",
    "section": "Maksimum likelihood estimation",
    "text": "Maksimum likelihood estimation\nI den logistiske regressionsmodel \\[\n\\ln (O(x)) = \\text{logit}(p(x)) = ax  + b.\n\\] indgår to ukendte konstanter \\(a\\) og \\(b\\). Hvis vi har et datasæt, hvordan finder vi så de værdier af \\(a\\) og \\(b\\), der passer bedst til vores data?\nVed at se på figur 7 kunne man fristes til at benytte lineær regression til at finde \\(a\\) og \\(b\\). Bemærk dog, at hvert punkt egentlig er beregnet ud fra fra flere observationer, som ikke har samme \\(x\\)-værdi. Med et lille datasæt ville det slet ikke være muligt at lave en intervalinddeling som i tabel 1, uden at der kommer meget få personer i nogle grupper. Begge dele gør, at de beregnede værdier af \\(\\ln(O(x))\\) bliver meget upræcise, og det samme gør estimaterne for \\(a\\) og \\(b\\) derfor.\nI stedet benytter man som regel maksimum likelihood metoden, som er en teknik, der stammer fra statistikken. Kort fortalt er idéen at vælge de værdier af \\(a\\) og \\(b\\), der gør vores data så sandsynligt som muligt.\nLad os kalde punkterne i vores datasæt \\((x_i,y_i)\\), hvor \\(i=1,\\ldots,n\\) er en nummerering af datapunkterne. Her angiver \\(x_i\\) altså blodtrykket hos den \\(i\\)’te person, og \\(y_i\\) er en variabel, der antager værdien \\(1\\) hvis \\(i\\)’te person har hjerte-kar-sygdom og er \\(0\\) ellers. For hvert par \\((x_i,y_i)\\) kan vi nu forsøge at beregne sandsynligheden \\(p_i\\) for at \\(i\\)’te person faktisk har den sygsomsstatus \\(y_i\\), som vi observerer. Hvis den \\(i\\)’te person er syg, dvs. \\(y_i=1\\), er \\(p_i\\) altså sandsynligheden for at være syg, når blodtrykket er \\(x_i\\), så \\[\np_i= p(x_i)  = \\frac{ 1}{1 + e^{-(ax_i  + b)}}.\n\\tag{4}\\] Hvis patienten er rask, altså \\(y_i=0\\), er \\(p_i\\) sandsynligheden for at være rask, når blodtrykket er \\(x_i\\), det vil sige \\[\np_i=1-  p(x_i)  = 1- \\frac{ 1}{1 + e^{-(ax_i  + b)}}.\n\\tag{5}\\] Vi kan opskrive et samlet udtryk for \\(p_i\\) uden at opdele efter værdien af \\(y_i\\), nemlig \\[\np_i= p_i(x_i)^{y_i}(1-p(x_i))^{1-y_i}.\n\\tag{6}\\] For at indse dette, ser vi først på tilfældet \\(y_i=1\\), hvor (6) giver \\[\np_i = p(x_i)^{1} (1-p(x_i))^{0} = p(x_i),\n\\] da \\(a^0=1\\) for alle værdier af \\(a\\).\nFor \\(y_i=0\\) giver (6)\n\\[\np_i = p(x_i)^{0} (1-p(x_i))^{1} = 1-p(x_i).\n\\] Det passer altså med formlerne i henholdsvis (4) og (5). Bemærk at \\(p_i\\) afhænger af de ukendte værdier \\(a\\) og \\(b\\). Vi kan altså opfatte \\(p_i\\) som en funktion af to variable \\(p_i(a,b)\\).\nNu kigger vi på den samlede sandsynlighed for at observere netop de værdier \\(y_1,\\ldots,y_n\\), som vi faktisk har observeret, når vi ved at patienternes blodtryk er givet ved \\(x_1,\\ldots,x_n\\). Til det formål antager vi, at personerne i datasættet er uafhængige af hinanden5.\n5 Afhængigheder kan for eksempel opstå, hvis mange af personerne er i familie med hinanden, går i klasse sammen eller bor i samme by. I så fald kan de have noget til fælles, der gør at deres \\(y\\)-værdier er mere ens end ellers. Familiemedlemmer kan fx have samme arvelige tendens til hjerte-kar-sygdom. Som regel forsøger man at undgå sådanne afhængigheder, når man indsamler data.For at komme videre, er vi nødt til at vide lidt om uafhængighed af hændelser: Husk på at to hændelser \\(A\\) og \\(B\\) er uafhængige, hvis man kan finde sandsynligheden for fælleshændelsen \\(A\\cap B\\) (at \\(A\\) og \\(B\\) indtræffer på en gang) ved at gange de enkelte sandsynligheder sammen: \\[\n    P(A\\cap B) = P(A)\\cdot P(B).\n\\]\nUafhængighed af \\(n\\) hændelser \\(A_1,\\ldots,A_n\\) betyder tilsvarende, at sandsynligheden for, at alle \\(n\\) hændelser indtræffer på samme tid \\(A_1 \\cap A_2 \\cap \\dotsm \\cap A_n\\), kan findes som et produkt af sandsynlighederne for de enkelte hændelser6 \\[\n    P(A_1 \\cap A_2 \\cap \\dotsm \\cap A_n) = P(A_1)\\cdot P(A_2) \\cdot \\dotsm \\cdot P(A_n).\n\\]\n6 Desuden skal der gælde, at hver gang vi udtager \\(m\\) ud af de \\(n\\) hændelser, skal sandsynligheden for, at de \\(m\\) hændelser indtræffer samtidig, kunne findes ved en tilsvarende produktformel, men dette skal vi ikke bruge i det følgende.Vi vender nu tilbage til vores data og lader \\(A_1\\) være hændelsen at første patient har sygdomsstatus \\(y_1\\), \\(A_2\\) være hændelsen at anden patient har sygdomsstatus \\(y_2\\) og så videre. Bemærk, at \\(P(A_i)\\) er det samme, som det vi tidligere kaldte \\(p_i(a,b)\\). Hændelsen at vi observerer \\(y_1,\\ldots,y_n\\) på samme tid, er fælleshændelsen \\(A_1 \\cap A_2 \\cap \\dotsm \\cap A_n\\). Da vi antog, at de \\(n\\) personer er udvalgt uafhængigt af hinanden, kan vi bruge produktformlen: \\[\nP(A_1 \\cap A_2 \\cap \\dotsm \\cap A_n) = P(A_1) \\cdot \\dotsm \\cdot P(A_n) = p_1(a,b) \\cdot p_2(a,b)\\cdot \\dotsm \\cdot p_n(a,b).\n\\] Bemærk, at sandsynligheden for vores udfald \\(y_1,\\ldots,y_n\\) afhænger af \\(a\\) og \\(b\\). Den kan derfor betragtes som en funktion af to variable \\[\nL(a,b) = p_1(a,b) \\cdot p_2(a,b)\\cdot \\dotsm \\cdot p_n(a,b).\n\\] Denne funktion kaldes likelihoodfunktionen. Idéen med maksimum likelihood metoden er at vælge de værdier af \\(a\\) og \\(b\\), der gør sandsynligheden \\(L(a,b)\\) for det, vi har observeret så stor som mulig. Vi søger altså de \\(a\\) og \\(b\\), der maksimerer funktionen \\(L(a,b)\\). I praksis vælger man som regel at maksimere \\(\\ln(L(a,b))\\), som kaldes for log-likelihoodfunktionen. Det kommer vi mere ind på i det følgende afsnit. På figur 11 er det vist, hvordan grafen for en log-likelihoodfunktion kunne se ud. Den viser altså logaritmen af sandsynligheden for vores observationer som funktion af \\(a\\) og \\(b\\). Det sorte punkt angiver, hvor funktionsværdien er størst. De tilhørende \\(a\\)- og \\(b\\)-koordinater er altså dem, der gør vores observationer mest sandsynlige.\n\n\n\n\n\n\n\n\nFigur 11: Graf for en log-likelihoodfunktion. Det sorte punkt angiver, hvor funktionsværdien er størst.\n\n\n\n\nMaksimum for \\(L(a,b)\\) kan ikke beregnes eksakt. I stedet kan man bruge numeriske metoder, for eksempel gradient nedstigning, som du kan læse mere om her. Man kan også forsøge at finde kritiske punkter, altså punkter, hvor de partielt afledte er nul, ved hjælp af numeriske metoder. Det kan du læse mere om her. I praksis kan optimeringen foretages ved hjælp af Excel som forklaret nedenfor.\n\nBestemmelse af \\(a\\) og \\(b\\) med Excels problemløser-værktøj\nVi vil nu finde estimater for \\(a\\) og \\(b\\) ved hjælp af Excel. Først og fremmest skal man sørge for, at man har aktiveret problemløser-værktøjet. Det gøres på følgende måde:\n\nGå op under filer og vælg indstillinger.\nVælg derefter tilføjelsesprogrammer.\nNederst vælges Excel-tilføjelsesprogrammer. Tryk på udfør.\nVælg til sidst tilføjelsesprogrammet problemløser fra en liste.\n\n\n\n\nIllustration af Excel ark til bestemmelse af a og b samt brug af problemløser.\n\n\nPå billedet ses, hvordan man kan lave et lille regneark til at beregne de relevante størrelser. Der er lavet et par celler til de ukendte parametre \\(a\\) og \\(b\\), som med fordel kan sættes til 0 fra starten for at undgå numeriske problemer i Excel. Det oprindelige datasæt indsættes i søjlerne \\(x_i\\) og \\(y_i\\). I de næste søjler beregnes odds, \\(p(x_i)\\) og \\(\\ln(p_i)\\) med formlerne7 \\[\\begin{align*}\nodds &= e^{ax_i + b}\\\\\np(x_i) &= \\frac{e^{ax_i + b}}{1+e^{ax_i +b}} = \\frac{odds}{1+odds}\\\\\n\\ln(p_i)&= {y_i}\\cdot \\ln(p(x_i))+(1-y_i)\\cdot \\ln(1-p(x_i)).\n\\end{align*}\\]\n7 I Excel på dansk fås eksponentialfunktionen ved at skrive EKSP (og EXP i den engelske version). For at få den naturlige logaritmen skriver man LN i begge tilfælde.Her er det vigtigt, at cellerne, der indeholder værdien af \\(a\\) og \\(b\\), benyttes når oddsene beregnes (det vil være smart med fastlåsning af referencerne, hvor man har $ foran både tal og bogstav ved reference). Til sidst finder man \\(l(a,b)\\) i det blå felt ved at beregne summen af alle \\(\\ln(p_i)\\), som i formlen (9).\nNu mangler man bare at benytte problemløseren til at finde de værdier af \\(a\\) og \\(b\\), der gør værdien i det blå felt maksimal. På billedet er der vist med rød, hvor man finder problemløseren, og hvad der skal justeres. Målsætningen er den blå celle, der indeholder summen. Variabelcellerne er de to, der indeholder \\(a\\) og \\(b\\). Sørg for ikke at sætte flueben i boksen \"Gør variabler uden begrænsninger ikke-negative\". Tryk på løs.\nFinder man \\(a\\) og \\(b\\) ved hjælp af maksimum likelihood metoden i vores dataeksempel, fås følgende funktionsudtryk for sandsynlighederne og oddsene \\[\n    p(x) = \\frac{1}{1+e^{-0.022 x +3.9}}, \\qquad O(x)=e^{0.022 x - 3.9}.\n\\]\nGrafen for \\(p\\) er vist på figur 4. Vi får en odds-ratio på \\(e^{0.022} \\approx 1.022\\). Odds for hjerte-kar-sygdom stiger derfor med en faktor 1.022 (altså 2.2%), for hver gang blodtrykket stiger med \\(1\\) mmHg.\n\n\nYderligere omskrivning af likelihoodfunktionen\nVi ser nu lidt nærmere på, hvordan man selv kan finde \\(a\\) og \\(b\\), der maksimerer værdien af likelihoodfunktionen \\(L(a,b)\\). Til det formål omskriver vi først likelihoodfunktionen til noget, der er lidt nemmere at regne på. Vi havde \\[\nL(a,b) = p_1(a,b) \\cdot p_2(a,b)\\cdot \\dotsm \\cdot p_n(a,b).\n\\tag{7}\\] Da \\(\\ln(x)\\) er en voksende funktion, vil \\(L(a,b)\\) have maksimum for de samme værdier af \\(a\\) og \\(b\\) som den sammensatte funktion \\(l(a,b)=\\ln(L(a,b))\\). Det er altså nok at finde de værdier af \\(a\\) og \\(b\\), der maksimerer \\(l(a,b)\\).\nTager vi den naturlige logaritme i (7) og bruger logaritmeregnereglen \\(\\ln(a\\cdot b) = \\ln(a) + \\ln(b)\\), får vi \\[\nl(a,b)=\\sum_{i=1}^n \\ln(p_i(a,b)).\n\\tag{8}\\] Vi ser her, at logaritmen laver produktet i likelihoodfunktionen om til en sum – og summer er nemmere at regne på end produkter (for eksempel når vi senere skal differentiere). Bemærk, at det er denne funktion, som vi kalder for log-likelihoodfunktionen.\nVi fandt i (6), at \\[\np_i(a,b)=p(x_i)^{y_i}\\cdot (1-p(x_i))^{1-y_i}.\n\\] Vi kan nu finde \\(\\ln(p_i(a,b))\\) ved først at benytte regnereglen \\(\\ln(a\\cdot b) = \\ln(a) + \\ln(b)\\) og dernæst regnereglen \\(\\ln(a^k)=k\\cdot \\ln(a)\\). Det giver \\[\\begin{align*}\n\\ln(p_i(a,b)) &=  \\ln\\big(p(x_i)^{y_i}\\big) + \\ln\\big((1-p(x_i))^{1-y_i}\\big) \\\\\n&= {y_i}\\cdot \\ln(p(x_i))+(1-y_i)\\cdot \\ln(1-p(x_i))\n\\end{align*}\\] Samlet set får vi \\[\n\\begin{aligned}\nl(a,b) &=\\sum_{i=1}^n \\ln(p_i(a,b)) \\\\  &= \\sum_{i=1}^n\\big( {y_i}\\cdot \\ln(p(x_i))+(1-y_i)\\cdot \\ln(1-p(x_i)) \\big).\n\\end{aligned}\n\\tag{9}\\] Dette udtryk kan man nemt selv udregne og maksimere ved hjælp af Excel.\n\n\nVIDEO: Maksimum likelihood estimation\nIdéen i maksimum likelihood estimation forklares i videoen herunder."
  },
  {
    "objectID": "materialer/logistisk/log-reg.html#multipel-logistisk-regression",
    "href": "materialer/logistisk/log-reg.html#multipel-logistisk-regression",
    "title": "Logistisk regression",
    "section": "Multipel logistisk regression",
    "text": "Multipel logistisk regression\nI praksis er der selvfølgelig flere faktorer end blodtryk, der afgør ens risiko for hjerte-kar-sygdom. For eksempel stiger risikoen med alderen, ligesom rygning øger risikoen. Vi kan opstille en model, der inddrager alle tre variable på en gang. Lader vi \\(x_1\\) betegne blodtryk, \\(x_2\\) betegne alder, og \\(x_3\\) betegne antal cigaretter, man ryger pr. dag, kan vi lave en model, hvor logaritmen til oddsene afhænger af alle tre variable: \\[\n    \\ln \\left ( O(x_1,x_2,x_3)  \\right) = a_1x_1 + a_2x_2 +a_3x_3 + b.\n\\] Nu er der fire ukendte konstanter \\(a_1\\), \\(a_2\\), \\(a_3\\) og \\(b\\) i modellen, som skal bestemmes ud fra data. Dette kaldes den multiple regressionsmodel. Ved at tage eksponentialfunktionen får vi en formel for oddsene \\[\n     O(x_1,x_2,x_3) = e^{a_1x_1 + a_2x_2 +a_3x_3 + b}.\n\\] Man kan også bruge den standard logistiske funktion og få en formel for sandsynligheden \\[\n    p(x_1,x_2,x_3) = \\frac{1}{1+e^{-(a_1x_1 + a_2x_2 +a_3x_3 + b)}}.\n\\]\nHvordan skal vi forstå denne model? Jo, lad os forestille os en patient med alder \\(x_1\\) og blodtryk \\(x_2\\), som ryger \\(x_3\\) cigaretter om dagen. Hvis vedkommende begynder at ryge \\(1\\) cigaret mere om dagen (og vi forestiller os at alder og blodtryk er uændret) så vil odds-ratioen være \\[\n\\begin{aligned}\n    \\frac{O(x_1,x_2,x_3+1)}{O(x_1,x_2,x_3)} &= \\frac{ e^{a_1x_1 + a_2x_2 +a_3(x_3+1) + b}}{e^{a_1x_1 + a_2x_2 +a_3x_3 + b}} \\\\\n    &=\\frac{e^{a_1x_1} \\cdot e^{a_2x_2} \\cdot e^{a_3x_3} \\cdot e^{a_3} \\cdot e^b}{e^{a_1x_1} \\cdot e^{a_2x_2} \\cdot e^{a_3x_3}\\cdot e^b} \\\\ &=e^{a_3}.\n\\end{aligned}\n\\] Den ekstra daglige cigaret vil altså øge odds for sygdom med en faktor \\(e^{a_3}\\). Tilsvarende har \\(e^{a_1}\\) og \\(e^{a_2}\\) fortolkninger som odds-ratioer, når henholdsvis blodtryk og alder stiger med 1, mens alle andre variable fastholdes. Selv om modellen tager alle tre variable i betragtning, giver odds-ratioerne et mål for den individuelle effekt af hver af de tre variable.\nMaximum likelihood metoden kan igen benyttes til at estimere parametrene \\(a_1,a_2,a_3\\) og \\(b\\). Likelihoodfunktionen, som skal maksimeres, bliver nu til en funktion af fire variable. Vi vil ikke gå i detaljer med, hvordan denne maksimering finder sted.\nFramingham datasættet er et rigtigt datasæt, der indeholder data for hjerte-kar-sygdom og de tre risikofaktorer \\(x_1\\), \\(x_2\\) og \\(x_3\\). Estimerer man \\(a_1,a_2,a_3\\) og \\(b\\) på en udvalgt del af dette datasæt, får man \\[\n    O(x_1,x_2,x_3) = e^{0.06x_1 + 0.02x_2 + 0.02x_3 -6.77 }.\n\\] Odds for hjerte-kar-sygdom stiger således med en faktor \\(e^{0.02}\\approx 1.02\\) (altså med 2%), for hver cigaret man ryger om dagen. Tilsvarende stiger odds for sygdom med en faktor \\(e^{0.06}\\approx 1.06\\), for hvert år ældre man bliver, og med en faktor \\(e^{0.02}\\approx 1.02\\), for hver gang blodtrykket stiger med 1 mmHg."
  },
  {
    "objectID": "materialer/logistisk/log-reg.html#prædiktion",
    "href": "materialer/logistisk/log-reg.html#prædiktion",
    "title": "Logistisk regression",
    "section": "Prædiktion",
    "text": "Prædiktion\nNår vi har fundet en god model for sammenhængen mellem sygdom og forskellige risikofaktorer, kan vi bruge den til at forudsige (prædiktere), om en ny patient er syg. Som eksempel kan vi se på den multiple regressionsmodel, hvor risikoen for hjerte-kar-sygdom var givet ved \\[\n    p(x_1,x_2,x_3) = \\frac{1}{1+e^{-(0.06x_1 + 0.02x_2 +0.02x_3 -6.77)}},\n\\] hvor \\(x_1\\) var alderen, \\(x_2\\) var blodtrykket, og \\(x_3\\) var antal cigaretter.\nForestil dig nu, at vi får en ny patient med alderen \\(x_1\\) og blodtrykket \\(x_2\\), som ryger \\(x_3\\) cigaretter om dagen. Vi kan beregne sandsynligheden \\(p(x_1,x_2,x_3)\\) for, at patienten er syg ud fra vores model. Den mest oplagte prædiktionsregel er at prædiktere det mest sandsynlige:\n\nHvis \\(p(x_1,x_2,x_3)&gt;1/2\\): Patienten er syg.\nHvis \\(p(x_1,x_2,x_3)\\leq 1/2\\): Patienten er rask.\n\nLad os for eksempel sige, at vores patient er 30 år gammel, har et blodtryk på \\(145\\) mmHg og ryger 7 cigaretter om dagen. Ifølge vores model vil hans risiko for hjerte-kar-sygdom være \\[\n    p(30,145,7) = \\frac{1}{1+e^{-(0.06\\cdot 30 + 0.02\\cdot 145 +0.02\\cdot 7 -6.77)}}\\approx 0.127.\n\\] Hans risiko er på 12.7%. Hvis vi skal lave en prædiktion, vil vi sige, at han er rask, da dette vil være det mest sandsynlige.\nI praksis kan der være et problem med altid at vælge det mest sandsynlige. Hvis man gerne vil kunne forudsige en meget sjælden sygdom, vil det ofte være sådan, at \\(p(x)\\leq 1/2\\) for alle patienter. Ingen ville blive diagnosticeret med sygdommen på denne måde - og så er prædiktionsalgoritmen jo ikke meget værd. Derfor vælger man ofte et lavere delepunkt end \\(p(x)=1/2\\). Dermed kommer man til at fejldiagnosticere en hel del patienter. Til gengæld får man fanget flere af dem, der faktisk er syge.\nHer på siden har vi flere eksempler på algoritmer, som vil kunne bruges til at prædiktere om patienter er syge eller raske, fx neurale netværk8 og Bayes klassifikation. Fordelen ved at bruge logistisk regression er, at man ikke bare får en prædiktion, men også en model for, hvordan sandsynligheden \\(p(x)\\) afhænger af variablen \\(x\\). Dermed opnår man en indsigt i, hvordan sammenhængen mellem for eksempel blodtryk og hjerte-kar-sygdom er. Ved hjælp af odds-ratioer kan vi endda sætte tal på, hvordan odds for sygdom ændrer sig, når blodtrykket vokser. Dette er i modsætning til mange andre prædiktionsalgoritmer, der blot giver en prædiktion, uden at brugeren af algoritmen ved, hvor den kommer fra. Inden for medicin er det ofte vigtigt at kende baggrunden for en given prædiktion, så man kan forholde sig kritisk til resultatet og rådgive patienten om, hvordan man sænker risikoen for sygdom (for eksempel med blodtrykssænkende medicin). Til gengæld har de mere avancerede algoritmer, så som neurale netværk, mulighed for at give en mere præcis prædiktion.\n8 Logistisk regression er i øvrigt et meget simpelt eksempel på et neuralt netværk, hvis man vælger af bruge cross-entropy funktionen som tabsfunktion.\nAndre eksempler på anvendelser\nLogistisk regression kan bruges til at modellere meget andet end sygdom. Forestil dig for eksempel en nyhedshjemmeside, der benytter cookies til at målrette reklamer. Hjemmesiden registrerer, hvor mange gange du har læst kulturnyheder, \\(x_1\\), og hvor mange gange du har læst sportsnyheder, \\(x_2\\), inden for den sidste måned. Desuden registrerer den, om du har klikket på en bestemt reklame for en ny biograffilm. Man kan bruge disse data til at finde en logistisk regressionsmodel for sandsynligheden \\(p(x_1,x_2)\\) for, at en ny bruger klikker på reklamen. Med sådan en model kan man så prædiktere, om en ny bruger vil klikke på reklamen ud fra indsamlet data om brugerens forbrug af sports- og kulturnyheder. Reklamen vil så kun blive vist til brugeren, hvis det prædikteres, at brugeren rent faktisk vil klikke på reklamen.\nEt andet eksempel kunne være en meningsmåling. Et mindre antal vælgere spørges, om de har tænkt sig at stemme på rød eller blå blok. Desuden noteres deres alder \\(x_1\\) og årsindtægt \\(x_2\\). Ud fra dette datasæt laves en model for sandsynligheden \\(p(x_1,x_2)\\) for at stemme på rød blok som funktion af alder og årsindtægt. Ud fra modellen kan man så prædiktere, hvad resten af befolkningen har tænkt sig at stemme.\nHvis du vil læse mere om sammenhæng mellem logistisk regression og logistisk vækst, kan du folde boksen nedenfor ud.\n\n\n\n\n\n\nSammenhæng mellem logistisk regression og logistisk vækst\n\n\n\n\n\nHvis du har hørt om logistisk vækst og logistisk regression, spekulerer du måske over, om der er en sammenhæng mellem de to begreber. Vi skal nu se, at der i nogle anvendelser faktisk er en sammenhæng.\nLad os se på et eksempel med en smitsom sygdom, hvor infektionen aldrig forlader kroppen igen, og man kan fortsætte med at smitte andre resten af livet, når først man er blevet smittet. HIV og herpes er eksempler på sådanne sygdomme. Lad \\(I(x)\\) betegne antallet af smittede efter \\(x\\) dage (\\(I\\) står for inficeret). Ifølge den klassiske SI-model, er væksthastigheden for \\(I\\) proportional med både antallet af smittede \\(I(x)\\) og antallet af raske \\(M-I(x)\\), hvor \\(M\\) er det samlede befolkningstal. Det vil sige \\[\nI'(x) = k I(x)(M-I(x)),\n\\] hvor \\(k&gt;0\\) er en konstant. Denne ligning kaldes den logistiske differentialligning, og løsningen er givet ved \\[\nI(x)=\\frac{M}{1+c\\cdot e^{-M\\cdot k\\cdot x}},\n\\] hvor \\(c&gt;0\\) igen er en konstant, som kan bestemmes, hvis man kender antallet af smittede \\(I(0)\\) til tiden \\(x=0\\). Sætter vi \\(c=\\exp(-b)\\) og \\(a=Mk\\), får vi \\[\nI(x)=\\frac{M}{1+e^{-b}\\cdot e^{-a\\cdot x}} = \\frac{M}{1+e^{-(a\\cdot x+b)}}.\n\\] På dag \\(x\\) vil en tilfældigt udvalgt person have en sandsynlighed på \\(p(x)=I(x)/M\\) for at være smittet. Denne sandsynlighed vil være beskrevet af en logistisk funktion \\[\np(x)=\\frac{I(x)}{M} = \\frac{1}{1+e^{-(a\\cdot x+b)}}.\n\\] Dette genkender vi som en logistisk regressionsmodel for sandsynligheden \\(p(x)\\).\nFor at bestemme \\(a\\) og \\(b\\), kunne man derfor lave et datasæt, hvor vi hver dag tager en test af en tilfældig person og ser, om personen er smittet eller rask. Derved får vi et datasæt med punkter \\((x,y)\\), hvor \\(x\\) er antal dage, og \\(y\\) er \\(0\\) hvis personen er rask, eller \\(1\\) hvis personen er smittet. Vi kan nu finde \\(a\\) og \\(b\\) ved at lave logistisk regression på dette datasæt og finde et udtryk for \\(p(x)\\). Hvis vi gerne vil vide, hvor mange der faktisk er syge efter \\(x\\) dage, ganger vi bare sandsynligheden for at være syg op med befolkningstallet \\[\nI(x)=M\\cdot p(x)=\\frac{M}{1+e^{-(a\\cdot x+b)}}.\n\\] Det er dog ikke ved alle eksempler, det er muligt at lave denne kobling mellem de to emner. Logistisk vækst vedrører en udvikling i tid, dvs. \\(x\\)-variablen skal angive tid. Desuden skal udviklingen foregå i en population af fast størrelse \\(M\\)."
  },
  {
    "objectID": "materialer/logistisk/log-reg.html#relaterede-forløb",
    "href": "materialer/logistisk/log-reg.html#relaterede-forløb",
    "title": "Logistisk regression",
    "section": "Relaterede forløb",
    "text": "Relaterede forløb\n\n\n\n\n\nForløb\n\n\nKort beskrivelse\n\n\n\n\n\n\nLogistisk regression\n\n\nEt længere forløb om logistisk regression som supplerende stof på A-niveau inklusiv spørgsmål til mundtlig eksamen\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "materialer/gradientnedstigning/bevis_vha_middelvaerdisaetningen.html",
    "href": "materialer/gradientnedstigning/bevis_vha_middelvaerdisaetningen.html",
    "title": "Argument for at de retningsafledede kan udregnes med et prikprodukt ved hjælp af middelværdisætningen",
    "section": "",
    "text": "Vi vil her argumentere for formlen for, at de retningsafledede kan udregnes som et prikprodukt:\n\\[\nD_{\\vec{u}}f\\left( x_{0},y_{0} \\right) = \\nabla f(x_{0},y_{0}) \\cdot \\vec{u}\n\\]\nved at bruge middelværdisætningen for funktioner af én variabel:\n\n\nSætning 1 (Middelværdisætningen) Hvis \\(f\\) er kontinuert på \\(\\left\\lbrack a;b \\right\\rbrack\\) og differentiabel i \\(\\left\\rbrack a;b \\right\\lbrack\\), så findes der et tal \\(c\\) mellem \\(a\\) og \\(b\\), så tangenthældningen i \\(c\\) er lig med middelværdien af hældningen på hele intervallet \\(\\left\\lbrack a;b \\right\\rbrack\\). Det vil sige, at \\[f^{'}\\left( c \\right) = \\frac{f\\left( b \\right) - f(a)}{b - a}\\]\n\n\nResultatet i middelværdisætningen kan omskrives til\n\\[\nf\\left( b \\right) - f\\left( a \\right) = f^{'}\\left( c \\right) \\cdot (b - a)\n\\tag{1}\\]\nsom er det, vi får brug for. Middelværdisætningen virker indlysende korrekt, hvis man prøver at tegne situationen, og beviset for middelværdisætningen kan findes i flere gymnasiebøger.\nInden vi går til argumentet for formlen for de retningsafledede, vil vi se på et enkelt eksempel med middelværdisætningen.\n\nEksempel 1 Funktionen \\(f\\left( x \\right) = \\sqrt{x}\\) er kontinuert på \\(\\left\\lbrack 0;4 \\right\\rbrack\\) og differentiabel i \\(\\left\\rbrack 0;4 \\right\\lbrack\\), så betingelserne for at bruge middelværdisætningen er opfyldt.\nDer findes så et tal \\(c\\) mellem 0 og 4, så \\(f^{'}\\left( c \\right) = \\frac{f\\left( 4 \\right) - f(0)}{4 - 0}\\).\nVi ved, at \\(f^{'}\\left( x \\right) = \\frac{1}{2\\sqrt{x}}\\) så ligningen ovenfor bliver \\[\n\\frac{1}{2\\sqrt{c}} = \\frac{\\sqrt{4} - \\sqrt{0}}{4 - 0}\n\\] Det vil sige, at \\[\n\\frac{1}{2\\sqrt{c}} = \\frac{1}{2}\n\\] hvilket giver \\(c = 1\\).\nTangenthældningen af grafen for \\(f\\left( x \\right) = \\sqrt{x}\\) i \\(c = 1\\) er altså det samme som middelværdien af hældningen af grafen på hele intervallet \\(\\left\\lbrack a;b \\right\\rbrack = \\left\\lbrack 0;4 \\right\\rbrack\\), det vil sige hældningen af den sekant, der forbinder startpunktet \\((0,f\\left( 0 \\right))\\) og slutpunktet \\((4,f\\left( 4 \\right))\\).\nPå figur 1 illustreres dette princip.\n\n\n\n\n\n\n\nFigur 1: Illustration af middelværdisætningen. Her har tangenten i \\((1,f(1))\\) (den grønne linje) samme hældning som sekanten gennem \\((0,f(0))\\) og \\((4,f(4))\\) (den blå linje).\n\n\n\nMiddelværdisætningen siger altså bare, at hvis man forbinder start og slutpunktet – den blå linje – og udregner dens hældning, så kan man altid finde mindst et punkt i det indre af intervallet, hvor tangenten i punktet – den grønne linje – har samme hældning. I eksemplet fandt vi et bestemt \\(c\\), som vi ifølge middelværdisætningen vidste, at vi kunne. Når vi i det følgende skal tænke endnu mere generelt, så bliver middelværdisætningen nyttig.\nVi vender nu tilbage til definitionen af de retningsafledede. Vi får i det følgende brug for at antage, at både \\(f_x(x,y)\\) og \\(f_y\\left( x,y \\right)\\) eksisterer, så vi kan bruge middelværdisætningen. Desuden får vi også brug for at antage, at \\(f_x(x,y)\\) og \\(f_y\\left( x,y \\right)\\) er kontinuerte på en omegn af \\((x_{0},y_{0})\\).\nVi husker på, at de retningsafledede var defineret ved\n\\[\nD_{\\vec{u}}f\\left( x_{0},y_{0} \\right) = \\lim_{h \\rightarrow 0}\\frac{f\\left( x_{0} + hu_{1},y_{0} + hu_{2} \\right) - f(x_{0},y_{0})}{h}\n\\tag{2}\\]\nVi omskriver nu tælleren i (2) for at kunne bringe middelværdisætningen i spil \\[\n\\begin{aligned}\nf( x_{0} + h \\cdot u_{1}, y_{0} + h &\\cdot u_{2}) - f(x_{0}, y_{0})  = \\\\\n& f\\left( x_{0} + h \\cdot u_{1},y_{0} +  h \\cdot u_{2} \\right) \\\\\n& \\color{red}- f\\left( x_{0},y_{0} + h \\cdot u_{2} \\right)  + f\\left( x_{0},y_{0} + h \\cdot u_{2} \\right) \\color{black}\\\\\n&- f(x_{0},y_{0})\n\\end{aligned}\n\\] Bemærk, at vi har lagt et led til og trukket det samme led fra (markeret med rødt). Det svarer til, at vi har indskudt et punkt i \\(xy\\)-planen, som illustreret i figur 2.\n\n\n\n\n\n\nFigur 2: Et rødt punkt er indskud i \\(xy\\)-planen.\n\n\n\nVi ser nu, at de to første led kun afviger på \\(x\\)-koordinaten (markeret med blåt nedenfor), og de to sidste led afviger kun på \\(y\\)-koordinaten (markeret med grønt): \\[\n\\begin{aligned}\nf\\left( x_{0} + h \\cdot u_{1},y_{0} + h \\cdot u_{2} \\right) - f(x_{0},y_{0})   &= \\\\\n\\color{blue} f\\left( x_{0} + h \\cdot u_{1},y_{0} +  h \\cdot u_{2} \\right)  - & \\color{blue} f\\left( x_{0},y_{0} + h \\cdot u_{2} \\right)  \\color{black} + \\\\  \\color{green} f\\left( x_{0},y_{0} + h \\cdot u_{2} \\right) - & \\color{green} f(x_{0},y_{0})\n\\end{aligned}\n\\tag{3}\\]\nAfvigelsen på henholdsvis \\(x\\)- og \\(y\\)-koordinaten er vist i figur 3.\n\n\n\n\n\n\nFigur 3: Afvigelsen på \\(x\\)-koordinaten er markeret med blåt, mens afvigelsen på \\(y\\)-koordinaten er markeret med grønt.\n\n\n\nVed at bruge den omskrevne middelværdisætning i (1) på de to snitfunktioner \\(f\\left( x,y_{0} + h \\cdot u_{2} \\right)\\) som en funktion af \\(x\\) og \\(f(x_{0},y)\\) som en funktion af \\(y\\), får vi nu følgende:\n\\[\n\\begin{aligned}\n\\color{blue} f\\left( x_{0} + h \\cdot u_{1},y_{0} + h \\cdot u_{2} \\right) - f\\left( x_{0},y_{0} + h \\cdot u_{2} \\right) =  \\color{blue} f_x(c_{1},y_{0} + h \\cdot u_{2}) \\cdot h \\cdot u_{1}\n\\end{aligned}\n\\] og \\[\n\\color{green} f\\left( x_{0},y_{0} + h \\cdot u_{2} \\right) - f\\left( x_{0},y_{0} \\right) = f_y(x_{0},c_{2}) \\cdot h \\cdot u_{2}\n\\]\nHer har vi brugt, at den afledede af en snitfunktion, hvor vi kun varierer \\(x\\) er \\(f_x\\), og den afledede af en snitfunktion, hvor vi kun varierer \\(y\\) er \\(f_y\\). Tallet \\(c_{1}\\) ligger mellem \\(x_{0}\\) og \\(x_{0} + h \\cdot u_{1}\\), og tallet \\(c_{2}\\) ligger mellem \\(y_{0}\\) og \\(y_{0} + h \\cdot u_{2}\\). Dette er vist i figur 4.\n\n\n\n\n\n\nFigur 4: Tallet \\(c_{1}\\) ligger mellem \\(x_{0}\\) og \\(x_{0} + h \\cdot u_{1}\\), og tallet \\(c_{2}\\) ligger mellem \\(y_{0}\\) og \\(y_{0} + h \\cdot u_{2}\\).\n\n\n\nIndsætter vi de to udtryk ovenfor på højreside i (3) får vi \\[\n\\begin{multline}\nf\\left( x_{0} + h \\cdot u_{1},y_{0} + h \\cdot u_{2} \\right) - f(x_{0},y_{0})  = \\color{blue} f_x(c_{1},y_{0} + h \\cdot u_{2}) \\cdot h \\cdot u_{1} \\color{black} + \\\\ \\color{green} f_y(x_{0},c_{2}) \\cdot h \\cdot u_{2} \\\\\n\\end{multline}\n\\]\nOg bruges dette i definitionen for den retningsafledede i (2) ender vi med \\[\n\\begin{aligned}\nD_{\\vec{u}}f\\left( x_{0},y_{0} \\right) &= \\lim_{h \\rightarrow 0}\\frac{f\\left( x_{0} + h \\cdot u_{1},y_{0} + h \\cdot u_{2} \\right) - f(x_{0},y_{0})}{h}\n\\\\\n&=\n\\lim_{h \\rightarrow 0}\\frac{f_x\\left( c_{1},y_{0} + h \\cdot u_{2} \\right) \\cdot h \\cdot u_{1} + f_y(x_{0},c_{2}) \\cdot h \\cdot u_{2}\\ }{h}\n\\end{aligned}\n\\] Vi kan nu dividere \\(h\\) op i hvert led og får \\[\n\\begin{aligned}\nD_{\\vec{u}}f\\left( x_{0},y_{0} \\right)\n&= \\underset{h \\rightarrow 0}{\\text{lim}} f_x\\left( c_{1},y_{0} + h \\cdot u_{2} \\right) \\cdot u_{1} + f_y(x_{0},c_{2}) \\cdot u_{2}\\\n\\\\\n&= \\lim_{h \\rightarrow 0}\\begin{pmatrix}\nf_x\\left( c_{1},y_{0} + h \\cdot u_{2} \\right) \\\\\nf_y(x_{0},c_{2})\n\\end{pmatrix} \\cdot\n\\begin{pmatrix}\nu_{1} \\\\\nu_{2}\n\\end{pmatrix}\n\\end{aligned}\n\\tag{4}\\] hvis grænsen eksisterer.\nHusk på, at \\(c_1\\) ligger i intervallet \\((x_0,x_0+h \\cdot u_1)\\) og \\(c_2\\) ligger i intervallet \\((y_0,y_0+h \\cdot u_2)\\). Derfor vil\n\\[\n\\lim_{h \\rightarrow 0}\\left( c_{1},y_{0} + h \\cdot u_{2} \\right) =\n(x_{0},y_{0})\n\\] og \\[\n\\lim_{h \\rightarrow 0}\\left( x_{0},c_{2} \\right) = \\ (x_{0},y_{0})\n\\]\nVi startede med at antage, at de partielle afledede er kontinuerte. Det får vi brug for nu. Det betyder nemlig, at grænseværdien i (4) eksisterer, og vi får det ønskede resultat\n\\[\nD_{\\vec{u}}f\\left( x_{0},y_{0} \\right) = \\begin{pmatrix}\nf_x\\left( x_{0},y_{0} \\right) \\\\\nf_y(x_{0},y_{0}) \\\\\n\\end{pmatrix} \\cdot \\begin{pmatrix}\nu_{1} \\\\\nu_{2} \\\\\n\\end{pmatrix} = \\nabla f(x_{0},y_{0}) \\cdot \\vec{u}\n\\] Det var netop, hvad vi ønskede at vise1.\n\n\n1 Vi startede med at antage, at de partielle afledede eksisterer og er kontinuerte på en omegn. Bemærk, at vi ud fra den antagelse nu har vist, at alle de retningsafledede også vil eksistere."
  },
  {
    "objectID": "materialer/gradientnedstigning/bevis_geometrisk_argument.html",
    "href": "materialer/gradientnedstigning/bevis_geometrisk_argument.html",
    "title": "Geometrisk argument for at de retningsafledede kan udregnes med et prikprodukt",
    "section": "",
    "text": "Her på siden vil vi give et geometrisk argument for, at de retningsafledede kan skrives som et prikprodukt:\n\\[\nD_{\\vec{u}}f\\left( x_{0},y_{0} \\right) = \\nabla f(x_{0},y_{0}) \\cdot \\vec{u}\n\\] Vi antager her, at alle snitfunktioner er differentiable således, at alle de retningsafledede eksisterer.\nAlle planer gennem \\(P(x_0,y_0,f(x_0,y_0))\\), som er parallelle med \\(z\\)-aksen, har retningsvektorer \\[\\vec k =\n\\begin{pmatrix}\n0 \\\\\n0 \\\\\n1 \\\\\n\\end{pmatrix}\n\\qquad \\textrm{og} \\qquad \\vec u =\n\\begin{pmatrix}\nu_1 \\\\\nu_2 \\\\\n0 \\\\\n\\end{pmatrix}\\]\nDette er illustreret i figur 1, hvor man ved at trække i skyderen kan ændre på den retning, \\(\\vec u\\) peger i.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigur 1: Plan parallel med \\(z\\)-aksen med retningsvektor \\(\\vec k\\) og \\(\\vec u\\).\n\n\n\nDet er disse planer, vi snitter grafen for \\(f\\) med. Et eksempel er vist i figur 2. Ved at trække i skyderen kan man igen ændre på planen, som er parallel med \\(z\\)-aksen.\n\n\n\n\n\n\n\n\nFigur 2: Grafen for en funktion \\(f\\) (grøn) sammen med en plan gennem \\(P(x_0,y_0,f(x_0,y_0))\\) som er parallelle med \\(z\\)-aksen (blå). Snitkurven mellem grafen og planen er markeret med sort.\n\n\n\nHældningen for tangenten til snitkurven svarer netop til den retningsafledede \\(D_{\\vec{u}}f ( x_{0},y_{0} )\\). Vi sørger nu for at vælge \\(\\vec u\\), så denne vektor har længde \\(1\\). Så har snitkurven i \\(P\\) tangentvektor\n\\[\n\\begin{pmatrix}\nu_1 \\\\\nu_2 \\\\\nD_{\\vec{u}}f ( x_{0},y_{0} ) \\\\\n\\end{pmatrix}.\n\\]\nNu er det sådan at hvis tangenterne til alle snitkurverne ligger i en plan, så kaldes denne plan for tangentplanen. Et eksempel herpå ses i figur 3. Her er det tydeligt, at de indtegnede tangenter alle ligger i den samme plan.\n\n\n\n\n\n\n\n\nFigur 3: Grafen for en funktion \\(f\\) (grøn) sammen med forskellige tangenter til snitkurverne i et punkt \\(P(x_0,y_0,f(x_0,y_0))\\). Den plan, som alle disse tangenter ligger i, kaldes for tangentplanen og er indtegnet med blå.\n\n\n\nDenne plan har retningsvektorer \\[\n\\begin{pmatrix}\n1 \\\\\n0 \\\\\nf_x(x_0,y_0) \\\\\n\\end{pmatrix}\n\\qquad \\textrm{og} \\qquad\n\\begin{pmatrix}\n0 \\\\\n1 \\\\\nf_y(x_0,y_0) \\\\\n\\end{pmatrix}\\]\nog normalvektoren til planen bliver derfor\n\\[\n\\vec{n} =\n\\begin{pmatrix}\n1 \\\\ 0 \\\\ f_x(x_0,y_0)\n\\end{pmatrix}\n\\times\n\\begin{pmatrix}\n0 \\\\ 1 \\\\ f_y(x_0,y_0)\n\\end{pmatrix}\n\\]\nDet giver\n\\[\n\\begin{aligned}\n\\vec{n}&=\n\\begin{pmatrix}\n0 \\cdot f_y(x_0,y_0) - f_x(x_0,y_0) \\cdot 1\n\\\\\nf_x(x_0,y_0) \\cdot 0 - 1 \\cdot f_y(x_0,y_0)\n\\\\\n1 \\cdot 1 - 0 \\cdot 0\n\\end{pmatrix} =\n\\begin{pmatrix}\n- f_x(x_0,y_0)\n\\\\\n-f_y(x_0,y_0)\n\\\\\n1\n\\end{pmatrix}\n\\end{aligned}\n\\] Vi så tidligere, at tangenten til snitkurven i \\(P\\) har retningsvektor \\[\n\\vec{r}=\n\\begin{pmatrix}\nu_1 \\\\ u_2 \\\\ D_{\\vec{u}}f ( x_{0},y_{0} ).\n\\end{pmatrix}\n\\]\nDenne retningsvektor ligger per definition i tangentplanen og derfor står den vinkelret på enhver normalvektor. Derfor er\n\\[\n\\vec r \\cdot \\vec n = 0.\n\\]\nDet giver \\[\n\\begin{aligned}\n\\vec r \\cdot \\vec n &= \\begin{pmatrix}\nu_1 \\\\ u_2 \\\\ D_{\\vec{u}}f ( x_{0},y_{0} ).\n\\end{pmatrix}\n\\cdot\n\\begin{pmatrix}\n- f_x(x_0,y_0)\n\\\\\n-f_y(x_0,y_0)\n\\\\\n1\n\\end{pmatrix} \\\\\n&= - f_x(x_0,y_0) \\cdot u_1 -f_y(x_0,y_0) \\cdot u_2+D_{\\vec{u}}f ( x_{0},y_{0} )=0.\n\\end{aligned}\n\\]\nDerfor fås \\[\nD_{\\vec{u}}f ( x_{0},y_{0} ) = f_x(x_0,y_0) \\cdot u_1 +f_y(x_0,y_0) \\cdot u_2 = \\nabla f(x_{0},y_{0}) \\cdot \\vec{u}\n\\] Nu har vi så, fra dette geometriske argument, at den retningsafledte i retning \\(\\vec u\\) fås som skalarproduktet mellem gradienten og \\(\\vec u\\), hvilket netop var det, vi gerne ville vise."
  },
  {
    "objectID": "materialer/softmax/softmax.html",
    "href": "materialer/softmax/softmax.html",
    "title": "Simple kunstige neurale netværk til multipel klassifikation",
    "section": "",
    "text": "Et kunstigt neuralt netværk fungerer på den måde, at man på baggrund af en række forskellige informationer gerne vil kunne forudsige en eller anden ting. Det kan være, at man på baggrund af en række forskellige blodprøveværdier vil forudsige, om en patient har en bestemt sygdom. Det kunne også være, at man baseret på svarene fra en række forskellige spørgsgmål vil udtale sig om, om en person vil stemme på rød eller blå blok. De nævnte eksempler kalder man for binær klassifikation – fordi der i hvert tilfælde er to muligheder: syg/ikke syg og rød blok/blå blok. Men det er ikke svært at forestille sig scenarier, hvor der kan være mere end to klasser. For eksempel er eksemplet med rød og blå nok tvivlsomt. Her ville det måske være bedre at prøve at forudsige et bestemt parti. Denne note handler om, hvordan man udvider en simpel kunstig neuron, så den ikke kun kan bruges til binær klassifikation, men derimod til at forudsige hvilke blandt flere klasser et givent tilfælde befinder sig i. Lad os starte med et eksempel."
  },
  {
    "objectID": "materialer/softmax/softmax.html#hvor-hårdt-skal-du-arbejde-i-matematiktimerne",
    "href": "materialer/softmax/softmax.html#hvor-hårdt-skal-du-arbejde-i-matematiktimerne",
    "title": "Simple kunstige neurale netværk til multipel klassifikation",
    "section": "Hvor hårdt skal du arbejde i matematiktimerne?",
    "text": "Hvor hårdt skal du arbejde i matematiktimerne?\nDu kender det sikkert godt. Der er gruppearbejde i matematiktimen, og du gider egentlig ikke. Det er nemmere bare at snige sin mobiltelefon i lommen og drible i kantinen. På den anden side er du også ambitiøs og vil gerne have en god karakter til eksamen. What to do?\n\n\n\n\n\nLad os sige at du svarer på følgende tre spørgsmål på en skala fra 1 til 10:\n\n\\(x_1\\): Hvor godt har jeg sovet i nat? (1=\"Elendigt\", 10=\"Fantastisk\").\n\\(x_2\\): Hvor spændende er det emne, vi er i gang med lige nu? (1=\"Mega kedeligt\", 10=\"Det er awesome\").\n\\(x_3\\): Hvor godt vil jeg gerne klare mig til eksamen? (1=\"Jeg er ligeglad\", 10=\"Det skal gå så godt som muligt\").\n\nBaseret på disse tre spørgsmål er der nu følgende fire valg, du kan træffe:\n\nJeg bliver i klassen, hvor læreren kan hjælpe mig, og regner alt det, jeg kan.\nJeg sætter mig ud og regner opgaverne, så godt jeg kan.\nJeg går i kantinen og sniger min telefon med – jeg prøver at regne nogle få opgaver.\nJeg går hjem (og håber på ikke at få fravær)!\n\nDet valg du træffer, skal vi have oversat til matematik (beklager, men nu er det jo en matematik tekst, du er i gang med at læse!). Det gør vi ved at definere fire forskellige værdier \\(t_1, t_2, t_3, t_4\\).\nHvis du vælger 1. sætter vi: \\[\nt_1 = 1, \\quad t_2=0, \\quad t_3=0, \\quad t_4=0.\n\\]\nHvis du vælger 2. sætter vi: \\[\nt_1 = 0, \\quad t_2=1, \\quad t_3=0, \\quad t_4=0.\n\\]\nHvis du vælger 3. sætter vi: \\[\nt_1 = 0, \\quad t_2=0, \\quad t_3=1, \\quad t_4=0.\n\\]\nHvis du vælger 4. sætter vi: \\[\nt_1 = 0, \\quad t_2=0, \\quad t_3=0, \\quad t_4=1.\n\\]\nDet kan man repræsentere lidt smart ved hjælp af en vektor i fire dimensioner:\n\\[\n\\vec{t}=\n\\begin{pmatrix}\nt_1 \\\\\nt_2 \\\\\nt_3 \\\\\nt_4 \\\\\n\\end{pmatrix}\n\\]\nVektoren \\(\\vec t\\) kaldes for targetværdien eller targetvektoren.\nLæg mærke til, at der altid gælder følgende\n\\[\nt_1 + t_2 + t_3 + t_4 = 1.\n\\tag{1}\\]\nPå grund af denne egenskab kalder man også \\(\\vec{t}\\) for en one hot vektor. Det får vi brug for senere."
  },
  {
    "objectID": "materialer/softmax/softmax.html#træningsdata",
    "href": "materialer/softmax/softmax.html#træningsdata",
    "title": "Simple kunstige neurale netværk til multipel klassifikation",
    "section": "Træningsdata",
    "text": "Træningsdata\nVi forestiller os nu, at vi har stillet 12 elever de tre spørgsmål ovenfor. Derefter har vi observeret hvilket af de fire valg, de træffer. Det kunne se sådan her ud:\n\n\n\n\n\n\nElev nr.\n\\(x_1\\) (søvn)\n\\(x_2\\) (emne)\n\\(x_3\\) (eksamen)\nValg\n\n\n\n\n\\(1\\)\n\\(10\\)\n\\(10\\)\n\\(10\\)\n\\({\\color{#020873} 1}\\)\n\n\n\\(2\\)\n\\(8\\)\n\\(7\\)\n\\(8\\)\n\\({\\color{#020873} 1}\\)\n\n\n\\(3\\)\n\\(9\\)\n\\(6\\)\n\\(10\\)\n\\({\\color{#020873} 1}\\)\n\n\n\\(4\\)\n\\(4\\)\n\\(10\\)\n\\(10\\)\n\\({\\color{#020873} 1}\\)\n\n\n\\(5\\)\n\\(5\\)\n\\(8\\)\n\\(7\\)\n\\({\\color{#8086F2} 2}\\)\n\n\n\\(6\\)\n\\(10\\)\n\\(7\\)\n\\(4\\)\n\\({\\color{#8086F2} 2}\\)\n\n\n\\(7\\)\n\\(7\\)\n\\(7\\)\n\\(10\\)\n\\({\\color{#8086F2} 2}\\)\n\n\n\\(8\\)\n\\(8\\)\n\\(3\\)\n\\(4\\)\n\\({\\color{#F2B33D} 3}\\)\n\n\n\\(9\\)\n\\(6\\)\n\\(2\\)\n\\(5\\)\n\\({\\color{#F2B33D} 3}\\)\n\n\n\\(10\\)\n\\(10\\)\n\\(2\\)\n\\(2\\)\n\\({\\color{#F2B33D} 3}\\)\n\n\n\\(11\\)\n\\(1\\)\n\\(1\\)\n\\(3\\)\n\\({\\color{#F288B9} 4}\\)\n\n\n\\(12\\)\n\\(5\\)\n\\(2\\)\n\\(2\\)\n\\({\\color{#F288B9} 4}\\)\n\n\n\n\n\nTabel 1: Træningsdata fra 12 elever.\n\n\n\nFor eksempel har elev nummer 1 sovet fantastisk, eleven synes at emnet er vildt spændende, og eleven vil gerne klare sig rigtig godt til eksamen – denne elev vælger derfor at blive i klassen. Targetværdien for denne elev er:\n\\[\n\\vec{t}=\n\\begin{pmatrix}\n1 \\\\\n0 \\\\\n0 \\\\\n0 \\\\\n\\end{pmatrix}\n\\]\nEleven nummer 12 har derimod sovet semi godt, til gengæld synes eleven ikke at emnet er særlig spændende, og er også ligeglad med at klare sig godt til eksamen. Denne elev laver derfor en \"sniger\" og går hjem. Targetværdien for eleven er derfor:\n\\[\n\\vec{t}=\n\\begin{pmatrix}\n0 \\\\\n0 \\\\\n0 \\\\\n1 \\\\\n\\end{pmatrix}\n\\]\nData i tabel 1 kaldes for træningsdata.\nI figur 1 er træningsdata indtegnet i et tre-dimensionelt koordinatsystem. Punkterne har koordinatsæt \\((x_1, x_2, x_3)\\) og punktets farve angiver valget (mørkeblå svarer til 1, lyseblå svarer til 2, gul svarer til 3 og lyserød svarer til 4).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigur 1: Punktplot af træningsdata fra tabel 1. Punkternes farve angiver valget (mørkeblå svarer til 1, lyseblå svarer til 2, gul svarer til 3 og lyserød svarer til 4).\n\n\n\nDet, vi gerne vil nu, er at lave et meget simpelt kunstigt neuralt netværk, som vi fremover kan bruge til at forudsige, hvilket valg du skal træffe baseret på svaret på de tre spørgsmål. Så idéen er altså, at du i et fremtidsscenarie svarer på de tre spørgsmål, og så fortæller din nye AI assistent dig, hvilket valg du skal træffe. Det er da smart – eller måske lidt dumt, men nu er det jo også bare et eksempel!\nLad os forklare, hvordan man kan gøre det – blot i et lidt mere generelt tilfælde."
  },
  {
    "objectID": "materialer/softmax/softmax.html#feedforward",
    "href": "materialer/softmax/softmax.html#feedforward",
    "title": "Simple kunstige neurale netværk til multipel klassifikation",
    "section": "Feedforward",
    "text": "Feedforward\nVi forestiller os, at vi generelt har \\(n\\) inputvariable\n\\[\nx_1, x_2, \\dots, x_n.\n\\]\nI eksemplet ovenfor var \\(n=3\\), fordi vi svarede på tre spørgsmål.\nDisse \\(n\\) inputvariable er vist i figur 2 som lilla cirkler. De grønne cirkler repræsenterer \\(J\\) output neuroner (i vores eksempel er \\(J=4\\), fordi der skal træffes et valg blandt 4 muligheder).\n\n\n\n\n\n\nFigur 2: Neuralt netværk med \\(n\\) input neuroner og \\(m\\) output neuroner.\n\n\n\nVi ønsker at træne netværket, så \\(o_1\\) bliver sandsynligheden for at et givent træningseksempel tilhører klasse \\(1\\), \\(o_2\\) skal være sandsynligheden for at træningseksemplet tilhører klasse \\(2\\) og så videre. Hvis man vil skrive det lidt kompakt op, kan man samle alle outputværdierne i en vektor:\n\\[\n\\vec{o} =\n\\begin{pmatrix}\no_1 \\\\\no_2 \\\\\n\\vdots \\\\\no_J\n\\end{pmatrix}\n\\]\nI vores eksempel vil det svare til, at \\(o_1\\) skal være sandsynligheden for, at du bliver i klassen og regner opgaver (mulighed 1), \\(o_2\\) skal være sandsynligheden for, at du sætter dig ud og regner opgaver og så videre.\nDet vil sige, at det skal være sådan, at\n\\[\no_1 + o_2 + \\cdots + o_J = 1\n\\]\nfordi sandsynlighederne for de \\(J\\) forskellige muligheder til sammen skal give 1.\nVi vil starte med at se på, hvordan vi på baggrund af inputvariablene \\(x_1, x_2, \\cdots, x_n\\) kan beregne de \\(J\\) outputværdier, så ovenstående er opfyldt. På figur 2 illustrerer de forskelligt farvede pile, at alle \\(n\\) inputvariable sendes frem i netværket til alle \\(J\\) outputværdier. Så for eksempel sendes \\(x_1, x_2, \\cdots, x_n\\) frem til \\(o_1\\) (vist ved de lyseblå pile), ligesom de også sendes frem til \\(o_2\\) (vist ved de mellemblå pile) og så videre.\nFor at forklare den beregning der så foregår, har vi i figur 3 kun vist de pile, som går fra inputvariablene frem til den \\(j\\)’te outputværdi.\n\n\n\n\n\n\nFigur 3: Neuralt netværk hvor vægtene fra de \\(n\\) input neuroner over til den \\(j\\)’te output neuron er vist.\n\n\n\nFør \\(o_j\\) bestemmes, beregner vi først en værdi \\(z_j\\) på denne måde:\n\\[\nz_j = w_{j,0} + w_{j,1} \\cdot x_1 + w_{j,2} \\cdot x_2 + \\cdots + w_{j,n} \\cdot x_n.\n\\]\nTallene \\(w_{j,0}, w_{j,1}, w_{j,2}, \\cdots, w_{j,n}\\) kaldes for vægte.\nVærdien \\(z_j\\) er vist i figur 3 inde i den grønne cirkel. På tilsvarende vis beregnes \\(z_1, z_2, \\cdots, z_J\\). Bemærk her, at vægtene er forskellige. For eksempel er\n\\[\nz_2 = w_{2,0} + w_{2,1} \\cdot x_1 + w_{2,2} \\cdot x_2 + \\cdots + w_{2,n} \\cdot x_n\n\\]\nså vægtene er her \\(w_{2,0}, w_{2,1}, w_{2,2}, \\cdots, w_{2,n}\\).\nI alt er der \\((n+1)\\cdot J\\) forskellige vægte (det vil sige i vores eksempel vil der være \\((3+1)\\cdot4=16\\) vægte).\nAlle \\(z\\)-værdierne kan antage et hvilket som helst reelt tal og kan alene af den grund ikke fortolkes som en sandsynlighed. Vi bruger derfor en såkaldt aktiveringsfunktion \\(\\alpha\\) på alle \\(z\\)-værdierne, så vi kan få beregnet en outputværdi, som kan fortolkes som en sandsynlighed:\n\\[\no_j = \\alpha(z_j),\n\\]\nhvor\n\\[\n0 \\leq \\alpha(z_j) \\leq 1.\n\\]\nSom aktiveringsfunktion \\(\\alpha\\) vil vi bruge en funktion, som kaldes for softmax, fordi den præcis har de egenskaber, som vi efterspørger – det ser vi lige om lidt. På baggrund af alle \\(z\\)-værdierne beregnes \\(o_j\\) ved hjælp af softmax på denne måde:\n\\[\no_j = \\alpha(z_j) = \\frac{e^{z_j}}{\\sum_{i=1}^J e^{z_i}}.\n\\]\nFor det første kan vi se, at både tæller og nævner er positive. Derfor må \\(o_j&gt;0\\). For det andet er \\(e^{z_j} &lt; \\sum_{i=1}^J e^{z_i}\\) og derfor er\n\\[\no_j =  \\frac{e^{z_j}}{\\sum_{i=1}^J e^{z_i}} &lt; \\frac{\\sum_{i=1}^J e^{z_i}}{\\sum_{i=1}^J e^{z_i}} = 1.\n\\]\nAltså er\n\\[\n0&lt;o_j&lt;1\n\\]\nhvilket betyder, at \\(o_j\\) kan opfattes som en sandsynlighed. Endelig er\n\\[\n\\begin{aligned}\no_1 + o_2 + \\cdots + o_J &= \\frac{e^{z_1}}{\\sum_{i=1}^J e^{z_i}} + \\frac{e^{z_2}}{\\sum_{i=1}^J e^{z_i}} + \\cdots + \\frac{e^{z_J}}{\\sum_{i=1}^J e^{z_i}} \\\\\n&= \\frac{e^{z_1} + e^{z_2} + \\cdots + e^{z_J}}{\\sum_{i=1}^J e^{z_i}} \\\\\n&= \\frac{\\sum_{i=1}^J e^{z_i}}{\\sum_{i=1}^J e^{z_i}} = 1,\n\\end{aligned}\n\\]\nhvilket også var et krav til de beregnede outputværdier.\nI det helt specielle tilfælde, hvor der kun er to output neuroner, vil softmax-funktionen for \\(o_1\\) blot være en funktion af to variable:\n\\[\no_1 = \\frac{e^{z_1}}{e^{z_1} + e^{z_2}}\n\\]\nGrafen for denne funktion er vist i figur 4. Her ses det tydeligt, at værdien af \\(o_1\\) ligger i intervallet \\(]0,1[\\).\n\n\n\n\n\n\n\n\nFigur 4: Grafen for softmax funktionen \\(o_1 = \\frac{e^{z_1}}{e^{z_1} + e^{z_2}}\\).\n\n\n\nDet betyder, at hvis \\(o\\)-værdierne beregnes på denne måde, er der altså tale om en sandsynlighedsfordeling. Beregningen af alle \\(z\\)- og \\(o\\)-værdier kan udføres, hvis bare man kender alle vægtene. I et neuralt netværk kaldes disse udregninger for feedforward og er opsummeret herunder.\n\n\n\n\n\n\nFeedforward-udtryk\n\n\n\n\n\nPå baggrund af inputværdierne \\(x_1, x_2, \\cdots, x_n\\) beregnes først \\(z\\)-værdier:\n\\[\n\\begin{aligned}\nz_1 &= w_{1,0} + w_{1,1} \\cdot x_1 + w_{1,2} \\cdot x_2 + \\cdots + w_{1,n} \\cdot x_n \\\\\n& \\,\\,\\, \\vdots \\\\\nz_j &= w_{j,0} + w_{j,1} \\cdot x_1 + w_{j,2} \\cdot x_2 + \\cdots + w_{j,n} \\cdot x_n \\\\\n& \\,\\,\\, \\vdots \\\\\nz_J &= w_{J,0} + w_{J,1} \\cdot x_1 + w_{J,2} \\cdot x_2 + \\cdots + w_{J,n} \\cdot x_n \\\\\n\\end{aligned}\n\\tag{2}\\]\nHerefter beregnes outputværdierne:\n\\[\n\\begin{aligned}\no_1 &= \\frac{e^{z_1}}{\\sum_{i=1}^J e^{z_i}} \\\\\n& \\,\\,\\, \\vdots \\\\\no_j &= \\frac{e^{z_j}}{\\sum_{i=1}^J e^{z_i}} \\\\\n& \\,\\,\\, \\vdots \\\\\no_J &= \\frac{e^{z_J}}{\\sum_{i=1}^J e^{z_i}} \\\\\n\\end{aligned}\n\\tag{3}\\]\n\n\n\nVi har indtil videre skrevet, at outputværdierne kan fortolkes som sandsynligheder. Men bare fordi at en række tal (\\(o_1, o_2, \\dots, o_J\\)) alle ligger mellem 0 og 1 og alle summerer til 1, så er det jo ikke sikkert, at de på en fornuftig måde angiver sandsynligheden for de fire forskellige muligheder, som de enkelte elever har. For eksempel kunne de fleste lærere nok ønske sig, at\n\\[\no_1 = 0.5, \\quad 0_2 = 0.5, \\quad o_3=0, \\quad o_4=0\n\\] fuldstændig uafhængig af svarene på de tre spørgsmål.\nDet svarer til, at cirka halvdelen af elever bliver i klassen og regner opgaver, mens den anden halvdel sætter sig ud og regner. Til gengæld er der ingen, som går i kantinen og feder den, ligsom der heller ikke er nogle, som bare går hjem.\nFor at vores nye AI assistent skal give et nogenlunde retvisende billede af virkeligheden (det vil sige elevernes valg og ikke lærerens ønsker!) skal vi have fundet nogle outputværdier, som for det første afhænger af inputværdierne (man kan jo se på figur 1 at inputværdierne har indflydelse), og som for det andet rent faktisk giver en realistisk sandsynlighed for hver af de fire muligheder. Det gør vi ved at blive ved med at \"skrue\" på alle vægtene indtil, at de beregnede outputværdier i (3) giver et godt bud på sandsynlighederne for de 4 muligheder.\nHvordan, det rent faktisk lader sig gøre, kommer her."
  },
  {
    "objectID": "materialer/softmax/softmax.html#cross-entropy-tabsfunktionen",
    "href": "materialer/softmax/softmax.html#cross-entropy-tabsfunktionen",
    "title": "Simple kunstige neurale netværk til multipel klassifikation",
    "section": "Cross-entropy tabsfunktionen",
    "text": "Cross-entropy tabsfunktionen\nForestil dig at vi bare har valgt nogle tilfældige værdier af vægtene. På den baggrund kan vi for et givent sæt af inputværdier beregne outputværdierne ved hjælp af feedforward-udtrykkene i (3). Vi vil som eksempel se på elev nummer 7 fra tabel 1. Denne elev har valgt mulighed 2 (gå uden for klassen for at regne opgaver) og har derfor targetværdi\n\\[\n\\vec t =\n\\begin{pmatrix}\n0 \\\\\n1 \\\\\n0 \\\\\n0 \\\\\n\\end{pmatrix}\n\\tag{4}\\]\nEn bestemt \"indstilling\" af vægtene kunne for eksempel give denne outputvektor:\n\\[\n\\vec o =\n\\begin{pmatrix}\n0.85 \\\\\n0.10 \\\\\n0.03 \\\\\n0.02 \\\\\n\\end{pmatrix}\n\\tag{5}\\]\nDet svarer til at vægtene ikke har fået nogle \"gode\" værdier, fordi denne outputvektor svarer til, at der kun er \\(10 \\%\\) chance for at eleven vælger mulighed 2. Hvis vægtene i stedet havde haft værdier, som ville resultere i denne outputvektor\n\\[\n\\vec o =\n\\begin{pmatrix}\n0.10 \\\\\n0.85 \\\\\n0.03 \\\\\n0.02 \\\\\n\\end{pmatrix}\n\\tag{6}\\]\nså vil vi straks være mere tilfredse med vores AI assistent, fordi sandsynligheden for mulighed 2 nu er steget til \\(85 \\%\\). Faktisk vil vi allerhelst kunne vælge vægtene, så outputvektoren for elev nummer 7 kommer så tæt som muligt på targetvektoren i (4) – og noget tilsvarende skal gerne gøre sig gældende for de øvrige 11 elever i træningsdata.\nVi har derfor brug for en metode til at vælge vægtene, så outputvektoren i (6) bliver \"belønnet\" fremfor outputvektoren i (5). For at gøre det definerer man en såkaldt tabsfunktion. Vi vil her bruge en tabsfunktion, som kaldes for cross-entropy.\nFor at holde tingene simple starter vi med at se på ét træningseksempel ad gangen (til sidst generaliserer vi). Cross-entropy tabsfunktionen er defineret sådan her:\n\\[\nE = - \\sum_{j=1}^J t_j \\cdot \\ln(o_j)\n\\]\nDet ser måske lige lidt mærkeligt ud, men vi skal nok forklare det. Vi kan prøve at skrive summen ud:\n\\[\nE = - \\left (t_1 \\cdot \\ln(o_1)  + t_2 \\cdot \\ln(o_2) + \\cdots + t_j \\cdot \\ln(o_j) + \\cdots + t_J \\cdot \\ln(o_J) \\right)\n\\]\nVi husker nu på, at \\(\\vec t\\) er en one hot vektor. Det vil sige, at det kun er ét af \\(t_j\\)’erne i ovenstående, der er 1 – resten er 0. Lad os sige at det er \\(t_j\\), der er 1. Så er\n\\[\nE = - t_j \\cdot \\ln(o_j) = - \\ln(o_j).\n\\]\nI figur 5 har vi tegnet grafen for den naturlige logaritme-funktion samt grafen for minus den naturlige logartime-funktion:\n\n\n\n\n\n\nFigur 5: Grafen for \\(\\ln(x)\\) og \\(-\\ln(x)\\).\n\n\n\nDa \\(0&lt;o_j&lt;1\\) kan vi for det første se, at \\(-\\ln(o_j) &gt;0\\). Det vil sige, at tabsfunktionen er positiv.\nHusk nu på at \\(t_j=1\\). Hvis vægtene i vores neurale netværk er \"indstillet\" godt, så skal \\(o_j\\) være tæt på 1. I figur 5 kan vi se, at det svarer til, at \\(-\\ln(o_j)\\) er tæt på \\(0\\). Det betyder, at værdien af tabsfunktionen er lille. Omvendt hvis vægtene er \"indstillet\" dårligt, så \\(o_j\\) er tæt på \\(0\\) (selvom \\(t_j=1\\)), så vil \\(-\\ln(o_j)\\) være et stort positivt tal. Altså er værdien af tabsfunktionen stor.\nDet betyder, at tabsfunktionen på den måde måler \"kvaliteten\" af netværket:\n\nFor et godt netværk (med gode indstillinger af vægtene) vil tabsfunktionen have en lille, men positiv værdi.\nFor et dårligt netværk (med dårlige indstillinger af vægtene) vil tabsfunktionen have en stor positiv værdi.\n\nLad også illustrere det med det tidligere eksempel. Hvis\n\\[\n\\vec t =\n\\begin{pmatrix}\n0 \\\\\n1 \\\\\n0 \\\\\n0 \\\\\n\\end{pmatrix}\n\\quad \\textrm{og} \\quad\n\\vec o =\n\\begin{pmatrix}\n0.85 \\\\\n0.10 \\\\\n0.03 \\\\\n0.02 \\\\\n\\end{pmatrix}\n\\]\nså har vi et dårligt netværk og værdien af tabsfunktionen bliver\n\\[\n\\begin{aligned}\nE &= - \\left( 0 \\cdot \\ln(0.85) + 1 \\cdot \\ln(0.10) + 0 \\cdot \\ln(0.03) + 0 \\cdot \\ln(0.02)\\right) \\\\ &= - \\ln(0.10) \\approx 2.30.\n\\end{aligned}\n\\]\nHar vi derimod et bedre netværk, som i stedet giver følgende outputvektor:\n\\[\n\\vec t =\n\\begin{pmatrix}\n0 \\\\\n1 \\\\\n0 \\\\\n0 \\\\\n\\end{pmatrix}\n\\quad \\textrm{og} \\quad\n\\vec o =\n\\begin{pmatrix}\n0.10 \\\\\n0.85 \\\\\n0.03 \\\\\n0.02 \\\\\n\\end{pmatrix}\n\\]\nså vil værdien af tabsfunktionen være\n\\[\n\\begin{aligned}\nE &= - \\left( 0 \\cdot \\ln(0.10) + 1 \\cdot \\ln(0.85) + 0 \\cdot \\ln(0.03) + 0 \\cdot \\ln(0.02)\\right) \\\\\n&= - \\ln(0.85) \\approx 0.16.\n\\end{aligned}\n\\]\nAltså kan vi her se, at det netværk, som er bedre, også har en lavere værdi af tabsfunktionen. Hele idéen er derfor, at vi for et givent træningsdatasæt vil bestemme de værdier af vægtene, som minimerer tabsfunktionen. Hvordan det gøres forklares i det næste afsnit."
  },
  {
    "objectID": "materialer/softmax/softmax.html#opdatering-af-vægtene",
    "href": "materialer/softmax/softmax.html#opdatering-af-vægtene",
    "title": "Simple kunstige neurale netværk til multipel klassifikation",
    "section": "Opdatering af vægtene",
    "text": "Opdatering af vægtene\nVi skal bestemme de værdier af vægtene, som minimerer tabsfunktionen\n\\[\nE = - \\sum_{i=1}^J t_i \\cdot \\ln(o_i)\n\\tag{7}\\]\nHusk på at outputværdierne \\(o_i\\) afhænger af \\(z\\)-værdierne via (3), mens \\(z\\)-værdierne afhænger af vægtene via (2). Altså afhænger tabsfunktionen også indirekte af alle vægtene.\nNår man skal minimere en funktion, som afhænger af flere variable (her vægtene), kan man finde alle de partielle afledede og sætte dem lig med \\(0\\) (ligesom du sikkert er vant til, at løse \\(f'(x)=0\\), hvis du skal bestemme minimum for funktionen \\(f\\)). Det vil give lige så mange ligninger, som der er vægte, og desuden vil ligningerne være koblet med hinanden. Det betyder, at denne fremgangsmåde er beregningsmæssig tung og/eller vil kræve alt for meget plads på en computer. Derfor vælger man i stedet at bruge en approksimativ metode, som kaldes for gradientnedstigning. Vi vil her kort forklare, hvad det går ud på.\nHvis en funktion \\(f\\) afhænger af \\(x_1, x_2, \\dots, x_n\\) så kaldes den vektor, som består af alle de partielle afledede for gradienten:\n\\[\n\\nabla f(x_1, x_2, \\dots, x_n) =\n\\begin{pmatrix}\n\\frac{\\partial f}{\\partial x_1} \\\\\n\\frac{\\partial f}{\\partial x_2} \\\\\n\\vdots \\\\\n\\frac{\\partial f}{\\partial x_n}\n\\end{pmatrix}.\n\\]\nDet viser sig, at denne gradient peger i den retning, hvor funktionsværdien vokser mest. Omvendt vil minus gradienten \\(-\\nabla f(x_1, x_2, \\dots, x_n)\\) pege i den retning, hvor funktionsværdien aftager mest. Hvis vi derfor står et vilkårligt sted på grafen for \\(f\\) og går et lille skridt i den negative gradientens retning, så vil vi være på vej ned mod et minimum (eventuelt kun lokalt). Når vi har gået det lille skridt, udregner vi gradienten igen og bevæger os igen et lille skridt i den negative gradients retning1. Sådan fortsætter man indstil funktionsværdien ikke ændrer sig ret meget – det svarer forhåbentlig til, at vi har fundet et (lokalt) minimum.\n1 Du kan tænke på gradienten som et kompas, der hele tiden viser dig, hvilken vej du skal gå for at bevæge dig ned mod et minimum.Nu hedder vores funktion ikke \\(f\\), men \\(E\\), og \\(E\\) afhænger af alle vægtene \\(w_{j,k}\\). Derfor, når vægten \\(w_{j,k}\\) skal opdateres, så gør vi følgende:\n\\[\nw_{j,k}^{\\textrm{ny}} \\leftarrow w_{j,k} - \\eta \\cdot \\frac{\\partial E}{\\partial w_{j,k}}.\n\\tag{8}\\]\nTallet \\(\\eta\\) kaldes for en learning rate og er typisk et lille tal mellem \\(0\\) og \\(1\\). Det svarer til den skridtlængde vi bruger, når vi går i den negative gradients retning.\nDet vil sige for at opdatere \\(w_{j,k}\\)-vægten, skal vi have udregnet den partielle afledede\n\\[\n\\frac{\\partial E}{\\partial w_{j,k}}.\n\\]\nHvis vi ser på figur 6 og (2) kan vi se, at \\(w_{j,k}\\) kun har indflydelse på \\(z_j\\). Til gengæld har alle \\(z\\)-værdierne indflydelse på alle \\(o\\)-værdierne på grund af udtrykket i (3).\n\n\n\n\n\n\nFigur 6: Neuralt netværk hvor vægtene fra de \\(n\\) input neuroner over til den \\(i\\)’te output neuron er vist.\n\n\n\nDerfor kan vi ved hjælp af kædereglen for flere variable finde den partielle afledede af \\(E\\) med hensyn til \\(w_{j,k}\\) på denne måde\n\\[\n\\frac{\\partial E}{\\partial w_{j,k}} = \\sum_{i=1}^J \\frac{\\partial E}{\\partial z_i} \\cdot \\frac{\\partial z_i}{\\partial w_{j,k}}\n\\]\nMen da \\(w_{j,k}\\) kun har indflydelse på \\(z_j\\) (jævnfør figur 6 og (2)), så vil\n\\[\n\\frac{\\partial z_i}{\\partial w_{j,k}}=0 \\qquad \\text{når} \\qquad i \\neq j\n\\]\nog derfor kan vi nøjes med følgende forsimplede udtryk:\n\\[\n\\frac{\\partial E}{\\partial w_{j,k}} = \\frac{\\partial E}{\\partial z_j} \\cdot \\frac{\\partial z_j}{\\partial w_{j,k}}\n\\tag{9}\\]\nVi starter med at regne på den sidste faktor \\(\\frac{\\partial z_j}{\\partial w_{j,k}}\\) (fordi den er nemmeste!). Ifølge (2) er\n\\[\n\\begin{aligned}\n\\frac{\\partial z_j}{\\partial w_{j,k}} &= \\frac{\\partial }{\\partial w_{j,k}} \\left ( w_{j,0} + w_{j,1} \\cdot x_1 + w_{j,2} \\cdot x_2 + \\cdots +  w_{j,k} \\cdot x_k + \\cdots +  w_{j,n} \\cdot x_n \\right) \\\\\n&= x_k\n\\end{aligned}\n\\tag{10}\\]\nFor at bestemme den første faktor \\(\\frac{\\partial E}{\\partial z_j}\\) bruger vi definitionen af tabsfunktionen i (7) og differentierer ledvist:\n\\[\n\\frac{\\partial E}{\\partial z_j} = - \\sum_{i=1}^J t_i \\cdot \\frac{1}{o_i} \\cdot \\frac{\\partial o_i}{\\partial z_j},\n\\tag{11}\\]\nhvor vi har brugt, at \\(\\ln(o_i)\\) differentieret er \\(\\frac{1}{o_i}\\).\nNu er\n\\[\no_i = \\frac{e^{z_i}}{\\sum_{l=1}^J e^{z_l}}.\n\\]\nDa \\(o_i\\) er udtrykt ved en brøk, får vi brug for kvotientreglen, når vi skal differentiere \\(o_i\\):\n\\[\n\\left ( \\frac{f}{g} \\right )'(x)= \\frac{f'(x)  \\cdot g(x) - f(x) \\cdot g'(x)}{(g(x))^2}\n\\]\nNår \\(o_i\\) skal differentieres med hensyn til \\(z_j\\), er der to muligheder alt efter om \\(i=j\\) eller \\(i \\neq j\\).\nHvis \\(i \\neq j\\), får vi\n\\[\n\\begin{aligned}\n\\frac{\\partial o_i}{\\partial z_j} &= \\frac{0 \\cdot (\\sum_{l=1}^J e^{z_l}) - e^{z_i} \\cdot e^{z_j}}{\\left ( \\sum_{l=1}^J e^{z_l} \\right )^2} \\\\\n&= - \\frac{e^{z_i}}{\\sum_{l=1}^J e^{z_l}} \\cdot \\frac{e^{z_j}}{\\sum_{l=1}^J e^{z_l}} = - o_i \\cdot o_j, \\quad \\quad i \\neq j\n\\end{aligned}\n\\]\nhvor sidste lighedstegn følger af definitionen i (3).\nHvis \\(i=j\\), får vi\n\\[\n\\begin{aligned}\n\\frac{\\partial o_i}{\\partial z_j} &= \\frac{\\partial o_j}{\\partial z_j} = \\frac{e^{z_j} \\cdot (\\sum_{l=1}^J e^{z_l}) - e^{z_j} \\cdot e^{z_j}}{\\left ( \\sum_{l=1}^J e^{z_l} \\right )^2} \\\\\n&= \\frac{e^{z_j} \\cdot (\\sum_{l=1}^J e^{z_l})}{\\left ( \\sum_{l=1}^J e^{z_l} \\right )^2} - \\frac{(e^{z_j})^2}{\\left ( \\sum_{l=1}^J e^{z_l} \\right )^2} \\\\\n&= \\frac{e^{z_j}}{\\sum_{l=1}^J e^{z_l}} - \\left ( \\frac{e^{z_j}}{\\sum_{l=1}^J e^{z_l}} \\right)^2 \\\\\n& = o_j-o_j^2 = o_j(1-o_j), \\quad \\quad i = j\n\\end{aligned}\n\\]\nVi kan nu indsætte i (11):\n\\[\n\\begin{aligned}\n\\frac{\\partial E}{\\partial z_j} &= - \\left ( \\sum_{\\substack{i=1 \\\\ i \\neq j }}^J t_i \\cdot \\frac{1}{o_i} \\cdot (-o_i \\cdot o_j) \\right ) - t_j \\cdot \\frac{1}{o_j} \\cdot o_j \\cdot (1-o_j) \\\\\n&=  - \\left ( \\sum_{\\substack{i=1 \\\\ i \\neq j }}^J t_i \\cdot (-o_j) \\right ) - t_j \\cdot (1-o_j) \\\\\n&=  \\left ( \\sum_{\\substack{i=1 \\\\ i \\neq j }}^J t_i \\cdot o_j \\right ) - t_j + t_j \\cdot o_j\n\\end{aligned}\n\\]\nVi kan nu se, at det led \\(t_j \\cdot o_j\\), som ikke er med i den første sum (hvor \\(i \\neq j\\)), fremkommer som sidste led i ovenstående udtryk. Derfor kan vi inkludere dette led i den første sum og få:\n\\[\n\\begin{aligned}\n\\frac{\\partial E}{\\partial z_j} &= \\left (\\sum_{i=1}^J t_i \\cdot o_j  \\right ) - t_j \\\\\n& =  \\left (o_j \\cdot  \\sum_{i=1}^J t_i  \\right ) - t_j,\n\\end{aligned}\n\\]\nhvor sidste lighedstegn følger af, at \\(o_j\\) ikke afhænger af det indeks, vi summerer over, og derfor kan \\(o_j\\) sættes ud foran summen (det svarer til at sætte en fællesfaktor ud foran en parentes).\nVi udnytter nu, at \\(\\vec t\\) er en one hot vektor – det vil sige, at \\(\\sum_{i=1}^J t_i = 1\\). Derfor ender vi med det meget simple udtryk\n\\[\n\\frac{\\partial E}{\\partial z_j} = o_j - t_j = -(t_j-o_j)\n\\]\nVi indsætter i (9) og får\n\\[\n\\frac{\\partial E}{\\partial w_{j,k}} = \\underbrace{-(t_j - o_j)}_{\\frac{\\partial E}{\\partial z_j}} \\cdot \\underbrace{x_k}_{\\frac{\\partial z_j}{\\partial w_{j,k}}}\n\\tag{12}\\]\nBruger vi opdateringsreglen for \\(w_{j,k}\\)-vægten i (8), ender vi med følgende:\n\n\n\n\n\n\nOpdateringsregel for \\(w_{i,k}\\)-vægten (baseret på ét træningseksempel)\n\n\n\n\n\nVægten fra det \\(k\\)’te input \\(x_k\\) til den \\(j\\)’te outputneuron opdateres således:\n\\[\nw_{j,k}^{(\\textrm{ny})} \\leftarrow w_{j,k} + \\eta \\cdot (t_j - o_j) \\cdot x_k\n\\]\n\n\n\n\n\n\n\n\n\nOpdatering ved hjælp af hele træningsdatasættet\nI det ovenstående har vi udledt opdateringsreglen for \\(w_{j,k}\\)-vægten baseret ét enkelt træningseksempel ad gangen ved at finde minimum for tabsfunktionen:\n\\[\nE = - \\sum_{i=1}^J t_i \\cdot \\ln(o_i)\n\\]\nI virkeligheden definerer man tabsfunktionen baseret på hele træningsdatasættet. Vi starter med at nummerere træningsdata fra \\(1\\) til \\(M\\) og kalder targetværdien og outputværdien hørende til det \\(m\\)’te træningseksempel for \\(\\vec t^{(m)}\\) og \\(\\vec o^{(m)}\\):\n\\[\n\\vec t^{(m)} =\n\\begin{pmatrix}\nt_1^{(m)} \\\\\nt_2^{(m)} \\\\\n\\vdots \\\\\nt_J^{(m)} \\\\\n\\end{pmatrix} \\quad \\quad \\textrm{og} \\quad \\quad\n\\vec o^{(m)} =\n\\begin{pmatrix}\no_1^{(m)} \\\\\no_2^{(m)} \\\\\n\\vdots \\\\\no_J^{(m)} \\\\\n\\end{pmatrix}\n\\]\nSå definerer man tabsfunktionen på denne måde:\n\\[\nE = \\sum_{m=1}^M \\left (- \\sum_{i=1}^J t_i^{(m)} \\cdot \\ln(o_i^{(m)}) \\right )\n\\] Og sætter vi\n\\[\nE^{(m)} = - \\sum_{i=1}^J t_i^{(m)} \\cdot \\ln(o_i^{(m)})\n\\] så bliver tabsfunktionen bare en sum over de individuelle bidrag til tabsfunktionen fra hvert træningseksempel:\n\\[\nE = \\sum_{m=1}^M E^{(m)}\n\\] Vi kan heldigvis differentiere ledvist og får derfor\n\\[\n\\frac{\\partial E}{\\partial w_{j,k}} = \\sum_{m=1}^M \\frac{\\partial E^{(m)}}{\\partial w_{j,k}}\n\\] I det foregående afsnit var det netop \\(\\frac{\\partial E^{(m)}}{\\partial w_{j,k}}\\) vi udledte i (12) – dog uden at specificere nummeret på træningseksemplet:\n\\[\n\\frac{\\partial E^{(m)}}{\\partial w_{j,k}} = -(t_j^{(m)} - o_j^{(m)}) \\cdot x_k^{(m)}\n\\]\nDerfor bliver \\[\n\\frac{\\partial E}{\\partial w_{j,k}} = \\sum_{m=1}^M \\frac{\\partial E^{(m)}}{\\partial w_{j,k}} = - \\sum_{m=1}^M (t_j^{(m)} - o_j^{(m)}) \\cdot x_k^{(m)}\n\\] Opdateringsreglen for \\(w_{j,k}\\)-vægten bliver i det tilfælde:\n\n\n\n\n\n\nOpdateringsregel for \\(w_{i,k}\\)-vægten (baseret på hele træningsdatasættet)\n\n\n\n\n\nVægten fra det \\(k\\)’te input \\(x_k\\) til den \\(j\\)’te outputneuron opdateres således:\n\\[\nw_{j,k}^{(\\textrm{ny})} \\leftarrow w_{j,k} + \\eta \\cdot \\sum_{m=1}^M (t_j^{(m)} - o_j^{(m)}) \\cdot x_k^{(m)}\n\\]\n\n\n\n\n\n\n\n\nSamlet set trænes netværket på denne måde:\n\nSæt alle vægtene til en tilfældig værdi og vælg en værdi for learning raten \\(\\eta\\).\nFor alle træningseksempler udregnes \\(z_j^{(m)}\\) og \\(o_j^{(m)}\\) ved hjælp af feedforward-udtrykkene:\n\\[\nz_j^{(m)} = w_{j,0} + w_{j,1} \\cdot x_1^{(m)} + w_{j,2} \\cdot x_2^{(m)} + \\cdots + w_{j,n} \\cdot x_n^{(m)}\n\\]\nog\n\\[\no_j^{(m)} = \\frac{e^{z_j^{(m)}}}{\\sum_{i=1}^J e^{z_i^{(m)}}}\n\\]\nfor \\(j=1, 2, \\dots, J\\).\nOpdatér alle vægtene:\n\\[\nw_{j,k}^{(\\textrm{ny})} \\leftarrow w_{j,k} + \\eta \\cdot \\sum_{m=1}^M (t_j^{(m)} -    o_j^{(m)}) \\cdot x_k^{(m)}\n\\]\n\nAlle vægtene er nu opdateret, og vi kan gentage punkt 2 og 3, hvor feedforward i 2 hver gang er baseret på de netop opdaterede vægte fra det foregående gennemløb. Opdateringen af vægtene fortsætter indtil værdien af tabsfunktionen næsten ikke ændrer sig. Håbet er nu, at vi har fundet et minimum (eventuelt kun lokalt) for tabsfunktionen."
  },
  {
    "objectID": "materialer/softmax/softmax.html#tilbage-til-eksemplet",
    "href": "materialer/softmax/softmax.html#tilbage-til-eksemplet",
    "title": "Simple kunstige neurale netværk til multipel klassifikation",
    "section": "Tilbage til eksemplet",
    "text": "Tilbage til eksemplet\nVi har nu fået udledt opdateringsreglerne for alle vægtene, og vi vil derfor prøve at træne et netværk ved hjælp af træningsdata i tabel 1. Hvis vi til start sætter alle vægtene til \\(0.5\\), vælger en learning rate på \\(0.001\\) og laver i alt \\(100000\\) iterationer (det vil sige, at vægtene alt i alt opdateres \\(100000\\) gange), så nærmer vi os et minimum for tabsfunktionen. Alle outputværdierne kan nu beregnes ved hjælp af (3). Gør vi det for alle data i træningsdatasættet, får vi følgende2:\n2 Bemærk, at hvis \\(o_1+o_2+o_3+ o_4\\) ikke giver \\(1\\), så skyldes det afrunding.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nElev nr.\n\\(x_1\\) (søvn)\n\\(x_2\\) (emne)\n\\(x_3\\) (eksamen)\nValg\n\\(o_1\\)\n\\(o_2\\)\n\\(o_3\\)\n\\(o_4\\)\n\n\n\n\n\\(1\\)\n\\(10\\)\n\\(10\\)\n\\(10\\)\n\\({\\color{#020873} 1}\\)\n\\(0.98\\)\n\\(0.02\\)\n\\(0.00\\)\n\\(0.00\\)\n\n\n\\(2\\)\n\\(8\\)\n\\(7\\)\n\\(8\\)\n\\({\\color{#020873} 1}\\)\n\\(0.50\\)\n\\(0.50\\)\n\\(0.00\\)\n\\(0.00\\)\n\n\n\\(3\\)\n\\(9\\)\n\\(6\\)\n\\(10\\)\n\\({\\color{#020873} 1}\\)\n\\(0.76\\)\n\\(0.23\\)\n\\(0.00\\)\n\\(0.00\\)\n\n\n\\(4\\)\n\\(4\\)\n\\(10\\)\n\\(10\\)\n\\({\\color{#020873} 1}\\)\n\\(0.77\\)\n\\(0.23\\)\n\\(0.00\\)\n\\(0.00\\)\n\n\n\\(5\\)\n\\(5\\)\n\\(8\\)\n\\(7\\)\n\\({\\color{#8086F2} 2}\\)\n\\(0.19\\)\n\\(0.81\\)\n\\(0.00\\)\n\\(0.00\\)\n\n\n\\(6\\)\n\\(10\\)\n\\(7\\)\n\\(4\\)\n\\({\\color{#8086F2} 2}\\)\n\\(0.15\\)\n\\(0.85\\)\n\\(0.00\\)\n\\(0.00\\)\n\n\n\\(7\\)\n\\(7\\)\n\\(7\\)\n\\(10\\)\n\\({\\color{#8086F2} 2}\\)\n\\(0.70\\)\n\\(0.30\\)\n\\(0.00\\)\n\\(0.00\\)\n\n\n\\(8\\)\n\\(8\\)\n\\(3\\)\n\\(4\\)\n\\({\\color{#F2B33D} 3}\\)\n\\(0.00\\)\n\\(0.00\\)\n\\(0.98\\)\n\\(0.02\\)\n\n\n\\(9\\)\n\\(6\\)\n\\(2\\)\n\\(5\\)\n\\({\\color{#F2B33D} 3}\\)\n\\(0.00\\)\n\\(0.00\\)\n\\(0.99\\)\n\\(0.01\\)\n\n\n\\(10\\)\n\\(10\\)\n\\(2\\)\n\\(2\\)\n\\({\\color{#F2B33D} 3}\\)\n\\(0.00\\)\n\\(0.00\\)\n\\(1.00\\)\n\\(0.00\\)\n\n\n\\(11\\)\n\\(1\\)\n\\(1\\)\n\\(3\\)\n\\({\\color{#F288B9} 4}\\)\n\\(0.00\\)\n\\(0.02\\)\n\\(0.00\\)\n\\(0.98\\)\n\n\n\\(12\\)\n\\(5\\)\n\\(2\\)\n\\(2\\)\n\\({\\color{#F288B9} 4}\\)\n\\(0.00\\)\n\\(0.02\\)\n\\(0.02\\)\n\\(0.96\\)\n\n\n\n\n\nTabel 2: Træningsdata fra 12 elever inklusion de bergende outputværdier.\n\n\n\nEt netværk vil altid være forholdsvis godt til at prædiktere korrekt på de data, som netværket er trænet på. Det kan du læse mere om i noten om Overfitting, modeludvælgelse og krydsvalidering. Med det i baghovedet kan vi alligevel se fra tabel 2 se, at den prædikterede sandsynlighed for det valg, som hver elev træffer, er høj. For eksempel vælger elev nr. 1 også valg 1 (at blive i klassen), og den prædikterede sandsynlighed for dette valg er \\(o_1 = 0.98\\).\nFor elev nr. 2 kan vi se, at vores AI assistent er i tvivl om (\\(o_1=o_2=0.50\\)), om den skal anbefale valg 1 eller 2 (eleven har valgt 1). For elev nr. 7 vil vores AI assisten anbefale valg 1 (\\(o_1 = 0.70\\)), men eleven træffer i virkeligheden valg 2. De resterende anbefalinger er korrekte.\nPå figur 7 er elev 2 og 7 fremhævet ved, at de tilhørende punkter er tegnet større. Hvis man drejer lidt rundt på figuren, kan man se, at de to punkter ligger forholdsvis tæt på hinanden og i nærheden af andre mørkeblå punkter, så det er ikke helt så underligt, at netværket netop har svært ved at prædiktere, som det gør.\n\n\n\n\n\n\n\n\nFigur 7: Punktplot af træningsdata fra tabel 2. Punkternes farve angiver valget (mørkeblå svarer til 1, lyseblå svarer til 2, gul svarer til 3 og lyserød svarer til 4). De to punkter, som er tegnet større, svarer til elev 2 og 7, hvor netværket ikke prædikterer korrekt.\n\n\n\nNu er idéen jo ikke at komme med et godt råd til de elever, som allerede har truffet et valg (svarende til at prædiktere på træningsdata), men derimod at vejlede kommende elever.\nByd derfor velkommen til tre nye elever:\n\nDen første elev, som træder ind ad døren er Anton. Anton har sovet fuldstændig fantastisk (\\(x_1=10\\)), han synes, at det emne, vi er i gang med, er pænt kedeligt (\\(x_2=2\\)). Til gengæld har Anton høje ambitioner om at klare sig godt til eksamen (\\(x_3=9\\)).\nHerefter følger Signe. Signe bøvler lidt med sin søvn (\\(x_1=4\\)), hun synes, at emnet vi er i gang med er semi godt \\(x_2=5\\), og så har Signe skyhøje forventninger til eksamen (\\(x_3=10\\)).\nTil sidst kommer Mads – lidt for sent i øvrigt… Mads har nemlig spillet computer den halve nat (\\(x_1=3\\)), han synes, at emnet er ret interessant (\\(x_2=8\\)), men han er pænt ligeglad med, hvordan det går til eksamen (\\(x_3=2\\)).\n\nAlle tre elever hiver straks deres ny AI assistent op af lommen, indtaster svaret på de tre spørgsmål og beder om en anbefaling. Her er, hvad der kommer ud af det:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nElev\n\\(x_1\\)\n\\(x_2\\)\n\\(x_3\\)\n\\(o_1\\)\n\\(o_2\\)\n\\(o_3\\)\n\\(o_4\\)\nValg\n\n\n\n\nAnton\n\\(10\\)\n\\(2\\)\n\\(9\\)\n\\(0.00\\)\n\\(0.00\\)\n\\(1.00\\)\n\\(0.00\\)\n\\({\\color{#F2B33D} 3}\\)\n\n\nSigne\n\\(4\\)\n\\(5\\)\n\\(10\\)\n\\(0.17\\)\n\\(0.82\\)\n\\(0.00\\)\n\\(0.00\\)\n\\({\\color{#8086F2} 2}\\)\n\n\nMads\n\\(3\\)\n\\(8\\)\n\\(2\\)\n\\(0.00\\)\n\\(1.00\\)\n\\(0.00\\)\n\\(0.00\\)\n\\({\\color{#8086F2} 2}\\)\n\n\n\nAnton bliver anbefalet, at gå i kantinen (valg 3), mens Signe og Mads bliver anbefalet at gå ud for at regne opgaver (valg 2). Det kan godt se ud som om, at \\(x_2\\) (interessen for emnet) er forholdsvis afgørende for den endelig anbefaling. Hvis du tager et kig på figur 1, vil du også opdage, at hvis \\(x_2&lt;5\\), så er alle punkter lyserøde eller gule (svarende til valg 3 og 4), mens alle punkter, hvor \\(x_2 \\geq 5\\) er lyse- eller mørkeblå (valg 1 og 2). Det kunne jo få en til at tænke, om det i virkeligheden ville være nok at svare på spørgsmål 2, uden at det går udover klassifikationsnøjagtigheden. Det vil man kunne undersøge ved at lave en model med kun \\(x_2\\) som inputvariabel og en anden model med alle tre inputvariable og så for eksempel vurdere de to modellers klassifikationsnøjagtighed ved hjælp af krydsvalidering, men det ligger uden for formålet med denne note.\nI figur 8 er de tre nye elever indtegnet sammen med træningsdata. Når man ser, hvordan de tre nye elever ligger i forhold til de andre punkter i træningsdata, så giver det faktisk god mening, at Anton bliver \"farvet\" gul, mens Signe og Mads bliver \"farvet\" lyseblå.\n\n\n\n\n\n\n\n\nFigur 8: Punktplot af træningsdata fra tabel 1. Punkternes farve angiver valget (mørkeblå svarer til 1, lyseblå svarer til 2, gul svarer til 3 og lyserød svarer til 4). Derudover er de tre nye elever indtegnet (punkterne er farvet grå)."
  },
  {
    "objectID": "materialer/funktioner_af_flere_variable/funktioner_af_flere_variable.html",
    "href": "materialer/funktioner_af_flere_variable/funktioner_af_flere_variable.html",
    "title": "Funktioner af flere variable",
    "section": "",
    "text": "En funktion kan godt afhænge af flere forskellige variable, og i det tilfælde taler man om en funktion af flere variable. Denne type af funktioner viser sig at spille en helt central rolle i rigtig mange metoder inden for kunstig intelligens. Derfor vil vi i denne note behandle de vigtigste begreber i forbindelse med funktioner af flere variable."
  },
  {
    "objectID": "materialer/funktioner_af_flere_variable/funktioner_af_flere_variable.html#funktioner-af-én-variabel",
    "href": "materialer/funktioner_af_flere_variable/funktioner_af_flere_variable.html#funktioner-af-én-variabel",
    "title": "Funktioner af flere variable",
    "section": "Funktioner af én variabel",
    "text": "Funktioner af én variabel\nFra gymnasiematematikken kender vi lineære funktioner, eksponentialfunktioner, potensfunktioner og en hel masse andre typer af funktioner. Fælles for dem er, at de alle afhænger af én variabel \\(x\\). For eksempel de lineære funktioner:\n\\[\nf(x)=a \\cdot x+b.\n\\] Grafen for \\(f\\) består af alle de punkter \\((x,y)\\), hvor \\(y=f(x)\\). Det er illustreret på figur 1.\n\n\n\n\n\n\nFigur 1: Grafen for en lineær funktion \\(f(x)=ax+b\\), hvor det er illustreret at et punkt \\((x,y)\\) ligger på grafen for \\(f\\), hvis \\(y=f(x)\\).\n\n\n\nHvis funktionen \\(f\\) tager et reelt tal som input og giver et reelt tal som output1, så skriver man\n1 Hverken definitions- eller værdimængden for funktionen behøver ikke at være hele \\(\\mathbb{R}\\), men kan godt bare være en delmængde af \\(\\mathbb{R}\\).\\[\nf: \\mathbb{R} \\rightarrow \\mathbb{R}.\n\\] Du har måske også været vant til at se en \"maskine-metafor\", som illustreret på figur 2.\n\n\n\n\n\n\nFigur 2: Funktionen \\(f\\) illustreret som en maskine.\n\n\n\nHer er tanken, at man sender et \\(x\\) ind i funktionsmaskinen, som så ved hjælp af forskriften for \\(f\\) beregner funktionsværdi \\(y=f(x)\\), som herefter bliver sendt ud af maskinen2.\n2 Faktisk er det ikke alle funktioner, som har en forskrift. For eksempel er der ikke nødvendigvis en forskrift for den funktion, hvis graf ses til venstre i figur 3. Her vil man i stedet kunne aflæse en funktionsværdi for en given værdi af \\(x\\). En anden mulighed er, at funktionsværdien skal findes i en tabel.For at der overhovedet er tale om en funktion, skal det være sådan, at der til enhver værdi af \\(x\\) svarer én og kun én funktionsværdi \\(f(x)\\). Så hvis man for eksempel sender \\(x=2\\) ind i maskinen, så må funktionen ikke nogle gange sende \\(y=5\\) ud og andre gange \\(y=-3\\). Hvis \\(x=2\\) kommer ind, så skal det altid være den samme funktionsværdi, der kommer ud.\nGrafisk er det illustreret på figur 3.\n\n\n\n\n\n\nFigur 3: Til venstre ses grafen for en funktion. Til højre ses en kurve, som ikke kan være grafen for en funktion. Ved den grønne linje ses for eksempel en \\(x\\)-værdi hvortil der svarer ikke kun én, men tre \\(y\\)-værdier."
  },
  {
    "objectID": "materialer/funktioner_af_flere_variable/funktioner_af_flere_variable.html#funktioner-af-to-variable",
    "href": "materialer/funktioner_af_flere_variable/funktioner_af_flere_variable.html#funktioner-af-to-variable",
    "title": "Funktioner af flere variable",
    "section": "Funktioner af to variable",
    "text": "Funktioner af to variable\nIdéen med funktioner af to variable er en funktion \\(f\\), som skal bruge to tal som input for at give et output. Vi kalder her de to inputværdier for \\(x\\) og \\(y\\). Her er et eksempel:\n\\[\nf(x,y)= 2x^2-y^2+3xy+1.\n\\]\nGrafen for \\(f\\) består nu af alle de punkter \\((x,y,z)\\) i et tre-dimensionelt koordinatsystem, hvor \\(z=f(x,y)\\). For eksempel er\n\\[\n\\begin{aligned}\nf(1,-2)&=2\\cdot 1^2-(-2)^2+3 \\cdot 1 \\cdot (-2)+1 \\\\\n&=2-4-6+1=-7\n\\end{aligned}\n\\] Det betyder, at punktet \\(P(1,-2,-7)\\) ligger på grafen for \\(f\\). Grafen for \\(f\\) og punktet \\(P\\) ses i figur 4 herunder.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigur 4: Grafen for funktionen \\(f\\) med forskrift \\(f(x,y)=2x^2-y^2+3xy+1\\) samt punktet \\(P(1,-2,-7)\\).\n\n\n\nFaktisk kender du allerede en særlig type af funktioner af to variable. Nemlig den slags funktioner, hvis graf er en plan. Som du måske husker, kan en plan gennem punktet \\((x_0,y_0,z_0)\\) og med normalvektor\n\\[\n\\vec n =\n\\begin{pmatrix}\na \\\\\nb \\\\\nc\n\\end{pmatrix}\n\\]\nbeskrives ved ligningen\n\\[\na(x-x_0)+b(y-y_0)+c(z-z_0)=0.\n\\]\nEn alternativ skrivemåde er\n\\[\nax+by+cz+d=0.\n\\] Hvis \\(c \\neq 0\\) kan vi i denne ligning isolere \\(z\\):\n\\[\nz = -\\frac{a}{c}x -\\frac{b}{c}y-\\frac{d}{c}.\n\\]\nEn ikke-lodret plan i rummet er derfor graf for en funktion af to variable med en forskrift på formen\n\\[\nf(x,y)= -\\frac{a}{c}x -\\frac{b}{c}y-\\frac{d}{c}.\n\\] Og skrevet lidt simplere:\n\\[\nf(x,y) = Ax+By+C,\n\\]\nhvor \\(A=-a/c, B=-b/c\\) og \\(C=-d/c\\).\nVi kan igen bruge \"maskine-metaforen\" for funktioner af to variable, som illustreret i figur 5.\n\n\n\n\n\n\nFigur 5: Funktionen \\(f\\) af to variable illustreret som en maskine.\n\n\n\nFor at vi kan tale om, at det er en funktion, kræver vi igen, at der til enhver værdi af \\((x,y)\\) svarer én og kun én funktionsværdi \\(z=f(x,y).\\) Maskinen skal altså altid returnere den samme funktionsværdi for en given værdi af \\((x,y)\\).\nHvis en funktion \\(f\\), som input kan tage en \\((x,y)\\)-værdi, og som output giver en funktionsværdi \\(z\\), skriver vi\n\\[\nf: \\mathbb{R}^2 \\rightarrow \\mathbb{R}.\n\\]\nHer indikerer \\(2\\)-tallet altså, at der er tale om en funktion af to variable.\n\nSnitfunktioner og snitkurver\nVi vil nu for en funktion af to variable tage udgangspunkt i et konkret punkt \\(P(x_0, y_0, f(x_0,y_0))\\). Forestil dig at vi i \\(P\\) laver et lodret snit ned gennem grafen for \\(f\\) med en plan, som er parallel med \\(x\\)-aksen. Det er lidt ligesom, at lave et snit ned gennem en lagkage! Et eksempel er vist i figur 6. Den lyseblå plan svarer til den lagkagekniv, vi har skåret med, og den skærer altså lodret og er samtidig parallel med \\(x\\)-aksen.\nNår man laver sådan et lodret snit med grafen for \\(f\\), så kalder man skæringen mellem den lodrette plan (lagkagekniven) og grafen for \\(f\\) for en snitkurve. Snitkurven er markeret med sort på figur 6. Den funktion, hvis graf svarer til snitkurven, kaldes for en snitfunktion. Forskriften for snitfunktionen fås ved, at vi fastholder \\(y\\)-værdien på \\(y_0\\) og lader \\(x\\) varierer:\n\\[\ng(x)=f(x,y_0).\n\\] Vi kan også lave et lodret snit gennem \\(P(x_0,y_0,f(x_0,y_0))\\), men hvor snittet i stedet er parallel med \\(y\\)-aksen – se figur 7. Det svarer til, at vi fastholder \\(x\\) på værdien \\(x_0\\) og lader \\(y\\) variere. Gør vi det fås snitfunktionen\n\\[\nh(y)=f(x_0,y).\n\\]\nLad os se på eksemplet fra tidligere \\[\nf(x,y)= 2x^2-y^2+3xy+1.\n\\]\nFastholder vi for eksempel \\(y\\) på \\(-2\\), får vi snitfunktionen\n\\[\n\\begin{aligned}\ng(x) &=f(x,-2)=2x^2-(-2)^2+3 \\cdot x \\cdot (-2)+1 \\\\\n&=2x^2-6x-3.\n\\end{aligned}\n\\] Den tilhørende snitkurve svarer til skæringskurven mellem grafen for \\(f\\) og planen med ligning \\(y=-2\\), som ses i figuren herunder. Bemærk, at snitfunktionen \\(g\\) er et andengradspolynomium, hvis graf er en parabel med grene, som vender opad, idet koefficienten til andengradsleddet er positiv.\n\n\n\n\n\n\n\n\nFigur 6: Grafen for snitfunktionen \\(g\\) med forskrift \\(g(x)=2x^2-6x-3\\) markeret med sort. Den lyseblå plan er planen med ligning \\(y=-2\\).\n\n\n\nFastholder vi derimod \\(x\\) på \\(1\\), får vi snitfunktionen\n\\[\n\\begin{aligned}\nh(y)&=f(1,y)=2 \\cdot 1^2 -y^2 +3 \\cdot 1 \\cdot y +1 \\\\\n&=-y^2+3y+3.\n\\end{aligned}\n\\] Her ser vi igen, at snitfunktionen er et andengradspolynomium, og grafen vil være en parabel med grene, der vender nedad. Snitkurven svarer til skæringskurven mellem grafen for \\(f\\) og planen med ligning \\(x=1\\), som vist herunder.\n\n\n\n\n\n\n\n\nFigur 7: Grafen for snitfunktionen \\(h\\) med forskrift \\(h(y)=-y^2+3y+3\\) markeret med sort. Den lyseblå plan er planen med ligning \\(x=1\\).\n\n\n\n\n\nPartielle afledede\nFra funktioner af én variabel ved vi, at nogle funktioner er differentiable. Det kan funktioner af to variable også være. Her defineres de såkaldte partielle afledede ved simpelthen af differentiere de to forskellige typer af snitfunktioner, som vi definerede ovenfor.\nLad os forklare det lidt nærmere. Snitfunktionen \\(g(x)=f(x,y_0)\\) er jo en \"almindelig\" funktion af én variabel \\(x\\). Hvis \\(g\\) er differentiabel, så kalder man \\(g'(x)\\) for den partielle afledede af \\(f\\) med hensyn til \\(x\\). Notationen for den partielle afledede af \\(f\\) med hensyn til \\(x\\) er som regel en af følgende:\n\\[\ng'(x)=f_x(x,y_0)=\\frac{\\partial f}{\\partial x}=\\frac{\\partial}{\\partial x}f(x,y_0),\n\\]\nhvor \\(y_0\\) her er en konstant.\nDefinitionen af den partielle afledede kan også skrives med den vante \"grænseværdi-notation\". Gør man det kommer det til at se sådan her ud:\n\\[\nf_x(x,y_0) = \\lim_{h \\rightarrow 0} \\frac{f(x+h,y_0)-f(x,y_0)}{h}\n\\]\nSer vi igen på vores eksempel, får vi\n\\[\nf(x,y_0)= 2x^2-y_0^2+3xy_0+1.\n\\] Så vil den partielle afledede med hensyn til \\(x\\) være\n\\[\nf_x(x,y_0)=2 \\cdot 2x-0 + 3 \\cdot 1 \\cdot y_0 + 0 = 4x+3y_0.\n\\] Bemærk her, at \\(y_0^2\\) differentieret bliver \\(0\\), fordi \\(y_0\\) er en konstant, og en konstant, som er lagt til, bliver som bekendt \\(0\\), når vi differentierer. Når vi skal differentiere udtrykket \\(3xy_0\\), så er \\(y_0\\) en konstant, som er ganget på, og derfor lader vi den stå, når vi differentierer (ligesom vi lader \\(3\\)-tallet stå og differentierer \\(x\\), som giver \\(1\\)).\nNormalvis gider man ikke slæbe rundt på \\(y_0\\) i ovenstående udtryk, fordi \\(y_0\\) jo kan være en hvilken som helst værdi svarende til, at vi flytter det lodrette snit. Derfor skriver man som oftest bare\n\\[\nf_x(x,y)=4x+3y.\n\\]\nNår vi finder den partielle afledede med hensyn til \\(x\\), kan vi altså gøre det helt generelt, hvor vi bare tænker på \\(y\\) som en konstant.\nTidligere fastholdt vi \\(y\\) på værdien \\(-2\\). Indsætter vi \\(y=-2\\) i ovenstående udtryk for \\(f_x(x,y)\\) får vi\n\\[\nf_x(x,-2)=4x+3 \\cdot (-2)=4x-6.\n\\] Men vi kunne lige så godt have differentieret snitfunktionen\n\\[\ng(x)=f(x,-2)=2x^2-6x-3.\n\\] Gør vi det, får vi \\[\ng'(x)=4x-6,  \n\\] der heldigvis svarer til udtrykket for \\(f_x(x,-2)\\), som vi netop har fundet.\nHelt tilsvarende definerer vi den partielle afledede af \\(f\\) med hensyn til \\(y\\) ved at differentiere snitfunktionen \\(h(y)\\) (såfremt denne snitfunktion er differentiabel):\n\\[\nh'(y)=f_y(x_0,y)=\\frac{\\partial f}{\\partial y}=\\frac{\\partial}{\\partial y}f(x_0,y)\n\\]\nog med \"grænseværdi-notationen\" bliver det\n\\[\nf_y(x_0,y) =\n\\lim_{h \\rightarrow 0} \\frac{f(x_0,y+h)-f(x_0,y)}{h}.\n\\] $$\nSer vi igen på \\[\nf(x_0,y)= 2x_0^2-y^2+3x_0y+1,\n\\] så vil den partielle afledede med hensyn til \\(y\\) være\n\\[\nf_y(x_0,y)=0-2y+3x_0\\cdot 1+0=3x_0-2y.\n\\]\nHer er \\(x_0\\) en konstant, og derfor er \\(2x_0^2\\) differentieret \\(0\\), og \\(3x_0y\\) differentieret med hensyn til \\(y\\) bliver \\(3x_0\\).\nIgen vil vi som oftest bare skrive\n\\[\nf_y(x,y)=3x-2y.\n\\]\n\n\nGrafisk betydning af de partielle afledede\nFor en funktion \\(f\\) af én variabel ved vi, at hvis \\(f\\) er differentiabel i \\(x_0\\), så vil \\(f'(x_0)\\) svarer til hældningen for tangenten til grafen for \\(f\\) i punktet \\((x_0,f(x_0))\\).\nVi kan nu udlede en tilsvarende grafisk betydning af de partielle afledede. Vi ser igen på snitfunktionen \\(g(x)\\), hvor \\(y\\) er fastholdt på \\(y_0\\):\n\\[\ng(x)=f(x,y_0)\n\\]\nDen partielle afledede med hensyn til \\(x\\) er så\n\\[\ng'(x)=f_x(x,y_0).\n\\] Men nu må \\(g'(x_0)\\) være hældningen for tangenten til grafen for snitfunktionen \\(g\\) i punktet \\((x_0,g(x_0))\\).\nLad os illustrere det med vores eksempel hvor \\(f(x,y)= 2x^2-y^2+3xy+1\\). Her er\n\\[\nf_x(x,y)=4x+3y.\n\\] Vi fandt tidligere, at \\(P(1,-2,-7)\\) ligger på grafen for \\(f\\). Ser vi på snitfunktionen \\(g(x)=f(x,-2)\\), så ligger \\(P\\) altså også på den tilsvarende snitkurve.  Udregner vi \\(g'(1)=f_x(1,-2)\\), får vi\n\\[\nf_x(1,-2)=4 \\cdot 1 + 3 \\cdot (-2) = 4-6=-2\n\\]\nDet betyder, at hvis vi tegner tangenten til snitkurven i \\(P\\), så vil denne tangent have en hældning på \\(-2\\), som illustreret i figuren herunder.\n\n\n\n\n\n\n\n\nFigur 8: Tangenten (stiplet linje) til grafen for snitfunktionen \\(g\\) med forskrift \\(g(x)=2x^2-6x-3\\) i punktet \\(P(1,-2,-7)\\) har en hældning på \\(-2\\).\n\n\n\nHelt tilsvarende kan vi fortolke den partielle afledede af \\(f\\) med hensyn til \\(y\\) i punktet \\(P\\). Vi fandt, at\n\\[\nf_y(x,y)=3x-2y.\n\\]\nSå i \\((1,-2)\\) har vi\n\\[\nf_y(1,-2)= 3 \\cdot 1 - 2 \\cdot (-2)=3+4=7\n\\] Altså vil tangenten til snitkurven hørende til snitfunktionen \\(h(y)=f(1,y)\\) have en tangenthældning på \\(7\\) i punktet \\((-2,h(-2))\\). Det er vist i figuren herunder.\n\n\n\n\n\n\n\n\nFigur 9: Tangenten (stiplet linje) til grafen for snitfunktionen \\(h\\) med forskrift \\(h(y)=-y^2+3y+3\\) i punktet \\(P(1,-2,-7)\\) har en hældning på \\(7\\).\n\n\n\nDe partielle afledede svarer altså til tangenthældninger på snitkurver, som er fremkommet ved at finde skæringskurven mellem grafen for \\(f\\) og en plan med ligning \\(x=x_0\\) eller grafen for \\(f\\) og en plan med ligning \\(y=y_0\\).\nMan kan også bestemme tangenthældninger for mere generelle snitkurver, som fremkommer ved, at man finder skæringskurven mellem grafen for \\(f\\) og en plan med ligning \\(ax+by+c=0\\) (som står vinkelret på \\(xy\\)-planen). Differentierer man de tilhørende snitfunktioner, kalder man de afledede for retningsafledede. Det kan du læse meget mere om her.\nFor funktioner af flere variable kan man også bestemme en ligning for en såkaldt tangentplan. Det kan du læse mere om her.\n\n\nGradienten og betydningen af denne\nMan definerer gradienten for en funktion \\(f\\) af to variable, som den vektor hvis koordinater svarer til de partielle afledede. Gradienten skrives \\(\\nabla f (x,y)\\). Det vil sige, at\n\\[\n\\nabla f(x,y) =\n\\begin{pmatrix}\nf_x(x,y) \\\\ f_y(x,y)\n\\end{pmatrix}.\n\\]\nVi ser her, at gradienten er en to-dimensionel vektor. Det betyder, at man kan tegne en repræsentant for vektoren i \\(xy\\)-planen.\nLad os regne lidt på det i vores eksempel. Vi husker, at \\(f(x,y)=2x^2-y^2+3xy+1\\) og vi fandt ovenfor, at \\[\nf_x(1,-2)=-2\n\\] og\n\\[\nf_y(1,-2)=7.\n\\] Det vil sige, at \\[\n\\nabla f(1,-2) =\n\\begin{pmatrix}\n-2 \\\\ 7\n\\end{pmatrix}\n\\]\nTegner vi en repræsentant for denne vektor i \\(xy\\)-planen med udgangspunkt i punktet \\(Q(1,-2,0)\\) (som er projektionen af \\(P(1,-2,-7)\\) op på \\(xy\\)-planen) ses resultatet i figur 10 herunder. Hvis du drejer lidt rundt på grafen, kan du se, at gradienten angiver en retning i \\(xy\\)-planen. Laver man et snit med en lodret plan gennem \\(P\\), som peger i gradientens retning fås den snitkurve, som er indtegnet med sort.\n\n\n\n\n\n\n\n\nFigur 10: En repræsentant for vektoren \\(\\nabla f(1,-2)\\) er tegnet med udgangspunkt i \\(P(1,-2,7)\\)’s projektion på \\(xy\\)-planen.\n\n\n\nDet er jo alt sammen fint nok, men hvad skal man mon bruge det til? Det er nemmest at forklare, hvis du forestiller dig, at grafen for \\(f\\) er et landskab, hvor du står i punktet \\(P(x_0,y_0,f(x_0,y_0))\\). Så viser det sig, at gradienten \\(\\nabla f(x_0,y_0)\\) peger i den retning, hvor funktionsværdien vokser mest3. Det vil altså sige, at hvis du står i \\(P\\) og gerne vil gå allermest opad bakke, så skal du gå i gradientens retning. Det svarer derfor til at følge den snitkurve, som er markeret på app’en ovenfor. Hvis du drejer rundt på grafen i app’en, kan du måske få en fornemmelse af, at snitkurven netop angiver den \"sti\", man skal følge, hvis man i punktet \\(P\\) vil gå mest opad bakke.\n3 Argumentet for at det er rigtigt, kan du læse om her.Omvendt vil det også være sådan, at hvis du vil bevæge dig allermest nedad bakke, så skal du gå i retningen \\(-\\nabla f(x_0,y_0)\\) (det svarer til, at du lige har vendt dig rundt \\(180^{\\circ}\\) i forhold til den retning, som gradienten peger i). Beviset for at det forholder sig sådan, kan du læse her.\nDet er vigtigt her at bemærke, at det med at gå i gradientens positive eller negative retning for at gå allermest opad eller nedad bakke kun gælder i nærheden af punktet \\(P\\). Man kalder det derfor også for en \"lokal\" egenskab. Det betyder, at hvis man er kommet lidt væk fra punktet \\(P\\), så må man beregne en ny gradient i det nye punkt, man står i, og denne gradient vil nu formentlig pege i en ny retning. Det vil sige, at vi i dette nye punkt nu skal gå langs en ny \"sti\" for at gå allermest opad eller nedad bakke.\nFint nok tænker du måske, men hvem gider at gå allermest opad bakke? Se det er her, at det fine kommer ind i billedet og grunden til, at vi overhovedet gider tale om funktioner er flere variable i forbindelse med kunstig intelligens. I rigtig mange metoder inden for kunstig intelligens skal \"den kunstige intelligens\" trænes for at blive god4. Eksempler er generelle neurale netværk, perceptroner og simple neurale netværk, som du kan læse meget mere om senere.\n4 Og nu tænker du nok, at det er derfor, at man skal gå opad bakke, men det er alligevel ikke helt sådan det forholder sig 😊.5 Når et ekstremum for en funktion bestemmes på denne måde, kalder man det for en numerisk metode. Det står i modsætning til at bestemme ekstrema for en funktion analytisk. Bestemmes ekstrema analytisk sættes den afledede funktion (eller de partielle afledede funktioner) lig med \\(0\\), og herefter finder man ud af, om der er tale om et maksimum eller minimum (eller eventuelt ingen af delene). Nogle gange er det enten beregningsmæssigt tungt eller helt umuligt at løse de ligninger, som det kræves for at finde ekstrema analytisk. Derfor er de numeriske metoder smarte, også selvom man ikke nødvendigvis finder det præcise ekstrema, men kun et punkt som er tæt på. Du kender faktisk allerede en anden numeriske metode nemlig Newton-Raphsons metode, som bruges til at bestemme en funktions nulpunkter (det vil sige, at løse ligningen \\(f(x)=0\\)).Ser vi for eksempel på et kunstigt neuralt netværk, så kan det grundlæggende ingenting til at starte med. Men så giver man netværket nogle træningsdata, så det gradvist kan blive bedre. Det er her, at man siger, at man træner netværket. Det foregår ved, at man definerer en såkaldt tabsfunktion. Den måler basalt set, hvor godt netværket er lige nu. Man ønsker at tabsfunktionen skal minimeres (lille tab = godt netværk). Det kan være en meget kompliceret opgave, hvis man analytisk skal bestemme minimum for en sådan tabsfunktion, og det er lige præcis her, at gradienten kommer ind i billedet. Man starter nemlig et tilfældigt sted på grafen for tabsfunktionen (svarende til at man stiller sig i et punkt \\(P\\) på grafen for en funktion \\(f\\)). Så udregner man gradienten, og da man gerne vil finde minimum for tabsfunktionen, så går man et lille skridt i den negative gradients retning. For vi ved jo netop, at det er den retning, vi skal gå i, hvis vi gerne vil gå i den retning, hvor funktionsværdien falder mest (og det er jo smart, hvis man gerne vil ende i et minimum). Så står man i et nyt punkt på grafen, udregner gradienten i det nye punkt og går så et lille skridt i denne gradients negative retning. Sådan fortsætter man, indtil man har fundet minimum eller noget, der er tæt på (eller måske bare \"godt nok\" – det kan nemlig godt være et lokalt minimum, man rammer ind i)5. Se det er faktisk the backbone i nogle af de mest populære og moderne metoder inden for kunstig intelligens, som anvendes i dag!"
  },
  {
    "objectID": "materialer/funktioner_af_flere_variable/funktioner_af_flere_variable.html#funktioner-af-flere-variable",
    "href": "materialer/funktioner_af_flere_variable/funktioner_af_flere_variable.html#funktioner-af-flere-variable",
    "title": "Funktioner af flere variable",
    "section": "Funktioner af flere variable",
    "text": "Funktioner af flere variable\nVi har lige redegjort for, at gradienten er helt central i forbindelse med minimering af tabsfunktioner. Men faktisk vil det være sådan, at tabsfunktioner i virkeligheden ikke kun afhænger af to, men derimod af millioner af variable! Derfor har man helt generelt brug for at se på funktioner af flere variable end to. Vi kalder input-værdierne til funktionen \\((x_1, x_2, \\dots , x_n)\\), og man taler så om en funktion af \\(n\\) variable, hvis der for enhver værdi af \\((x_1, x_2, \\dots , x_n)\\) svarer én og kun én funktionsværdi: \\[\ny = f(x_1, x_2, \\dots, x_n).\n\\]\nMan skriver derfor\n\\[\nf: \\mathbb{R}^n \\rightarrow \\mathbb{R},\n\\] hvor \\(n\\)’et her tydeliggør, at der er tale om en funktion af \\(n\\) variable.\nDet er faktisk ikke helt så svært at forestille sig funktioner af flere variable end to, hvis nedenstående eksempel illustrerer.\n\nEksempel 1 En virksomhed producerer en bestem vare. Virksomhedens fortjeneste afhænger af en række faktorer. Fx antal solgte varer, løn til medarbejdere, elprisen, prisen på en bestemt råvarer (som bruges i produktionen) og antal sygedage blandt med arbejderne. Virksomheden har fundet ud af, at fortjenesten tilnærmelsesvist kan udregnes på følgende måde6:\n6 Bemærk, at eksemplet er fiktivt og tjener kun som en illustration.\\[\n\\begin{aligned}\n\\textrm{fortjeneste } = 7.2 \\cdot \\sqrt{\\textrm{( antal solgte varer )}}- \\textrm{( løn )} -0.9 \\cdot \\textrm{( elprisen )} \\\\ -1.4 \\cdot \\textrm{( pris på råvarer )} -0.5 \\cdot \\textrm{( antal sygedage )}^2\n\\end{aligned}\n\\]\nDet kan skrives som en funktion af fem variable \\[\nf(x_1, x_2, x_3, x_4,x_5) = 7.2 \\cdot \\sqrt{x_1}-x_2 -0.9 \\cdot x_3 - 1.4 \\cdot x_4 - 0.5 \\cdot (x_5)^2,\n\\] hvor \\(f(x_1,x_2,x_3,x,x_4,x_5)\\) betegner fortjeneste, \\(x_1\\) er antal solgte varer, \\(x_2\\) er løn til medarbejderne, \\(x_3\\) er elprisen, \\(x_4\\) er prisen på råvarer og \\(x_5\\) er antal sygedage.\n\nGrafen for en funktion \\(f\\) af \\(n\\) variable består af alle de punkter \\((x_1, x_2, \\dots, x_n,y)\\) i et \\((n+1)\\)-dimensionalt koordinatsystem, hvor \\(y = f(x_1, x_2, \\dots, x_n)\\). Koordinatsystemer på \\(4\\) dimensioner eller flere er svære at rumme i vores \\(3\\)-dimensionelle verden, så af den grund behøver vi ikke at bekymre os om, hvordan grafen for \\(f\\) ser ud.\nDe partielle afledede defineres helt som før. Når man for eksempel skal finde den partielle afledede med hensyn \\(x_1\\), så betragtes \\(x_2, x_3, \\dots, x_n\\) som konstanter, og man differentierer den tilsvarende snitfunktion med hensyn til \\(x_1\\). De partielle afledede betegnes med\n\\[\n\\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2}, \\dots, \\frac{\\partial f}{\\partial x_n}.\n\\]\nGradienten defineres som en naturlig udvidelse af den tidligere definition\n\\[\n\\nabla f(x_1, x_2, \\dots, x_n) =\n\\begin{pmatrix}\n\\frac{\\partial f}{\\partial x_1} \\\\\n\\frac{\\partial f}{\\partial x_2} \\\\\n\\vdots \\\\\n\\frac{\\partial f}{\\partial x_n}\n\\end{pmatrix}.\n\\]\nHelt analogt til før viser det sig, at gradienten peger i den retning, hvor funktionsværdien vokser mest. Og minus gradienten peger så altså i den retning, hvor funktionsværdien aftager mest.\nDerfor kan vi igen gå i den negative gradients retning, når vi gerne vil minimere en tabsfunktion. Denne metode kaldes for øvrigt for gradientnedstigning eller på engelsk gradient descent."
  },
  {
    "objectID": "materialer/funktioner_af_flere_variable/funktioner_af_flere_variable.html#videre-læsning",
    "href": "materialer/funktioner_af_flere_variable/funktioner_af_flere_variable.html#videre-læsning",
    "title": "Funktioner af flere variable",
    "section": "Videre læsning",
    "text": "Videre læsning\n\nForberedelsesmaterialet om \"Funktioner af to variable\" fra 2013. Ministeriet for børn og undervisning."
  },
  {
    "objectID": "materialer/kunstige_neuroner/kunstige_neuroner.html",
    "href": "materialer/kunstige_neuroner/kunstige_neuroner.html",
    "title": "Kunstige neuroner",
    "section": "",
    "text": "Vi vil her beskrive kunstige neuroner, som er en udvidelse af den klassiske perceptron, men med den tilføjelse at vi her indfører en såkaldt aktiveringsfunktion. De kunstige neuroner er de byggesten, som et kunstigt neuralt netværk består af, og kan dermed ses som en trædesten på vej mod at forstå generelle kunstige neurale netværk."
  },
  {
    "objectID": "materialer/kunstige_neuroner/kunstige_neuroner.html#medlemsapp-til-good-food",
    "href": "materialer/kunstige_neuroner/kunstige_neuroner.html#medlemsapp-til-good-food",
    "title": "Kunstige neuroner",
    "section": "Medlemsapp til Good Food",
    "text": "Medlemsapp til Good Food\nLad os tage udgangspunkt i et fiktivt eksempel. Vi forestiller os, at dagligvarekæden Good Food er ved at udvikle en ny medlemsapp, som kunderne kan hente og bruge til at aktivere forskellige tilbud, når de handler i Good Food. Når kunderne opretter en profil i app’en, oplyser de deres navn, fødselsdato og køn. Samtidig registrer app’en løbende, hvilke køb kunden foretager, hvilken ugedag de handler med videre. For at undgå at app’en bliver for uoverskuelig for kunderne, skal app’en kun vise et begrænset udvalg af tilbud, som kunden kan aktivere. For eksempel skal en midaldrende mand, som i den seneste måned har købt for 10000 kr. i app’en, have vist nogle andre tilbud end en teenagepige, som kun sjældent handler i Good Food.\n\n\n\n\n\nGood Food sætter derfor en undersøgelse i gang. Om alle deres kunder, som har app’en, registrerer de:\n\n\\(x_1\\): kundens alder målt i år\n\\(x_2\\): kundens forbrug i Good Food den seneste måned målt i kr.\n\nDisse to værdier \\(x_1\\) og \\(x_2\\) kaldes for inputværdier. Samtidig har de i en periode for hver kunde registreret, om kunden har aktiveret et bestemt tilbud. Denne information gemmes på denne måde:\n\\[\nt=\n\\begin{cases}\n1 & \\textrm{hvis tilbuddet aktiveres} \\\\\n0 & \\textrm{hvis tilbuddet ikke aktiveres} \\\\\n\\end{cases}\n\\]\nVærdien \\(t\\) kaldes for en targetværdi, fordi det er denne værdi, vi gerne i fremtiden vil kunne forudsige baseret på kundens alder og forbrug. Hvis Good Food kan forudsige, om en given kunde med stor sandsynlighed vil aktivere et bestemt tilbud, så vil det være en god idé at vise lige præcis dét tilbud fremfor et alternativ, som kunden måske er mindre tilbøjelig til at aktivere.\nEt datasæt, som for hver kunde består af inputværdierne \\(x_1\\), \\(x_2\\) og den tilhørende targetværdi \\(t\\), kaldes for et træningsdatasæt. I figur 1 ses et fiktivt eksempel på sådan et træningsdatasæt. Her er et punkt farvet rødt, hvis targetværdien er \\(1\\) (det vil sige, at tilbuddet er aktiveret) og blåt, hvis targetværdien er \\(0\\) (og tilbuddet er ikke aktiveret).\n\n\n\n\n\n\n\n\nFigur 1: Fiktivt datasæt som viser 100 Good Food kunders alder og forbrug. Hvert punkt, som repræsenterer en kunde, er farvet rødt, hvis kunden har aktiveret tilbuddet og blåt ellers.\n\n\n\n\n\nFor at forudsige – eller med et fint ord: at prædiktere – om tilbuddet aktiveres eller ej, vil vi prøve, om vi kan beregne en værdi \\(o\\) (\\(o\\) kaldes også for outputværdien), som kunne være et bud på sandsynligheden for, at en kunde med en given alder og et givent forbrug vil aktivere tilbuddet1. En måde at modellere en sandsynlighed på er at bruge en såkaldt sigmoid-funktion. Forskriften for sigmoid-funktionen er\n1 Læg mærke til at det er en sandsynlighed, som vi forsøger at beregne. Man kan sagtens forestille sig to kunder på præcis samme alder og med præcis samme forbrug, hvor den ene vil aktivere tilbuddet, mens den anden ikke vil. Vi kan altså ikke forudsige nøjagtigt, hvad en given kunde vil gøre – men vi kan måske være heldig at komme med et godt bud på sandsynligheden for, at en bestemt kunden vil aktivere tilbuddet.\\[\n\\sigma(x)=\\frac{1}{1+e^{-x}}\n\\tag{1}\\]\nog grafen ses i figur 2.\n\n\n\n\n\n\nFigur 2: Grafen for sigmoid-funktionen med forskrift \\(\\sigma(x)=\\frac{1}{1+e^{-x}}\\).\n\n\n\nDefinitionsmængden for sigmoid-funktionen er alle reelle tal, mens værdimængden er intervallet \\((0,1)\\). Det kan skrives sådan her:\n\\[\n\\sigma: \\mathbb{R} \\rightarrow (0,1).\n\\]\nDa værdimængden er \\((0,1)\\), kan sigmoid-funktionen netop bruges til at modellere sandsynligheden for om tilbuddet aktiveres. Spørgsmålet er nu, hvordan man gør det.\nFor det første skal sigmoid-funktionen selvfølgelig på en eller anden måde afhænge af vores inputværdier \\(x_1\\) og \\(x_2\\). Det kan man gøre på mange måder, men en ofte anvendt metode er, at \"sende\" en linearkombination2 af inputværdierne ind i sigmoid-funktionen, så outputværdien \\(o\\) beregnes sådan her:\n2 En linearkombination af \\(x_1\\) og \\(x_2\\) betyder bare \\(w_0 + w_1 \\cdot x_1 + w_2 \\cdot x_2\\), hvor \\(w_0, w_1\\) og \\(w_2\\) er konstanter.\\[\no = \\sigma(w_0 + w_1 \\cdot x_1 + w_2 \\cdot x_2).\n\\tag{2}\\]\nHer kaldes \\(w_0, w_1\\) og \\(w_2\\) for vægte.\nGrafisk kan det illustreres sådan her:\n\n\n\n\n\n\nFigur 3: Grafisk illustration af en kunstig neuron i eksemplet om Good Food app’en.\n\n\n\nOpgaven bliver nu, at finde værdier af disse vægte sådan, at outputværdien \\(o\\) for givne værdier af \\(x_1\\) og \\(x_2\\) bliver god til at modellere sandsynligheden for, om tilbuddet aktiveres eller ej.\nDet er her, at træningsdata kommer i spil, fordi vi for en lang række af inputværdier \\(x_1\\) og \\(x_2\\) jo faktisk ved, om tilbuddet blev aktiveret eller ej (husk på at den oplysning er gemt i targetværdien \\(t\\)).\nForestil dig for en stund at vi på en eller anden måde har bestemt værdier af \\(w_0, w_1\\) og \\(w_2\\). Vi kan nu sammenligne værdien af \\(o\\) (vores pt bedste bud på sandsynligheden) og targetværdien (som er den værdi, vi gerne vil kunne forudsige). Hvis \\(t=0\\) vil vi også gerne have, at \\(o\\) er tæt på \\(0\\), og omvendt hvis \\(t=1\\) vil vi gerne have, at \\(o\\) er tæt på \\(1\\). Det vil sige, at differensen\n\\[\nt-o = t-\\sigma(w_0 + w_1 \\cdot x_1 + w_2 \\cdot x_2)\n\\] ønskes tæt på \\(0\\). Nu kan differensen både være positiv og negativ, og for at slippe for fortegn vælger vi i stedet at se på den kvadrerede differens: \\[\n\\left ( t-\\sigma(w_0 + w_1 \\cdot x_1 + w_2 \\cdot x_2) \\right )^2\n\\]\nDer er ikke bare ét, men rigtig mange træningsdata og derfor vælger man, at summere (det vil sige, \"at lægge sammen\") alle disse kvadrerede differenser:\n\\[\nE = \\frac{1}{2} \\sum \\left ( t-\\sigma(w_0 + w_1 \\cdot x_1 + w_2 \\cdot x_2) \\right )^2,\n\\]\nhvor der altså her summeres over alle træningsdata. Vi har lige ganget med \\(\\frac{1}{2}\\) foran. Det kan virke lidt mærkeligt, men du ser fidusen senere.\nHvis vægtene \\(w_0, w_1\\) og \\(w_2\\) er valgt, så sigmoid-funktionen er god til at prædiktere, om tilbuddet aktiveres eller ej, så vil ovenstående udtryk være tæt på \\(0\\). Det vil sige, at hvis \\(E\\) er tæt på \\(0\\), så har vi valgte gode værdier af vægtene, mens hvis \\(E\\) er langt væk fra \\(0\\), så har vi valgt mindre gode værdier af vægtene (i forhold til det overordnede ønske om at være i stand til at prædiktere om tilbuddet aktiveres eller ej). Denne funktion \\(E\\), som jo afhænger af vægtene \\(w_0, w_1\\) og \\(w_2\\), kaldes for en tabsfunktion (eller på engelsk error function).\nNu er vægtene jo ikke givet på forhånd, men det er lige præcis tabsfunktionen, man bruger til at bestemme \"gode\" værdier af vægtene. Det gøres ved at bestemme de værdier af vægtene, som minimerer tabsfunktionen. Det er altså et optimeringsproblem, vi står overfor. Hvordan det løses, kan du læse om i næste afsnit."
  },
  {
    "objectID": "materialer/kunstige_neuroner/kunstige_neuroner.html#hvordan-bestemmes-vægtene",
    "href": "materialer/kunstige_neuroner/kunstige_neuroner.html#hvordan-bestemmes-vægtene",
    "title": "Kunstige neuroner",
    "section": "Hvordan bestemmes vægtene?",
    "text": "Hvordan bestemmes vægtene?\nInden vi går i gang med at finde ud af, hvordan vægtene bestemmes, så værdien af tabsfunktionen bliver så lille som mulig, vil vi lige gør det lidt mere generelt. For det første har man i virkelighedens verden sjældent kun to inputværdier \\(x_1\\) og \\(x_2\\). Vi siger derfor helt generelt, at vi har \\(n\\) inputværdier \\(x_1, x_2, \\cdots, x_n\\). Det betyder, at outputværdien \\(o\\) nu beregnes sådan her:\n\\[\no = \\sigma (w_0 + w_1 \\cdot x_1 + w_2 \\cdot x_2 + \\cdots + w_n \\cdot x_n).\n\\]\nDen generelle kunstige neuron kan illustreres sådan her:\n\n\n\n\n\n\nFigur 4: Grafisk illustration af en generel kunstig neuron med \\(n\\) inputvariable.\n\n\n\nSamtidig forestiller vi os, at vi har \\(M\\) træningsdata. Det vil sige, \\(M\\) forskellige træningseksempler bestående af inputværdier med tilhørende targetværdi. Det kan opskrives sådan her:\n\\[\n\\begin{aligned}\n&\\text{Træningseksempel 1:} \\quad (x_1^{(1)}, x_2^{(1)}, \\dots, x_n^{(1)}, t^{(1)}) \\\\\n&  \\quad \\quad \\quad \\quad \\vdots \\\\\n&\\text{Træningseksempel m:} \\quad (x_1^{(m)}, x_2^{(m)}, \\dots, x_n^{(m)}, t^{(m)}) \\\\\n&  \\quad \\quad \\quad \\quad \\vdots \\\\\n&\\text{Træningseksempel M:} \\quad (x_1^{(M)}, x_2^{(M)}, \\dots, x_n^{(M)}, t^{(M)}) \\\\\n\\end{aligned}\n\\]\nog tabsfunktionen bliver da\n\\[\n\\begin{aligned}\nE(w_0, w_1, &\\dots, w_n) \\\\ &= \\frac{1}{2} \\sum_{m=1}^{M} \\left (t^{(m)}-\n\\sigma(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)}) \\right)^2.\n\\end{aligned}\n\\]\nDet er en funktion af flere variable. I princippet kan man bestemme minimum ved at sætte alle de partielle afledede lig med \\(0\\) og dernæst overbevise sig selv om, at man har fundet et minimum. Det vil give et ligningssystem med \\(n+1\\) ligninger, som alle er koblet med hinanden. Det viser sig, at være en beregningsmæssig tung opgave at løse dette ligningssystem analytisk. Derfor bruger man i stedet for den metode, som kaldes for gradientnedstigning. Gradientnedstigning går ud på først at vælge tilfældige værdier af vægtene \\(w_0, w_1, \\cdots, w_n\\). Det viser sig så, at den negative gradient vil pege i den retning, hvor funktionsværdien falder mest. Derfor er idéen at bevæge sig et lille stykke i den negative gradients retning – fordi vi så kommer lidt tættere på minimum. Når vi har gjort det, beregner vi gradienten igen, og bevæger os igen et lille stykke i den negative gradients retning. Det forsætter vi med indtil værdien af tabsfunktionen ikke ændrer sig særlig meget, hvilket svarer til, at vi har fundet minimum.\nNår vi for alle vægtene bevæger os et lille stykke i den negative gradients retning, kan opdateringen af vægtene skrives sådan her:\n\\[\n\\begin{aligned}\nw_0^{(\\textrm{ny})} \\leftarrow & w_0 - \\eta \\cdot \\frac{\\partial E }{\\partial w_0} \\\\\nw_1^{(\\textrm{ny})} \\leftarrow & w_1 - \\eta \\cdot \\frac{\\partial E }{\\partial w_1} \\\\\n&\\vdots  \\\\\nw_n^{(\\textrm{ny})} \\leftarrow & w_n - \\eta \\cdot \\frac{\\partial E }{\\partial w_n} \\\\\n\\end{aligned}\n\\]\nhvor \\(\\eta\\) (udtales \"eta\") kaldes for en learning rate. Det er \\(\\eta\\), som bestemmer hvor stort et skridt i gradientens retning, vi tager. Den konkrete værdi af \\(\\eta\\) sættes til et lille tal større end \\(0\\). Det kunne for eksempel være \\(0.01\\), men her må man prøve sig lidt frem. Pilene til venstre illustrerer opdatering af vægtene.\nFor at foretage opdateringerne har vi altså brug for at bestemme den partielle afledede for hver af vægtene. Den partielle afledede for den \\(i\\)’te vægt kan findes ved at bruge sum- og kædereglen:\n\\[\n\\begin{aligned}\n\\frac{\\partial E}{\\partial w_i} &= \\frac{1}{2} \\sum_{m=1}^{M} \\frac{\\partial}{\\partial w_i}\\left (t^{(m)}-\n\\sigma(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)}) \\right)^2 \\\\\n&= \\frac{1}{2} \\sum_{m=1}^{M} 2 \\cdot \\left (t^{(m)}-\n\\sigma(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)}) \\right) \\\\\n& \\quad  \\quad \\quad  \\quad  \\cdot \\frac{\\partial}{\\partial w_i} \\left (t^{(m)}-\n\\sigma(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)} ) \\right) \\\\\n&=  \\sum_{m=1}^{M} \\left (t^{(m)}-\n\\sigma(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)}) \\right) \\\\\n& \\quad  \\quad \\quad  \\quad  \\cdot \\frac{\\partial}{\\partial w_i} \\left (t^{(m)}-\n\\sigma(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)} ) \\right) \\\\\n\\end{aligned}\n\\tag{3}\\]\nBemærk, at \\(\\frac{1}{2}\\) forkortede ud – det var derfor, at vi gangede \\(\\frac{1}{2}\\) på tabsfunktionen til at starte med.\nBetragter vi nu kun den sidste faktor og bruger kædereglen igen, får vi\n\\[\n\\begin{aligned}\n\\frac{\\partial}{\\partial w_i} (t^{(m)} &- \\sigma(w_0 +  w_1 \\cdot x_1^{(m)} + \\cdots   + w_n \\cdot x_n^{(m)} )) = \\\\\n&- \\sigma'(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)})\\cdot  \\\\ & \\qquad \\qquad \\qquad\n\\qquad \\frac{\\partial}{\\partial w_i} \\left (w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)} \\right)\n\\end{aligned}\n\\]\nNu er\n\\[\n\\frac{\\partial}{\\partial w_i} \\left (w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_i \\cdot x_i^{(m)} + \\cdots  + w_n \\cdot x_n^{(m)} \\right) = x_i^{(m)}\n\\tag{4}\\]\nnår \\(i \\in \\{1, 2, \\dots, n\\}\\). Så \\[\n\\begin{aligned}\n\\frac{\\partial}{\\partial w_i} (t^{(m)} -\n\\sigma(w_0 &+ w_1 \\cdot x_1^{(m)}  + \\cdots  + w_n \\cdot x_n^{(m)} )) = \\\\ &- \\sigma'(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)})\\cdot x_i^{(m)}\n\\end{aligned}\n\\]\nVi mangler nu bare at finde den afledede sigmoid-funktion. Man kan vise – se forløbet om aktiveringsfunktioner – at\n\\[\n\\sigma'(x)=\\sigma(x)\\cdot(1-\\sigma(x))\n\\]\nDerfor bliver\n\\[\n\\begin{aligned}\n\\frac{\\partial}{\\partial w_i} (t^{(m)} -\n\\sigma(w_0 &+ w_1 \\cdot x_1^{(m)} + \\cdots  + w_n \\cdot x_n^{(m)} )) = \\\\\n&- \\sigma(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)}) \\cdot \\\\ & (1-\\sigma(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots  + w_n \\cdot x_n^{(m)} )) \\cdot x_i^{(m)}\n\\end{aligned}\n\\]\nI eksemplet med Good Food app’en kaldte vi \\(\\sigma(w_0 + w_1 \\cdot x_1 + w_2 \\cdot x_2)\\) for outputværdien \\(o\\) (se (2)). På samme måde kan vi at gøre ovenstående lidt mere læsevenligt ved at kalde outputværdien hørende til det \\(m\\)’te træningseksempel for \\(o^{(m)}\\):\n\\[\no^{(m)} = \\sigma(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)})\n\\]\nVi får så\n\\[\n\\begin{aligned}\n\\frac{\\partial}{\\partial w_i} (t^{(m)} -\n\\sigma(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots  &+ w_n \\cdot x_n^{(m)} )) = \\\\ &- o^{(m)}\\cdot (1-o^{(m)}) \\cdot x_i^{(m)}\n\\end{aligned}\n\\]\nIndsættes dette i (3) samtidig med at vi bruger, at\n\\[o^{(m)} = \\sigma(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)})\\]\nfår vi\n\\[\n\\begin{aligned}\n\\frac{\\partial E}{\\partial w_i} = - \\sum_{m=1}^{M} \\left (t^{(m)}-o^{(m)} \\right) \\cdot o^{(m)}\\cdot (1-o^{(m)}) \\cdot x_i^{(m)}\n\\end{aligned}\n\\]\nDette gælder for \\(i \\in \\{1, 2, \\dots, n \\}\\). Når \\(i=0\\) kan det fra (4) ses, at den partielle med hensyn til \\(w_0\\) bliver \\(1\\). Derfor er det ikke svært at overbevise sig selv om, at\n\\[\n\\frac{\\partial E}{\\partial w_0} = - \\sum_{m=1}^{M} \\left (t^{(m)}-o^{(m)} \\right) \\cdot o^{(m)}\\cdot (1-o^{(m)}) \\cdot 1\n\\]\nVi ender således med:\n\n\n\n\n\n\nOpdateringsregler for kunstige neuroner\n\n\n\n\n\n\\[\n\\begin{aligned}\nw_0^{(\\textrm{ny})} \\leftarrow & w_0 + \\eta \\cdot \\sum_{m=1}^{M} \\left (t^{(m)}-o^{(m)} \\right) \\cdot o^{(m)}\\cdot (1-o^{(m)}) \\\\\nw_1^{(\\textrm{ny})} \\leftarrow & w_1 + \\eta \\cdot \\sum_{m=1}^{M} \\left (t^{(m)}-o^{(m)} \\right) \\cdot o^{(m)}\\cdot (1-o^{(m)}) \\cdot x_1^{(m)}\\\\\n&\\vdots  \\\\\nw_n^{(\\textrm{ny})} \\leftarrow & w_n + \\eta \\cdot \\sum_{m=1}^{M} \\left (t^{(m)}-o^{(m)} \\right) \\cdot o^{(m)}\\cdot (1-o^{(m)}) \\cdot x_n^{(m)}\n\\end{aligned}\n\\]\nhvor \\(o^{(m)} = \\sigma(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)})\\).\n\n\n\nI praksis vil man som sagt blive ved med at opdatere vægtene, indtil værdien af tabsfunktionen ikke ændrer sig særlig meget.\nNår vi på den måde har bestemt værdien af vægtene, kan vi bruge outputværdien \\(o\\) til at forudsige, om en kunde vil aktivere tilbuddet eller ej. Det vil vi gøre på denne måde:\n\\[\n\\textrm{Kunden aktiverer tilbuddet: }\n\\begin{cases}\n\\textrm{Ja} & \\textrm{hvis } o \\geq 0.5\\\\\n\\textrm{Nej} & \\textrm{hvis } o &lt; 0.5\\\\\n\\end{cases}\n\\tag{5}\\]\nhvor\n\\[\no = \\sigma(w_0 + w_1\\cdot x_1 + \\cdots + w_n \\cdot x_n).\n\\] Bemærk, at når vi tænker på \\(o\\) som sandsynligheden for, at kunden vil aktivere tilbuddet, så giver det god mening, at vi vil prædiktere, at kunden vil aktivere tilbuddet, hvis \\(o \\geq 0.5\\) og ellers ikke.\nSkillelinjen, som afgører, om vi prædikterer, at kunden aktiverer tilbuddet eller ej, går ved\n\\[\n\\sigma(w_0 + w_1\\cdot x_1 + \\cdots + w_n \\cdot x_n) = 0.5.\n\\]\nSer vi på definitionen af sigmoid-funktionen i (1) svarer det til, at\n\\[\n\\frac{1}{1+e^{-(w_0 + w_1\\cdot x_1 + \\cdots + w_n \\cdot x_n)}} = 0.5.\n\\]\nNu giver brøken til venstre præcis \\(0.5\\), hvis\n\\[\ne^{-(w_0 + w_1\\cdot x_1 + \\cdots + w_n \\cdot x_n)} = 1.\n\\] Det vil sige, at\n\\[\nw_0 + w_1\\cdot x_1 + \\cdots + w_n \\cdot x_n = 0.\n\\]\nI vores eksempel om Good Food app’en havde vi kun to inputværdier. Det betyder, at ovenstående kan reduceres til\n\\[\nw_0 + w_1\\cdot x_1 + w_2 \\cdot x_2 = 0.\n\\] Det er lige præcis ligningen for en ret linje i et \\((x_1,x_2)\\)-koordinatsystem. Hvis vi i vores eksempel prøver at finde vægtene ved hjælp af gradientnedstigning, som beskrevet ovenfor, så ender vi med\n\\[\nw_0 = -0.298, \\quad  w_1 = -0.0375 \\quad \\textrm{ og } \\quad  w_2=0.000769\n\\] Det giver ligningen \\[\n-0.298 - 0.0375\\cdot x_1 + 0.000769\\cdot x_2=0\n\\] hvilket også kan omskrives til\n\\[\nx_2 = 48.7 \\cdot x_1 +387\n\\]\neller måske den lidt mere velkendte skrivemåde:\n\\[\ny = 48.7 \\cdot x+387\n\\]\nIndtegnes denne linje sammen med datasættet fra Good Food får vi:\n\n\n\n\n\n\n\n\nFigur 5: Fiktivt datasæt som viser 100 Good Food kunders alder og forbrug. Hvert punkt, som repræsenterer en kunde, er farvet rødt, hvis kunden har aktiveret tilbuddet og blåt ellers. Samtidig er den linje indtegnet, som fås ved at bruge en kunstig neuron på data.\n\n\n\n\n\nBemærk her, at den indtegnede linje er rigtig god til at adskille de røde punkter fra de blå i træningsdatasættet. Det betyder ikke nødvendigvis, at denne linje har samme gode prædiktive egenskab for et datasæt bestående af nye kunder. Hvis man gerne vil vurdere, hvor god modellen er på ukendte data, kan man for eksempel træne sin model på en delmængde af data (kaldet træningsdata) og så teste modellen på den resterende del af data (kaldet testdata). Man kan også anvende en metode, som kaldes for krydsvalidering. Det kan du alt sammen læse mere om i noten om Overfitting, modeludvælgelse og krydsvalidering.\nDet vil nu være sådan, at for alle punkter \\((x_1,x_2)\\), som ligger over linjen i figur 5, vil\n\\[\n-0.298 - 0.0375\\cdot x_1 + 0.000769\\cdot x_2 &gt; 0.\n\\] Det vil sige, at (se eventuelt figur 2) \\[\no = \\sigma (-0.298 - 0.0375\\cdot x_1 + 0.000769\\cdot x_2) &gt; 0.5.\n\\] Ifølge (5) betyder det, at for alle punkter, som ligger over linjen, vil vi prædiktere, at den tilhørende kunde, vil aktivere tilbuddet. Og det omvendte gælder så selvfølgelig for alle punkter, som ligger under linjen: her vil vi prædiktere, at de tilhørende kunder ikke aktiverer tilbuddet.\nLad os se på et eksempel.\n\nEksempel 1 Kunderne Hans og Gerda har downloadet Good Foods app. Hans er 50 år og har et forbrug på 3500 kroner. Gerda er derimod 65 år og med et forbrug på 2800 kroner.\nVi vil nu beregne outputværdien \\(o\\) for hver af de to kunder. Det gør vi ved at indsætte i: \\[\no = \\sigma (-0.298 - 0.0375\\cdot x_1 + 0.000769\\cdot x_2).\n\\] Da får vi \\[\n\\begin{aligned}\n&\\textrm{Hans:} \\quad \\quad &o=\\sigma (-0.298 - 0.0375\\cdot 50 + 0.000769\\cdot 3500) = 0.627 \\\\\n&\\textrm{Gerda:} \\quad \\quad &o=\\sigma (-0.298 - 0.0375\\cdot 65 + 0.000769\\cdot 2800) = 0.358\n\\end{aligned}\n\\]\nIfølge vores model er der altså en sandsynlighed på \\(62.7 \\%\\) for, at Hans vil aktivere tilbuddet, mens den tilsvarende sandsynlighed for Gerda er på \\(35.8 \\%\\). Vores bedste bud vil derfor være at prædiktere, at Hans vil aktivere tilbuddet, mens Gerda ikke vil. Vi vælger derfor at vise det pågældende tilbud til Hans, men ikke til Gerda.\n\n\n\n\n\n\n\n\nFigur 6: Datasættet fra figur 5. Desuden er de to punkter, som repræsenterer kunderne Hans og Gerda indtegnet.\n\n\n\n\n\nPå figur 6 ses de to punkter \\((50,3500)\\) og \\((65,2800)\\), som repræsenterer Hans og Gerda indtegnet. Her ses det også, at Hans’ punkt ligger over linjen (svarende til at vi mener, at han vil aktivere tilbuddet), mens Gerdas punkt ligger under linjen (svarende til at vi ikke mener, at hun vil aktivere tilbuddet)."
  },
  {
    "objectID": "materialer/kunstige_neuroner/kunstige_neuroner.html#aktiviteringsfunktioner",
    "href": "materialer/kunstige_neuroner/kunstige_neuroner.html#aktiviteringsfunktioner",
    "title": "Kunstige neuroner",
    "section": "Aktiviteringsfunktioner",
    "text": "Aktiviteringsfunktioner\nSigmoid-funktionen, som er anvendt her, kaldes for en aktiveringsfunktion. Her brugte vi den, fordi den har den egenskab, at værdimængden er \\((0,1)\\), og derfor kan outputværdien fra sigmoid-funktionen fortolkes som en sandsynlighed. Men man behøver ikke nødvendigvis at bruge sigmoid-funktionen som aktiveringsfunktion. Der findes en lang række andre aktiveringsfunktioner, som kan bruges i stedet for. Hvis du har lyst til at lære mere, kan du se på vores forløb om andre aktiveringsfunktioner."
  },
  {
    "objectID": "materialer/kunstige_neuroner/kunstige_neuroner.html#smartere-end-adaline",
    "href": "materialer/kunstige_neuroner/kunstige_neuroner.html#smartere-end-adaline",
    "title": "Kunstige neuroner",
    "section": "Smartere end ADALINE?",
    "text": "Smartere end ADALINE?\nHvis du har læst noten om perceptroner er du blevet præsenteteret for den klassiske perceptron. Her forklarede vi to forskellige måder at opdatere vægtene på: perceptron learning algoritmen og ADALINE. Perceptron learning algoritmen dur kun, hvis data er lineært separable. Det problem klarede ADALINE. Men faktisk er den kunstige neuron, som vi har præsenteret her, smartere end ADALINE. Hvis du vil blive klogere på hvorfor, kan du læse mere her."
  },
  {
    "objectID": "materialer/kunstige_neuroner/kunstige_neuroner.html#overblik",
    "href": "materialer/kunstige_neuroner/kunstige_neuroner.html#overblik",
    "title": "Kunstige neuroner",
    "section": "Overblik",
    "text": "Overblik\nPerceptron learning algoritmen, ADALINE og kunstige neuroner – det kan være svært at holde tungen lige i munden. Hvad er forskellene, og hvordan peger det videre hen mod de helt generelle kunstige neurale netværk. Vi vil i dette afsnit prøve at skabe det overblik. Du kan læse med, hvis du vil nørde lidt videre – men du kan også springe afsnittet over!\nI alle tilfælde har vi at gøre med træningsdata, som består af en række inputværdier \\(x_1, x_2, \\cdots, x_n\\) med en tilhørende targetværdi \\(t\\). Ønsket i alle tilfælde er også, at kunne beregne en outputværdi \\(o\\), som skal bruges til at prædiktere targetværdien i fremtidige data.\n\nPerceptron learning algoritmen\nI perceptron learning algoritmen kan targetværdien3 antage værdierne \\(-1\\) og \\(1\\):\n3 I virkeligheden er det ikke så afgørende her. Men i forhold til de opdateringsregler, som vi præsenterer her, skal targetværdierne bare være symmetriske omkring \\(0\\).\\[\nt \\in \\{-1,1\\}.\n\\] Outputværdien \\(o\\) defineres ved \\[\n\\begin{aligned}\n    o = \\begin{cases}\n    1 & \\text{hvis } w_0 + w_1 \\cdot x_1 + \\cdots + w_n \\cdot x_n \\geq 0 \\\\\n    -1 & \\text{hvis } w_0 + w_1 \\cdot x_1 + \\cdots + w_n \\cdot x_n &lt; 0. \\\\\n    \\end{cases}\n\\end{aligned}\n\\]\nDenne outputværdi kan selvsagt ikke fortolkes som en sandsynlighed, men blot som en angivelse af, om vi forventer, at et nyt punkt er rødt eller blåt (altså om den ukendte targetværdi er \\(-1\\) eller \\(1\\)).\nDer er ikke knyttet nogen tabsfunktion til perceptron learning algoritmen, men den \\(i\\)’te vægt opdateres på denne måde:\n\n\n\n\n\n\nOpdateringsregler – Perceptron Learning Algoritmen\n\n\n\n\n\nVægtene opdateres således – ét træningseksempel ad gangen: \\[\nw_i^{(\\textrm{ny})} \\leftarrow w_i +  \\eta \\cdot  (t-o) \\cdot x_i\n\\] for \\(i \\in \\{0, 1, 2, \\dots, n\\}\\), hvis vi sætter \\(x_0=1\\).\n\n\n\n\n\nADALINE\nI ADALINE er targetværdierne igen \\(-1\\) eller \\(1\\): \\[\nt \\in \\{-1,1\\}.\n\\] Outputværdien \\(o\\) defineres igen ved \\[\n\\begin{aligned}\n    o = \\begin{cases}\n    1 & \\text{hvis } w_0 + w_1 \\cdot x_1 + \\cdots + w_n \\cdot x_n \\geq 0 \\\\\n    -1 & \\text{hvis } w_0 + w_1 \\cdot x_1 + \\cdots + w_n \\cdot x_n &lt; 0. \\\\\n    \\end{cases}\n\\end{aligned}\n\\]\nIgen kan outputværdien her ikke fortolkes som en sandsynlighed.\nI ADALINE bestemmes vægtene ved at minimere tabsfunktionen:\n\\[\n\\begin{aligned}\nE(w_0, w_1, \\dots, w_n) = \\frac{1}{2} \\sum_{m=1}^{M} \\left (t^{(m)}-\n\\left (w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)} \\right) \\right)^2.\n\\end{aligned}\n\\tag{6}\\]\nGør man det, bliver opdateringsreglerne\n\n\n\n\n\n\nOpdateringsregler – ADALINE\n\n\n\n\n\nVægtene opdateres således: \\[\nw_i^{(\\textrm{ny})} \\leftarrow w_i + \\eta \\cdot  \\sum_{m=1}^{M} \\left (t^{(m)}-\n\\left (w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)} \\right ) \\right) \\cdot \\left (x_i^{(m)} \\right)\n\\] for \\(i \\in \\{0, 1, 2, \\dots, n\\}\\), hvis vi sætter \\(x_0^{(m)}=1\\) for alle værdier af \\(m\\).\n\n\n\n\n\nKunstige neuroner\nI kunstige neuroner er targetværdierne \\(0\\) eller \\(1\\):\n\\[\nt \\in \\{0,1\\}.\n\\] Her beregner vi en outputværdi \\(o\\) som\n\\[\no = \\sigma(w_0 + w_1 \\cdot x_1 + \\cdots + w_n \\cdot x_n).\n\\]\nHvis vi sammenligner med reglen i (5) vil vi sige, at hvis denne outputværdi \\(o \\geq 0.5\\), så vil vi prædiktere4, at den ukendte targetværdi er \\(1\\) og \\(0\\) ellers. Her kan man altså tænke på \\(o\\), som sandsynligheden for, at den ukendte targetværdi er \\(1\\).\n4 Der er faktisk ingen, som siger, at vi skal skære ved \\(0.5\\). Hvis man er i gang med at screene for en meget alvorlig sygdom, som det er vigtigt at opdage hurtigt, kunne der være god grund til at vælge en lavere værdi end \\(0.5\\).I kunstige neuroner er tabsfunktionen \\[\n\\begin{aligned}\nE(w_0, w_1, &\\dots, w_n) \\\\ &= \\frac{1}{2} \\sum_{m=1}^{M} \\left (t^{(m)}-\n\\sigma(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)}) \\right)^2\n\\\\ &= \\frac{1}{2} \\sum_{m=1}^{M} \\left (t^{(m)}-\no^{(m)} \\right)^2,\n\\end{aligned}\n\\tag{7}\\]\nhvor \\(o^{(m)} = \\sigma(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)})\\).\nOpdateringsreglen er:\n\n\n\n\n\n\nOpdateringsregler – Kunstige neuroner\n\n\n\n\n\nVægtene opdateres således: \\[\nw_i^{(\\textrm{ny})} \\leftarrow w_i + \\eta \\cdot \\sum_{m=1}^{M} \\left (t^{(m)}-o^{(m)} \\right) \\cdot o^{(m)}\\cdot \\left (1-o^{(m)} \\right) \\cdot x_i^{(m)}\n\\] for \\(i \\in \\{0, 1, 2, \\dots, n\\}\\), hvis vi sætter \\(x_0^{(m)}=1\\) for alle værdier af \\(m\\) og hvor \\[\no^{(m)} = \\sigma(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)}).\n\\]\n\n\n\nLæg mærke til at i Perceptron Learning Algoritmen er opdateringen af vægtene baseret på ét træningseksempel, mens det i ADALINE og kunstige neuroner er baseret på hele træningsdatasættet.\nSer vi på tabsfunktionen for ADALINE i (6) og sammenligner den med tabsfunktionen for kunstig neuroner i (7), kan vi se, at i ADALINE bruges sigmoid-funktionen ikke som aktiveringsfunktion. I stedet bruges den funktion \\(f\\), som man kalder for identiteten. Den har forskrift \\[\nf(x)=x.\n\\]\nForskellen på ADALINE og kunstige neuroner er altså, at aktivieringsfunktionen i ADALINE er identiteten, mens den for kunstige neuroner er sigmoid-funktionen. Den helt store fordel ved det, kan du læse mere om her.\n\n\nGenerelle neurale netværk\nEt generelt neuralt netværk består egentlig bare af en masse kunstige neuroner, som er sat sammen. Det kunne se sådan her ud:\n\n\n\n\n\n\nFigur 7: Et generelt kunstigt neuralt netværk (som dog stadig er forholdsvist simpelt!).\n\n\n\nHer repræsenterer de fire lilla cirkler fire inputværdier \\(x_1, x_2, x_3\\) og \\(x_4\\). De fire grønne cirkler i midten svarer til en kunstig neuron, som det er beskrevet her. Den blå cirkel svarer til den outputværdi, som netværket ender med at beregne. Hver pil i figuren svarer til en vægt, som skal beregnes. Man siger, at det netværk, som er illustreret på figur 7 har to skjulte lag (svarende til de to søjler med grønne cirkler), fordi der er to lag af neuroner fra input til output. Til sammenligning har en kunstig neuron ingen skjulte lag, fordi man direkte fra inputværdierne beregner outputværdien. Når mængden af skjulte lag bliver tilpas stor, taler man om deep learning.\nTabsfunktion og opdateringsregler bliver noget mere kompliceret for generelle neurale netværk, men du kan læse meget mere om det i vores note om kunstige neurale netværk.\nMen alt i alt kan man altså tænke på de kunstige neuroner, som byggesten til det generelle neurale netværk.\n\n\nSamlet skematisk overblik\nI tabellen herunder finder du et samlet overblik over perceptron learning algoritmen, ADALINE, kunstige neuroner og generelle neurale netværk.\n\n\n\n\n\n\n\n\n\n\n\nAI metode\nSkal data være lineært separable\nAktiveringsfunktion\nGraf\nTargetværdi\nAntal skjulte lag\n\n\n\n\nPerceptron learning algoritmen\nJa\nIngen\n–\n\\(\\{-1,1\\}\\)\n\\(0\\)\n\n\nADALINE\nNej\nIdentiteten\n\n\\(\\{-1,1\\}\\)\n\\(0\\)\n\n\nKunstig neuron\nNej\nSigmoid eller andre\n\n\\(\\{0,1\\}\\)\n\\(0\\)\n\n\nGenerelle neurale netværk\nNej\nSigmoid eller andre\n\n\\(\\{0,1\\}\\)\n\\(\\geq 1\\)"
  },
  {
    "objectID": "materialer/kunstige_neuroner/kunstige_neuroner.html#relaterede-forløb",
    "href": "materialer/kunstige_neuroner/kunstige_neuroner.html#relaterede-forløb",
    "title": "Kunstige neuroner",
    "section": "Relaterede forløb",
    "text": "Relaterede forløb\n\n\n\n\n\nForløb\n\n\nKort beskrivelse\n\n\n\n\n\n\nAktiveringsfunktioner\n\n\nI opbygningen af kunstige neurale netværk er aktiveringsfunktioner helt centrale. Og aktiveringsfunktioner skal differentieres – det handler dette forløb om.\n\n\n\n\nScreeningsprogrammer\n\n\nKan man lave screeningsprogrammer for sygdomme baseret på genetiske markører med brug af AI? Det undersøger vi i dette forløb, som med fordel kan foregå i et samarbejde med bioteknologi.\n\n\n\n\nOpklar et mord!\n\n\nDer er blevet begået et mord på skolen i nat. Det er jeres opgave at opklare det!\n\n\n\n\nOpdatering af vægte i en kunstig neuron\n\n\nEn øvelse i at opdatere vægtene i en kunstig neuron.\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "materialer/simple_neurale_net/dobbelt-sigmoid.html",
    "href": "materialer/simple_neurale_net/dobbelt-sigmoid.html",
    "title": "Dobbelt-sigmoid",
    "section": "",
    "text": "#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 420\n# Load the shiny package\nlibrary(shiny)\n\n# Define UI for the application\nui &lt;- fluidPage(\n  # titlePanel(\"Plotting a Function of x with Parameters a, b, c, d\"),\n  \n  sidebarLayout(\n    sidebarPanel(\n      numericInput(\"a\", \"Parameter a:\", value = 1),\n      numericInput(\"b\", \"Parameter b:\", value = 1),\n      numericInput(\"c\", \"Parameter c:\", value = 1),\n      numericInput(\"d\", \"Parameter d:\", value = 1)\n    ),\n    \n    mainPanel(\n      plotOutput(\"plot\")\n    )\n  )\n)\n\n# Define server logic\nserver &lt;- function(input, output) {\n  output$plot &lt;- renderPlot({\n    a &lt;- input$a\n    b &lt;- input$b\n    c &lt;- input$c\n    d &lt;- input$d\n\n    # Define the sigmoid activation function\n    sigmoid &lt;- function(x, a=0, b=1) {\n      1 / (1 + exp(-(a+b*x)))\n    }\n    \n    ssigmoid &lt;- function(x, a=0, b=1, c=0, d=1) {\n      1 / (1 + exp(-(a+b*sigmoid(x, c, d))))\n    }\n \n    x &lt;- seq(-10, 10, length.out = 201)\n    y &lt;- ssigmoid(x, a, b, c, d)\n    # yy &lt;- log(y/(1-y))\n    # co &lt;- coef(lm(yy~x))\n    loss &lt;- function(par){\n      mean((y - sigmoid(x, par[1], par[2]))^2)\n    }\n    o &lt;- optim(c(0, 1), loss)\n    co &lt;- o$par\n\n    plot(x, y, type = \"l\", col = \"blue\", lwd = 2,\n         xlim = c(-10, 10), ylim = c(0, 1),\n         xlab = \"x\", ylab = \"sigmoid(a+b*sigmoid(c+d*x))\",\n         main = \"\")\n    lines(x, sigmoid(x, co[1], co[2]), col = \"red\", lty = 2)\n  })\n}\n\n# Run the application\nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "materialer/simple_neurale_net/dobbelt-sigmoid.html#plot",
    "href": "materialer/simple_neurale_net/dobbelt-sigmoid.html#plot",
    "title": "Dobbelt-sigmoid",
    "section": "",
    "text": "#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 420\n# Load the shiny package\nlibrary(shiny)\n\n# Define UI for the application\nui &lt;- fluidPage(\n  # titlePanel(\"Plotting a Function of x with Parameters a, b, c, d\"),\n  \n  sidebarLayout(\n    sidebarPanel(\n      numericInput(\"a\", \"Parameter a:\", value = 1),\n      numericInput(\"b\", \"Parameter b:\", value = 1),\n      numericInput(\"c\", \"Parameter c:\", value = 1),\n      numericInput(\"d\", \"Parameter d:\", value = 1)\n    ),\n    \n    mainPanel(\n      plotOutput(\"plot\")\n    )\n  )\n)\n\n# Define server logic\nserver &lt;- function(input, output) {\n  output$plot &lt;- renderPlot({\n    a &lt;- input$a\n    b &lt;- input$b\n    c &lt;- input$c\n    d &lt;- input$d\n\n    # Define the sigmoid activation function\n    sigmoid &lt;- function(x, a=0, b=1) {\n      1 / (1 + exp(-(a+b*x)))\n    }\n    \n    ssigmoid &lt;- function(x, a=0, b=1, c=0, d=1) {\n      1 / (1 + exp(-(a+b*sigmoid(x, c, d))))\n    }\n \n    x &lt;- seq(-10, 10, length.out = 201)\n    y &lt;- ssigmoid(x, a, b, c, d)\n    # yy &lt;- log(y/(1-y))\n    # co &lt;- coef(lm(yy~x))\n    loss &lt;- function(par){\n      mean((y - sigmoid(x, par[1], par[2]))^2)\n    }\n    o &lt;- optim(c(0, 1), loss)\n    co &lt;- o$par\n\n    plot(x, y, type = \"l\", col = \"blue\", lwd = 2,\n         xlim = c(-10, 10), ylim = c(0, 1),\n         xlab = \"x\", ylab = \"sigmoid(a+b*sigmoid(c+d*x))\",\n         main = \"\")\n    lines(x, sigmoid(x, co[1], co[2]), col = \"red\", lty = 2)\n  })\n}\n\n# Run the application\nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "materialer/diverse_ai.html",
    "href": "materialer/diverse_ai.html",
    "title": "Øvrige AI materialer",
    "section": "",
    "text": "Øvrige AI materialer\nPå denne side finder du øvrige AI materialer, som ikke er dækket i de forskellige noter om neurale net og sprogmodeller. Noterne varierer i sværhedsgrad og i matematisk fokus. Noterne er skrevet til elever i gymnasiet og kan læses uafhængigt af hinanden.\nSværhedsgraden af noterne er klassificeret fra \"forholdvis nem\" (*) til \"svær\" (****).\n\n\n\nLogistisk regression\n\nLogistisk regression er en metode, som kan bruges til klassifikation, og metoden har faktisk fællestræk med simple neurale netværk. Logistisk regression er et helt andet emne end logistisk vækst, som vi kender fra gymnasieundervisningen. Det eneste, de to emner umiddelbart har til fælles, er, at den logistiske funktion spiller en rolle begge steder. I slutningen af noten vil vi dog se et eksempel, hvor der alligevel er en sammenhæng mellem logistisk regression og logistisk vækst.\nSværhedsgrad: ***\n\n\n\n\n\n\nTabsfunktioner\n\n\n\nI langt de fleste tilfælde sker træning af AI modeller ved at minimere en tabsfunktion. Lidt løst sagt kan man sige, at en tabsfunktion måler, hvor god en AI model er til at forudsige det, vi gerne vil have den til at sige noget om. I denne note forklarer vi, hvordan tabsfunktioner kan se ud, og hvad træningsdata er for en størrelse.\nSværhedsgrad: ***\n\n\n\n\n\n\nKrydsvalidering\n\nI denne note forklarer vi, hvordan man vælger den bedste model til beskrivelse af data. Vi undersøger, om man bare skal vælge den mest komplicerede, eller om der kan gå noget galt, hvis man gør det. Det handler kort sagt om overfitting og krydsvalidering.\nSværhedsgrad: ***\n\n\n\n\n\n\nSensitivitet, specificitet, ROC-kurver og AUC\n\nNår man skal vælge en god algoritme, som kan anvendes til en klassifikation, har man brug for at kunne sammenligne, hvor godt forskellige algoritmer prædikterer. Hvordan det kan gøres, handler denne note om.\nSværhedsgrad: ***\n\n\n\n\n\n\nNaiv Bayes klassifier\n\nDenne note handler om klassifikation ved hjælp af en metode, som kaldes for \"naiv Bayes\". Noten er baseret på sandsynlighedsregning – herunder betingede sandsynligheder og uafhængige hændelser.\nSværhedsgrad: ***\n\n\n\n\n\n\nClustering med K-means\n Clustering med K-means er en metode, som kan bruges til at opdele observationer i et antal grupper. Metoden er et eksempel på unsupervised learning, fordi vi ikke på forhånd har nogle observationer, hvor vi ved hvilken gruppe, hver observation tilhører.\nSværhedsgrad: ****"
  },
  {
    "objectID": "materialer/neurale_net.html",
    "href": "materialer/neurale_net.html",
    "title": "Materialer om kunstige neurale netværk",
    "section": "",
    "text": "Materialer om kunstige neurale netværk\nPå denne side finder du forskellige noter om kunstige neurale netværk. Noterne varierer i sværhedsgrad og i matematisk fokus.\nNoterne er skrevet til elever i gymnasiet og kan læses uafhængigt af hinanden. Til gengæld er den overordnede beskrivelse af noterne nedenfor nok nemmest at læse for lærerne.\nSværhedsgraden af noterne er klassificeret fra \"forholdvis nem\" (*) til \"svær\" (****).\nHelt overordnet kan man sige, at et neuralt netværk er en funktion, der, som input, tager et antal målte variable. Det kunne for eksempel være en vælgers svar på en kandidattest. Som output giver det en klasse/kategori, for eksempel et parti vælgeren bør stemme på. I et neuralt netværk indgår nogle ikke-lineære funktioner kaldet aktiveringsfunktioner, som i sig selv er matematisk interessante. For at finde et neuralt netværk, der giver gode klassifikationer, minimeres en tabsfunktion. Til det formål får man brug for at finde partielt afledte, som bruges i forbindelse med gradientnedstigning.\n\n\n\nPerceptroner\n\n\n\nNoten beskriver først \"Perceptron Learning Algoritmen\", som kan bruges i forbindelse med binær klassifikation, men som kun konvergerer, hvis data er lineært separabel. Der gives ikke noget matematisk argument for dette, men det sandsynliggøres, hvorfor algoritmen virker. I behandlingen af \"Perceptron Learning Algoritmen\" anvendes der ikke eksplicit en tabsfunktion.\nDernæst beskrives \"ADALINE\", som også bruges til binær klassifikation, men som konvergerer – også i det tilfælde, hvor data ikke er lineært separabel. Opdateringsreglerne til ADALINE algoritmen udledes ved at minimere squared error tabsfunktionen ved hjælp af gradientnedstigning. Den anvendte aktiveringsfunktion er her identiteten, hvilket gør denne udledning lettere end i de efterfølgende noter.\n\n\n\nType af klassifikation\nAktiveringsfunktion\nTabsfunktion\n\n\n\n\nBinær\nIngen/identiteten\nIngen/squared error\n\n\n\nSværhedsgrad: *\n\n\n\n\n\n\nKunstige neuroner\n\n\n\nNoten behandler byggestenene til de mere generelle kunstige neurale netværk nemlig de kunstige neuroner. De kunstige neuroner bruges – som de beskrives her – til binær klassifikation. Opdateringsreglerne til justering af vægtene udledes ved at minimere squared error tabsfunktionen ved hjælp af gradientnedstigning. Til forskel fra ADALINE algoritmen anvendes her sigmoid-funktionen som aktiveringsfunktion, og der er også henvisning til en side, som beskriver hvilken fordel det har sammenlignet med ADALINE.\n\n\n\nType af klassifikation\nAktiveringsfunktion\nTabsfunktion\n\n\n\n\nBinær\nSigmoid\nSquared error\n\n\n\nSværhedsgrad: **\n\n\n\n\n\n\nSimple neurale netværk\n\n\n\nDenne noten behandler et egentlig kunstigt neuralt netværk dog med den væsentlige forsimpling, at der kun er to skjulte lag, hvor hver af disse lag kun består af én kunstige neuron. Det har den fordel, at det nu giver mening at tale om feedforward og backpropagation, men uden at sidstnævnte drukner i kædereglen af flere variable. Til gengæld bruges der tid på at forklare og anvende den kæderegel, som eleverne allerede kender. Også her udledes opdateringsreglerne ved at minimere squared error tabsfunktionen ved hjælp af gradientnedstigning.\n\n\n\nType af klassifikation\nAktiveringsfunktion\nTabsfunktion\n\n\n\n\nBinær\nSigmoid\nSquared error\n\n\n\nSværhedsgrad: ***\n\n\n\n\n\n\nSimple kunstige neurale netværk til multipel klassifikation\n\n\n\nI denne noten behandles det tilfælde, hvor man ikke er interesseret i binær klassifikation, men derimod er ønsket at kunne prædiktere blandt mere end to klasser. Noten er holdt simpel på den måde, at det beskrevne netværk ikke indeholder nogle skjulte lag, men outputlaget består i stedet af flere neuroner. Det får den konsekvens, at den anvendte aktiveringsfunktion nu er den såkaldte softmax funktion, som kan se som en udvidelse af sigmoid-funktionen. Derudover behandles også cross-entropy tabsfunktionen, som minimeres ved hjælp af gradientnedstigning.\n\n\n\nType af klassifikation\nAktiveringsfunktion\nTabsfunktion\n\n\n\n\nMultipel\nSoftmax\nCross-entropy\n\n\n\nSværhedsgrad: ****\n\n\n\n\n\n\nKunstige neurale netværk\n\n\n\nNoten gennemgår et mere generelt kunstigt neuralt netværk med to skjulte lag, som hver består af to neuroner. Netværket bruges her til binær klassifikation, som aktiveringsfunktion anvendes igen sigmoid-funktionen og vægtene opdateres ved at minimere squared error tabsfunktionen ved hjælp af gradientnedstigning. Da de skjulte lag består af flere neuroner end én, må kædereglen for funktioner af flere variable bringes i spil for at finde de partielle afledede, som anvendes i forbindelse med gradientnedstigning.\nDesuden gives der i denne note også en forklaring på fordelene ved cross-entropy tabsfunktionen sammenlignet med squared error tabsfunktionen, der linkes til en side hvor opdateringsreglerne i et helt generelt kunstigt neuralt netværk forklares (ved hjælp af en masse indekser!) og endelig gives der en overordnet beskrivelse af convolutional neural networks, som bruges i forbindelse med prædiktion af billeder.\n\n\n\nType af klassifikation\nAktiveringsfunktion\nTabsfunktion\n\n\n\n\nPrimært binær\nSigmoid\nSquared error\n\n\n\nSværhedsgrad: ****"
  },
  {
    "objectID": "materialer/naivbayes/NaivBayes.html",
    "href": "materialer/naivbayes/NaivBayes.html",
    "title": "Naiv Bayes klassifier",
    "section": "",
    "text": "Denne note handler om klassifikation ved hjælp af den metode, som kaldes for naiv Bayes."
  },
  {
    "objectID": "materialer/naivbayes/NaivBayes.html#bayes-klassifikation",
    "href": "materialer/naivbayes/NaivBayes.html#bayes-klassifikation",
    "title": "Naiv Bayes klassifier",
    "section": "Bayes klassifikation",
    "text": "Bayes klassifikation\nFor at introducere teorien om Bayes naive klassifikation, vil vi starte med at se på et eksempel for at få en idé om, hvad Bayes klassifikation går ud på.\nVi vil se på en person, og vi ønsker at give et bud på, om vedkommende stemmer på rød eller blå blok. Vi har på forhånd oplysninger om en del andre personer og ønsker at bruge den viden til at give det bedste bud på, om personen stemmer på rød eller blå blok.\nHer har vi følgende data, der viser, hvem der stemmer på rød og blå blok.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlle\nMænd\nKvinder\nUnge\nÆldre\nSjælland\nJylland\nAnden bopæl\n\n\n\n\nRød\n\\(51.85 \\%\\)\n\\(48.00 \\%\\)\n\\(55.00 \\%\\)\n\\(65.00 \\%\\)\n\\(47.47 \\%\\)\n\\(54.00 \\%\\)\n\\(49.90 \\%\\)\n\\(52.78 \\%\\)\n\n\nBlå\n\\(48.15 \\%\\)\n\\(52.00 \\%\\)\n\\(45.00 \\%\\)\n\\(35.00 \\%\\)\n\\(52.53 \\%\\)\n\\(46.00 \\%\\)\n\\(50.10 \\%\\)\n\\(47.22 \\%\\)\n\n\nAntal\n\\(10000\\)\n\\(4500\\)\n\\(5500\\)\n\\(2500\\)\n\\(7500\\)\n\\(3000\\)\n\\(4500\\)\n\\(2500\\)\n\n\n\n\n\n\n\n\n\nOpgave\n\n\n\n\n\nBrug tabellen ovenfor og giv det bedste bud på hvilken blok en person stemmer på:\n\nHvis det er en tilfældig person.\nHvis det er en mand.\n\n\n\n\nFra skemaet med oplysninger kan det være svære at give et bud på, hvad en ældre kvinde fra Sjælland vil stemme på, da oplysningen om køn tyder på personen vil stemme på rød, mens information om, at det er en ældre person, tyder på, at personen vil stemme på blå. Endelig vil oplysningen om, at kvinden bor på Sjælland igen få os til at tænke, at hun stemmer på rød blok.\nHer kunne vi selvfølgelig løse problemet ved at få information for hver kombination af køn, aldersgruppe og bopæl. Men det viser sig ikke at være en helt gangbar fremgangsmåde. Forklaringen følger her: Hvis vi ser på kombinationer af køn, aldersgruppe og bopæl vil det i dette eksempel give \\(2\\cdot 2\\cdot 3=12\\) kombinationer, og hvis vi i stedet havde set på, om man svarer ja eller nej til \\(50\\) spørgsmål, vil man kunne få \\(2^{50}\\) forskellige kombinationer af svar. Hvis man ser på en person, der har svaret på de \\(50\\) spørgsmål, kan man her forvente, at man i ens data kun har ganske få eller måske slet ingen personer, der har svaret på fuldstændig samme måde, og der vil ikke være meget at basere ens bud på.\nDerfor ønsker vi en metode, hvor vores bud, på hvad en ny person vil stemme på, udelukkende baseres på information svarende til det fra skemaet ovenfor, hvor vi ikke ser på alle de forskellige kombinationer. Det er det Naive Bayes klassifikation kan."
  },
  {
    "objectID": "materialer/naivbayes/NaivBayes.html#bayes-klassifier",
    "href": "materialer/naivbayes/NaivBayes.html#bayes-klassifier",
    "title": "Naiv Bayes klassifier",
    "section": "Bayes klassifier",
    "text": "Bayes klassifier\nI det følgende indfører vi det nødvendige matematik og notation til Naive Bayes klassifikation. Først og fremmest indfører vi en stokastisk variabel \\(Y\\), som kan antage de værdier, der svarer til vores forskellige forudsigelser/bud. I vores eksempel vil \\[Y\\in\\{blå, rød\\}.\\]\nLidt mere generelt siger man, at \\(Y\\) skal være en diskret stokastisk variabel med et bestemt antal mulige udfald, og der behøver altså ikke nødvendigvis kun at være to udfald.\nDerudover indfører vi en stokastisk variabel \\(\\mathbf{X}\\), hvor de mulige udfald er alle kombinationer af informationer. Her kan vi tænke \\(\\mathbf{X}\\) som en stokastisk vektor \\(\\mathbf{X} =(X_1,X_2,…,X_q)\\), hvor man ved eksemplet kunne sige \\(X_1\\):køn, \\(X_2\\):aldersgruppe og \\(X_3\\):bopæl, og et udfald kunne være \\(\\mathbf{x}=(kvinde,ældre,Sjælland)\\).\nFor hvert udfald af \\(Y\\) ønsker vi, at bestemme sandsynligheden for at værdien \\(y\\) antages, når vi allerede har observeret, at \\(\\mathbf{X}=\\mathbf{x}\\).\nSandsynligheden vil vi skrive som \\[P(Y = y \\mid \\mathbf{X} = \\mathbf{x})\\]\nDenne notation og betydningen deraf ser vi snart på.\nVi kalder \\(P(Y = y \\mid \\mathbf{X} = \\mathbf{x})\\) en posterior sandsynlighed, fordi den udtrykker sandsynligheden for \\(Y\\) efter (post), vi har informationen \\(\\mathbf{x}\\).\nDet mest sandsynlige udfald for \\(Y\\), når vi har informationen \\(\\mathbf{x}\\), betegnes \\(C(\\mathbf{x})\\) og kaldes Bayes klassifikation."
  },
  {
    "objectID": "materialer/naivbayes/NaivBayes.html#betinget-sandsynlighed-og-uafhængighed",
    "href": "materialer/naivbayes/NaivBayes.html#betinget-sandsynlighed-og-uafhængighed",
    "title": "Naiv Bayes klassifier",
    "section": "Betinget sandsynlighed og uafhængighed",
    "text": "Betinget sandsynlighed og uafhængighed\nFørst vender vi dog lige tilbage til notationen \\(P(Y = y \\mid \\mathbf{X} = \\mathbf{x})\\), som vi kaldte en posterior sandsynlighed. I sandsynlighedsregningen kalder vi det også for en betinget sandsynlighed, hvilket er grunden til notationen \\(P(Y = y \\mid \\mathbf{X} = \\mathbf{x})\\).\nGivet to hændelser \\(A\\) og \\(B\\) så benyttes notationen \\(P(A\\mid B)\\) som sandsynligheden for, at \\(A\\) sker, når det er givet, at \\(B\\) er sket. Det læses derfor også som sandsynligheden for \\(A\\) givet \\(B\\).\nSå \\(P(Y = y \\mid \\mathbf{X} = \\mathbf{x})\\) er derved sandsynligheden for \\(Y = y\\), når det er givet, at \\(\\mathbf{X} = \\mathbf{x}\\).\nEt banalt eksempel kunne være at \\(Y\\) angiver antal ben på et givent dyr, mens \\(\\mathbf{X}\\) angiver dyrearten. Her er det oplagt, at sandsynligheden for fire eller to ben afhænger af hvilken dyreart, der er tale om.\nFormelt defineres betinget sandsynlighed for to hændelser \\(A\\) og \\(B\\) som: \\[P(A\\mid B) = \\frac{P(A \\cap B)}{P(B)} \\tag{1}\\]\nUdtrykket \\(P(A \\cap B)\\) i tælleren er sandsynligheden for fælleshændelsen mellem \\(A\\) og \\(B\\) – det vil sige hændelsen, at både \\(A\\) og \\(B\\) indtræffer – og i nævneren sørger vi for, at man kun ser på de udfald, hvor \\(B\\) er givet1.\n1 Man siger også, at nævneren normaliserer sandsynligheden i forhold til sandsynligheden for hændelsen \\(B\\).\nEksempel med betinget sandsynlighed\nLad os fokusere på en almindelig terning med seks sider. Lad \\(B\\) være hændelsen at antal øjne er mindre eller lig med \\(3\\). Det vil sige, at hændelsen \\(B\\) består af udfaldene: \\(B\\) = {⚀, ⚁, ⚂}. Lad hændelsen \\(A\\) være udfald med ulige antal øjne: \\(A\\) = {⚀, ⚂, ⚄}.\nDa kan vi nemt indse, at \\[P(A) = 3/6 = 1/2\\] samt ligeledes at \\[P(B) = 1/2\\] på grund af det symmetriske udfaldsrum.\nSer vi imidlertid på den betingede sandsynlighed for at \\(A\\) indtræffer givet, at \\(B\\) allerede er indtruffet, får vi \\(P(A\\mid B)\\). Det svarer til sandsynligheden for at slå et ulige antal øjne, hvis vi allerede ved at antallet af øjne er mindre end eller lig med \\(3\\).\nFørst ser vi, at \\(A\\cap B\\) = {⚀, ⚂, ⚄} \\(\\cap\\) {⚀, ⚁, ⚂} = {⚀, ⚂}, hvilket igen på grund af det symmetriske sandsynlighedsfelt betyder, at \\[P(A\\cap B) = 2/6 = 1/3\\] Efter at vi normaliserer sandsynligheden ud fra betingelsen om at \\(B\\) er indtruffet får vi \\[P(A\\mid B) =  \\frac{P(A \\cap B)}{P(B)} = \\frac{1/3}{1/2}  = \\frac{2}{3}.\\] At betinge med hændelsen \\(B\\) svarer i dette simple eksempel til at indskrænke udfaldet for \\(A\\) fra alle ulige øjne til dem, som er mindre end eller lig med \\(3\\). Der er således tre mulige udfald i vores “\\(B\\)-verden”, hvoraf to er ulige."
  },
  {
    "objectID": "materialer/naivbayes/NaivBayes.html#stokastisk-uafhængighed",
    "href": "materialer/naivbayes/NaivBayes.html#stokastisk-uafhængighed",
    "title": "Naiv Bayes klassifier",
    "section": "Stokastisk uafhængighed",
    "text": "Stokastisk uafhængighed\nMan siger, at to hændelser \\(A\\) og \\(B\\) er uafhængige af hinanden, hvis \\[P(A \\cap B) = P(A) \\cdot P(B)\\] Hvis vi ser på udtrykket for \\(P(A\\mid B)\\) i (1) og antager, at \\(A\\) og \\(B\\) er uafhængige, ser vi at \\[\nP(A\\mid B) = \\frac{P(A\\cap B)}{P(B)} \\stackrel{\\text{uafh.}}{=} \\frac{P(A) \\cdot P(B)}{P(B)} = P(A)\n\\] Med andre ord betyder det, at sandsynligheden for \\(A\\) givet \\(B\\) er den samme som sandsynligheden for \\(A\\). Det vil sige, at oplysningen om, at \\(B\\) allerede er indtruffet, ikke ændrer på sandsynligheden for \\(A\\). Information om \\(B\\) tilfører altså ikke noget nyt i forhold til information om \\(A\\), og det giver derfor mening af sige, at \\(A\\) og \\(B\\) er uafhængige af hinanden."
  },
  {
    "objectID": "materialer/naivbayes/NaivBayes.html#bayes-sætning",
    "href": "materialer/naivbayes/NaivBayes.html#bayes-sætning",
    "title": "Naiv Bayes klassifier",
    "section": "Bayes’ sætning",
    "text": "Bayes’ sætning\nEn meget vigtig matematisk egenskab ved betinget sandsynlighed er muligheden for at ombytte rollerne i formlen, således vi kan udtrykke \\(P(B\\mid A)\\) ud fra vores viden om \\(P(A\\mid B)\\). Sætningen kaldes Bayes’ sætning (eller formel) og kan let vises ved først at bestemme \\(P(A\\cap B)\\) ved at isolere denne sandsynlighed. Fra (1) får vi\n\\[P(A\\cap B)=P(A\\mid B)\\cdot P(B)\\] På helt tilsvarende vis må der også gælde, at\n\\[P(B\\cap A)=P(B\\mid A)\\cdot P(A)\\] Og da \\(A\\cap B=B\\cap A\\) må også \\(P(A\\cap B)=P(B\\cap A)\\). De to ovenfor udledte sandsynligheder, må derfor være ens:\n\\[P(A\\mid B)\\cdot P(B)=P(B\\mid A)\\cdot P(A)\\] Her Kan \\(P(A\\mid B)\\) isoleres \\[\nP(A\\mid B)=  \\frac{P(B\\mid A)\\cdot P(A)}{P(B)}\n\\] Dette resultat er netop Bayes’ sætning:\n\n\nSætning 1 (Bayes’ sætning) Lad \\(A\\) og \\(B\\) være hændelser, hvor \\(P(B) \\neq 0\\). Da gælder, at \\[\nP(A\\mid B)=  \\frac{P(B\\mid A)\\cdot P(A)}{P(B)}\n\\]\n\n\nVi kan altså ved at kende \\(P(B\\mid A)\\), \\(P(B)\\) og \\(P(A)\\) udtrykke den betingede sandsynlighed \\(P(A\\mid B)\\). Vi vender lige om lidt tilbage til, hvad vi kan bruge det til.\nSom sidste bemærkning er det væsentligt at understrege, at \\(P(A\\mid B) \\neq P(B\\mid A)\\) med mindre \\(P(A) = P(B)\\) jævnfør (1) ovenfor. F.eks. er sandsynligheden for et tilfældigt dyr er en elefant, givet dyret har fire ben ikke den samme som sandsynligheden for, at dyret har fire ben givet, at dyret er en elefant!"
  },
  {
    "objectID": "materialer/naivbayes/NaivBayes.html#binær-bayes-klassifier",
    "href": "materialer/naivbayes/NaivBayes.html#binær-bayes-klassifier",
    "title": "Naiv Bayes klassifier",
    "section": "Binær Bayes klassifier",
    "text": "Binær Bayes klassifier\nAntag nu at \\(Y\\) kun kan antage to tilstande som ved eksemplet med rød eller blå. I dette tilfælde oversætter man ofte de to udfald til henholdsvis \\(0\\) og \\(1\\), eller i visse sammenhænge til \\(-1\\) og \\(+1\\). Husk på at Bayes klassifikationen \\(C(\\mathbf{x})\\) er det mest sandsynlige udfald for \\(Y\\), når vi har informationen \\(\\mathbf{x}\\). I det tilfælde hvor \\(Y\\) kun kan antage to tilstande, får vi derfor\n\\[ C(\\mathbf{x}) = \\begin{cases}\n0 & \\textrm{hvis } P(Y = 0 \\mid \\mathbf{X} = \\mathbf{x}) &gt; P(Y = 1 \\mid \\mathbf{X} = \\mathbf{x}) \\\\\n1 & \\textrm{ellers} \\\\\n\\end{cases} \\tag{2}\\]\nDette kan også udtrykkes på anden vis: \\[\n\\begin{aligned}\nP(Y = 0 \\mid \\mathbf{X} = \\mathbf{x}) &gt; P(Y = 1 \\mid \\mathbf{X} = \\mathbf{x}) \\Leftrightarrow\n\\frac{P(Y = 0 \\mid \\mathbf{X} = \\mathbf{x})}{P(Y = 1 \\mid \\mathbf{X} = \\mathbf{x})} &gt; 1.\n\\end{aligned}\n\\] Her er vi dog nødt til at antage, at \\[P(Y = 1 \\mid \\mathbf{X} = \\mathbf{x})\\neq 0,\\] så vi ikke kommer til at dividere med \\(0\\).\nBruger vi denne omskrivning, kan vi udtrykke den binære Bayes klassifikation i (2) på denne måde:\n\\[ C(\\mathbf{x}) = \\begin{cases}\n0 & \\textrm{hvis } \\frac{P(Y = 0 \\mid \\mathbf{X} = \\mathbf{x})}{P(Y = 1 \\mid \\mathbf{X} = \\mathbf{x})} &gt; 1 \\\\\n1 & \\textrm{ellers} \\\\\n\\end{cases} \\tag{3}\\]\nI det følgende vil vi benytte os af Bayes’ sætning til at se på, hvordan ovenstående brøk kan beregnes."
  },
  {
    "objectID": "materialer/naivbayes/NaivBayes.html#bayes-sætning-i-anvendelse",
    "href": "materialer/naivbayes/NaivBayes.html#bayes-sætning-i-anvendelse",
    "title": "Naiv Bayes klassifier",
    "section": "Bayes’ sætning i anvendelse",
    "text": "Bayes’ sætning i anvendelse\nVi bruger først Bayes’ sætning til at udtrykke \\(P(A\\mid C)\\) og \\(P(B\\mid C)\\). \\[\nP(A\\mid C) = \\frac{P(C\\mid A)P(A)}{P(C)} \\quad\\text{og}\\quad\nP(B\\mid C) = \\frac{P(C\\mid B)P(B)}{P(C)},\n\\] Når vi bestemmer forholdet mellem \\(P(A\\mid C)\\) og \\(P(B\\mid C)\\) vil vi kunne slippe af med nævneren, som de har til fælles:\n\\[\n\\begin{aligned}\n\\frac{P(A\\mid C)}{P(B\\mid C)} &= \\frac{\\frac{P(C\\mid A)P(A)}{P(C)}}{\\frac{P(C\\mid B)P(B)}{P(C)}}  \n= \\frac{P(C\\mid A)P(A)}{P(C)} \\cdot \\frac{P(C)}{P(C\\mid B)P(B)} \\\\\n&= \\frac{P(C\\mid A)P(A)}{P(C\\mid B)P(B)},\n\\end{aligned}\n\\] hvor vi har udnyttet, at man dividerer med en brøk ved at gange med den omvendte brøk.\nI den binære Bayes klassifikation i (3) indgår brøken \\(\\frac{P(Y = 0 \\mid \\mathbf{X} = \\mathbf{x})}{P(Y = 1 \\mid \\mathbf{X} = \\mathbf{x})}\\), som vi ved at benytte ovenstående kan omskrive til: \\[\n\\frac{P(Y = 0 \\mid \\mathbf{X} = \\mathbf{x})}{P(Y = 1 \\mid \\mathbf{X} = \\mathbf{x})} =\n\\frac{P(\\mathbf{X} = \\mathbf{x} \\mid Y = 0)P(Y = 0)}{P(\\mathbf{X} = \\mathbf{x} \\mid Y = 1)P(Y = 1)}.\n\\tag{4}\\]"
  },
  {
    "objectID": "materialer/naivbayes/NaivBayes.html#naiv-bayes-klassifier",
    "href": "materialer/naivbayes/NaivBayes.html#naiv-bayes-klassifier",
    "title": "Naiv Bayes klassifier",
    "section": "Naiv Bayes klassifier",
    "text": "Naiv Bayes klassifier\nUd fra udtrykket for forholdet mellem de to posterior sandsynligheder \\(P(Y = 0 \\mid \\mathbf{X} = \\mathbf{x})\\) og \\(P(Y = 1 \\mid \\mathbf{X} = \\mathbf{x})\\) som indgår i (4) kan vi se, at der indgår to typer af sandsynligheder:\n\\[P(\\mathbf{X} = \\mathbf{x}\\mid Y = y) \\quad \\textrm{og} \\quad P(Y = y)\\]\nDisse benævnes henholdsvis likelihood og prior sandsynlighed, idet \\(P(\\mathbf{X} = \\mathbf{x}\\mid Y = y)\\) udtrykker likelihooden (troligheden) for at observere \\(\\mathbf{X} = \\mathbf{x}\\) givet \\(Y = y\\). Omvendt er prior sandsynligheden \\(P(Y = y)\\) et udtryk for forhåndsandsynligheden for at \\(Y = y\\). Altså bruger vi disse betegnelser:\n\\[\n\\begin{aligned}\n&\\textrm{Likelihood: }  &P(\\mathbf{X} = \\mathbf{x}\\mid Y = y) \\\\\n&\\textrm{Prior sandsynlighed: } &P(Y = y)\n\\end{aligned}\n\\]\nVi kan sammenfatte udtrykket i (4) til det såkaldte posterior forhold: \\[\n\\underbrace{\\frac{P(Y = 0 \\mid \\mathbf{X} = \\mathbf{x})}{P(Y = 1 \\mid \\mathbf{X} = \\mathbf{x})}}_\\text{Posterior forhold} =\n\\underbrace{\\frac{P(\\mathbf{X} = \\mathbf{x} \\mid Y = 0)}{P(\\mathbf{X} = \\mathbf{x} \\mid Y = 1)}}_\\text{Likelihood forhold} \\cdot\n\\underbrace{\\frac{P(Y = 0)}{P(Y = 1)}}_\\text{Prior forhold}\n\\]\nHvis vi vender tilbage til vores spørgsmål om at stemme på blå eller rød blok og så kan vi sige, at \\[ Y=\n\\begin{cases}\n0 & \\textrm {hvis der stemmes på rød blok} \\\\\n1 & \\textrm {hvis der stemmes på blå blok} \\\\\n\\end{cases}\n\\] Hvis \\(x=(kvinde, ung, Sjælland)\\), så udtrykker \\(P(\\mathbf{X} = \\mathbf{x} \\mid Y = 0)\\) således sandsynligheden for, at en person er en ung kvinde fra Sjælland givet, at personen stemmer på rød blok. Når man skal bestemme den sandsynlighed skal vi huske, at det er sandsynligheden for det samlede udsagn med køn, alder og bopæl.\nFor at kunne beregne ovenstående sandsynligheder bliver vi nødt til at antage et eller andet, der gør det muligt. Man siger, at vi opstiller en model.\nÉn af de simpleste modeller er at antage at køn, alder og bopæl er uafhængige af hinanden givet \\(Y = y\\). Denne forsimplende antagelse har medvirket til metodens navn: Naiv Bayes eller Uafhængig Bayes klassifikation.\nDet betyder ifølge vores tidligere definition af uafhængighed at \\[\n\\begin{aligned}\nP(\\mathbf{X} = \\mathbf{x} \\mid Y = y) &=\nP(X_1 = x_1, X_2 = x_2, \\dots, X_q = x_q \\mid Y = y)\\\\\n&= P(X_1 = x_1\\mid Y = y)P(X_2 = x_2\\mid Y = y)\\cdots P(X_q = x_q \\mid Y = y)\\\\\n&= \\prod_{i=1}^q P(X_i = x_i\\mid Y = y),\n\\end{aligned}\n\\] hvor \\(\\prod\\)-symbolet i sidste linje betyder, at vi tager produktet af alle faktorerne på formen \\(P(X_i = x_i\\mid Y = y)\\) fra \\(i=1\\) op til \\(q\\) – altså præcist det, som står i linjen over. Det minder således om sum-tegnet \\[\\sum_{i=1}^n x_i = x_1 + x_2 + \\cdots + x_n,\\] men blot for multiplikation i stedet for addition."
  },
  {
    "objectID": "materialer/naivbayes/NaivBayes.html#posterior-forholdet-score-og-vægte",
    "href": "materialer/naivbayes/NaivBayes.html#posterior-forholdet-score-og-vægte",
    "title": "Naiv Bayes klassifier",
    "section": "Posterior forholdet, score og vægte",
    "text": "Posterior forholdet, score og vægte\nSamler vi nu udtrykkene, som indgår i vores posterior forhold i (4), samtidig med at vi antager, at \\(X_1, X_2, \\cdots, X_q\\) er uafhængige af hinanden givet \\(Y\\), får vi nedenstående:\n\\[\n\\begin{aligned}\n\\frac{P(Y = 0 \\mid \\mathbf{X} = \\mathbf{x})}{P(Y = 1 \\mid \\mathbf{X} = \\mathbf{x})} &=\n\\frac{P(Y=0)}{P(Y=1)}\\cdot \\frac{P(\\mathbf{X} = \\mathbf{x} \\mid Y = 0)}{P(\\mathbf{X} = \\mathbf{x} \\mid Y = 1)} \\\\\n&= \\frac{P(Y = 0)}{P(Y = 1)}\n\\prod_{i=1}^q\\frac{P(X_i = x_i \\mid Y = 0)}{P(X_i = x_i \\mid Y = 1)},\n\\end{aligned}\n\\]\nhvor hver faktor på højre siden bidrager ligeligt til, om observationen \\(\\mathbf{x}\\) skal klassificeres som \\(Y=0\\) eller \\(Y=1\\).\nNår vi skal lave beregninger på computer baseret på data, er det ofte væsentligt at tage højde for numerisk præcision. Alle tal på en computer skal repræsenteres af et endelig antal bits. Det betyder, at visse tal (f.eks. \\(1/3\\)) bliver afrundet efter et vist antal decimaler. Derfor kan der opstå problemer, når man enten ganger eller adderer meget små (eller store) tal sammen. For at undgå dette i udtrykket ovenfor, er det derfor tit en god idé at benytte sig af (den naturlige) logaritme på begge sider af lighedstegnet:\n\\[\n\\begin{aligned}\n\\ln \\left(\\frac{P(Y = 0 \\mid \\mathbf{X} = \\mathbf{x})}{P(Y = 1 \\mid \\mathbf{X} = \\mathbf{x})}\\right) &=\n\\ln \\left(\\frac{P(Y = 0)}{P(Y = 1)}\\right) +\n\\sum_{i=1}^q \\ln \\left(\\frac{P(X_i = x_i \\mid Y = 0)}{P(X_i = x_i \\mid Y = 1)}\\right),\n\\end{aligned}\n\\tag{5}\\]\nhvor vi har brugt logaritmeregnereglen \\[\\ln(a\\cdot b) = \\ln(a) + \\ln(b)\\] gentagende gange.\nVi minder om, at forholdet mellem \\(P(Y = 0 \\mid \\mathbf{X} = \\mathbf{x})\\) og \\(P(Y = 1 \\mid \\mathbf{X} = \\mathbf{x})\\) er af særlig interesse omkring værdien 1 – se (3). Når forholdet er \\(1\\) betyder det, at de to klasser er lige sandsynlige givet \\(\\mathbf{x}\\). Endvidere, når forholdet er over \\(1\\), er \\(Y=0\\) mere sandsynlig end \\(Y=1\\), og når det er under \\(1\\), er det omvendte tilfældet.\nLad os nu se på hvilken effekt det får, at vi ikke længere ser direkte på det posterior forhold \\[ \\frac{P(Y = 0 \\mid \\mathbf{X} = \\mathbf{x})}{P(Y = 1 \\mid \\mathbf{X} = \\mathbf{x})}\\] men i stedet på logaritmen af det posterior forhold \\[ \\ln \\left ( \\frac{P(Y = 0 \\mid \\mathbf{X} = \\mathbf{x})}{P(Y = 1 \\mid \\mathbf{X} = \\mathbf{x})}\\right )\\]\nI figur 1 nedenfor er grafen for logaritmefunktionen tegnet for \\(x\\in ]0, 10].\\)\n\n\n\n\n\n\nFigur 1: Grafen for \\(f(x)=\\ln (x)\\).\n\n\n\nVi ved, at \\(\\ln(1) = 0\\) (hvilket også kan ses på grafen i figur 1), samt at for \\(x&lt;1\\) er \\(\\ln(x)&lt;0\\), mens for \\(x&gt;1\\) er \\(\\ln(x)&gt;0\\).\nSå når vi ser på \\[\\ln \\left(\\frac{P(Y = 0 \\mid \\mathbf{X} = \\mathbf{x})}{P(Y = 1 \\mid \\mathbf{X} = \\mathbf{x})}\\right)\\] bliver det vigtige nu, om denne størrelse er positiv eller negativ.\nLad os derfor indføre \\(S\\) som en score, der er lig med logaritmen til posterior forholdet:\n\\[\nS = \\ln \\left(\\frac{P(Y = 0 \\mid \\mathbf{X} = \\mathbf{x})}{P(Y = 1 \\mid \\mathbf{X} = \\mathbf{x})}\\right)\n\\tag{6}\\]\nDen binære Bayes klassifikation i (3) kan derfor i stedet skrives ved hjælp af scoren \\(S\\) på denne måde:\n\\[ C(\\mathbf{x}) = \\begin{cases}\n0 & \\textrm{hvis } \\ S&gt;0  \\\\\n1 & \\textrm{ellers} \\\\\n\\end{cases} \\tag{7}\\]\nVi ved således, at hvis \\(S&gt;0\\), så klassificerer vi \\(\\mathbf{x}\\), som \\(C(x)=0\\) og ellers \\(C(x)=1\\).\nSammenholder vi definitionen af \\(S\\) i (6) med udtrykket i (5), ser vi, at \\(S\\) også kan skrives som\n\\[\n\\begin{aligned}\nS &= \\ln \\left(\\frac{P(Y = 0 \\mid \\mathbf{X} = \\mathbf{x})}{P(Y = 1 \\mid \\mathbf{X} = \\mathbf{x})}\\right) \\\\&=\n\\ln \\left(\\frac{P(Y = 0)}{P(Y = 1)}\\right) +\n\\sum_{i=1}^q \\ln \\left(\\frac{P(X_i = x_i \\mid Y = 0)}{P(X_i = x_i \\mid Y = 1)}\\right),\n\\end{aligned}\n\\tag{8}\\]\nIndfører vi nu bidragene til \\(S\\) som \\(w_0\\) og \\(w_i(x_i)\\) således \\[\nw_0 = \\ln \\left(\\frac{P(Y = 0)}{P(Y = 1)}\\right)\n\\quad\\text{og}\\quad\nw_i(x_i) = \\ln \\left(\\frac{P(X_i = x_i \\mid Y = 0)}{P(X_i = x_i \\mid Y = 1)}\\right)\n\\] kan vi skrive udtrykket for \\(S\\) i (8) som \\[\nS = w_0 + \\sum_{i = 1}^q w_i(x_i),\n\\tag{9}\\] hvor det tydeliggøres, at hvis \\(w_i(x_i)&gt;0\\), så understøtter bidraget fra den \\(i\\)’te oplysning \\(x_i\\), at \\(Y=0\\) og ellers hvis \\(w_i(x_i)&lt;0\\) at \\(Y=1\\). Denne egenskab gør, at man også kan omtale \\(w_i(x_i)\\) som en slags “bevismæssig” vægt.\n\nVægten \\(w_0\\)\nVi har altså set i (5) og (9), hvordan vi kan omskrive forholdet mellem posterior sandsynlighederne for de to klasser \\(Y=0\\) og \\(Y=1\\) til en sum af bidrag.\nDet første led \\(w_0\\) afhænger ikke af nogen information \\(x_i\\), og vi har tidligere omtalt disse sandsynligheder som prior sandsynligheder. Man kan sige, at det er vores umiddelbare bud på hvad \\(Y\\) er, uden at vi kender noget som helst til informationerne i \\(\\mathbf{x}\\).\nNår vi går fra vores model, som vi har udledt i det foregående, til at skulle implementere den i en specifik anvendelse, bliver vi derfor nødt til at estimere de parametre, som indgår i modellen. For \\(w_0\\) betyder det, at vi skal estimere både \\(P(Y=0)\\) og \\(P(Y=1)\\). Her vil det være oplagt blot at estimere \\(P(Y=0)\\) og \\(P(Y=1)\\) ud fra træningsdata ved helt simpelt at bestemme andelen, som stemmer på henholdsvis rød og blå, hvorefter vi kan beregne \\[\nw_0 = \\ln \\left(\\frac{P(Y = 0)}{P(Y = 1)}\\right)\\]\nHvis du vil se en mere teoretisk begrundelse for dette valg, kan du folde boksen nedenfor ud.\n\n\n\n\n\n\nTeoretisk begrundelse for hvordan \\(P(Y=0)\\) kan estimeres\n\n\n\n\n\nVi ønsker at bestemme det bedst mulige estimat for \\(p=P(Y=0)\\) ud fra vores træningsdata. Vi vil her tænke på resultaterne fra datasættet som kommende fra et binomialforsøg med sandsynligheds-parameter \\(p\\) og antalsparameter \\(n\\). I eksemplet kan vi derfor lade \\(Z\\) være en stokastisk variabel, der betegner antallet, som stemmer på rød blok. Det vil sige, at\n\\[ Z \\sim bin(n,p) \\]\nog fra binomialfordelingen ved vi, at\n\\[\nP(Z = r) = {n \\choose r}p^r(1-p)^{n-r} = \\frac{n!}{(n-r)!r!}p^r(1-p)^{n-r}\n\\] Når vi skal estimere \\(p\\) (altså sandsynligheden for at stemme på rød blok – det vil sige \\(P(Y=0)\\)) ud fra data benyttes en metode, som kaldes for maksimum likelihood estimation. Den går i al sin enkelhed ud på at bestemme den værdi af \\(p\\), som gør de data, vi har set, mest sandsynlige. Altså vil vi maksimere udtrykket ovenfor med hensyn til \\(p\\). Dette kan vi gøre ved at differentiere udtrykket og sætte det lig med \\(0\\). I stedet for at arbejde direkte med \\(P(Z = r)\\) er det nemmere at arbejde med udtrykket for \\(\\ln\\bigl(P(Z = r)\\bigr)\\), idet der gælder, at \\(f(p)=P(Z = r)\\) og \\(\\ln\\bigl(f(p) \\bigr)\\) har maksimum ved samme \\(p\\) (fordi logaritmefunktionen er voksende).\nVi finder derfor først et udtryk for \\(\\ln\\bigl(P(Z = r)\\bigr)\\):\n\\[ \\ln\\bigl(P(Z = r)\\bigr) = \\ln {n \\choose r} + r \\cdot \\ln(p) + (n-r) \\cdot \\ln(1-p)\\] hvor vi har brugt logaritmeregnereglerne \\[\\ln(a\\cdot b) = \\ln(a) + \\ln(b) \\quad \\textrm{og} \\quad \\ln(a^x)=x \\cdot \\ln(a)\\] Derfor bliver den afledede med hensyn til \\(p\\) \\[\n\\frac{d}{dp} \\left ( \\ln\\bigl(P(Z = r)\\bigr) \\right ) = \\frac{r}{p} - \\frac{n-r}{1-p}\n\\] Sætter vi ovenstående lig \\(0\\) og isolerer for \\(p\\), får vi, at\n\\[\\hat{p} = \\frac{r}{n}\\]\nhvilket svarer til den andel af de \\(n\\) observationer, som har \\(Y=0\\). Vi sætter en “hat” på \\(p\\) for at tydeliggøre, at det er et estimat af \\(p\\) – og altså ikke den ukendte, sande værdi af \\(p\\).\nBemærk, at man også kan vise, at denne værdi af \\(p\\) rent faktisk svarer til et maksimumssted.\n\n\n\n\n\nVægtene \\(w_i\\)\nDe øvrige bidrag til \\(S\\) afhænger af den specifikke værdi af \\(x_i\\). Det er altså her data for observationen, vi ønsker at klassificere, kommer ind i billedet. Her vil vægten \\(w_i(x_i)\\), som bidrager til den samlede score \\(S\\), afhænge af informationen2 \\(x_i\\).\n2 Hvis \\(w_i(x_i)\\) er mere eller mindre konstant for forskellige værdier af \\(X_i\\), betyder det, at den \\(i\\)’te information ikke er særlig informativ (og måske bør udelades fra modellen).Ved hver information \\(X_i\\) estimeres \\(P(X_i = x_i \\mid Y = y)\\) ved at se på andelen af \\(x_i\\) blandt alle træningsdata med \\(Y = y\\). Vægtene \\(w_i\\) estimeres således på tilsvarende måde som for \\(w_0\\).\nNår disse estimater er fundet, kan man bestemme \\[w_i(x_i) = \\ln \\left(\\frac{P(X_i = x_i \\mid Y = 0)}{P(X_i = x_i \\mid Y = 1)}\\right)\n\\]"
  },
  {
    "objectID": "materialer/naivbayes/NaivBayes.html#eksempel-med-rødblå-blok",
    "href": "materialer/naivbayes/NaivBayes.html#eksempel-med-rødblå-blok",
    "title": "Naiv Bayes klassifier",
    "section": "Eksempel med rød/blå blok",
    "text": "Eksempel med rød/blå blok\nLad os se på eksemplet fra tidligere med at stemme på rød eller blå blok, hvor vi tænker på \\(Y=0\\) som en stemme på rød blok og \\(Y=1\\) som en stemme på blå blok.\nVi havde allerede følgende information fra træningsdata:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlle\nMænd\nKvinder\nUnge\nÆldre\nSjælland\nJylland\nAnden bopæl\n\n\n\n\nRød\n\\(51.85 \\%\\)\n\\(48.00 \\%\\)\n\\(55.00 \\%\\)\n\\(65.00 \\%\\)\n\\(47.47 \\%\\)\n\\(54.00 \\%\\)\n\\(49.90 \\%\\)\n\\(52.78 \\%\\)\n\n\nBlå\n\\(48.15 \\%\\)\n\\(52.00 \\%\\)\n\\(45.00 \\%\\)\n\\(35.00 \\%\\)\n\\(52.53 \\%\\)\n\\(46.00 \\%\\)\n\\(50.10 \\%\\)\n\\(47.22 \\%\\)\n\n\nAntal\n\\(10000\\)\n\\(4500\\)\n\\(5500\\)\n\\(2500\\)\n\\(7500\\)\n\\(3000\\)\n\\(4500\\)\n\\(2500\\)\n\n\n\nFra dette bestemmes først vægten \\(w_0\\) ved \\[w_0 = \\ln \\left(\\frac{P(Y = 0)}{P(Y = 1)}\\right)=\\ln\\left(\\frac{51.85\\%}{48.15\\%}\\right)=0.074\\]\nFor at kunne beregne vores vægte \\[w_i(x_i) = \\ln \\left(\\frac{P(X_i = x_i \\mid Y = 0)}{P(X_i = x_i \\mid Y = 1)}\\right)\n\\]\nskal vi for at beregne tælleren i ovenstående brøk have fat på hvor stor en andel af de stemmer, der går til rød blok, som kommer fra henholdsvis mænd, kvinder, unge, ældre og så videre.\nVi tager beregningen for kvinder og starter med at finde \\(P(X_1 = kvinde \\mid Y = 0)\\). Her ved vi at \\(55 \\%\\) af de i alt \\(5500\\) kvinder stemte på rød blok. Samtidig ved vi, at der var \\(51.85 \\%\\) ud af i alt \\(10000\\) adspurgte (det vil sige \\(5185\\) pesroner), som stemte på rød blok. Derfor får vi \\[P(X_1 = kvinde \\mid Y = 0)=\\frac{55\\% \\cdot 5500}{5185}=58.34 \\%\\] Da \\(X_1\\) kun kan antage værdierne kvinde og mand, ved vi også, at\n\\[P(X_1 = mand \\mid Y = 0)=100\\%-58.34 \\%=41.66\\%.\\] På tilsvarende måde kan vi finde \\(P(X_1 = kvinde \\mid Y = 1)\\). Her ved vi, at \\(45 \\%\\) af de \\(5500\\) kvinder stemte på blå blok, og samtidig ved vi, at der var \\(4815\\) stemmer på blå blok i alt (igen \\(48.15 \\%\\) af \\(10000\\)). Derfor får vi \\[P(X_1 = kvinde \\mid Y = 1)=\\frac{45\\%\\cdot 5500}{4815}= 51.40 \\%\\] og \\[P(X_1 = mand \\mid Y = 1)=100\\%-51.40 \\%=48.60\\%\\] Alle tilsvarende sandsynligheder kan beregnes, så man kan se hvor stor en andel af stemmerne på de to blokke, der kommer fra hver gruppe. Resultatet ses i nedenstående tabel:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMænd\nKvinder\nUnge\nÆldre\nSjælland\nJylland\nAnden bopæl\n\n\n\n\nRød\n\\(41.66 \\%\\)\n\\(58.34 \\%\\)\n\\(31.34 \\%\\)\n\\(68.66 \\%\\)\n\\(31.24 \\%\\)\n\\(43.31 \\%\\)\n\\(25.45 \\%\\)\n\n\nBlå\n\\(48.60 \\%\\)\n\\(51.40 \\%\\)\n\\(18.17 \\%\\)\n\\(81.83 \\%\\)\n\\(28.66 \\%\\)\n\\(46.82 \\%\\)\n\\(24.52 \\%\\)\n\n\n\nNu kan vi bestemme vægtene \\(w_i(x_i)\\). Her findes \\(w_1(kvinde)\\) ved\n\\[w_1(kvinde) = \\ln \\left(\\frac{P(X_1 = kvinde \\mid Y = 0)}{P(X_1 = kvinde \\mid Y = 1)}\\right)=\\ln \\left(\\frac{58.34\\%}{51.40\\%}\\right)=0.1267\\] Herunder ses vægtene for alle grupper:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(w_0\\)\n\\(w_1\\)\n\n\\(w_2\\)\n\n\\(w_3\\)\n\n\n\n\n\n\n\nMænd\nKvinder\nUnge\nÆldre\nSjælland\nJylland\nAnden bopæl\n\n\n\\(0.074\\)\n\\(-0.154\\)\n\\(0.127\\)\n\\(0.545\\)\n\\(-0.175\\)\n\\(0.086\\)\n\\(-0.078\\)\n\\(0.037\\)\n\n\n\nTidligere havde vi indset, at når \\(w_i(x_i)&gt;0\\), så understøtter bidraget fra den \\(i\\)’te oplysning \\(x_i\\), at \\(Y=0\\) (altså at stemme på rød blok). I tabellen ovenfor ses det derfor, at oplysningerne kvinde, ung, Sjælland og anden bopæl gør det mere sandsynligt med en stemme på rød blok, mens oplysningerne mand, ældre og Jylland gør det mere sandsynligt med en stemme på blå blok.\nVi kan nu beregne scoren \\(S\\) for en kvinde, som er ældre og fra Sjælland, altså hvor \\(x=(kvinde,ældre,Sjælland)\\). \\[\\begin{equation}\n\\begin{split}\nS &  = w_0 + \\sum_{i = 1}^q w_i(x_i)=w_0+w_1(kvinde)+w_2(ældre)+w_3(Sjælland) \\\\\n& =0.074+0.127+(-0.175)+0.086=0.112\n\\end{split}\n\\end{equation}\\]\nDerved bliver forudsigelsen ud fra Bayes Naive metode, at en ældre kvinde, der bor på Sjælland, med størst sandsynlighed stemmer på rød blok."
  },
  {
    "objectID": "materialer/naivbayes/NaivBayes.html#opgave-ham-or-spam",
    "href": "materialer/naivbayes/NaivBayes.html#opgave-ham-or-spam",
    "title": "Naiv Bayes klassifier",
    "section": "Opgave: Ham or Spam?",
    "text": "Opgave: Ham or Spam?\nI denne opgave skal vi se på, hvordan man kan lave et simpelt spamfilter. Vi har et datasæt med \\(35000\\) mails med oplysninger om emailens oprindelse (Danmark, Europa uden Danmark, USA og anden oprindelse), afsenders mailadresse (firma, Google, Hotmail og anden) samt indhold (dating, spil og andet). Målet er, at man gerne ud fra disse oplysninger gerne automatisk vil kunne afgøre, om det er spam og derved at mailen ikke skal vises i mail-boxen, eller om det er Ham (non-spam). For hver af de \\(35000\\) mails er det også noteret om, der er tale om spam eller ham.\nTræningsdata består af\n\n\n\n\nOprindelse\n\n\n\n\n\n\n\n\nDK\nEuropa\nUSA\nAndet\n\n\nSpam\n\\(20 \\%\\)\n\\(30 \\%\\)\n\\(35 \\%\\)\n\\(55 \\%\\)\n\n\nHam\n\\(80 \\%\\)\n\\(70 \\%\\)\n\\(65 \\%\\)\n\\(45\\%\\)\n\n\nAntal\n\\(10000\\)\n\\(12000\\)\n\\(8000\\)\n\\(5000\\)\n\n\n\nog\n\n\n\n\nMail\n\n\n\nIndhold\n\n\n\n\n\n\n\nFirma\nGoogle\nHotmail\nAndet\nDating\nSpil\nAndet\n\n\nSpam\n\\(10 \\%\\)\n\\(20 \\%\\)\n\\(60 \\%\\)\n\\(80 \\%\\)\n\\(80 \\%\\)\n\\(90 \\%\\)\n\\(12.5 \\%\\)\n\n\nHam\n\\(90 \\%\\)\n\\(80 \\%\\)\n\\(40 \\%\\)\n\\(20 \\%\\)\n\\(20\\%\\)\n\\(10\\%\\)\n\\(87.5\\%\\)\n\n\nAntal\n\\(17000\\)\n\\(6450\\)\n\\(5400\\)\n\\(6150\\)\n\\(4325\\)\n\\(4975\\)\n\\(25700\\)\n\n\n\n\n\n\n\n\n\nOpgave 1\n\n\n\n\n\n\nHvis man blot modtager en mail fra en Hotmail-konto, vil man da tænke, at det er spam eller ham?\nHvis man blot modtager en tilfældig mail, vil man da tænke, at det er spam eller ham?\nForklar hvorfor det kan være svært at afgøre, om det er spam, hvis man modtager en mail fra Danmark, som er sendt fra en firma-mail og hvor indhold er relateret til dating.\n\n\n\n\n\n\n\n\n\n\nOpgave 2\n\n\n\n\n\nIndfør selv stokastiske variable \\(X1\\), \\(X2\\), \\(X3\\) og \\(Y\\) og angiv udfaldsrum for hver af dem.\n\n\n\n\n\n\n\n\n\nOpgave 3\n\n\n\n\n\n\nOpstil posterior forholdet\n\n\\[ \\frac{P(Y = 0 \\mid X_1=x_1, X_2=x_2, X_3=x_3)}{P(Y = 1 \\mid X_1=x_1, X_2=x_2, X_3=x_3)}\\]\nog forklar det smarte, der er sket ved at bruge Bayes formel.\n\nRedegør for betydningen af forholdet og forklar hvorfor man ser på, om det er over eller under \\(1\\).\n\n\n\n\n\n\n\n\n\n\nOpgave 4\n\n\n\n\n\nAngiv den antagelse (modelforudsætning), som anvendes ved Bayes Naive klassifikation, og forklar hvad det gør for beregningen af sandsynlighederne fra opgave 3.\n\n\n\n\n\n\n\n\n\nOpgave 5\n\n\n\n\n\nBestem prior forholdet\n\\[\\frac{P(Y=0)}{P(Y=1)}\\]\nog beregn på den baggrund vægten\n\\[w_0 = \\ln \\left ( \\frac{P(Y=0)}{P(Y=1)} \\right )\\]\n\n\n\n\n\n\n\n\n\nOpgave 6\n\n\n\n\n\nBestem alle betingede sandsynligheder\n\\[P(X_i=x_i \\mid Y=0) \\quad \\textrm{og} \\quad P(X_i=x_i \\mid Y=1)\\]\nfor hver enkelt information, givet at det er henholdsvis spam og ham (i alt 22 sandsynligheder) og forklar idéen bag én af disse udregninger.\n\n\n\n\n\n\n\n\n\nOpgave 7\n\n\n\n\n\nFor hver af de 11 informationer bestemmes forholdet mellem sandsynlighederne\n\\[ \\frac{P(X_i=x_i \\mid Y=0)}{P(X_i=x_i \\mid Y=1)}\\]\n\n\n\n\n\n\n\n\n\nOpgave 8\n\n\n\n\n\nForklar hvordan man kommer fra resultaterne i opgave 7 til vægte og udregn vægtene hørende til hver af informationerne (i alt 11).\n\n\n\n\n\n\n\n\n\nOpgave 9\n\n\n\n\n\nForklar hvad der sker ved at benytte logaritmen på udtrykket fra opgave 3 og 4, hvor man ellers ganger faktorer sammen.\n\n\n\n\n\n\n\n\n\nOpgave 10\n\n\n\n\n\nAfgør ud fra de vægte, som du har beregnet i opgave 8, hvilke informationer der taler for spam, og hvilke der taler for ham.\n\n\n\n\n\n\n\n\n\nOpgave 11\n\n\n\n\n\nAfgør ved at beregne scoren \\(S\\), om man vil tænke at en mail er ham eller spam i følgende to situationer:\n\nMailens oprindelse er andet, den er sendt fra en hotmail-konto og omhandler ikke dating eller spil.\nMailen er en firma-mail fra Danmark med indhold relateret til dating."
  },
  {
    "objectID": "materialer/afstande/AfstandeMellemDNA.html",
    "href": "materialer/afstande/AfstandeMellemDNA.html",
    "title": "Afstand mellem DNA- og RNA-strenge",
    "section": "",
    "text": "RNA er strenge med bogstaverne U (uracil), G (guanin), C (cytosin), A, (adenin). DNA har ikke U, men i stedet T (thymin) og DNA er dobbelt. Bogstaverne U, G, C, A og T kaldes for nukleotider.\nVi ser her på afstande mellem DNA (eller RNA), som bygger på antallet af mutationer for at nå fra den ene til den anden og desuden, hvor hyppige disse mutationer er - hvis man ved, en mutation sker ofte, er afstanden mellem en streng uden mutationen og en med mutationen ikke så lang, som hvis mutationen er meget sjælden. Udover regler for, hvilke ændringer, man tillader, giver man derfor en omkostning ved ændringen – afstanden er ikke bare antal ændringer, men summen af, hvor \"dyre\" disse ændringer er.\nAfstand mellem DNA bruges til at analysere slægtskab og hvilke dyr, herunder mennesket, der nedstammer fra hvilke andre dyr – det kaldes for fylogenetiske træer – se mere her.\nI den sammenhæng kalder man skift mellem A og G eller mellem C og T for transitioner1. De fire andre mulige skift mellem A og C, mellem A og T, mellem G og T, mellem G og C, kaldes for transversioner. Transitioner er hyppigere mutationer end transversioner, så afstanden mellem \\(GATTACA\\) og \\(GATTACG\\) er mindre end afstanden mellem \\(GATTACA\\) og \\(GATTACC\\). Den slags udskiftning af et bogstav (et basepar) kaldes en punktmutation.\n1 A og G er puriner, mens C og T er pyrimediner. Transition bytter en purin med en purin eller en pyrimedin med en pyrimedin.Indel mutationer er indsætning (\"In\") eller fjernelse (\"Del\" for delete\") af et eller flere basepar. Det er mindre hyppigt og svarer til længere afstand. I kilden ovenfor bruges følgende omkostninger og altså afstande mellem DNA-strenge. Bemærk, at det er et valg - der er mange andre muligheder:\n\nTransition: 1\nTransversion: 2\nGap åbning: 9 (indsæt eller fjern præcis en base - altså et bogstav)\nGap forlængelse: 4 (indsæt eller fjern en base på samme sted, som er åbnet)\n\nMan kan samle de to sidste og sige, at det koster \\(5+4L\\) at indsætte eller fjerne en delstreng med \\(L\\) bogstaver midt i et ord (overvej, at I forstår, at det er samme regel).\nVi tilføjer forlængelse/forkortelse: Det koster \\(4L\\) at indsætte eller fjerne \\(L\\) bogstaver i start eller slut af et ord. Alt i alt:\n\nTransition: 1\nTransversion: 2\nIndsæt eller fjern delord med \\(L\\) bogstaver midt i et ord: \\(5+4L\\)\nForlæng/forkort: Indsæt eller fjern \\(L\\) bogstaver i start eller slut af et ord: \\(4L\\)\n\nAfstand mellem to strenge er så den kortest mulige måde, man kan komme fra den ene til den anden med de tilladte moves vægtet som her.\n\n\n\n\n\n\n\nI det følgende bruger vi meget korte strenge. Det er naturligvis ikke realistisk. Vi vil finde afstanden fra \\(AGT\\) til \\(ATG\\). Der er mange muligheder for, hvordan man kan komme fra \\(AGT\\) til \\(ATG\\), altså hvordan mutationerne kunne have set ud. For eksempel kunne det være:\n\\[AGT \\to ATGT \\to ATG\\] Det vil sige, indsæt \\(T\\) mellem \\(A\\) og \\(G\\) og fjern så det sidste \\(T\\). Det koster \\(9+4 =13\\). Altså er længden af denne vej \\(13\\). En anden mulighed er\n\\[AGT\\to ATT \\to ATG\\]\nHer er der to punktmutationer og begge er transversioner (fra \\(T\\) til \\(G\\) eller omvendt), så det koster \\(2+2=4\\). Det er den korteste vej, så afstanden er \\(4\\). At denne vej faktisk er den kortest, kræver mere eftertanke.\nHavde vi brugt samme omkostning/vægt for alle tilladte ændringer, ville begge de to veje have samme længde.\nHvad med fra \\(AGT\\) til \\(TGA\\)? Jo, det er faktisk nemmere. Det er i virkeligheden samme DNA-sekvens – man har bare læst den fra den anden ende...\nMed lange strenge, som er ens på lange stykker, finder man afstande ved først at \"aligne\". Det vil sige, at man anbringer strengene, så de passer sammen på flest mulige pladser. Og derefter udregner man afstande, men det er stadig ikke nemt – der skal algoritmer til. Her er et eksempel.\nStreng 1: \\(TCGTAGG\\)\nStreng 2: \\(TCTGTATCGA\\)\nFørste alignment: \\[\\begin{matrix}T&C&G&-&-&-&T&A&G&G\\\\T&C&T&G&T&A&T&C&G&A\\end{matrix}\\] Det koster:\n\nIndsættelse af \\(GTA\\): \\(5+4\\cdot 3=17\\)\nTo transversioner \\(G\\leftrightarrow T\\) og \\(A\\leftrightarrow C\\) samt en transition \\(G\\leftrightarrow A\\).\nI alt \\(17+4+1=22\\).\n\nHvis man i stedet vælger denne alignment \\[\\begin{matrix}T&C&-&-&-&G&T&A&G&G\\\\T&C&T&G&T&A&T&C&G&A\\end{matrix}\\] er transversionen mellem \\(G\\) og \\(T\\) erstattet med en transition \\(G\\leftrightarrow A\\) og omkostningen falder med \\(1\\) til \\(21.\\)\nMan indser ret let, at prisen for at klippe gør, at man ikke vil klippe to gange og bruge \\[\\begin{matrix}T&C&-&G&-&-&T&A&G&G\\\\T&C&T&G&T&A&T&C&G&A\\end{matrix}\\] hvor man kun sparer en enkelt transition.\nMen hvad med: \\[\\begin{matrix}T&C&-&G&T&A&-&-&G&G\\\\T&C&T&G&T&A&T&C&G&A\\end{matrix}\\] Her er omkostningen \\(9\\) for det første gap og \\(13\\) for det andet. Og der er en transition i sidste plads \\(G\\leftrightarrow A,\\) så omkostningen er \\(23\\), men det er ikke helt så klart, at det er for dyrt at klippe to gange. I kan nok finde på eksempler, hvor det kan svare sig at klippe flere steder."
  },
  {
    "objectID": "materialer/afstande/index_afstande.html",
    "href": "materialer/afstande/index_afstande.html",
    "title": "Afstande og feature-skalering",
    "section": "",
    "text": "Det er ikke altid helt klart, hvordan man skal bestemme afstanden mellem to datapunkter, hvis koordinaterne i hvert datapunkter beskriver vidt forskellige ting. Det er faktisk ikke en gang entydigt, hvad man overhovedet skal forstå ved en afstand – eller det som man i matematik vil kalde for en metrik. Her på siden behandler vi nogle af disse problemstillinger. Vi vil se nærmere på, hvilke problemer, der kan opstå, hvis man ikke tænker sig om – og hvad man kan gøre for at løse dem.\nLæs mere i noterne herunder.\n\n\n\n\n\n\n\n\n\n\nFeature-skalering\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfstande mellem punkter i planen\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfstande mellem ord\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfstand mellem DNA- og RNA-strenge\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDefinition af en metrik – det abstrakte afstandsbegreb\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "materialer/afstande/MetrikDetAbstrakteAfstandsBegreb.html",
    "href": "materialer/afstande/MetrikDetAbstrakteAfstandsBegreb.html",
    "title": "Definition af en metrik – det abstrakte afstandsbegreb",
    "section": "",
    "text": "Man har ikke frit valg til at bestemme, hvad man vil bruge som afstandsmål. Hvis det skal give mening, skal man have en metrik – det betyder, at afstanden skal opfylde nogle betingelser:\nEn metrik på en mængde \\(M\\) er en funktion \\(d\\) fra \\(M\\times M\\) til \\(\\mathbb{R}\\) – altså en funktion, som tager to elementer i \\(M\\) og giver et reelt tal.\nHvis en funktion \\(d\\) skal være en metrik, så vil vi kræve, at den opfylder følgende fire betingelser:\nFor alle \\(p,q,r\\) i \\(M\\) skal der gælde, at\n\n\\(d(p,q)\\geq 0\\). Med ord: Alle afstande er positive eller \\(0\\).\n\\(d(p,p)=0\\) og \\(d(p,q)=0\\) hvis og kun hvis \\(p=q\\). Med ord: Afstanden fra et punkt til sig selv er \\(0\\), og ingen andre afstande er \\(0\\).\n\\(d(p,q)=d(q,p)\\). Det vil sige, at afstanden er symmetrisk. Med ord: Der er lige så langt fra \\(p\\) til \\(q\\) som fra \\(q\\) til \\(p\\).\n\\(d(p,q)+d(q,r)\\geq d(p,r)\\). Det kaldes for trekantsuligheden. Med ord: Der er mindst lige så langt fra \\(p\\) til \\(r\\) via \\(q\\), som direkte fra \\(p\\) til \\(r\\).\n\nLad os tage et velkendt eksempel.\n\nEksempel 1 (Euklidisk afstand som metrik) Lad \\(M\\) være alle punkter i planen og lad metrikken være den euklidiske afstand, som vi kender. Funktionen \\(d\\) vil så tage to punkter \\(P(x_1,y_1)\\) og \\(Q(x_2,y_2)\\) i planen og give et reelt tal som output svarende til den euklidiske afstand mellem \\(P\\) og \\(Q\\). Det vil sige, at \\[ d(P,Q) = \\sqrt{(x_2-x_1)^2+(y_2-y_1)^2}\\] Vi vil senere vise, at denne funktion opfylder betingelserne for en metrik, som defineret ovenfor.\n\nDet er en meget kort definition. Og meget, meget generel. \\(M\\) er en mængde - der er en strengt logisk måde at gå til mængder på, men lad os her sige en samling af objekter, som vi også kalder elementer af mængden. Læg mærke til, at vi her bare graver problemet lidt længere ned i sandet – fejer det ind under gulvtæppet – for hvad er \"objekter\"? Det kommer vi ikke nærmere her.\nDet er ret nemt at acceptere, at de tre krav er rimelige. Men er det nok? Og er det nu alligevel rimeligt? Hvad med symmetrien? Der er vel længere \\(10\\) km op ad bakke end \\(10\\) km ned ad bakke, hvis man tænker på arbejdsindsats. Så måske giver det ikke altid mening?1\n1 Hvis funktionen \\(d\\) opfylder 1,2,4, er det en quasimetrik. Opfylder den 1,2,3, er det en semimetrik. Opfylder den 1, 3 og 4, og første del af 2 (\\(d(p,p)=0\\), men der kan være andre afstande, der er \\(0\\)) er det en pseudometrik. Der findes såmænd også præmetrikker, metametrikker, pseudoquasimetrikker og sikkert andre – \"falske metrikker\".2 Ordet \"rum\" skal man ikke lægge for meget i. Der er ikke anden information i det end definitionen. Intuition skal man være varsom med.Definitionen af metrik som her, er den, vi bruger i matematik. Den har vist sig nyttig. Der er en skov af artikler og bøger, hvor man kan se, hvad man ved, når man har en metrik. En mængde med en metrik kaldes et metrisk rum.2\n\nEksempel 2 (Den diskrete metrik) På en mængde \\(M\\) er funktionen \\(d\\) givet ved.\n\n\\(d(p,p)=0\\)\nHvis \\(p\\neq q\\) er \\(d(p,q)=1\\).\n\nDet er en metrik – den opfylder definitionen ovenfor. Men det er ikke nogen specielt nyttig metrik. Alle elementer ligger lige tæt på alle andre, så der er ikke ny information – udover, om to elementer er ens eller ej.\n\n\nEksempel 3 (Euklidisk afstand som metrik, fortsat) Vi vil vise, at den euklidiske afstand mellem to punkter rent faktisk opfylder betingelserne for en metrik, som vi definerede dem ovenfor:\n\nDen første betingelse er opfyldt, da \\[d(P,Q)=\\sqrt{(x_2-x_1)^2+(y_2-y_1)^2} \\geq 0\\]\nI den anden betingelse er der to ting at vise. For det første ses det nemt, at \\[d(P,P)=\\sqrt{(x_1-x_1)^2+(y_1-y_1)^2} = \\sqrt{0}=0\\] For det andet – hvis \\[d(P,Q)=\\sqrt{(x_2-x_1)^2+(y_2-y_1)^2}=0\\] så kan det kun lade sig gøre, hvis både \\[(x_2-x_1)^2=0 \\quad \\textrm{og} \\quad (y_2-y_1)^2=0\\] Det kan igen kun lade sig gøre3, hvis \\[x_1=x_2 \\quad \\textrm{og} \\quad y_1=y_2\\] Det vil sige, at \\(P=Q\\), og den anden betingelse er således også opfyldt.\nDa \\((a-b)^2=(b-a)^2\\) får vi, at \\[d(P,Q)=\\sqrt{(x_2-x_1)^2+(y_2-y_1)^2}=\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}=d(Q,P)\\] og den tredje betingelse er opfyldt.\nDet kræver lidt mere at bevise trekantsuligheden, men intuitivt virker det fornuftigt nok. Hvis du i trekant \\(PQR\\), skal fra \\(P\\) til \\(R\\), så bliver turen dertil ikke kortere, hvis du først går om \\(Q\\).\n\n3 Brug nulreglen.\n\n\n\n\n\n\nOpgave: Levenshteinafstanden\n\n\n\n\n\nVis, at Levenshteinafstanden giver en metrik.\n\nHvilken mængde er det mon en metrik på? Her kan man vælge – hvilke bogstaver må bruges? Vil I begrænse længden på de ord, der kan optræde?\nOvervej, at afstanden mellem to ord er længden af den (eller rettere en - der kan være flere veje, som er lige lange) korteste mulige vej fra det ene til det andet i et netværk (en graf). \n\nNu skulle det være til at indse, at de fire betingelser er opfyldt.\n\n\n\n\nEksempel 4 (Ikke-metrik) En elev er træt af kvadratrødder og tænker, at man vel kan droppe den euklidiske afstand og i stedet definere en afstand mellem to punkter \\(p(x_1,y_1)\\) og \\(q(x_2,y_2)\\) i planen som følger:\n\\[D(p,q)=(x_2-x_1)^2+(y_2-y_1)^2 \\tag{1}\\]\nDer er bare et lille problem: \\(D\\) er ikke en metrik! Den opfylder nemlig ikke trekantsuligheden. Men hvordan kan man se det? Husk på, at vi bare skal finde ét eksempel – det vil sige tre punkter \\(p,q,r\\), hvor trekantsuligheden ikke holder. Så har vi vist, at \\(D\\) ikke er en metrik.\nEt konkret eksempel: \\(p=(0,0)\\), \\(q=(2,0)\\), \\(r=(4,0)\\). Se figur 1.\n\n\n\n\n\n\nFigur 1: Koordinatsystem med punkterne \\(p=(0,0)\\), \\(q=(2,0)\\) og \\(r=(4,0)\\).\n\n\n\nAfstanden fra \\(p\\) til \\(r\\) er \\(D(p,r)=4^2+0^2=16\\), mens afstanden fra \\(p\\) til \\(q\\) er \\(D(p,q)=2^2+0^2=4\\) og det samme gælder afstanden fra \\(q\\) til \\(r\\): \\(D(q,r)=2^2+0^2=4\\) så \\[D(p,q)+D(q,r)=8\\] mens \\[D(p,r)=16\\] Altså er \\[ D(p,q)+D(q,r) \\ngeq D(p,r) \\]\nEt andet eksempel, som ligner en rigtig trekant: \\(p=(0,0)\\) \\(q=(2,1)\\), \\(r=(4,0)\\). Se figur 2.\n\n\n\n\n\n\nFigur 2: Koordinatsystem med punkterne \\(p=(0,0)\\), \\(q=(2,1)\\) og \\(r=(4,0)\\).\n\n\n\nHer er \\(D(p,q)=2^2+1^2=5\\) og \\(D(q,r)=(4-2)^2+1^2=5\\) så \\[D(p,q)+D(q,r)=10\\] mens \\[D(p,r)=4^2+0^2=16\\] Igen er det med dette afstandsmål kortere at gå fra \\(p\\) til \\(r\\) via \\(q\\) end at gå direkte. Og det er altså derfor ikke en metrik.\n\n\n\n\n\n\n\nOpgave: Ikke-metrik\n\n\n\n\n\nBrug funktionen\n\\[D(p,q)=(x_2-x_1)^2+(y_2-y_1)^2\\]\nfra eksempel 4. Vi vil undersøge, hvornår \\(D(p,q)+D(q,r) \\geq D(p,r)\\), således at trekantsuligheden er opfyldt.\nHer regner vi på trekanter \\(pqr\\) med: \\(p=(0,0)\\), \\(q=(2,y)\\) og \\(r=(4,0)\\), hvor midterpunktet \\(q\\) flyttes længere væk fra førsteaksen. Brug app’en nedenfor og find det \\(y\\), hvor \\(D(p,q)+D(q,r)=D(p,r)\\).\n\nHvad er \\(\\angle pqr\\), når denne ligning er opfyldt?\nKunne man have indset det uden at regne?\nHvad skal \\(\\angle pqr\\) være for at trekantsuligheden er opfyldt: \\(D(p,q)+D(q,r) \\geq D(p,r)\\)?"
  },
  {
    "objectID": "materialer/afstande/AfstandeMellemPunkteriPlanen.html",
    "href": "materialer/afstande/AfstandeMellemPunkteriPlanen.html",
    "title": "Afstande mellem punkter i planen",
    "section": "",
    "text": "Du har ikke nødvendigvis tænkt over det før, men hvordan måler man egentlig afstanden mellem to punkter i planen? “Ja, man finder afstanden mellem dem”, vil du måske sige, men det er jo ikke rigtigt et brugbart svar på spørgsmålet. Den afstand, du tænker på, er formentlig længden af det linjestykke, som forbinder de to punkter, men der findes faktisk mange andre måder at definere afstanden på. Det vil vi give et par eksempler på her.\nFor at blive lidt mere præcis forestiller vi os, at vi har to punkter i planen, som vi kalder for \\(P(x_1,y_1)\\) og \\(Q(x_2,y_2)\\)."
  },
  {
    "objectID": "materialer/afstande/AfstandeMellemPunkteriPlanen.html#sec-euklidisk_afstand",
    "href": "materialer/afstande/AfstandeMellemPunkteriPlanen.html#sec-euklidisk_afstand",
    "title": "Afstande mellem punkter i planen",
    "section": "Euklidisk afstand",
    "text": "Euklidisk afstand\nDen euklidisk afstand mellem \\(P\\) og \\(Q\\) er \\[\\sqrt{(x_2-x_1)^2+(y_2-y_1)^2}\\] Det er det, vi kender mest – og som formentlig er den afstand, du lige har tænkt på. Formlen ovenfor fremkommer ved at bruge Pythagoras.\nI app’en herunder er den euklidiske afstand illustreret. Du kan flytte rundt på punkterne og se, hvordan afstanden ændrer sig."
  },
  {
    "objectID": "materialer/afstande/AfstandeMellemPunkteriPlanen.html#sec-manhattan_afstand",
    "href": "materialer/afstande/AfstandeMellemPunkteriPlanen.html#sec-manhattan_afstand",
    "title": "Afstande mellem punkter i planen",
    "section": "Manhattanafstanden",
    "text": "Manhattanafstanden\nManhattanafstanden er den afstand, man får, når man er tvunget til at bevæge sig langs akserne, som vi kender det fra vejene i mange amerikanske byer, herunder på Manhattan. Den kaldes også taxi-afstanden. Formlen for at bestemme Manhattanafstanden er: \\[|x_2-x_1|+|y_2-y_1|\\] I app’en herunder er Manhattanafstanden illustreret. Du kan flytte rundt på punkterne og se, hvordan afstanden ændrer sig."
  },
  {
    "objectID": "materialer/afstande/AfstandeMellemPunkteriPlanen.html#max-afstanden",
    "href": "materialer/afstande/AfstandeMellemPunkteriPlanen.html#max-afstanden",
    "title": "Afstande mellem punkter i planen",
    "section": "Max-afstanden",
    "text": "Max-afstanden\nMax-afstanden er maksimum mellem den vandret og lodrette afstand mellem \\(P\\) og \\(Q\\). Det vil sige, maksimum af \\(|x_2-x_1|\\) og \\(|y_2-y_1|\\).\nDen kaldes også skak-konge afstanden. Kongen i skak kan gå diagonalt eller langs de to akser. Et diagonalt move fra \\((a,b)\\) til \\((a+k,b+k)\\) tænkes at have længde \\(k\\) – som i skak. Skal man fra eksempelvis \\(A(1,4)\\) til \\(B(3,7)\\) kan skakkongen gå fra \\(A(1,4)\\) til \\(C(3,6)\\) – det stykke har længde \\(2\\) og derefter fra \\(C(3,6)\\) til \\(B(3,7)\\) langs \\(y\\)-aksen - et stykke på længde \\(1\\). Samlet afstand er \\(3\\), maksimum af \\(|3-1|\\) og \\(|7-4|\\). Idéen er illustreret i figur 1.\n\n\n\n\n\n\nFigur 1: Kongen i skak skal fra \\(A\\) til \\(B\\) via \\(C.\\) Bemærk, at der også er andre veje fra \\(A\\) til \\(B\\) med afstand \\(3\\). For eksempel kan kongen gå fra \\(A(1,4)\\) til \\((1,5)\\) (det giver en afstand på \\(1\\)) og dernæst lave et diagonalt move fra \\((1,5)\\) til \\(B(3,7)\\) med en afstand på \\(2\\). Den samlede afstand bliver igen \\(1+2=3\\). Der er altså flere korteste veje fra \\(A\\) til \\(B\\).\n\n\n\nI app’en herunder er max-afstanden illustreret. Du kan flytte rundt på punkterne og se, hvordan afstanden ændrer sig."
  },
  {
    "objectID": "materialer/afstande/AfstandeMellemPunkteriPlanen.html#posthusafstanden",
    "href": "materialer/afstande/AfstandeMellemPunkteriPlanen.html#posthusafstanden",
    "title": "Afstande mellem punkter i planen",
    "section": "Posthusafstanden",
    "text": "Posthusafstanden\nPosthusafstanden1 mellem \\(P\\) og \\(Q\\) finder man, ved at tænke på, at der ligger et posthus i origo \\(O(0,0)\\), og vi skal sende et brev fra \\(P\\) til \\(Q\\). Det bliver transporteret fra \\(P\\) til posthuset først og derefter fra posthuset til \\(Q\\). Hvis man anvender Pythagoras to gange, kan man se, at formlen for denne afstand er: \\[\\sqrt{x_1^2+y_1^2}+\\sqrt{x_2^2+y_2^2}\\] I app’en herunder er posthusafstanden illustreret. Du kan flytte rundt på punkterne og se, hvordan afstanden ændrer sig.\n1 Den hedder også British Rail afstanden eller, hvis man er fransk, SNCF (Société Nationale des Chemins de fer Français) -afstanden. Man tænker sig, at man altid skal rejse via London (eller Paris) for at komme med tog fra et sted til et andet."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AI MAT - matematikken bag magien",
    "section": "",
    "text": "Hvad er AI-matematik? Det er al den spændende matematik, som ligger bag kunstig intelligens!\nPå denne side kan du lære, hvordan gymnasiematematikken bruges i en masse former for kunstig intelligens. Til gengæld kan du ikke lære, hvordan du får en kunstig intelligens til at løse dine matematikopgaver!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nForskellige undervisningsforløb til matematik i gymnasiet, som inddrager AI. Der findes forløb til både A-, B- og C-niveau.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoter om diverse AI relaterede emner.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIdéer til hvordan AI kan inddrages i SRO.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIdéer til hvordan AI kan inddrages i SRP.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiverse apps til træning af kunstig intelligens.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiverse referencer til andre AI materialer.\n\n\n\n\n\n\n\n\n\nNo matching items\n\n\nProjektet “AI - Aalborg Intelligence” er finansieret af Novo Nordisk Fonden og løber frem til 2026."
  },
  {
    "objectID": "undervisningsforloeb/screeningsprogrammer.html",
    "href": "undervisningsforloeb/screeningsprogrammer.html",
    "title": "Screeningsprogrammer",
    "section": "",
    "text": "Forudsætninger og tidsforbrug\n\n\n\n\n\nForløbet kræver kendskab til:\n\nDeskriptiv statistik.\nNormalfordelingen.\n\nTidsforbrug i matematik: Ca. 3 x 90 minutter.\nTidsforbrug i bioteknologi: Ca. 4 x 90 minutter."
  },
  {
    "objectID": "undervisningsforloeb/screeningsprogrammer.html#introduktion",
    "href": "undervisningsforloeb/screeningsprogrammer.html#introduktion",
    "title": "Screeningsprogrammer",
    "section": "Introduktion",
    "text": "Introduktion\nScreeningsprogrammer anvendes, når sundhedsmyndighederne til en udvalgt befolkningsgruppe tilbyder en eller anden form for test for en specifik sygdom. Testen skal helst være forholdsvis billig og nem at udføre, så man kan teste mange mennesker. Screeningsprogrammer anvendes ofte i forbindelse med kræft. For eksempel tilbydes alle danske kvinder i bestemte aldersgrupper screening for livmoderhalskræft og for brystkræft. Tilsvarende bliver alle danskere i alderen fra 50 til 74 år screenet for tarmkræft.\n\n\n\n\n\n\n\n\n\n\nScreeningsprogrammer - matematik\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScreeningsprogrammer - bioteknologi\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "undervisningsforloeb/aktiveringsfunktioner/softsign.html",
    "href": "undervisningsforloeb/aktiveringsfunktioner/softsign.html",
    "title": "AI MAT - matematikken bag magien",
    "section": "",
    "text": "Softsign-funktionen har forskrift\n\\[\nf(x)=\\frac{x}{1+|x|}.\n\\] Husk på at \\(|x|\\) betyder den numeriske værdi af \\(x\\). Det vil sige\n\\[\n|x| =\n\\begin{cases}\nx & \\textrm{hvis } x \\geq 0 \\\\\n-x & \\textrm{hvis } x &lt; 0 \\\\\n\\end{cases}\n\\tag{1}\\] Det betyder for eksempel at \\(|7|=7\\) og \\(|-7|=7\\). Grafen for \\(|x|\\) ses i figur 1.\n\n\n\n\n\n\nFigur 1: Grafen for \\(|x|\\).\n\n\n\nGrafen for softsign-funktionen \\(f\\) ses i figur 2.\n\n\n\n\n\n\nFigur 2: Grafen for softsign-funktionen.\n\n\n\nDa den numeriske værdi af \\(x\\) indgår i forskriften, kunne man få den tanke, at \\(f\\) måske hverken er kontinuert eller differentiabel i \\(0\\). For eksempel kan man i figur 1 se, at \\(|x|\\) ikke er differentiabel i \\(0\\).\nMen bruger vi definitionen på \\(|x|\\), får vi\n\\[\nf(x) =\n\\begin{cases}\n\\frac{x}{1+x} & \\textrm{hvis } x \\geq 0 \\\\\n\\\\\n\\frac{x}{1-x} & \\textrm{hvis } x &lt; 0 \\\\\n\\end{cases}\n\\tag{2}\\]\nUd fra denne omskrivning kan man vise, at \\(f\\) rent faktisk er kontinuert i \\(0\\). Det kan du læse mere om i boksen herunder, hvis du har lyst.\nPå figur 2 ser det ud som om, at værdimængden for \\(f\\) er \\((-1,1)\\) (også det argumenterer vi for i boksen):\n\\[\nVm(f) = (-1,1).\n\\]\nDet vil sige, at hvis vi skal bruge softsign-funktionen som aktiveringsfunktion, så skal targetværdierne være \\(\\pm 1\\).\n\n\n\n\n\n\nArgument for kontinuitet i \\(0\\) og værdimængde for \\(f\\)\n\n\n\n\n\nLad os først argumentere for, at \\(f\\) er kontinuert i \\(0\\). For det første ser vi, at \\(f(0)=0/(1+0)=0\\) og \\(f(x) \\rightarrow 0\\), når \\(x\\) nærmer sig \\(0\\) både fra højre og venstre. Det betyder, at \\(f\\) er kontinuert i \\(0\\).\nVi vil herefter indse, at funktionsværdierne for \\(f\\) ligger i \\((-1,1)\\). Ser vi på definitionen i (2), kan vi se, at vi skal inddele i to tilfælde, nemlig \\(x \\geq 0\\) og \\(x&lt;0\\):\n\nTilfælde 1\nHvis \\(x \\geq 0\\), så er \\[\nf(x)= \\frac{x}{1+x}.\n\\] Her er både tæller og nævner positiv, og derfor vil \\(-1&lt;0&lt;f(x)\\). Da \\[\nx &lt; 1+x\n\\] og \\(1+x\\) er positiv vil \\[\nf(x)=\\frac{x}{1+x}&lt;\\frac{1+x}{1+x}=1.\n\\] Altså er \\(-1&lt;f(x)&lt;1\\) i det tilfælde, hvor \\(x \\geq 0\\).\nTilfælde 2\nHvis \\(x&lt;0\\), så er \\[\nf(x) = \\frac{x}{1-x}.\n\\] Her er tælleren negativ, mens nævneren er positiv. Det vil sige, at \\(f(x)&lt;0&lt;1\\). Nu er \\[\nx-1&lt;x&lt;0.\n\\] Da \\(x-1&lt;0\\), vil \\(-(x-1)&gt;0\\), og vi kan derfor dividere ovenstående igennem med \\(-(x-1)\\) uden at ændre på ulighedstegnet: \\[\n\\frac{x-1}{-(x-1)}&lt;\\frac{x}{-(x-1)}.\n\\] Da venstre side giver \\(-1\\) og \\(-(x-1)=1-x\\) får vi \\[\n-1 &lt; \\frac{x}{1-x}=f(x).\n\\] Alt i alt har vi altså også i dette tilfælde vist, at \\[\n-1 &lt; f(x) &lt; 1.\n\\]\n\nDet vil sige, at \\(Vm(f) \\subseteq (-1,1)\\).\nVi vil nu vise, at værdimængden for \\(f\\) \"fylder\" hele intervallet \\((-1,1)\\) ud. Vi ser, at for store positive værdier af \\(x\\) vil \\[\nf(x)= \\frac{x}{1+x} \\approx \\frac{x}{x}=1\n\\] og for store negative værdier af \\(x\\) vil \\[\nf(x)= \\frac{x}{1-x} \\approx \\frac{x}{-x}=-1\n\\] Det betyder, at \\[\nf(x) \\rightarrow 1 \\quad \\textrm{når} \\quad x \\rightarrow \\infty\n\\] og\n\\[\nf(x) \\rightarrow -1 \\quad \\textrm{når} \\quad x \\rightarrow - \\infty\n\\] hvilket stemmer fint overens med figur 2.\nVi har hermed vist, at \\(Vm(f) = (-1,1).\\)\n\n\n\nI nedenstående opgaver skal vi vise, at\n\\[\nf'(x)=\\frac{1}{\\left ( 1+ |x| \\right )^2}\n\\tag{3}\\]\nog at den afledte kan findes ved hjælp af funktionsværdien selv på denne måde\n\\[\nf'(x)=(1-|f(x)|)^2.\n\\tag{4}\\]\n\n\n\n\n\n\nOpgave 3: Differentiation af softsign-funktionen\n\n\n\n\n\nVis, at \\[\nf'(x)=\\frac{1}{\\left ( 1+ |x| \\right )^2}\n\\] ved at bruge en brøkregneregel til at omskrive funktionsudtrykket i (2):\n\\[\nf(x) =\n\\begin{cases}\nx \\cdot \\frac{1}{1+x} & \\textrm{hvis } x \\geq 0 \\\\\n\\\\\nx \\cdot \\frac{1}{1-x} & \\textrm{hvis } x &lt; 0 \\\\\n\\end{cases}\n\\tag{5}\\]\nTegn til sidst grafen for \\(f'\\). Synes du, at det ser ud som om, at \\(f'\\) er differentiabel?\n\n\n\n\n\n\n\n\n\nHints til opgave 3\n\n\n\n\n\n\nAntag først, at \\(x &gt; 0\\) og vis ved hjælp af produktreglen for differentiation, at \\[\nf'(x)=\\frac{1}{(1+x)^2} = \\frac{1}{(1+|x|)^2}.\n\\tag{6}\\] OBS! Du får på et tidspunkt brug for at sætte på fælles brøkstreg – fællesnævneren er her \\((1+x)^2\\).\nAntag nu, at \\(x&lt;0\\) og vis igen ved hjælp af produktreglen for differentiation at \\[\nf'(x)=\\frac{1}{(1-x)^2} = \\frac{1}{(1+|x|)^2}.\n\\tag{7}\\]\nAntag slutteligt, at \\(x=0\\) og indsæt \\(x=0\\) i både (6) og (7) og se, at du får det samme. Da \\(f'(0)\\) giver det samme for de to grene af funktionen, siger man, at funktionen også er differentiabel i \\(x=0\\).\n\n\n\n\n\n\n\n\n\n\nOpgave 4: Omskrivning af \\(f'(x)\\) for softsign-funktionen\n\n\n\n\n\nVis nu, at den afledede af softsign-funktionen kan udtrykkes ved hjælp af softsign-funktionen selv: \\[\nf'(x)=(1-|f(x)|)^2.\n\\]\n\n\n\n\n\n\n\n\n\nHints til opgave 4\n\n\n\n\n\n\nStart med at overvise dig selv om, at \\[\n|f(x)|=f(|x|)\n\\] ved at bruge definitionen i (1).\nVis at \\[\n(1-f(|x|))^2 = \\frac{1}{(1+|x|)^2}=f'(x)\n\\] Hint! Skriv \\(1\\) som \\(\\frac{1+|x|}{1+|x|}\\)."
  },
  {
    "objectID": "undervisningsforloeb/aktiveringsfunktioner/hyperbolsk_tangens.html",
    "href": "undervisningsforloeb/aktiveringsfunktioner/hyperbolsk_tangens.html",
    "title": "AI MAT - matematikken bag magien",
    "section": "",
    "text": "Funktionen hyperbolsk tangens, \\(\\tanh\\), har forskrift \\[\n\\tanh(x) = \\frac{e^x-e^{-x}}{e^x+e^{-x}}\n\\]\nGrafen for hyperbolsk tangens er vist i figur 1.\n\n\n\n\n\n\nFigur 1: Grafen for hyperbolsk tangens.\n\n\n\nIfølge figuren ser det ud til, at \\(Vm(f)=(-1,1)\\). Det argumenterer vi nærmere for i boksen herunder.\n\n\n\n\n\n\nArgument for værdimængden for \\(\\tanh\\)\n\n\n\n\n\nVi starter med at vise, at\n\\[\n-1 &lt; \\tanh(x) &lt; 1.\n\\] Da \\[\n- e^x - e^{-x} &lt;e^x - e^{-x} &lt; e^x + e^{-x}\n\\] og \\(e^x + e^{-x}&gt;0\\) vil\n\\[\n-1 = \\frac{- e^x - e^{-x}}{e^x + e^{-x}} &lt; \\frac{e^x - e^{-x}}{e^x + e^{-x}} &lt; \\frac{e^x + e^{-x}}{e^x + e^{-x}} = 1.\n\\] Altså er \\(-1 &lt; \\tanh(x)&lt;1\\). Vi mangler kun at argumentere for, at værdimængden for \\(\\tanh\\) \"fylder\" hele intervallet \\((-1,1)\\) ud.\nPå figuren herunder ses grafen for den voksende eksponentialfunktion \\(e^x\\) (blå) og for den aftagende eksponentialfunktion \\(e^{-x}\\) (grøn).\n\n\n\n\n\nHer ses det, at for store positive værdier af \\(x\\) er \\(e^{-x} \\approx 0\\). Det vil sige, at for store positive værdier af \\(x\\) er\n\\[\n\\tanh(x)=\\frac{e^x-e^{-x}}{e^x+e^{-x}} \\approx \\frac{e^x-0}{e^x+0}=\\frac{e^x}{e^x}=1.\n\\]\nOmvendt gælder for store negative værdier af \\(x\\) er \\(e^x \\approx 0\\). Det vil sige, at for store negative værdier af \\(x\\) er\n\\[\n\\tanh(x)=\\frac{e^x-e^{-x}}{e^x+e^{-x}} \\approx \\frac{0-e^{-x}}{0+e^{-x}}=\\frac{-e^{-x}}{e^{-x}}=-1.\n\\] Det betyder, at \\[\n\\tanh(x) \\rightarrow 1 \\quad \\textrm{når} \\quad x \\rightarrow \\infty\n\\] og\n\\[\n\\tanh(x) \\rightarrow -1 \\quad \\textrm{når} \\quad x \\rightarrow - \\infty\n\\] hvilket stemmer fint overens med figur 1. Man siger for øvrigt, at linjerne med ligning \\(y=-1\\) og \\(y=1\\) er vandrette asymptoter.\nAltså har vi vist, at \\[\nVm(\\tanh)=(-1,1).\n\\]\n\n\n\nI nedenstående opgave skal vi vise, at \\(\\tanh\\) differentieret er\n\\[\n\\tanh'(x)=1-\\left ( \\tanh(x) \\right )^2.\n\\]\nFor at bevise det er det nemmeste at bruge kvotientreglen for differentiation. Måske har du hørt om den – måske har du ikke. Men her kommer den:\n\nKvotientreglen for differentiation \n\\[\n\\left ( \\frac{f}{g}\\right)'(x) = \\frac{f'(x) \\cdot g(x)-f(x) \\cdot g'(x)}{(g(x))^2}, \\quad g(x) \\neq 0\n\\]\n\n\n\n\n\n\n\nOpgave 5: Differentiation af tanh-funktionen og omskrivning\n\n\n\n\n\nVis, at tangens hyperbolsk \\[\n\\tanh(x)=\\frac{e^x-e^{-x}}{e^x+e^{-x}}\n\\] differentieret er \\[\n\\tanh'(x)=1-\\left ( \\tanh(x) \\right )^2.\n\\]\n\n\n\n\n\n\n\n\n\nHints til opgave 5\n\n\n\n\n\n\nBrug kvotientreglen for differentiation til at vise, at \\[\n\\tanh'(x)= 1 - \\left (\\frac{e^x-e^{-x}}{e^x+e^{-x}} \\right)^2\n\\] Hint! På et tidspunkt får du brug for brøkregnereglen \\(\\frac{a+b}{c}=\\frac{a}{c}+\\frac{b}{c}\\).\nBrug definitionen af tangens hyperbolsk til at indse at \\[\n\\tanh'(x)=1-\\left ( \\tanh(x) \\right )^2.\n\\]"
  },
  {
    "objectID": "undervisningsforloeb/screeningsprogrammer/gendata.html",
    "href": "undervisningsforloeb/screeningsprogrammer/gendata.html",
    "title": "AI MAT - matematikken bag magien",
    "section": "",
    "text": "#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 600 \nlibrary(shiny)\nlibrary(bslib)\nlibrary(writexl)\n\nui &lt;- page_fluid(\n  layout_columns(\n  card(card_header(\"Gen 1\"),\n         numericInput(\"m1\", \"Middelværdi:\", 10),\n         numericInput(\"s1\", \"Spredning:\", 5, min = 0),\n    ),\n    card(card_header(\"Gen 2\"),\n         numericInput(\"m2\", \"Middelværdi:\", 10),\n         numericInput(\"s2\", \"Spredning:\", 5, min = 0),\n    ),\n    card(card_header(\"Gen 3\"),\n         numericInput(\"m3\", \"Middelværdi:\", 10),\n         numericInput(\"s3\", \"Spredning:\", 5, min = 0),\n    ),\n    card(card_header(\"Gen 4\"),\n         numericInput(\"m4\", \"Middelværdi:\", 10),\n         numericInput(\"s4\", \"Spredning:\", 5, min = 0),\n    ),\n    card(card_header(\"Gen 5\"),\n         numericInput(\"m5\", \"Middelværdi:\", 10),\n         numericInput(\"s5\", \"Spredning:\", 5, min = 0),\n    ),\n    card(card_header(\"Indstillinger\"),\n         numericInput(\"nsim\", \"Antal observationer:\", 100, min = 1, max = 10000),\n         actionButton(\"run\", \"Kør\")),\n    card(card_header(\"Data\"),\n         tableOutput(\"dataTable\")),\n    card(card_header(\"Download\"),\n         downloadButton(\"excel\", \"Download (Excel)\"),\n         downloadButton(\"csv\", \"Download (csv)\")),\n  col_widths = c(rep(2,6),10,2)\n  )\n)\n\nserver &lt;- function(input, output) {\n  dat &lt;- reactiveVal()\n\n  observeEvent(input$run, {\n    sim &lt;- data.frame(\n        `Gen 1` = rnorm(input$nsim, mean = input$m1, sd = input$s1),\n        `Gen 2` = rnorm(input$nsim, mean = input$m2, sd = input$s2),\n        `Gen 3` = rnorm(input$nsim, mean = input$m3, sd = input$s3),\n        `Gen 4` = rnorm(input$nsim, mean = input$m4, sd = input$s4),\n        `Gen 5` = rnorm(input$nsim, mean = input$m5, sd = input$s5)\n        ) |&gt; round(2)\n\n    dat(sim)\n\n    output$dataTable &lt;- renderTable({\n      sim\n    })\n  })\n\n  output$excel &lt;- downloadHandler(\n    filename = function() {\n      paste(\"gen-data_\", Sys.Date(), \".xlsx\", sep = \"\")\n    },\n    content = function(file) {\n      write_xlsx(dat(), file)\n    }\n  )\n\n  output$csv &lt;- downloadHandler(\n    filename = function() {\n      paste(\"gen-data_\", Sys.Date(), \".csv\", sep = \"\")\n    },\n    content = function(file) {\n      write.csv(dat(), file, row.names = FALSE)\n    }\n  )\n}\n\n# Run the application\nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "undervisningsforloeb/screeningsprogrammer/gendata.html#data-generator",
    "href": "undervisningsforloeb/screeningsprogrammer/gendata.html#data-generator",
    "title": "AI MAT - matematikken bag magien",
    "section": "",
    "text": "#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 600 \nlibrary(shiny)\nlibrary(bslib)\nlibrary(writexl)\n\nui &lt;- page_fluid(\n  layout_columns(\n  card(card_header(\"Gen 1\"),\n         numericInput(\"m1\", \"Middelværdi:\", 10),\n         numericInput(\"s1\", \"Spredning:\", 5, min = 0),\n    ),\n    card(card_header(\"Gen 2\"),\n         numericInput(\"m2\", \"Middelværdi:\", 10),\n         numericInput(\"s2\", \"Spredning:\", 5, min = 0),\n    ),\n    card(card_header(\"Gen 3\"),\n         numericInput(\"m3\", \"Middelværdi:\", 10),\n         numericInput(\"s3\", \"Spredning:\", 5, min = 0),\n    ),\n    card(card_header(\"Gen 4\"),\n         numericInput(\"m4\", \"Middelværdi:\", 10),\n         numericInput(\"s4\", \"Spredning:\", 5, min = 0),\n    ),\n    card(card_header(\"Gen 5\"),\n         numericInput(\"m5\", \"Middelværdi:\", 10),\n         numericInput(\"s5\", \"Spredning:\", 5, min = 0),\n    ),\n    card(card_header(\"Indstillinger\"),\n         numericInput(\"nsim\", \"Antal observationer:\", 100, min = 1, max = 10000),\n         actionButton(\"run\", \"Kør\")),\n    card(card_header(\"Data\"),\n         tableOutput(\"dataTable\")),\n    card(card_header(\"Download\"),\n         downloadButton(\"excel\", \"Download (Excel)\"),\n         downloadButton(\"csv\", \"Download (csv)\")),\n  col_widths = c(rep(2,6),10,2)\n  )\n)\n\nserver &lt;- function(input, output) {\n  dat &lt;- reactiveVal()\n\n  observeEvent(input$run, {\n    sim &lt;- data.frame(\n        `Gen 1` = rnorm(input$nsim, mean = input$m1, sd = input$s1),\n        `Gen 2` = rnorm(input$nsim, mean = input$m2, sd = input$s2),\n        `Gen 3` = rnorm(input$nsim, mean = input$m3, sd = input$s3),\n        `Gen 4` = rnorm(input$nsim, mean = input$m4, sd = input$s4),\n        `Gen 5` = rnorm(input$nsim, mean = input$m5, sd = input$s5)\n        ) |&gt; round(2)\n\n    dat(sim)\n\n    output$dataTable &lt;- renderTable({\n      sim\n    })\n  })\n\n  output$excel &lt;- downloadHandler(\n    filename = function() {\n      paste(\"gen-data_\", Sys.Date(), \".xlsx\", sep = \"\")\n    },\n    content = function(file) {\n      write_xlsx(dat(), file)\n    }\n  )\n\n  output$csv &lt;- downloadHandler(\n    filename = function() {\n      paste(\"gen-data_\", Sys.Date(), \".csv\", sep = \"\")\n    },\n    content = function(file) {\n      write.csv(dat(), file, row.names = FALSE)\n    }\n  )\n}\n\n# Run the application\nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "undervisningsforloeb/polynomium_old.html",
    "href": "undervisningsforloeb/polynomium_old.html",
    "title": "Perceptroner og rødder",
    "section": "",
    "text": "Forudsætninger og tidsforbrug\n\n\n\n\n\nForløbet kræver kendskab til:\n\nAndengradspolynomier og rødder\n\nTidsforbrug: Ca. 90 minutter."
  },
  {
    "objectID": "undervisningsforloeb/polynomium_old.html#hvad-er-en-perceptron",
    "href": "undervisningsforloeb/polynomium_old.html#hvad-er-en-perceptron",
    "title": "Perceptroner og rødder",
    "section": "Hvad er en perceptron?",
    "text": "Hvad er en perceptron?\nI dette forløb skal vi arbejde med perceptoner, og det har du nok aldrig hørt om før! Start derfor med at se videoen herunder, hvor vi kort forklarer, hvad en perceptron er.\n\nDu kan også læse meget mere om perceptroner her."
  },
  {
    "objectID": "undervisningsforloeb/polynomium_old.html#andengradspolynomier-og-rødder",
    "href": "undervisningsforloeb/polynomium_old.html#andengradspolynomier-og-rødder",
    "title": "Perceptroner og rødder",
    "section": "Andengradspolynomier og rødder",
    "text": "Andengradspolynomier og rødder\nNu tilbage til vores eksempel om andengradspolynomier og rødder! Lad os for en god ordens skyld minde om, at et andengradspolynomium er en funktion med en forskrift på formen \\[\nf(x)=ax^2 + bx + c, \\quad a \\neq 0\n\\] Grafen for et andengradspolynomium kaldes som bekendt for en parabel. I figur 1 ses tre eksempler på sådanne parabler.\n\n\n\n\n\n\nFigur 1: Graferne for tre forskellige andengradspolynomier.\n\n\n\nHvis vi løser andengradsligningen \\[\nf(x)=ax^2 + bx + c=0\n\\] finder vi andengradspolynomiets rødder. Men at løse \\(f(x)=0\\), svarer netop til at bestemme, hvor den tilhørende parabel skærer \\(x\\)-aksen. I figur 1 kan vi se, at den grønne parabel skærer \\(x\\)-aksen to steder. Det vil sige, at det tilhørende andengradspolynomium har to rødder. Den røde parabel skærer \\(x\\)-aksen ét sted – det tilhørende andengradspolynomium har altså én rod. Endelig kan vi se, at den blå parabel slet ikke skærer \\(x\\)-aksen, og det tilhørende andengradspolynomium har derfor ingen rødder.\nDu husker nok, hvordan man bestemmer antallet af rødder i et andengradspolynomium. Vi har brug for diskriminanten \\(d\\):\n\\[\nd = b^2-4ac\n\\tag{1}\\]\nOg der gælder så, at \\[\n\\begin{aligned}\n&d&lt;0: \\quad f \\textrm{ har ingen rødder} \\\\\n&d=0: \\quad f \\textrm{ har én rod} \\\\\n&d&gt;0: \\quad f \\textrm{ har to rødder} \\\\\n\\end{aligned}\n\\]\nIdéen er nu at undersøge, om det er muligt at få en perceptron til at lære1, om et andengradspolynomium overhovedet har nogle rødder alene ude fra de tre koefficienter \\(a\\), \\(b\\) og \\(c\\) – og helt uden at kende noget til diskriminantformlen i (1)!\n1 Det er klart, at der er intet nyt under solen her. Vi kan jo bare selv beregne diskriminanten og svare på spørgsmålet. Men formålet er her at lære lidt om, hvad det vil sige at træne en perceptron i et tilfælde, hvor vi allerede selv kender svaret. Desuden findes der ingen lukkede løsningsformler for at bestemme rødder i et polynomium, så snart graden af polynomiet er \\(5\\) eller derover. Så idéen kan generaliseres, og så er den måske slet ikke så tosset endda!Inden vi går i gang, vil vi starte med at indse, at i stedet for at løse ligningen\n\\[\na x^2 + bx +c = 0\n\\tag{2}\\]\nSå kan vi lige så godt løse en ligning på formen\n\\[\nx^2 + bx +c =0\n\\] hvor altså \\(a=1\\). Det virker måske som en forsimpling, men da vi har antaget, at \\(a \\neq 0,\\) så kan vi i ligningen i (2) dividere igennem med \\(a\\) og få\n\\[\n\\begin{aligned}\n\\frac{a}{a} x^2 + \\frac{b}{a} x + \\frac{c}{a} &= \\frac{0}{a} \\quad \\Leftrightarrow \\\\\nx^2 + \\frac{b}{a} x + \\frac{c}{a} &= 0\n\\end{aligned}\n\\]\nDet betyder, at når vi skal bestemme rødder i andengradspolynomier, så er det tilstrækkeligt, at betragte andengradspolynomier med en forskrift på formen\n\\[\nf(x)=x^2+bx+c\n\\] fordi man simpelthen bare tager sit oprindelige andengradspolynomium og dividerer igennem med \\(a\\). Lad os illustrere det med et eksempel.\n\nBetragt andengradspolynomiet med forskriften\n\\[\nf(x)=-4x^2+8x+12\n\\] Her har vi \\(a=-4, b=8\\) og \\(c=12\\). Løser vi ligningen \\(f(x)=0\\), finder vi ud af, at \\(f\\) har to rødder nemlig \\(-1\\) og \\(3\\). Dividerer vi forskriften for \\(f\\) igennem med \\(a=-4\\) fås et nyt andengradspolynomium \\(g\\) med forskrift\n\\[\ng(x)=x^2-2x-3\n\\] Her er koefficienterne \\(a=1, b=-2\\) og \\(c=-3\\). Men \\(g\\) har præcis samme rødder som \\(f\\) – nemlig \\(-1\\) og \\(3\\). Dette ses også illustreret i figur 2, hvor grafen for \\(f\\) og \\(g\\) begge skærer \\(x\\)-aksen i \\(-1\\) og \\(3\\).\n\n\n\n\n\n\nFigur 2: Grafen for \\(f(x)=-4x^2+8x+12\\) (den blå) og \\(g(x)=x^2-2x-3\\) (den grønne), som begge skærer \\(x\\)-aksen samme sted. Det vil sige, at \\(f\\) og \\(g\\) har de samme rødder. I dette tilfælde \\(-1\\) og \\(3\\)."
  },
  {
    "objectID": "undervisningsforloeb/polynomium_old.html#træningsdata",
    "href": "undervisningsforloeb/polynomium_old.html#træningsdata",
    "title": "Perceptroner og rødder",
    "section": "Træningsdata",
    "text": "Træningsdata\nI dette eksempel vil vi nøjes med at se på, hvordan man kan træne en perceptron, så den forhåbentlig kan fortælle os, om et givent andengradspolynomium enten har ingen eller en eller to rødder. Det svarer til, at vi ønsker en perceptron, som for en given parabel kan svare på, om parablen skærer \\(x\\)-aksen eller ej (og altså ikke hvor mange gange den eventuelt skærer \\(x\\)-aksen).\n\n\n\n\n\n\nOpgave 1: Rødder eller ej?\n\n\n\n\n\nOvervej følgende:\n\nHvordan laver man et andengradspolynomium, der har én eller to rødder?\nHvordan laver man et andengradspolynomium, som ingen rødder har?\n\n\n\n\nFor at træne en perceptron, skal perceptronen se en masse eksempler på forskellige andengradspolynomier (det vil her sige med forskellige værdier af \\(b\\) og \\(c\\)) samtidig med, at vi fortæller perceptronen, om det tilhørende andengradspolynomium har rødder eller ej. At angive om et polynomium har rødder eller ej kalder man for en targetværdi. Tænk på det som en lille label du sætter på hvert eksempel, hvor du fortæller perceptronen, hvad det rigtige svar er – “det er altså det her, jeg gerne vil have, at du lærer!”. Samlet set kalder man de forskellige eksempler inklusiv targetværdien for træningsdata.\n\n\n\n\n\n\nOpgave 2: Træningsdata\n\n\n\n\n\n\nFind selv på forskellige værdier af \\(b\\) og \\(c\\) og find ud af om det tilhørende andengradspolynomium har rødder eller ej. Du skal finde på mindst to andengradspolynomier, der har rødder og to, der ikke har, men gerne et par stykker mere.Skriv dine værdier ned (enten bare på papir eller i f.eks. et regneark).\nIndtegn dine værdier \\(b\\) og \\(c\\) i et koordinatsystem, hvor værdien af \\(b\\) er på \\(x\\)-aksen, og værdien af \\(c\\) er på \\(y\\)-aksen. Herunder er lavet et eksempel med \\(b=0\\) og \\(c=-1\\), som svarer til et andengradspolynomium med to rødder samt \\(b=2\\) og \\(c=4\\), som svarer til et andengradspolynomium uden rødder."
  },
  {
    "objectID": "undervisningsforloeb/polynomium_old.html#træning-af-perceptron",
    "href": "undervisningsforloeb/polynomium_old.html#træning-af-perceptron",
    "title": "Perceptroner og rødder",
    "section": "Træning af perceptron",
    "text": "Træning af perceptron\nVi skal nu overveje, hvordan perceptronen kan trænes. Perceptronen gør dybest set det, at den prøver at bestemme en ret linje, som kan bruges til at adskille de røde punkter fra de blå punkter i punktplottet ovenfor. En ret linje i et 2-dimensionalt koordinatsystem har helt generelt en ligning på formen2\n2 Du er nok vant til at møde linjens ligning på denne form: \\(a \\cdot x+b \\cdot y+c=0\\). Skrivemåden, vi bruger her, er \\(w_0+w_1 \\cdot x + w_2 \\cdot y=0\\). Det vil sige i forhold til den skrivemåde, som du kender, så er \\(w_0=c, w_1=a\\) og \\(w_2=b\\).\\[\nw_0 + w_1 \\cdot x + w_2 \\cdot y = 0\n\\] Og for alle punkter på den ene side af linjen gælder, at\n\\[\nw_0 + w_1 \\cdot x + w_2 \\cdot y &gt; 0\n\\] og for alle punkter på den anden side, at\n\\[\nw_0 + w_1 \\cdot x + w_2 \\cdot y &lt; 0\n\\]\nI vores tilfælde har vi \\(b\\)-værdier ud af \\(x\\)-aksen og \\(c\\)-værdier op af \\(y\\)-aksen. Med de betegnelser bliver ligningen for en ret linje\n\\[\nw_0 + w_1 \\cdot b + w_2 \\cdot c = 0\n\\]\nHer tænker vi altså på \\(b\\) og \\(c\\) som de variable.\nNår man træner en perceptron, gør man det ved hjælp af en algoritme, som løbende opdaterer vægtene \\(w_0, w_1\\) og \\(w_2\\), så den linje, vægtene giver, bliver bedre og bedre til at adskille de røde punkter fra de blå. Hver gang man opdaterer vægtene, siger man, at algoritmen har foretaget én iteration3.\n3 En iteration betyder en gentagelse.Du kan godt løse resten af opgaverne uden at forstå, hvorfor vægtene opdateres, som de gør. Men hvis du gerne vil have en forklaring så se videoen herunder.\n\n\n\n\n\n\n\nOpgave 3: Træning af perceptron\n\n\n\n\n\nLad os bruge startvægtene \\(w_0=1\\), \\(w_1=-3\\) og \\(w_2=2\\).\n\nHvilken linje svarer det til? Indtegn linjen i et koordinatsystemet.\nAdskiller denne linje de to grupper af punkter (med og uden rødder)? Hvis grupperne allerede er adskilt, skal du tilføje punktet med \\(b=2\\) og \\(c=1\\), som svarer til et andengradspolynomium, der har én rod.\n\nTræningsdata der svarer til polynomier med rødder, giver vi targetværdien \\(t=-1\\) og dem uden rødder får targetværdien \\(t=1\\).\nAlle punkter, der ligger over startlinjen, opfylder uligheden \\[\nw_0 + w_1 \\cdot b + w_2 \\cdot c &gt; 0\n\\] og får outputværdien \\(o=1\\), mens dem, der ligger under linjen, opfylder den omvendte ulighed og får outputværdien \\(o=-1\\).\n\nUdvælg et punkt der bliver fejlklassificeret. Det vil sige som enten ligger under linjen (\\(o=-1\\)), men har target \\(t=1\\) svarende til ingen rødder eller omvendt.\nUdregn fejlen \\(error=t-o\\) som enten er -2 eller 2.\nOpdater nu alle tre vægte ved brug af opdateringsreglen (hvor du selv vælger \\(\\eta\\), f.eks. \\(\\eta=1\\)): \\[\n\\begin{aligned}\n  w_0 \\leftarrow w_0 + & \\,\\eta \\cdot error \\\\\n  w_1 \\leftarrow w_1 + & \\,\\eta \\cdot error \\cdot x_1 \\\\\n  w_2 \\leftarrow w_2 + & \\,\\eta \\cdot error \\cdot x_2 \\\\\n\\end{aligned}\n\\] Husk at \\(x_1\\) er \\(b\\)-værdien og \\(x_2\\) er \\(c\\)-værdien!\nFik du efter opdateringen en linje, der adskiller de to grupper?\nHvis ikke, kan du så selv lave en ret linje “på øjemål”, der adskiller dem?\n\n\n\n\n\n\n\n\n\n\nOpgave 4: Flere træningsdata\n\n\n\n\n\n\nAfgør om følgende andengradspolynomier har rødder og tilføj dem til dit træningsdata:\n\n\\[\n\\begin{aligned}\nf_1(x) &= x^2 + 10x + 26 \\\\\nf_2(x) &= x^2 + 10x + 24\\\\\nf_3(x) &= x^2 + 5x + 6\\\\\nf_4(x) &= x^2 + 5x + 7 \\\\\nf_5(x) &= x^2 + 2x + 1\\\\\nf_6(x) &= x^2 + 2x + 2 \\\\\n\\end{aligned}\n\\]\n\nKan det lade sig gøre at adskille de to grupper med en ret linje nu?\n\n\n\n\nSom du netop har opdaget, er det en umulig opgave, vi har givet perceptronen! Vi kan ikke finde en ret linje, som i alle tilfælde kan bruges til at adskille de to slags punkter. Lad os se på hvorfor. Som tidligere nævnt har vores linje en ligning på formen\n\\[\nw_0 + w_1 \\cdot b + w_2 \\cdot c = 0\n\\tag{3}\\]\nVi husker nu på formlen for diskriminanten \\(d=b^2-4ac=b^2-4c\\), da \\(a=1\\) i vores eksempel. Skillelinjen for om andengradspolynomiet har ingen eller flere rødder, går netop ved \\(d=0\\). Det vil sige\n\\[\nb^2-4c =0\n\\tag{4}\\]\nMen vi kan ikke finde nogle værdier af \\(w_0, w_1\\) og \\(w_2\\), så udtrykket i (3) kommer til at svare til udtrykket i (4). Det er fordi, at i (3) indgår der kun et \\(b\\), mens der i (4) indgår et \\(b^2\\). Denne observation giver os imidlertid også en løsning på vores problem. I stedet for at fodre perceptroner med forskellige værdier af \\(b\\) og \\(c\\), så giver vi den i stedet værdier af \\(b^2\\) og \\(c\\)!\n\n\n\n\n\n\nOpgave 5: Nye træningsdata\n\n\n\n\n\n\nLav et nyt koordinatsystem og indtegn dine træningsdata med værdien af \\(b^2\\) på \\(x\\)-aksen og værdien af \\(c\\) på \\(y\\)-aksen.\nHvilken linje kan du vælge til at adskille de to grupper?"
  },
  {
    "objectID": "undervisningsforloeb/Opdatering_af_vægte_i_NN1_facit.html",
    "href": "undervisningsforloeb/Opdatering_af_vægte_i_NN1_facit.html",
    "title": "Facit til forløb om opdatering af vægte i et simpelt neuralt netværk med ét skjulte lag",
    "section": "",
    "text": "Facit til opgave 1\n\n\n\n\n\nSummen giver\n1.9773575, 2.9659487, 4.4468601\n\\(y\\)-værdierne er\n0.8783992, 0.9510119, 0.9884204\n\n\n\n\n\n\n\n\n\nFacit til opgave 2\n\n\n\n\n\n\\(o\\)-værdierne er\n0.6738134, 0.6800149, 0.6831854\n\n\n\n\n\n\n\n\n\nFacit til opgave 3\n\n\n\n\n\n\\(\\delta_w^{(m)}\\)-værdierne er: \\[\n   \\begin{aligned}\n   \\delta_w^{(m)} &= (t^{(m)}-o^{(m)} )  \\\\\n   \\end{aligned}\n   \\]\nOpdateringsregler for \\(w\\)-vægtene: \\[\n   \\begin{aligned}\n   w_0^{\\textrm{ny}} & \\leftarrow w_0 + \\eta \\cdot \\sum_{m=1}^{M} \\delta_w^{(m)} \\cdot 1\\\\\n   w_1^{\\textrm{ny}} & \\leftarrow w_1 + \\eta \\cdot \\sum_{m=1}^{M} \\delta_w^{(m)} \\cdot y^{(m)}\\\\\n   \\end{aligned}\n   \\]\n\n\n\n\n\n\n\n\n\nFacit til opgave 4\n\n\n\n\n\n\n\\(\\delta_w\\)-værdierne er\n-0.7191802, 0.2736291, -0.7299771\nSummen\n\\(\\sum_{m=1}^3 \\delta_w^{(m)} =\\) -1.1755281\n\\(w_0\\)-vægten opdateres til\n\\(w_{0}^{ny}=\\) 0.3824472\nSummen\n\\(\\sum_{m=1}^{3} \\delta_w^{(m)} \\cdot y^{(m)}=\\) -1.093027\n\\(w_1\\)-vægten opdateres til\n\\(w_{1}^{ny}=\\) 0.3905243\n\n\n\n\n\n\n\n\n\n\nFacit til opgave 5\n\n\n\n\n\n\\(\\delta_r^{(m)}\\)-værdierne er: \\[\n   \\begin{aligned}\n   \\delta_r^{(m)} &= \\delta_w^{(m)} \\cdot w_1 \\cdot y^{(m)} \\cdot (1-y^{(m)})\n   \\end{aligned}\n   \\] Opdateringsreglerne for \\(r\\)-vægtene:\n\\[\n   \\begin{aligned}\n   r_0^{\\textrm{ny}} & \\leftarrow  r_0 + \\eta \\cdot \\sum_{m=1}^M \\delta_r^{(m)} \\cdot 1 \\\\\n   r_1^{\\textrm{ny}} & \\leftarrow  r_1 + \\eta \\cdot \\sum_{m=1}^M \\delta_r^{(m)} \\cdot x_1^{(m)} \\\\\n   r_2^{\\textrm{ny}} & \\leftarrow  r_2 + \\eta \\cdot \\sum_{m=1}^M \\delta_r^{(m)} \\cdot x_2^{(m)}\n   \\end{aligned}\n   \\]\n\n\n\n\n\n\n\n\n\nFacit til opgave 6\n\n\n\n\n\n\n\\(\\delta_r\\)-værdierne er\n-0.0377547, 0.0061808, -0.0039660\nSummen\n\\(\\sum_{m=1}^M \\delta_r^{(m)}=\\) -0.0355399\n\\(r_0\\)-vægten opdateres til\n\\(r_{0}^{ny}=\\) 0.496446\nSummen\n\\(\\sum_{m=1}^M \\delta_r^{(m)} \\cdot x_1^{(m)}=\\) -0.0372911\n\\(r_1\\)-vægten opdateres til\n\\(r_{1}^{ny}=\\) 0.4962709\nSummen\n\\(\\sum_{m=1}^M \\delta_r^{(m)} \\cdot x_2^{(m)}=\\) -0.0767971\n\\(r_2\\)-vægten opdateres til\n\\(r_{2}^{ny}=\\) 0.4923203\n\n\n\n\n\n\n\n\n\n\nFacit til opgave 7\n\n\n\n\n\n\nVærdien af tabsfunktionen før opdatering 2.8989851\nVærdien af tabsfunktionen efter første opdatering 2.6553645\n\n\n\n\n\n\n\n\n\n\nFacit til opgave 8\n\n\n\n\n\n\n\\(w_0 =\\) 0.2787458\n\\(w_1 =\\) 0.2942401\n\\(r_0 =\\) 0.4939121\n\\(r_1 =\\) 0.4937084\n\\(r_2 =\\) 0.4869186\nVærdien af tabsfunktionen efter anden opdatering 2.4674373"
  },
  {
    "objectID": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del7.html",
    "href": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del7.html",
    "title": "Del 7: Multipel logistisk regression og prædiktion",
    "section": "",
    "text": "Forventet tid ca. 60 min."
  },
  {
    "objectID": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del7.html#aktivitet-1",
    "href": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del7.html#aktivitet-1",
    "title": "Del 7: Multipel logistisk regression og prædiktion",
    "section": "Aktivitet 1",
    "text": "Aktivitet 1\nLæs afsnittet om multipel logistisk regression."
  },
  {
    "objectID": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del7.html#aktivitet-2",
    "href": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del7.html#aktivitet-2",
    "title": "Del 7: Multipel logistisk regression og prædiktion",
    "section": "Aktivitet 2",
    "text": "Aktivitet 2\nLav nedenstående opgave.\n\n\n\n\n\n\nOpgave 1\n\n\n\n\n\nI en multipel regression har man fundet følgende model for odds \\(O(x_1,x_2)\\) for, at en bruger af en hjemmeside klikker på en given reklame, hvor \\(x_1\\) og \\(x_2\\) er antal gange kunden har læst henholdsvis kulturnyheder og sportsnyheder inden for den sidste måned \\[\nO(x_1,x_2) = e^{-2+0.5x_1-0.1x_2 }.\n\\]\n\nEn bruger har læst kulturnyheder 4 gange og sportsnyheder 7 gange inden for den sidste måned. Hvad er odds for, at brugeren klikker på reklamen?\nHvad er odds ratioen for kulturnyheder?\nEr sandsynligheden for at klikke på reklamen højere eller lavere blandt brugere, der læser mange kulturnyheder?"
  },
  {
    "objectID": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del7.html#aktivitet-3",
    "href": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del7.html#aktivitet-3",
    "title": "Del 7: Multipel logistisk regression og prædiktion",
    "section": "Aktivitet 3",
    "text": "Aktivitet 3\nLæs afsnittet om prædiktion."
  },
  {
    "objectID": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del7.html#aktivitet-4",
    "href": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del7.html#aktivitet-4",
    "title": "Del 7: Multipel logistisk regression og prædiktion",
    "section": "Aktivitet 4",
    "text": "Aktivitet 4\nLav nedenstående opgave.\n\n\n\n\n\n\nOpgave 2\n\n\n\n\n\nVi kigger igen på en multipel regressionsmodel for odds \\(O(x_1,x_2)\\) for, at en bruger af en hjemmeside klikker på en given reklame, hvor \\(x_1\\) og \\(x_2\\) er antal gange kunden har læst henholdsvis kulturnyheder og sportsnyheder inden for den sidste måned. Modellen for odds er fundet til \\[\nO(x_1,x_2) = e^{-2+0.5x_1-0.1x_2 }.\n\\] Vi vil gerne prædiktere, om en bruger klikker på reklamen, så vi kan beslutte, om det er relevant at vise ham den.\n\nEn bruger har læst kulturnyheder 5 gange og sportsnyheder 8 gange inden for den sidste måned. Vil du prædiktere, at brugeren klikker på reklamen?"
  },
  {
    "objectID": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del3.html",
    "href": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del3.html",
    "title": "Del 3: Den logistiske regressionsmodel",
    "section": "",
    "text": "Forventet tid ca. 45 min."
  },
  {
    "objectID": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del3.html#aktivitet-1",
    "href": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del3.html#aktivitet-1",
    "title": "Del 3: Den logistiske regressionsmodel",
    "section": "Aktivitet 1",
    "text": "Aktivitet 1\nStart med at se denne video (eller læs afsnittet den logistiske regressionsmodel):"
  },
  {
    "objectID": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del3.html#aktivitet-2",
    "href": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del3.html#aktivitet-2",
    "title": "Del 3: Den logistiske regressionsmodel",
    "section": "Aktivitet 2",
    "text": "Aktivitet 2\nLav nedenstående opgave.\n\n\n\n\n\n\nOpgave 1\n\n\n\n\n\nI denne opgave ser vi på sandsynligheden \\(p(x)\\) for at lide af forhøjet blodtryk1 som funktion af kolestreroltallet \\(x\\). Vi kigger derfor på datasættet nedenfor, som er en udvalgt del af et virkeligt datasæt. I tabellen angiver \\(y=1\\) forhøjet blodtryk, mens \\(y=0\\) angiver normalt blodtryk.\n\nLav en tabel, hvor du beregner sandsynligheden for forhøjet blodtryk, odds og ln(odds) inden for hvert interval.\nIndtegn punkter i et koordinatsystem, hvor \\(x\\)-værdien er midtpunkterne for intervallerne, og \\(y\\)-værdien er de tilhørende ln(odds).\nSer sammenhængen lineær ud?\nVil det give mening at bruge en logistisk regression?\n\n\n\n\n\\(x\\)\n\\(y=0\\)\n\\(y=1\\)\n\n\n\n\n]100,150]\n27\n6\n\n\n]150,200]\n693\n202\n\n\n]200,250]\n1354\n571\n\n\n]250,300]\n716\n471\n\n\n]300,350]\n156\n132\n\n\n]350,400]\n20\n23\n\n\n]400,450]\n2\n5\n\n\n\n\n\n\n\n\n1 Forhøjet blodtryk er defineret som systolisk blodtryk højere end 140mmHg eller diastolisk blodtryk højere end 90mmHg."
  },
  {
    "objectID": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del4.html",
    "href": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del4.html",
    "title": "Del 4: Logit-funktionen",
    "section": "",
    "text": "Forventet tid ca. 90 min."
  },
  {
    "objectID": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del4.html#aktivitet-1",
    "href": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del4.html#aktivitet-1",
    "title": "Del 4: Logit-funktionen",
    "section": "Aktivitet 1",
    "text": "Aktivitet 1\nStart med at repetere hvad en invers (eller omvendt) funktion er."
  },
  {
    "objectID": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del4.html#aktivitet-2",
    "href": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del4.html#aktivitet-2",
    "title": "Del 4: Logit-funktionen",
    "section": "Aktivitet 2",
    "text": "Aktivitet 2\n\nIsolér \\(p\\) i nedenstående udtryk:\n\n\\[\ny = \\text{logit(p)} = \\ln\\left( \\frac{p}{1-p} \\right).\n\\tag{1}\\]\nHvis du går i stå, er der hjælp at hente i afsnittet logit-funktionen og den logistiske funktion.\n\nHvad er den inverse funktion til \\(\\text{logit(p)}\\)?\n\n\n\n\n\n\n\nLærergennemgang\n\n\n\n\n\n\nDin lærer vil lave en opsamling og gennemgå, hvordan \\(p\\) isoleres i (1)."
  },
  {
    "objectID": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_eksamen.html",
    "href": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_eksamen.html",
    "title": "Eksamensspørgsmål: Differentialregning og logistisk regression",
    "section": "",
    "text": "Forventet tid ca. 60 min."
  },
  {
    "objectID": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_eksamen.html#aktivitet-1",
    "href": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_eksamen.html#aktivitet-1",
    "title": "Eksamensspørgsmål: Differentialregning og logistisk regression",
    "section": "Aktivitet 1",
    "text": "Aktivitet 1\nForbered en fremlæggelse af nedenstående eksamensspørgsmål.\n\n\n\n\n\n\nDifferentialregning og logistisk regression\n\n\n\n\n\n\nForklar om logistisk regression, herunder odds.\nDifferentier \\(O(p)= {p \\over (1-p)}\\) og vis derved, at \\(O(p)\\) er voksende.\nIsoler \\(p\\) i udtrykket \\[\ny = \\text{logit(p)} = \\ln\\left( \\frac{p}{1-p} \\right).\n\\]"
  },
  {
    "objectID": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_forside.html",
    "href": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_forside.html",
    "title": "Logistisk regression",
    "section": "",
    "text": "Formål\nDette længere forløb handler om logistisk regression, som er en metode indenfor kunstig intelligens, der ikke er \"black-box\", som for eksempel kunstige neurale netværk er. Det er vigtigt at bemærke her, at logistisk regression ikke er det samme som logistisk vækst.\nMåske har I haft om logistisk vækst og måske er I i jeres CAS værktøj stødt på en kommando til logistisk regression, men metoden i dette forløb er noget andet, selvom noget vil virke bekendt.\nForløbet indeholder også et forslag til et spørgsmål til mundtlig eksamen, og kan derfor dække kravet på stx A om, at mindst ét spørgsmål skal stilles med udgangspunkt i det supplerende stof.\nEn introduktion til logistisk regression kan ses her:\n\n\n\nForudsætninger og tidsforbrug\nForløbet kræver kendskab til:\n\nInvers funktion.\nDen naturlige logaritme.\n\nTidsforbrug: 10-12 timer.\n\n\nForløbet\nForløbet består af følgende dele:\nDel 1: Logistisk regression\nDel 2: Odds\nDel 3: Den logistiske regressionsmodel\nDel 4: Logit-funktionen\nDel 5: Fortolkning\nDel 6: Maximum Likelihood Estimation\nDel 7: Multipel logistisk regression og prædiktion\nEksamensspørgsmål\n\n\nTil læreren\nHerunder findes diverse fif til læreren.\nTil læreren"
  },
  {
    "objectID": "undervisningsforloeb/OverfitPoly.html",
    "href": "undervisningsforloeb/OverfitPoly.html",
    "title": "Overfitting og krydsvalidering med polynomiel regression",
    "section": "",
    "text": "Forudsætninger og tidsforbrug\n\n\n\n\n\nForløbet kræver kendskab til:\n\nPolynomiel regression.\n\nTidsforbrug: ca. 90 minutter."
  },
  {
    "objectID": "undervisningsforloeb/OverfitPoly.html#introduktion",
    "href": "undervisningsforloeb/OverfitPoly.html#introduktion",
    "title": "Overfitting og krydsvalidering med polynomiel regression",
    "section": "Introduktion",
    "text": "Introduktion\nMan vil ofte gerne ud fra kendte observationer i en stikprøve kunne forudsige værdier af fremtidige observationer fra den population, som stikprøven er fra. Dette kaldes prædiktion. I virkeligheden vil man ofte have en stikprøve med 100 eller flere observationer, men for at undgå alt for mange beregninger, nøjes vi her med 8, selvom det i praksis er alt for lidt.\nI dette eksempel vil vi se på populationen ”danske gymnasieelever”, hvor vi – indrømmet fjollet – vil undersøge, om der en sammenhæng mellem den uafhængige variabel ”antal biografbesøg det seneste år” og den afhængige variabel ”antal venner på de sociale medier”. Vi lader som om, vi har indsamlet en stikprøve med 8 gymnasieelever med følgende resultat:\n\n\n\n\n\n\n\nAntal biografbesøg det seneste år\nAntal venner på de sociale medier\n\n\n\n\n\\(1\\)\n\\(14\\)\n\n\n\\(2\\)\n\\(27\\)\n\n\n\\(3\\)\n\\(11\\)\n\n\n\\(4\\)\n\\(19\\)\n\n\n\\(5\\)\n\\(27\\)\n\n\n\\(6\\)\n\\(24\\)\n\n\n\\(7\\)\n\\(12\\)\n\n\n\\(8\\)\n\\(39\\)\n\n\n\n\n\nVi ønsker ud fra disse data at opstille en model, som for nye observationer kan forudsige, hvor mange venner på de sociale medier en gymnasieelev har, hvis man kender antal biografbesøg.\nNår man opstiller en model, kan man nogle gange bygge på en forventning eller fysisk model, men andre gange har man som udgangspunkt ikke nogen bestemt idé, hvilket er tilfældet her. Vi vil derfor forsøge at modellere data ved hjælp af et polynomium, hvor vi så skal undersøge, hvilken grad af polynomiet, der ser ud til at kunne klare opgaven bedst. Her ses for eksempel resultatet af regression med et 3. gradspolynomium.\n\n\n\n\n\n\n\n\n\nFigur 1: Datasættet fra tabellen hvor der er udført 3. gradsregression.\n\n\n\n\n\n\n\n\n\n\n\nOpgave 1\n\n\n\n\n\n\nUndersøg med dit CAS værktøj, hvilke grader man kan lave polynomiel regression med på de 8 punkter. Hvad bliver den mindste grad og hvad bliver den højeste mulige grad?\nOvervej, hvorfor det er sådan.\n\n\n\n\n\n\n\n\n\n\nOpgave 2\n\n\n\n\n\n\nLav lineær regression samt polynomiel regression fra 2. til 7. grad på stikprøvens data.\nTegn for hver regression punktplottet og grafen for resultatet af regression sammen (hvis dit CAS-værktøj ikke gør det af sig selv).\n\nHvilket polynomium passer bedst til de 8 punkter?\n\n\n\n\nSvaret på opgave 2 bør ikke være overraskende. Desto højere grad af polynomium, desto bedre kan grafen tilpasse sig punkterne. Når graden bliver antallet af punkter minus 1, altså her graden 7, passer grafen perfekt til alle punkterne. Men betyder det så også, at det fundne 7. gradspolynomium passer godt til fremtidige observationer og dermed til at prædiktere, hvor mange venner på de sociale medier andre elever har ud fra antal biografbesøg? Det vil vi undersøge nærmere i resten af forløbet."
  },
  {
    "objectID": "undervisningsforloeb/OverfitPoly.html#krydsvalidering",
    "href": "undervisningsforloeb/OverfitPoly.html#krydsvalidering",
    "title": "Overfitting og krydsvalidering med polynomiel regression",
    "section": "Krydsvalidering",
    "text": "Krydsvalidering\nDen metode, vi vil anvende, kaldes for krydsvalidering. Vi vil lave regressionen ud fra 6 af de 8 punkter og beregne, hvor godt resultatet heraf passer med de sidste 2 punkter – vi lader så at sige som om, at vi skal prædiktere værdien for de 2 sidste punkter. Det vil vi gøre 4 gange – første gang anvendes punkt 1 og 2 ikke i regressionen, anden gang anvendes punkt 3 og 4 ikke, så anvendes 5 og 6 ikke og til sidst anvendes 7 og 8 ikke.\nHer er vist et eksempel i GeoGebra. I eksemplet laves 3. gradsregression, hvor punkterne 3 og 4 fjernet. Desuden er den lodrette afstand fra hver af de to fjernede punktet til grafen vist.\n\n\n\n\n\n\nFigur 2: 3. gradsregression på 6 af de 8 datapunkter.\n\n\n\n\n\n\n\n\n\nSamme eksempel lavet i Maple\n\n\n\n\n\nHer ses, hvordan beregningerne kan foretages i Maple.\n\n\n\n\n\n\n\n\n\n\n\n\nFigur 3: 3. gradsregression og residualer i Maple\nSom det ses af figuren, ligger det 3. punkt ca. 24,32 under grafen fra regressionen, mens det 4. punkt ligger ca. 12,56 under grafen.\n\n\n\n\n\n\nOpgave 3\n\n\n\n\n\nI skal nu på samme måde undersøge de øvrige muligheder, hvor man anvender 6 af de 8 punkter til at bestemme et 3. gradspolynomium.\n\nLav 3. gradsregression ud fra 6 af punkter, idet I ikke medtager de to første punkter.\nTegn grafen fra regressionen og alle 8 punkter i samme koordinatsystem for visuelt at illustrere, hvor godt eller skidt de 2 punkter er prædikteret af regressionen, som vist i eksemplet.\nBeregn den lodrette afstand mellem grafen og hver af de 2 punkter, som ikke var med i regression. Disse kaldes for residualer, så lad os kalde dem for \\(r_1\\) og \\(r_2\\). Skriv værdierne i en tabel som den nedenfor. Residualerne regnes med fortegn, så hvis punktet ligger under grafen, er residualet negativt.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResidual\n\\(r_1\\)\n\\(r_2\\)\n\\(r_3\\)\n\\(r_4\\)\n\\(r_5\\)\n\\(r_6\\)\n\\(r_7\\)\n\\(r_8\\)\n\n\n\n\nVærdi\n\n\n\n\n\n\n\n\n\n\n\nGentag regression og beregninger for samme grad, hvor det blot er de to næste punkter, der ikke er med i regression, så de to næste og endeligt de to sidste.\nTil sidst skal der beregnes en samlet afstand for alle 8 punkter. Det gøres ved at kvadrere hver enkelt værdi og beregne summen. Altså \\({r_1}^2+{r_2}^2+ {r_3}^2+{r_4}^2+{r_5}^2+{r_6}^2+{r_7}^2+{r_8}^2\\).\n\n\n\n\nTabellen nedenfor viser den tilsvarende samlede afstand for hver af graderne 1, 2, 4, og 5.\n\n\n\nGrad\nSamlet afstand\n\n\n\n\n1\n146513\n\n\n2\n142952\n\n\n4\n19821534237\n\n\n5\n66277073433\n\n\n\n\n\n\n\n\n\nOpgave 4\n\n\n\n\n\n\nSammenlign den samlede afstand I selv fandt for 3. gradsregression med de samlede afstande for de øvrige grader af regression fra tabellen. Hvilken grad er bedst til at prædiktere fremtidige værdier?"
  },
  {
    "objectID": "undervisningsforloeb/OverfitPoly.html#overfitting",
    "href": "undervisningsforloeb/OverfitPoly.html#overfitting",
    "title": "Overfitting og krydsvalidering med polynomiel regression",
    "section": "Overfitting",
    "text": "Overfitting\nDet fænomen, som dette forløb illustrerer, kaldes for overfitting. Ved at tilpasse modellen for godt til observationerne, får man ikke lavet en passende generel model, men derimod en model til netop disse punkter. Så selvom et 7. gradspolynomium passer perfekt til de 8 punkter, så viste det sig, at den bedste løsning var en noget mindre grad af polynomiet."
  },
  {
    "objectID": "undervisningsforloeb/OverfitPoly.html#afsluttende",
    "href": "undervisningsforloeb/OverfitPoly.html#afsluttende",
    "title": "Overfitting og krydsvalidering med polynomiel regression",
    "section": "Afsluttende",
    "text": "Afsluttende\nNår man til sidst har bestemt sig for en grad, laver man naturligvis den endelige model vha. alle punkterne, ikke med udeladelse af nogle af dem.\nHvis du og din gruppe er hurtigere færdig end de andre, så læs mere om krydsvalidering i denne note."
  },
  {
    "objectID": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_del2.html",
    "href": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_del2.html",
    "title": "Del 2: Kunstige neuroner",
    "section": "",
    "text": "Forventet tid ca. xx x 90 min."
  },
  {
    "objectID": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_del2.html#aktivitet-1---kunstige-neuroner",
    "href": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_del2.html#aktivitet-1---kunstige-neuroner",
    "title": "Del 2: Kunstige neuroner",
    "section": "Aktivitet 1 - Kunstige neuroner",
    "text": "Aktivitet 1 - Kunstige neuroner\nLæs de tre første afsnit (\"Medlemsapp til Good Food\", \"Hvordan bestemmes vægtene?\" og \"Aktiveringsfunktioner\") i noten om kunstige neuroner (du behøver ikke at forstå alt i noten):\n\n\n\n\n\n\n\n\n\n\nKunstige neuroner\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\nOpgave 1: Arbejdsspørgsmål til noten\n\n\n\n\n\nForklar med dine egne ord hvad følgende betyder:\n\nTargetværdi\nTræningsdatasæt\nTabsfunktion\n\n\n\n\nI noten forklarer vi, at man bruger gradientnedstigning til at bestemme minimum for tabsfunktionen. Denne metode vil vi se nærmere på i den næste aktivitet."
  },
  {
    "objectID": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_del2.html#aktivitet-2---gradientnedstigning",
    "href": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_del2.html#aktivitet-2---gradientnedstigning",
    "title": "Del 2: Kunstige neuroner",
    "section": "Aktivitet 2 - Gradientnedstigning",
    "text": "Aktivitet 2 - Gradientnedstigning\nVi vil illustrere gradientnedstigning i et simpelt eksempel:\n\n\n\n\n\n\nOpgave 2: Minimum for en funktion af to variable\n\n\n\n\n\nLad os se på en funktion \\(f\\), som afhænger af to variable \\(x\\) og \\(y\\) (i noten om kunstige neuroner svarer de to variable til et eksempel med to vægte):\n\\[\nf(x,y)= 0.2x^2-1.2x+0.3y^2-2.4y+8.6\n\\]\n\nTegn grafen for funktionen (for eksempel i GeoGebra – her skriver man forskriften ind i inputfeltet og vælger derefter \"Vis\" \\(\\rightarrow\\) \"3D Grafik\").\n\nTænk på grafen som en skibakke. Nede i bunden af bakken er der \"After Ski\", så der vil du selvfølgelig gerne ned! Det svarer matematisk til funktionens minimum.\n\nHvis du kigger på grafen alene - hvad er så dit bedste bud på minimumsstedet \\((x,y)\\) (altså i hvilket \\((x,y)\\)-koordinat ser det ud til, at \"After Ski\" ligger)?\n\n\n\n\nVi vil nu bruge gradientnedstigning til at bestemme minimum.\n\n\n\n\n\n\nOpgave 3: Opdateringsregler\n\n\n\n\n\n\nBestem de såkaldte partielle afledede \\(\\frac{\\partial f}{\\partial x}\\) og \\(\\frac{\\partial f}{\\partial y}\\). Når du for eksempel skal finde \\(\\frac{\\partial f}{\\partial x}\\), så skal du differentiere \\(f(x,y)\\), hvor du tænker på \\(x\\) som den variable og \\(y\\) som en konstant. Tilsvarende med \\(\\frac{\\partial f}{\\partial y}\\).\nBrug de partielle afledede til at opskrives opdateringsreglerne:\n\\[\n\\begin{aligned}\nx^{(ny)} &\\leftarrow x - \\eta \\cdot \\frac{\\partial f}{\\partial x} \\\\\ny^{(ny)} &\\leftarrow y - \\eta \\cdot \\frac{\\partial f}{\\partial y}\n\\end{aligned}\n\\]\nNu stiller vi os et tilfældigt sted på skibakken – lad og sige i punktet \\((6,8,f(6,8))\\). Udregn funktionsværdien \\(f(6,8)\\) og indtegn punktet \\((6,8,f(6,8))\\) i dit koordinatsystem (i GeoGebra skriver du bare \\((6,8,f(6,8))\\)).\nDu skal nu bruge ovenstående opdateringsregler til at finde ned mod \"After Ski\". Vi beslutter os for at vælge en skridtlængde på \\(\\eta = 0.1\\). Den første opdatering bliver så:\n\\[\n\\begin{aligned}\nx^{(ny)} &\\leftarrow 6 - 0.1 \\cdot \\frac{\\partial f}{\\partial x}(6,8) \\\\\ny^{(ny)} &\\leftarrow 8 - 0.1 \\cdot \\frac{\\partial f}{\\partial y}(6,8)\n\\end{aligned}\n\\]\nHint! Her er \\[\\frac{\\partial f}{\\partial x}(6,8)=0.4 \\cdot 6-1.2= 1.2\\] og \\[\\frac{\\partial f}{\\partial y}(6,8)=0.6 \\cdot 8-2.4=2.4\\]\nUdregn funktionsværdien \\(f(x^{(ny)}, y^{(ny)})\\). Er funktionsværdien blevet mindre sammenlignet med \\(f(6,8)\\)?\nIndtegn punktet \\((x^{(ny)},y^{(ny)},f(x^{(ny)},y^{(ny)}))\\) i dit koordinatsystem. Kan du se, at du er på vej ned mod skibakken?\n\n\n\n\nDet bliver lidt tungt at skulle lave disse udregninger i hånden. Vi vil derfor gøre det i Excel eller i GeoGebras regneark. I den næste opgave forklarer vi, hvordan man gør i GeoGebra:\n\n\n\n\n\n\nOpgave 4: Gradientnedstigning i GeoGebra\n\n\n\n\n\n\nUdfyld et regneark på denne måde:\n\n\n\n\n\n\nI celle A1 skriver du 6 (svarende til \\(x=6\\) der hvor vi starter).\nI celle B1 skriver du 8.\nI celle C1 skriver du f(A1,B1).\nI celle D1 skriver du (A1,B1,C1) (læg mærke til at punktet bliver tegnet ind i koordinatsystemet).\n\nVi skal nu have skrevet opdateringsreglerne ind. Du har nok tidligere fået, at \\(\\frac{\\partial f}{\\partial x}=0.4x-1.2\\) og \\(\\frac{\\partial f}{\\partial y}=0.6y-2.4\\). Du skal nu udvide regnearket på denne måde:\n\n\n\n\n\n\nI celle A2 skriver du = A1 - 0.1*(0.4*A1-1.2).\nI celle B2 skriver du = B1 - 0.1*(0.6*B1-2.4).\nI celle C2 skriver du f(A2,B2).\nI celle D2 skriver du (A2,B2,C2).\n\nDu kan nu markere række to, tage ved den lille kasse i nederste højre hjørne for at beregne ny punkter. Gør det!\nHvor mange opdateringer skal du lave, for at funktionsværdien ikke ser ud til at ændre sig mere?\nSvarer det minimum, du finder ved hjælp af gradientnedstigning til det minimum, som du tidligere har aflæst på grafen?\n\nTillykke! Du er nu kommet til \"After Ski\"!!"
  },
  {
    "objectID": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_del2.html#aktivitet-3---tabsfunktioner",
    "href": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_del2.html#aktivitet-3---tabsfunktioner",
    "title": "Del 2: Kunstige neuroner",
    "section": "Aktivitet 3 - Tabsfunktioner",
    "text": "Aktivitet 3 - Tabsfunktioner\nVi vil her se lidt nærmere på tabsfunktionen, men baseret på et meget lille træningsdatasæt.\nVi ser igen på medlemsapp’en til Good Food, som vi også beskrev i noten. Nu vil vi bare nøjes med at se på kundens alder, som inputvariabel:\n\n\\(x\\): kundens alder målt i år\n\nTargetværdien er igen:\n\\[\nt=\n\\begin{cases}\n1 & \\textrm{hvis tilbuddet aktiveres} \\\\\n0 & \\textrm{hvis tilbuddet ikke aktiveres} \\\\\n\\end{cases}\n\\]\nTræningsdatasættet består af følgende tre træningseksempler:\n\n\n\n\n\n\n\n\n\n\n\nNr. på træningseksempel \\(m\\)\nKundens alder \\(x^{(m)}\\)\nTargetværdi \\(t^{(m)}\\)\n\n\n\n\n\\(1\\)\n\\(25\\)\n\\(0\\)\n\n\n\\(2\\)\n\\(40\\)\n\\(0\\)\n\n\n\\(3\\)\n\\(60\\)\n\\(1\\)\n\n\n\n\n\nTabel 1: Et meget lille træningsdatasæt til Good Food app’en.\n\n\n\nTabsfunktionen bliver så:\n\\[\n\\begin{aligned}\nE &= \\frac{1}{2} \\sum_{m=1}^3 (t^{(m)}-\\sigma(w_0 + w_1 \\cdot x^{(m)}))^2 \\\\\n& = \\frac{1}{2}  ((t^{(1)}-\\sigma(w_0 + w_1 \\cdot x^{(1)}))^2 +\\\\\n&\\quad  \\qquad (t^{(2)}-\\sigma(w_0 + w_1 \\cdot x^{(2)}))^2 + \\\\\n  &\\quad \\qquad (t^{(3)}-\\sigma(w_0 + w_1 \\cdot x^{(3)}))^2) \\\\\n\\end{aligned}\n\\tag{1}\\]\n\n\n\n\n\n\nOpgave 5: Tabsfunktion\n\n\n\n\n\n\nOpskriv forskriften for tabsfunktionen \\(E\\) ved at indsætte træningseksemplerne fra tabel 1 i tabsfunktionen defineret i (1).\n\n\n\n\nI flere CAS programmer kan det give problemer at tegne grafen for \\(E\\), selvom du nu har forskriften for funktionen. Derfor kommer grafen her:\n\n\n\n\n\n\n\n\nFigur 1: Grafen for tabsfunktionen baseret på det lille træningsdatasæt i tabel 1.\n\n\n\n\nDet røde punkt svarer til minimum.\n\n\n\n\n\n\nOpgave 6: Minimum for tabsfunktionen\n\n\n\n\n\n\nAflæs \\(w_0\\)- og \\(w_1\\)-værdien for minimum på figur 1.\nBrug disse værdier til at opstille forskriften for sigmoid-funktionen, som bruges til at udregne outputværdien \\(o\\):\n\n\\[\no = \\sigma(x) = \\frac{1}{1+e^{-(w_0 +w_1 \\cdot x)}}\n\\]\n\nTegn grafen for denne sigmoid-funktion.\nSvar ved hjælp af grafen på følgende spørgsmål:\n\nFor hvilke værdier af kundens alder \\(x\\) får vi en outputværdi, som er meget tæt på \\(0\\) – svarende til at vi er ret sikre på, at kunden ikke vil aktivere tilbuddet.\nFor hvilke værdier af kundens alder \\(x\\) får vi en outputværdi, som er meget tæt på \\(1\\) – svarende til at vi er ret sikre på, at kunden vil aktivere tilbuddet.\nHvilken alder \\(x\\) svarer til en outputværdi på \\(0.5\\)?\n\nUdregn \\(\\sigma(25), \\sigma(40)\\) og \\(\\sigma(60)\\) svarende til de prædikterede outputværdier for træningsdatasættet."
  },
  {
    "objectID": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_del2.html#aktivitet-4---brug-af-app",
    "href": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_del2.html#aktivitet-4---brug-af-app",
    "title": "Del 2: Kunstige neuroner",
    "section": "Aktivitet 4 - Brug af app",
    "text": "Aktivitet 4 - Brug af app"
  },
  {
    "objectID": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_delxx.html",
    "href": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_delxx.html",
    "title": "Del 1: Aktiveringsfunktioner",
    "section": "",
    "text": "Forventet tid 1-2 x 90 min."
  },
  {
    "objectID": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_delxx.html#aktivitet-1",
    "href": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_delxx.html#aktivitet-1",
    "title": "Del 1: Aktiveringsfunktioner",
    "section": "Aktivitet 1",
    "text": "Aktivitet 1"
  },
  {
    "objectID": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_delxx.html#aktivitet-2",
    "href": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_delxx.html#aktivitet-2",
    "title": "Del 1: Aktiveringsfunktioner",
    "section": "Aktivitet 2",
    "text": "Aktivitet 2"
  },
  {
    "objectID": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_delxx.html#aktivitet-3",
    "href": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_delxx.html#aktivitet-3",
    "title": "Del 1: Aktiveringsfunktioner",
    "section": "Aktivitet 3",
    "text": "Aktivitet 3"
  },
  {
    "objectID": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_delxx.html#aktivitet-4",
    "href": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_delxx.html#aktivitet-4",
    "title": "Del 1: Aktiveringsfunktioner",
    "section": "Aktivitet 4",
    "text": "Aktivitet 4"
  },
  {
    "objectID": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_delxx.html#aktivitet-5",
    "href": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_delxx.html#aktivitet-5",
    "title": "Del 1: Aktiveringsfunktioner",
    "section": "Aktivitet 5",
    "text": "Aktivitet 5"
  },
  {
    "objectID": "undervisningsforloeb/Opdatering_af_vægte_i_NN_med_2_skjulte_lag.html",
    "href": "undervisningsforloeb/Opdatering_af_vægte_i_NN_med_2_skjulte_lag.html",
    "title": "Opdatering af vægte i et simpelt neuralt netværk med to skjulte lag",
    "section": "",
    "text": "Forudsætninger og tidsforbrug\n\n\n\n\n\n\nSimple neurale netværk.\nSigmoid aktiveringsfunktion.\nGradientnedstigning.\n\nForudsætningerne kan med fordel dækkes ved hjælp af noten om simple neurale netværk, da notationen derfra vil blive anvendt i dette forløb.\nTidsforbrug: Ca. 90 minutter."
  },
  {
    "objectID": "undervisningsforloeb/Opdatering_af_vægte_i_NN_med_2_skjulte_lag.html#et-meget-lille-datasæt",
    "href": "undervisningsforloeb/Opdatering_af_vægte_i_NN_med_2_skjulte_lag.html#et-meget-lille-datasæt",
    "title": "Opdatering af vægte i et simpelt neuralt netværk med to skjulte lag",
    "section": "Et meget lille datasæt",
    "text": "Et meget lille datasæt\nI neurale netværk er der ofte rigtige mange inputvariable (features), rigtigt mange vægte og rigtig mange træningsdata.\nFor bedre at forstå, hvordan vægtene opdateres i et neuralt netværk, vil vi her se på et meget lille eksempel, så det manuelt er muligt at lave opdateringen af vægtene.\nVi vil lave et netværk med 2 inputvariable (\\(x_1\\) og \\(x_2\\)), 1 neuron i det første skjulte lag (\\(y\\)), 1 neuron i det andet skjulte lag (\\(z\\)) og 1 neuron i outputlaget (\\(o\\)). Netværket er illustreret i figur 1.\n\n\n\n\n\n\nFigur 1: Grafisk illustration af et neuralt netværk med 2 inputvariable og to skjulte lag, som hver består af én neuron.\n\n\n\nKonkret vil vi se på to features \\(x_1\\) og \\(x_2\\) og en targetværdi \\(t\\) ud fra følgende træningsdatasæt:\n\n\n\n\\(x_1\\)\n\\(x_2\\)\n\\(t\\)\n\n\n\n\n1\n2\n0\n\n\n2\n3\n1\n\n\n3\n5\n0\n\n\n\nVi vælger en learning rate på\n\\[\\eta = 0.1,\\]\nsigmoid-funktionen som aktiveringsfunktion mellem lagene\n\\[\\sigma(x)=\\frac{1}{1+e^{-x}}\\] og squared error som tabsfunktion\n\\[E = \\frac{1}{2} \\sum_{m=1}^{M} \\left (t^{(m)}-o^{(m)} \\right)^2\\]\nEndeligt vælger vi alle startvægtene til at være \\(0.5\\), så \\[\nr_0=0.5 \\textrm{ (bias)},\\qquad r_1=0.5,\\qquad r_2=0.5\n\\]\n\\[\nv_0=0.5 \\textrm{ (bias)}, \\qquad v_1=0.5\\]\n\\[\nw_0=0.5 \\textrm{ (bias)}, \\qquad  w_1=0.5\n\\]"
  },
  {
    "objectID": "undervisningsforloeb/Opdatering_af_vægte_i_NN_med_2_skjulte_lag.html#opdateringsregler",
    "href": "undervisningsforloeb/Opdatering_af_vægte_i_NN_med_2_skjulte_lag.html#opdateringsregler",
    "title": "Opdatering af vægte i et simpelt neuralt netværk med to skjulte lag",
    "section": "Opdateringsregler",
    "text": "Opdateringsregler\nFra noten om simple neurale netværk har vi opdateringsreglerne, som vi nu skal til at anvende på det konkrete træningsdatasæt.\nFørst udregnes feedforward-udtrykkene: \\[\n   \\begin{aligned}\n   y^{(m)} &= \\sigma (r_0 + r_1 \\cdot x_1^{(m)} + r_2 \\cdot x_2^{(m)} + \\cdots + r_n \\cdot x_n^{(m)})  \\\\\n   z^{(m)} &= \\sigma (v_0 + v_1 \\cdot y^{(m)})  \\\\\n   o^{(m)} &= \\sigma(w_0 + w_1 \\cdot z^{(m)})\n   \\end{aligned}\n   \\] Herefter beregnes:\n\\[\n   \\begin{aligned}\n   \\delta_w^{(m)} &= (t^{(m)}-o^{(m)} ) \\cdot o^{(m)}  \\cdot (1-o^{(m)})  \\\\\n   \\delta_v^{(m)} &= \\delta_w^{(m)}\\cdot w_1 \\cdot z^{(m)} \\cdot (1-z^{(m)}) \\\\\n   \\delta_r^{(m)} &= \\delta_v^{(m)} \\cdot v_1 \\cdot y^{(m)} \\cdot (1-y^{(m)})\n   \\end{aligned}\n   \\] Vægtene kan nu opdateres:\n\\(w\\)-vægtene: \\[\n   \\begin{aligned}\n   w_0^{\\textrm{ny}} & \\leftarrow w_0 + \\eta \\cdot \\sum_{m=1}^{M} \\delta_w^{(m)} \\cdot 1\\\\\n   w_1^{\\textrm{ny}} & \\leftarrow w_1 + \\eta \\cdot \\sum_{m=1}^{M} \\delta_w^{(m)} \\cdot z^{(m)}\\\\\n   \\end{aligned}\n   \\]\n\\(v\\)-vægtene: \\[\n   \\begin{aligned}\n   v_0^{\\textrm{ny}} & \\leftarrow v_0 + \\eta \\cdot \\sum_{m=1}^{M} \\delta_v^{(m)}\\cdot 1\\\\\n   v_1^{\\textrm{ny}} & \\leftarrow v_1 + \\eta \\cdot \\sum_{m=1}^{M} \\delta_v^{(m)}\\cdot y^{(m)}\\\\\n   \\end{aligned}\n   \\]\n\\(r\\)-vægtene: \\[\n   \\begin{aligned}\n   r_0^{\\textrm{ny}} & \\leftarrow  r_0 + \\eta \\cdot \\sum_{m=1}^M \\delta_r^{(m)} \\cdot 1 \\\\\n   r_1^{\\textrm{ny}} & \\leftarrow  r_1 + \\eta \\cdot \\sum_{m=1}^M \\delta_r^{(m)} \\cdot x_1^{(m)} \\\\\n     & \\ \\ \\vdots & \\\\\n   r_n^{\\textrm{ny}} & \\leftarrow  r_n + \\eta \\cdot \\sum_{m=1}^M \\delta_r^{(m)} \\cdot x_n^{(m)}\n   \\end{aligned}\n   \\]"
  },
  {
    "objectID": "undervisningsforloeb/Opdatering_af_vægte_i_NN_med_2_skjulte_lag.html#beregninger",
    "href": "undervisningsforloeb/Opdatering_af_vægte_i_NN_med_2_skjulte_lag.html#beregninger",
    "title": "Opdatering af vægte i et simpelt neuralt netværk med to skjulte lag",
    "section": "Beregninger",
    "text": "Beregninger\n\n\n\n\n\n\nOpgave 1: Feedforward fra \\(x\\) til \\(y\\) lag\n\n\n\n\n\n\nUdregn \\[r_0 + r_1 \\cdot x_1^{(m)} + r_2 \\cdot x_2^{(m)}\\] for hver af de 3 træningseksempler.\nUdregn \\[y^{(m)}=\\sigma(r_0 +r_1 \\cdot x_1^{(m)} + r_2 \\cdot x_2^{(m)})\\] for hver af de 3 træningseksempler.\n\n\n\n\n\n\n\n\n\n\nOpgave 2: Feedforward fra \\(y\\) til \\(z\\) lag\n\n\n\n\n\n\nUdregn på tilsvarende vis \\(z^{(m)}\\) for hver af de 3 træningseksempler.\n\n\n\n\n\n\n\n\n\n\nOpgave 3: Feedforward fra \\(z\\) til \\(o\\) lag\n\n\n\n\n\n\nUdregn på tilsvarende vis \\(o^{(m)}\\) for hver af de 3 træningseksempler.\n\n\n\n\n\n\n\n\n\n\nOpgave 4: Opdatering af \\(w\\)-vægtene\n\n\n\n\n\n\nUdregn \\[\\delta_w^{(m)} = (t^{(m)}-o^{(m)}) \\cdot o^{(m)} \\cdot (1-o^{(m)})\\] for hver af de 3 træningseksempler.\nUdregn \\[\\sum_{m=1}^{3} \\delta_w^{(m)}\\]\nOpdatér \\(w_0\\)-vægten \\[w_0^{ny} \\leftarrow w_0 + \\eta \\cdot \\sum_{m=1}^{3} \\delta_w^{(m)}\\]\nUdregn \\[\\sum_{m=1}^{3} \\delta_w^{(m)} \\cdot z^{(m)}\\]\nOpdatér \\(w_1\\)-vægten \\[w_1^{ny} \\leftarrow w_1 + \\eta \\cdot \\sum_{m=1}^3 \\delta_w^{(m)} \\cdot z^{(m)}\\]\n\n\n\n\n\n\n\n\n\n\nOpgave 5: Opdatering af \\(v\\)-vægtene\n\n\n\n\n\n\nLav tilsvarende udregninger og opdatering af \\(v\\)-vægtene.\n\n\n\n\n\n\n\n\n\n\nOpgave 6: Opdatering af \\(r\\)-vægtene\n\n\n\n\n\n\nLav tilsvarende udregninger og opdatering af \\(r\\)-vægtene."
  },
  {
    "objectID": "undervisningsforloeb/Opdatering_af_vægte_i_NN_med_2_skjulte_lag.html#løsninger-til-opgaver",
    "href": "undervisningsforloeb/Opdatering_af_vægte_i_NN_med_2_skjulte_lag.html#løsninger-til-opgaver",
    "title": "Opdatering af vægte i et simpelt neuralt netværk med to skjulte lag",
    "section": "Løsninger til opgaver",
    "text": "Løsninger til opgaver\nFacitliste."
  },
  {
    "objectID": "undervisningsforloeb/klimaudfordring_innovation.html",
    "href": "undervisningsforloeb/klimaudfordring_innovation.html",
    "title": "Miljø- og klimaudfodringer",
    "section": "",
    "text": "Forudsætninger og tidsforbrug\n\n\n\n\n\nForløbet er et tværfagligt samarbejde med dansk og kræver kendskab til:\n\nPopulærvidenskabelige artikler som genre.\n\nTidsforbrug: ca. 4 x 90 minutter i hvert fag.\nI dette forløb skal I få en genial idé til en innovativ anvendelse af AI, som kan være med til at løse et aspekt af klimakrisen. I formidlingen af jeres innovative anvendelse af AI skal I kunne præsentere nogle af idéerne bag AI og argumentere for den fordel, det kan give.\nI skal overveje, hvor der i praksis er et område med betydning for klimakrisen og med adgang til store datamængder, hvor man eventuelt med fordel kan trække information ud af datamængderne ved at træne et kunstigt neuralt netværk."
  },
  {
    "objectID": "undervisningsforloeb/klimaudfordring_innovation.html#indhold-og-formål-i-matematik",
    "href": "undervisningsforloeb/klimaudfordring_innovation.html#indhold-og-formål-i-matematik",
    "title": "Miljø- og klimaudfodringer",
    "section": "Indhold og formål i matematik",
    "text": "Indhold og formål i matematik\n\nAt I bliver klædt på til at kunne skrive en formidlingsopgave i jeres kommende SRP med fagene dansk og matematik eller dansk i kombination med et naturvidenskabeligt fag.\nAt I øver jer i at skrive en smule stringent matematik med ræsonnementer baseret på et valg af et begrænset emne fra materialet her på siden (se anbefalinger nederst). I må gerne følge en kilde ret tæt, men I lære, at man demonstrerer forståelse ved at tilføje yderligere forklarende tekst og egne eksempler.\nAt I får en overordnet forståelse for matematikken bag AI og kan formidle nogle af de centrale idéer."
  },
  {
    "objectID": "undervisningsforloeb/klimaudfordring_innovation.html#indhold-og-formål-i-dansk",
    "href": "undervisningsforloeb/klimaudfordring_innovation.html#indhold-og-formål-i-dansk",
    "title": "Miljø- og klimaudfodringer",
    "section": "Indhold og formål i dansk",
    "text": "Indhold og formål i dansk\nI dansk har eleverne fået en introduktion til faglig formidling med afsæt i den særlige udfordring, der ligger i at etablere god formidling af videnskab til den almene borger. De har læst eksempler på populærvidenskabelige artikler og SRP-opgaver, og anvendt fagets teori og metoder til at analysere teksterne med henblik på at konkretisere, hvad den gode faglige formidling indebærer. Dernæst har de produceret egne populærvidenskabelige artikler med særligt fokus på layout, sprog og kommunikationssituation, og afslutningsvis opstiller de en danskfaglig analyse af deres eget produkt.\nBogen ”Del din viden” og Katinka Paludans speciale ”At fortælle om videnskab” har dannet teoretisk afsæt for arbejdet, og Paludan opstiller tre kriterier om den gode, faglige formidling, som har været rettesnor for elevernes egne produktioner."
  },
  {
    "objectID": "undervisningsforloeb/klimaudfordring_innovation.html#opgaveformulering",
    "href": "undervisningsforloeb/klimaudfordring_innovation.html#opgaveformulering",
    "title": "Miljø- og klimaudfodringer",
    "section": "Opgaveformulering",
    "text": "Opgaveformulering\n\nRedegør for dele af matematikken bag kunstig intelligens og præsenter et forslag til en mulig innovativ anvendelse af kunstig intelligens indenfor emnet ”klimaforandringer”.\nRedegør i den forbindelse for hvilket trænings- og testdata, der skal indsamles, og for fordelene ved den efterfølgende potentielle anvendelse af kunstig intelligens.\nSkriv en populærvidenskabelig artikel om jeres emne (omfang: 3-4 sider).\nBegrund jeres valg i forbindelse med layout, sprogbrug samt nyheds- og relevanskriterier og vurdér hvordan artiklen kan bidrage til nye indsigter og handlemuligheder."
  },
  {
    "objectID": "undervisningsforloeb/klimaudfordring_innovation.html#materiale",
    "href": "undervisningsforloeb/klimaudfordring_innovation.html#materiale",
    "title": "Miljø- og klimaudfodringer",
    "section": "Materiale",
    "text": "Materiale\nDansk: Changemaker-modellen.\nMatematik: Perceptroner, simple neurale netværk, gradientnedstigning og generelle neurale netværk."
  },
  {
    "objectID": "undervisningsforloeb/Opdatering_af_vægte_i_NN2_facit.html",
    "href": "undervisningsforloeb/Opdatering_af_vægte_i_NN2_facit.html",
    "title": "Facit til forløb om opdatering af vægte i et simpelt neuralt netværk med to skjulte lag",
    "section": "",
    "text": "Facit til opgave 1\n\n\n\n\n\n\\(y\\)-værdierne er\n0.8807971, 0.9525741, 0.9890131\n\n\n\n\n\n\n\n\n\nFacit til opgave 2\n\n\n\n\n\n\\(z\\)-værdierne er\n0.7191802, 0.7263709, 0.7299771\n\n\n\n\n\n\n\n\n\nFacit til opgave 3\n\n\n\n\n\n\\(o\\)-værdierne er\n0.702575, 0.7033258, 0.7037019\n\n\n\n\n\n\n\n\n\nFacit til opgave 4\n\n\n\n\n\n\n\\(\\delta_w\\)-værdierne er\n-0.1468124, 0.0619036, -0.1467257\nSummen\n\\(\\sum_{m=1}^3 \\delta_w^{(m)} =\\) -0.2316345\n\\(w_0\\)-vægten opdateres til\n\\(w_{0}^{ny}=\\) 0.4768365\nSummen\n\\(\\sum_{m=1}^{3} \\delta_w^{(m)} \\cdot z^{(m)} =\\) -0.167726\n\\(w_1\\)-vægten opdateres til\n\\(w_{1}^{ny}=\\) 0.4832274\n\n\n\n\n\n\n\n\n\n\nFacit til opgave 5\n\n\n\n\n\n\n\\(\\delta_v\\)-værdierne er\n-0.0148251, 0.0061519, -0.0144606\nSummen\n\\(\\sum_{m=1}^{3} \\delta_v^{(m)} =\\) -0.0231339\n\\(v_0\\)-vægten opdateres til\n\\(v_{0}^{ny}=\\) 0.4976866\nSummen\n\\(\\sum_{m=1}^{3} \\delta_v^{(m)}\\cdot y^{(m)} =\\) -0.0214995\n\\(v_1\\)-vægten opdateres til\n\\(v_{1}^{ny}=\\) 0.49785\n\n\n\n\n\n\n\n\n\n\nFacit til opgave 6\n\n\n\n\n\n\n\\(\\delta_r\\)-værdierne er\n-0.0007783, 0.0001390, -0.0000786\nSummen\n\\(\\sum_{m=1}^3 \\delta_r^{(m)} =\\) -0.0007179\n\\(r_0\\)-vægten opdateres til\n\\(r_{0}^{ny}=\\) 0.4999282\nSummen\n\\(\\sum_{m=1}^3 \\delta_r^{(m)} \\cdot x_1^{(m)} =\\) -0.0007360\n\\(r_1\\)-vægten opdateres til\n\\(r_{1}^{ny}=\\) 0.4999264\nSummen\n\\(\\sum_{m=1}^3 \\delta_r^{(m)} \\cdot x_2^{(m)} =\\) -0.0015325\n\\(r_2\\)-vægten opdateres til\n\\(r_{2}^{ny}=\\) 0.4998468"
  },
  {
    "objectID": "undervisningsforloeb/polynomium.html",
    "href": "undervisningsforloeb/polynomium.html",
    "title": "AI og rødder i andengradspolynomier",
    "section": "",
    "text": "Forudsætninger og tidsforbrug\n\n\n\n\n\nForløbet kræver kendskab til:\n\nRette linjer.\nAndengradspolynomier og rødder.\n\nTidsforbrug: Ca. 90 minutter.\nVi anbefaler, at I i dette forløb arbejder i grupper på 3-4 elever."
  },
  {
    "objectID": "undervisningsforloeb/polynomium.html#andengradspolynomier-og-rødder",
    "href": "undervisningsforloeb/polynomium.html#andengradspolynomier-og-rødder",
    "title": "AI og rødder i andengradspolynomier",
    "section": "Andengradspolynomier og rødder",
    "text": "Andengradspolynomier og rødder\nLad os lige starte med at minde om, at et andengradspolynomium er en funktion med en forskrift på formen \\[\nf(x)=ax^2 + bx + c, \\quad a \\neq 0\n\\] Grafen for et andengradspolynomium kaldes som bekendt for en parabel. I figur 1 ses tre eksempler på sådanne parabler.\n\n\n\n\n\n\nFigur 1: Graferne for tre forskellige andengradspolynomier.\n\n\n\nHvis vi løser andengradsligningen \\[\nf(x)=ax^2 + bx + c=0\n\\] finder vi andengradspolynomiets rødder. Men at løse \\(f(x)=0\\), svarer netop til at bestemme, hvor den tilhørende parabel skærer \\(x\\)-aksen. I figur 1 kan vi se, at den grønne parabel skærer \\(x\\)-aksen to steder. Det vil sige, at det tilhørende andengradspolynomium har to rødder. Den røde parabel skærer \\(x\\)-aksen ét sted – det tilhørende andengradspolynomium har altså én rod. Endelig kan vi se, at den blå parabel slet ikke skærer \\(x\\)-aksen, og det tilhørende andengradspolynomium har derfor ingen rødder.\nDu husker nok, hvordan man bestemmer antallet af rødder i et andengradspolynomium. Vi har brug for diskriminanten \\(d\\):\n\\[\nd = b^2-4ac\n\\tag{1}\\]\nOg der gælder så, at \\[\n\\begin{aligned}\n&d&lt;0: \\quad f \\text{ har ingen rødder} \\\\\n&d=0: \\quad f \\text{ har én rod} \\\\\n&d&gt;0: \\quad f \\text{ har to rødder} \\\\\n\\end{aligned}\n\\]\nIdéen er nu at undersøge, om vi kan bruge kunstig intelligens til at afgøre1, om et andengradspolynomium overhovedet har nogle rødder alene ude fra de tre koefficienter \\(a\\), \\(b\\) og \\(c\\) – og helt uden at kende noget til diskriminantformlen i (1)!\n1 Det er klart, at der er intet nyt under solen her. Vi kan jo bare selv beregne diskriminanten og svare på spørgsmålet. Men formålet er her at lære lidt om, hvad det vil sige at bruge kunstig intelligens i et tilfælde, hvor vi allerede selv kender svaret. Desuden findes der ingen lukkede løsningsformler for at bestemme rødder i et polynomium, så snart graden af polynomiet er \\(5\\) eller derover. Så idéen kan generaliseres, og så er den måske slet ikke så tosset endda!Inden vi går i gang, vil vi starte med at indse, at i stedet for at løse ligningen\n\\[\nA x^2 + Bx + C = 0, \\quad \\quad A \\neq 0\n\\tag{2}\\]\n(hvis du undrer dig, så er det med vilje, at vi lige nu bruger store bogstaver til koefficienterne), så kan vi lige så godt løse en ligning på formen\n\\[\nx^2 + bx +c =0\n\\] hvor altså \\(a=1\\). Det virker måske som en forsimpling, men da vi i (2) har antaget, at \\(A \\neq 0,\\) så kan vi dividere igennem med \\(A\\) og få\n\\[\n\\begin{aligned}\n\\frac{A}{A} x^2 + \\frac{B}{A} x + \\frac{C}{A} &= \\frac{0}{A} \\quad \\Leftrightarrow \\\\\nx^2 + \\frac{B}{A} x + \\frac{C}{A} &= 0.\n\\end{aligned}\n\\]\nDet betyder, at når vi skal bestemme rødder i andengradspolynomier, så er det tilstrækkeligt, at betragte andengradspolynomier med en forskrift på formen\n\\[\nf(x)=x^2+bx+c,\n\\] hvor \\(b=B/A\\) og \\(c=C/A\\). Man kan altså bare tage sit oprindelige andengradspolynomium \\(g(x)=Ax^2+Bx+C\\) og dividerer igennem med \\(A\\). Lad os illustrere det med et eksempel.\n\nEksempel 1 Betragt andengradspolynomiet med forskriften\n\\[\ng(x)=-4x^2+8x+12\n\\] Her har vi \\(A=-4, B=8\\) og \\(C=12\\). Løser vi ligningen \\(g(x)=0\\), finder vi ud af, at \\(g\\) har to rødder nemlig \\(-1\\) og \\(3\\). Dividerer vi forskriften for \\(g\\) igennem med \\(A=-4\\) fås et nyt andengradspolynomium \\(f\\) med forskrift\n\\[\nf(x)=x^2-2x-3\n\\] Her er koefficienterne \\(a=1, b=-2\\) og \\(c=-3\\). Men \\(f\\) har præcis samme rødder som \\(g\\) – nemlig \\(-1\\) og \\(3\\). Dette ses også illustreret i figur 2, hvor grafen for \\(g\\) og \\(f\\) begge skærer \\(x\\)-aksen i \\(-1\\) og \\(3\\).\n\n\n\n\n\n\nFigur 2: Grafen for \\(g(x)=-4x^2+8x+12\\) (den blå) og \\(f(x)=x^2-2x-3\\) (den grønne), som begge skærer \\(x\\)-aksen samme sted. Det vil sige, at \\(g\\) og \\(f\\) har de samme rødder. I dette tilfælde \\(-1\\) og \\(3\\)."
  },
  {
    "objectID": "undervisningsforloeb/polynomium.html#træningsdata",
    "href": "undervisningsforloeb/polynomium.html#træningsdata",
    "title": "AI og rødder i andengradspolynomier",
    "section": "Træningsdata",
    "text": "Træningsdata\nI dette eksempel vil vi nøjes med at se på, om vi kan bruge en metode fra kunstig intelligens, så vi forhåbentlig kan få svar på, om et givent andengradspolynomium enten har ingen eller en eller to rødder. Vi vil altså gerne finde en metode, som for en given parabel kan svare på, om parablen skærer \\(x\\)-aksen eller ej (og altså ikke hvor mange gange den eventuelt skærer \\(x\\)-aksen).\n\n\n\n\n\n\nOpgave 1: Rødder eller ej?\n\n\n\n\n\nOvervej følgende:\n\nHvordan laver man et andengradspolynomium, der har én eller to rødder?\nHvordan laver man et andengradspolynomium, som ingen rødder har?\n\n\n\n\nFor at bruge kunstig intelligens skal vi have lavet en masse eksempler på forskellige andengradspolynomier (det vil her sige med forskellige værdier af \\(b\\) og \\(c\\)) samtidig med, at vi også finder ud af, om det tilhørende andengradspolynomium har rødder eller ej. Den værdi, der angiver om et polynomium har rødder eller ej, kalder man for en targetværdi. Man kunne for eksempel gøre det ved at sige, at hvis et andengradspolynomium har én eller to rødder, så sætter vi targetværdien til \\(1\\), og hvis et andengradspolynomium ikke har nogle rødder, så sætter vi targetværdien til \\(-1\\). Tænk på det som en lille label du sætter på hvert eksempel, hvor du fortæller, hvad det rigtige svar er – “det er altså det her, jeg gerne vil have, at du lærer!”. Samlet set kalder man de forskellige eksempler inklusiv targetværdien for træningsdata.\n\n\n\n\n\n\nOpgave 2: Træningsdata\n\n\n\n\n\nAlle i gruppen skal nu:\n\nFinde et andengradspolynomium som ikke har nogle rødder (husk at \\(a=1\\)). Notér din værdi af \\(b\\) og \\(c\\) og sæt her targetværdien \\(t\\) til \\(-1\\).\nFinde et andengradspolynomium som har én eller to rødder (husk at \\(a=1\\)). Notér din værdi af \\(b\\) og \\(c\\) og sæt her targetværdien \\(t\\) til \\(1\\).\n\nNår alle har gjort det, skal I:\n\nIndsætte jeres forskellige værdier for \\(b, c\\) og \\(t\\) i et regneark, som er opbygget på denne måde:\n\n\nDisse data er nu præcis det, man kalder for træningsdata.\n\n\n\n\n\n\n\n\n\nOpgave 3: Træningsdata, fortsat\n\n\n\n\n\nI skal nu:\n\nIndtegn jeres værdier af \\(b\\) og \\(c\\) i et koordinatsystem, hvor værdien af \\(b\\) er på \\(x\\)-aksen, og værdien af \\(c\\) er på \\(y\\)-aksen. Hvis \\((b,c)\\)-punktet svarer til et andegradspolynomium, som har rødder (det vil sige, at \\(t=1\\)), farves punktet rødt og ellers farves det blåt (det vil sige, at \\(t=-1\\)). I videoen herunder er det vist, hvordan man gør i GeoGebra:"
  },
  {
    "objectID": "undervisningsforloeb/polynomium.html#træning-af-kunstig-intelligens",
    "href": "undervisningsforloeb/polynomium.html#træning-af-kunstig-intelligens",
    "title": "AI og rødder i andengradspolynomier",
    "section": "Træning af kunstig intelligens",
    "text": "Træning af kunstig intelligens\nEn simpel metode inden for kunstig intelligens er at prøve at bestemme en ret linje, som kan bruges til at adskille de røde punkter fra de blå punkter i det punktplot, som I har lavet i opgave 3.\nHvis man skal have en computer til at gøre det, så vil man typisk starte med en hel tilfældig ret linje med en ligning på formen\n\\[y=a \\cdot x+b\\]\nog så prøve at opdatere hældningen \\(a\\) og skæring med \\(y\\)-aksen \\(b\\), sådan at linjen bliver bedre og bedre til at adskille de røde punkter fra de blå.\nNu ser vi jo på andengradspolynomier med en forskrift på formen \\(f(x)=x^2+bx+c\\). Det vil sige, at \\(b\\) allerede har en betydning. Derfor er det ikke så hensigtsmæssigt at bruge \\(b\\) igen i ligningen for en ret linje. Derfor vælger vi her at beskrive den rette linje med en ligning på formen\n\\[\ny = w_1 \\cdot x + w_0\n\\] Det vil altså sige, at \\(w_1\\) er linjens hældning, og \\(w_0\\) er linjens skæring med \\(y\\)-aksen.\n\n\n\n\n\n\nOpgave 4: Bestemmelse af en linje som kan adskille de røde punkter fra de blå\n\n\n\n\n\n\nI inputfeltet i GeoGebra skal du taste: y=w1*x+w0.\nNår GeoGebra spørger, om du vil oprette skydere for w0 og w1, svarer du \"Opret skydere\".\nTræk i skyderne for w0 og w1 og prøv om du kan finde en ret linje, som kan adskille de røde punkter fra de blå.\n\n\n\n\n\n\n\n\n\n\nOpgave 5: Flere træningsdata\n\n\n\n\n\n\nAfgør om følgende andengradspolynomier har rødder og tilføj dem til dit træningsdata (husk ingen rødder svarer til at \\(t=-1\\) og det tilhørende punkt farves blåt, mens én eller to rødder svarer til \\(t=1\\) og punktet farves rødt):\n\n\\[\n\\begin{aligned}\nf_1(x) &= x^2 + 10x + 26 \\\\\nf_2(x) &= x^2 + 10x + 24\\\\\nf_3(x) &= x^2 + 5x + 6\\\\\nf_4(x) &= x^2 + 5x + 7 \\\\\nf_5(x) &= x^2 + 2x + 1\\\\\nf_6(x) &= x^2 + 2x + 2 \\\\\n\\end{aligned}\n\\]\n\nKan det lade sig gøre at adskille de to grupper med den rette linje, du fandt i opgave 4?\nHvis ikke kan du så bestemme en ny ret linje, som kan adskille de røde punkter fra de blå?\n\n\n\n\nSom du netop har opdaget, er det en umulig opgave, vi har givet os selv! Vi kan ikke finde en ret linje, som i alle tilfælde kan bruges til at adskille de røde punkter fra de blå. 😕\nLad os se på hvorfor. Som tidligere nævnt har vores linje en ligning på formen\n\\[\ny=w_1 \\cdot x + w_0\n\\]\nMen nu har vi \\(b\\)-værdier ud af \\(x\\)-aksen og \\(c\\)-værdier op af \\(y\\)-aksen, så i virkeligheden ser ligningen sådan her ud:\n\\[\nc=w_1 \\cdot b + w_0\n\\tag{3}\\]\nhvor \\(b\\) og \\(c\\) jo svarer til koefficinter i forskellige andengradspolymonier med forskrift \\(f(x)=x^2+bx+c\\).\nVi husker nu på formlen for diskriminanten \\(d=b^2-4ac=b^2-4c\\), da \\(a=1\\) i vores eksempel. Skillelinjen for om andengradspolynomiet har ingen eller flere rødder, går netop ved \\(d=0\\). Det vil sige\n\\[\nb^2-4c =0\n\\tag{4}\\]\nsom kan omskrives til\n\\[\nc = \\frac{1}{4}b^2\n\\tag{5}\\]\nMen vi kan ikke finde nogle værdier af \\(w_0\\) og \\(w_1\\), så udtrykket i (3) kommer til at svare til udtrykket i (5). Det er fordi, at i (3) indgår der kun et \\(b\\), mens der i (5) indgår et \\(b^2\\). Denne observation giver os imidlertid også en løsning på vores problem. I stedet for at lade træningsdata bestå af \\(b\\)- og \\(c\\)-værdier, så vil vi i stedet lade træningsdata bestå af \\(b^2\\)- og \\(c\\)-værdier! Det vil sige, at vi ud af \\(x\\)-aksen vil afsætte \\(b^2\\) og op af \\(y\\)-aksen, vil vi afsætte \\(c.\\)\n\n\n\n\n\n\nOpgave 6: Transformerede træningsdata\n\n\n\n\n\n\nBrug dit regneark fra tidligere og udregn \\(b^2\\).\nIndtegn dine værdier af \\(b^2\\) og \\(c\\) i et nyt koordinatsystem, hvor værdien af \\(b^2\\) er på \\(x\\)-aksen, og værdien af \\(c\\) er på \\(y\\)-aksen. Hvis \\((b^2,c)\\)-punktet svarer til et andegradspolynomium, som har rødder, farves punktet rødt og ellers farves det blåt.\nHvilken linje kan du vælge til at adskille de to grupper?\n\n\n\n\nIdéen med at prøve at adskille to grupper af punkter med en ret linje bruges blandt andet i den AI-metode, som kaldes for perceptroner. Metoden kan bruges, når man gerne vil kunne adskille to grupper af punkter fra hinanden baseret på en række forskellige værdier – disse værdier kalder man for features. Du kender måske kandidattests, hvor man på baggrund af svarene fra en række spørgsmål gerne vil kunne forudsige, om en person vil stemme på rød eller blå blok til det næste valg. Det kunne man for eksempel bruge en perceptron til at hjælpe med at afgøre, og det kan du læse meget mere om her.\nHvis du vil prøve at bruge den metode på dine data om andengradspolynomier, kan du gøre det her."
  },
  {
    "objectID": "undervisningsforloeb/hvem_ligner_du_mest.html",
    "href": "undervisningsforloeb/hvem_ligner_du_mest.html",
    "title": "Hvem ligner du mest?",
    "section": "",
    "text": "Forudsætninger og tidsforbrug\n\n\n\n\n\nForløbet kræver kendskab til:\n\nAfstand mellem to punkter.\n\nTidsforbrug: Ca. 2 x 90 minutter."
  },
  {
    "objectID": "undervisningsforloeb/hvem_ligner_du_mest.html#introduktion",
    "href": "undervisningsforloeb/hvem_ligner_du_mest.html#introduktion",
    "title": "Hvem ligner du mest?",
    "section": "Introduktion",
    "text": "Introduktion\nVi har apps på vores telefoner eller computere, som ud fra et billede kan genkende personer eller fra nogle få strofer kan genkende en sang. Der er scannere i lufthavne og andre steder, som kan genkende farlige ting, og biler har autopiloter, der selv holder afstanden til forankørende. Vi har også apps, som går den anden vej, og forvrænger et billede af en person, så personen bliver svær at genkende, men ofte alligevel kan genkendes, selvom ansigtet er fordrejet.\nSå alle steder og hele tiden foregår der bevist eller ubevist en skelnen mellem forskellige kategorier, men hvordan foregår denne skelnen i grunden? Hvis vi skulle svare fyldestgørende på dette spørgsmål, om overhovedet muligt, ville det nok betyde et langt studie på universitetet og sikkert mere end dette, men lad os starte med et meget simpelt eksempel, og tage den derfra.\nVi får brug for din viden om afstande mellem punkter, men kommer også til senere at se på andre former for afstande. Det er en fordel af lave opgaverne i grupper, da der kan blive en del af diskutere."
  },
  {
    "objectID": "undervisningsforloeb/hvem_ligner_du_mest.html#video-hvem-ligner-du-mest",
    "href": "undervisningsforloeb/hvem_ligner_du_mest.html#video-hvem-ligner-du-mest",
    "title": "Hvem ligner du mest?",
    "section": "VIDEO: Hvem ligner du mest?",
    "text": "VIDEO: Hvem ligner du mest?\nI denne video gives en kort introduktion til forløbet."
  },
  {
    "objectID": "undervisningsforloeb/hvem_ligner_du_mest.html#case-1-afstand-mellem-to-punkter",
    "href": "undervisningsforloeb/hvem_ligner_du_mest.html#case-1-afstand-mellem-to-punkter",
    "title": "Hvem ligner du mest?",
    "section": "Case 1 – Afstand mellem to punkter",
    "text": "Case 1 – Afstand mellem to punkter\n\n\n\n\n\n\nOpgave 1\n\n\n\n\n\nPå figur 1 nedenfor er der \\(10\\) røde punkter, \\(10\\) blå punkter og \\(10\\) grønne punkter – samt et enkelt gråt punkt \\(P\\) i midten. Et af de blå punkter er særligt markeret, men da det ligger ret langt fra \\(P\\) bør det nok ikke betyde så meget for, hvilket farve \\(P\\) skal have, som de punkter, der ligger tættere på \\(P\\)\nVurdér ud fra de øvrige punkter i nærheden af \\(P\\), om du synes, at \\(P\\) bør være rødt, blåt eller grønt så det mest ligner sine naboer.\n\n\n\n\n\n\n\n\n\nFigur 1: Koordinatsystem med \\(10\\) røde punkter, \\(10\\) blå punkter og \\(10\\) grønne punkter – samt et enkelt gråt punkt \\(P\\).\n\n\n\n\n\n\n\n\n\nOpgave 2\n\n\n\n\n\nPå figur 2 er der andre \\(31\\) punkter, samt en cirkel med radius \\(10\\) omkring det grå punkt \\(P(15,15)\\).\nTæl hvor mange røde, blå og grønne punkter, der ligger inde i cirklen. Kan det bruges til at beslutte, hvilken farve det grå punkt bør have?\n\n\n\n\n\n\n\n\n\nFigur 2: Koordinatsystem med \\(31\\) punkter, samt en cirkel med radius \\(10\\) omkring det grå punkt \\(P(15,15)\\)\n\n\n\n\n\n\n\n\n\nOpgave 2, fortsat\n\n\n\n\n\nHvilket resultat giver det, hvis cirklens radius kun var halvt så stor? Brug app’en nedenfor.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpgave 3\n\n\n\n\n\nDet går nok ikke i længden blot at ville vurdere på øjemål, så du må til at regne lidt. I tabellen herunder er koordinater og farver på de \\(10\\) punkter, der ligger tættest på det grå punkt i opgave 2.\nUdregn afstanden fra det grå punkt \\(P(15,15)\\) til hver af disse \\(10\\) punkter.\nAfgør så, hvor mange af hver farve, der ligger indenfor en cirkel med radius \\(5\\) omkring det grå punkt. Det er nok specielt det blå punkt lige på kanten af cirklen, hvor beregningen er vigtig, men hvis en computer skal lave arbejdet automatisk, vil den jo beregne alle afstandene, da den ikke bare kan “kigge på figuren”, som et menneske kan.\nHvilken farve tyder det på, at det grå punkt bør have?\nTabellens data er punkter i kommatal. F.eks. er det første blå punkt \\((13,8 ; 19,9)\\), så det har x-koordinaten \\(13,8\\) og y-koordinaten \\(19,9\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\nFarve\n1\n2\n3\n4\n\n\n\n\nBlå\n\\((13,8 ; 19,9)\\)\n\\((8,2 ; 14,9)\\)\n\\((16,4 ; 14,1)\\)\n\\((15,5 ; 13,1)\\)\n\n\nRød\n\\((10,6 ; 16,0)\\)\n\\((16,3 ; 15,2)\\)\n\\((15,6 ; 11,3)\\)\n\n\n\nGrøn\n\\((11,1 ; 18,6)\\)\n\\((16,4 ; 17,5)\\)\n\\((21,7 ; 13,4)\\)\n\n\n\n\n\n\n\n\n\n\nOpgave 4\n\n\n\n\n\nOvervej, hvad der sker, hvis cirklens radius vælges som en meget lille værdi eller som en meget stor værdi i forhold til at bruge metoden til at bestemme, hvilken farve det grå punkt bør have. Kan det give problemer?\n\n\n\n\n\n\n\n\n\nOpgave 5\n\n\n\n\n\n\nI app’en herunder er \\(27\\) andre punkter indsat i et koordinatsystem, og der er tegnet en cirkel med centrum i det grå punkt \\(P(15,15)\\). Ændr på radius af cirklen og se, om det gør en forskel.\nDiskutér, hvilken radius, der er bedst.\n\n\n\n\n\n\n\nAfslutning på case 1\nDet bliver nok klart, at der er brug for en metode til at beslutte, hvor stor radius skal være for at få det bedste resultat. Kort og lidt simpelt forklaret, involverer det noget, som man kalder træningsdata og testdata. Man har f.eks. 1000 punkter, som man kender farven på. Man lader så som om, at man ikke kender farven på f.eks. 200 af punkterne (som man så kalder testdata). Så bruger man de øvrige 800 punkter (træningsdata) til at forudsige farven af hver af de 200 punkter i testdata. Dette gør man for forskellige værdier af radius, hvorefter man vælger den radius, der forudsiger flest af de 200 punkters farve korrekt. Hvis f.eks. radius 5 forudsiger 121 punkters farve korrekt, radius 10 furudsiger 135 punkters farve korrekt, og radius 20 kun forudsiger 87 punkters farve korrekt, så har radius 10 jo klaret sig bedst."
  },
  {
    "objectID": "undervisningsforloeb/hvem_ligner_du_mest.html#case-2-manhattan-afstand",
    "href": "undervisningsforloeb/hvem_ligner_du_mest.html#case-2-manhattan-afstand",
    "title": "Hvem ligner du mest?",
    "section": "Case 2 – Manhattan afstand",
    "text": "Case 2 – Manhattan afstand\nI nogle situationer giver den almindelige afstand mellem punkter ikke så god mening. F.eks. er de fleste veje på Manhattan i New York enten nord-syd eller øst-vest, så man kan ikke bare gå eller køre “på skrå”, men kun lodret eller vandret.\nHvis vi ser på punkterne \\(P(2,3)\\) og \\(Q(5,7)\\), så er den almindelige afstand \\(5\\) vha. Pythagoras, mens Manhattan afstanden er \\(3+4=7\\). Dette er illustreret på figur 3.\n\n\n\n\n\n\nFigur 3: Den almindelige afstand mellem punkterne \\(P(2,3)\\) og \\(Q(5,7)\\) er \\(5\\), mens Manhattan afstanden er \\(7\\).\n\n\n\n\n\n\n\n\n\nOpgave 6\n\n\n\n\n\nIndtegn punkterne \\(A(1,7)\\), \\(B(3,4)\\) og \\(C(5,6)\\) i et koordinatsystem.\nUdregn både almindelig afstand og Manhattan afstand mellem hvert par af punkter.\n\n\n\n\n\n\n\n\n\nOpgave 7\n\n\n\n\n\nI eksemplet og i opgave 6 var Manhattan afstanden større end den almindelige afstand, men kan Manhattan afstanden være mindre end den almindelige afstand eller kan de to afstande være ens?\n\n\n\n\n\n\n\n\n\nOpgave 8\n\n\n\n\n\nSe på figur 4 fra opgave 2 igen.\nPunkterne inde i cirklen har en almindelig afstand på under \\(10\\) til det grå punkt, men hvilke af punkterne har en Manhattan afstand på under \\(10\\) til det grå punkt?\nDen almindelige afstand giver en cirkel med det grå punkt i centrum, men hvilken figur giver Manhatten afstand omkring det grå punkt?\nHvilken farve bør det grå punkt derfor have, hvis Manhattan afstanden benyttes? Giver det samme resultatet, som du fik i opgave 2?\n\n\n\n\n\n\n\n\n\nFigur 4: Koordinatsystem med \\(31\\) punkter, samt en cirkel med radius \\(10\\) omkring det grå punkt \\(P(15,15)\\)\n\n\n\n\n\n\n\n\n\nOpgave 9\n\n\n\n\n\nOpstil en formel for den almindelige afstand mellem to punkter med koordinaterne \\((x_1, y_1)\\) og \\((x_2, y_2)\\). Det er en formel, du kender i forvejen.\nOpstil tilsvarende en formel for Manhattan afstanden. Det er nok ikke en formel, du har set før.\nDu kan læse mere om Manhattan afstanden her."
  },
  {
    "objectID": "undervisningsforloeb/hvem_ligner_du_mest.html#case-3-hvor-ens-er-to-tekster",
    "href": "undervisningsforloeb/hvem_ligner_du_mest.html#case-3-hvor-ens-er-to-tekster",
    "title": "Hvem ligner du mest?",
    "section": "Case 3 – Hvor ens er to tekster?",
    "text": "Case 3 – Hvor ens er to tekster?\nI forbindelse med at undersøge om en tekst, f.eks. en dansk stil, er plagiat, bliver det relevant at sammenligne, hvor ens to tekster er. Helt så avanceret bliver det dog ikke her.\nVi vil kun se meget simpelt på ord med \\(5\\) bogstaver, og hvordan man f.eks. kan måle afstande mellem forskellige ord. Vi vil se på alle kombinationer af \\(5\\) bogstaver, også f.eks. xtmsp, selvom de ikke er normale ord.\n\n\n\n\n\n\nOpgave 10\n\n\n\n\n\nI tabellen herunder ses ordet “nedes” sammen med ordene “model”, “metal” og “nudts”.\n\n\n\n\n\n\n\n\n\n\n\n\n\nn\ne\nd\ne\ns\n\n\n\n\n\n\nm\no\nd\ne\nl\n\n\n\n\nm\ne\nt\na\nl\n\n\n\n\nn\nu\nd\nt\ns\n\n\n\n\nHvilket af ordene “model”, “metal” og “nudts” synes du, at ordet “nedes” ligner mest. Begrund dit svar.\n\n\n\n\n\n\n\n\n\nOpgave 11\n\n\n\n\n\nHvis vi vælger, at afstanden mellem to ord er antallet af bogstaver, som er forskellige incl. placering, så er afstanden mellem “xtmsp” og “xmtsq” \\(3\\), da kun \\(2\\) af de \\(5\\) bogstaver matcher incl. placering i de to ord, nemlig x og s.\nUdregn med den metode afstanden mellem “nedes” og hver af de \\(3\\) ord i opgave 10. Var det sådan du allerede havde gjort det i opgave 10, eller gav dette et andet resultat?\n\n\n\n\n\n\n\n\n\nOpgave 12\n\n\n\n\n\nOvervej og diskuter andre måder at regne afstand mellem to ord på hver \\(5\\) bogstaver. Det kunne f.eks. være noget, hvor ombytning af to nabobogstaver giver mindre afstand end helt tilfældige andre bogstaver, så f.eks. “kolon” og “kloon” er tættere på hinanden end “kolon” og “kston”."
  },
  {
    "objectID": "undervisningsforloeb/hvem_ligner_du_mest.html#case-4-dna-strenge-og-alignment",
    "href": "undervisningsforloeb/hvem_ligner_du_mest.html#case-4-dna-strenge-og-alignment",
    "title": "Hvem ligner du mest?",
    "section": "Case 4 – DNA-strenge og alignment",
    "text": "Case 4 – DNA-strenge og alignment\nUden i øvrigt at komme ind på biologien repræsenteres DNA som meget lange tekststrenge. Når mennesker og chimpanser er meget ens, kommer det til udtryk ved, at DNA-strengen for et menneske ligner den for en chimpanse meget, der er altså en kort afstand mellem DNA for et menneske og DNA for en chimpanse. Indenfor biologien kaldes dette for alignment. I stedet for at sammenligne på DNA niveau, sammenlignes også nogle gange på aminosyre niveau, hvilket vi vil bruge her,\nFølgende eksempel, der viser et meget lille udsnit af sådanne koder fra mus, rotter, mennesker og gær er taget fra Tema12-Link5.pdf (nucleus.dk), der kan anbefales, hvis man ønsker at arbejde mere med alignment.\n\n\n\nDyr\nKode\n\n\n\n\nMus\nS W A W A E G W T R Y G P\n\n\nRotte\nK W V W A E G W T R Y G P\n\n\nMenneske\nA W A W A E G W T R Y G P\n\n\nGær\nE W L R K P G W V K Y V P\n\n\n\nHvis afstanden her regnes som antal bogstaver, der er forskellige, ses det at afstanden mellem mus og rotte er på \\(2\\), som vist nedenfor.\n\n\n\nDyr\nKode\n\n\n\n\nMus\nS W A W A E G W T R Y G P\n\n\nRotte\nK W V W A E G W T R Y G P\n\n\n\n\n\n\n\n\n\nOpgave 13\n\n\n\n\n\nUdregn på tilsvarende vis afstandene mellem mus-menneske, mus-gær, rotte-menneske, rotte-gær og menneske-gær.\n\n\n\nNår resultatet sikkert virker overraskende, skyldes det, at vi kun har set på et meget lille udsnit af DNA for de fire. I figur 5 har man set på hele det protein, som udsnittet stammer fra, og her bliver resultatet mere som forventet.\n\n\n\n\n\n\nFigur 5: De faktiske afstande mellem mus-menneske, mus-gær, rotte-menneske, rotte-gær og menneske-gær."
  },
  {
    "objectID": "undervisningsforloeb/hvem_ligner_du_mest.html#case-5-hvilken-politiker-er-du-mest-enig-med",
    "href": "undervisningsforloeb/hvem_ligner_du_mest.html#case-5-hvilken-politiker-er-du-mest-enig-med",
    "title": "Hvem ligner du mest?",
    "section": "Case 5 – Hvilken politiker er du mest enig med?",
    "text": "Case 5 – Hvilken politiker er du mest enig med?\nOp til både folketingsvalg og kommunal- og regionalvalg kan man svare på en række spørgsmål, hvorefter ens svar bliver sammenlignet med politikernes svar på de samme spørgsmål. Herefter kan man så se, hvem man er mest enig med.\nHer er et eksempel fra kommunal- og regionalvalget i 2021.\nTag kandidattesten Kommunalvalg 2021 - Altinget - Alt om politik: altinget.dk\n\n\n\n\n\n\nOpgave 14\n\n\n\n\n\nKlik på linket ovenfor, vælg din egen kommune i testen og besvar spørgsmålene. Se derefter, hvem dine svar er mest enige med, og hvor mange procent enige I er.\n\n\n\nMen hvordan virker det mon? Hvordan vurderes, hvilken kandidat du er mest enig med, og hvordan udregnes, hvor mange procent enige I er?\nTil hvert spørgsmål kan der svares “helt uenig”, “uenig”, “enig” eller “helt enig”, men desuden er der en skjult “neutral” mulighed i midten, som man ikke kan vælge.\n\n\n\nHelt uenig\nUenig\nNeutral\nEnig\nHelt enig\n\n\n\nAfstanden mellem to svar regnes som antal “felter” i tabellen, så afstanden mellem Uenig og Enig er \\(2\\), mens afstanden mellem Enig og Helt enig er \\(1\\), og den største afstand er \\(4\\).\nI figur 6 ses en persons svar og et partis svar på \\(23\\) spørgsmål til kommunalvalget i 2021. Ved et partis svar forstås det svar, som flest af kandidaterne fra partiet har givet (ved lighed afgjort ud af, hvilken kandidat, der står først på listen). Så det er typetallet (typesvaret), der er anvendt for partierne, ikke gennemsnittet af svarene fra partiets kandidater. Figuren er fra testen på Altinget. Bemærk, at antallet af spørgsmål kan variere fra kommune til kommune, så du har måske færre eller flere spørgsmål.\n\n\n\n\n\n\nFigur 6: En persons svar (sort) og et partis svar (rød) på \\(23\\) spørgsmål til kommunalvalget i 2021.\n\n\n\nAfstanden i det første spørgsmål er \\(1\\), afstanden i det andet spørgsmål også \\(1\\) og afstanden i det tredje spørgsmål er \\(2\\) pga. den skjulte “neutral” mulighed i midten.\n\n\n\n\n\n\nOpgave 15\n\n\n\n\n\nDe 3 første afstand er altså 1, 1 og 2. Udregn afstanden for hver af de øvrige \\(20\\) spørgsmål.\nLæg så afstandene sammen, hvilket svarer til en form for Manhattan afstand, da afstanden regnes for hvert enkelt spørgsmål for sig. Hvilken samlet afstand giver det?\n\n\n\n\n\n\n\n\n\nOpgave 16\n\n\n\n\n\nHvad er den mindst mulig samlede afstand for de \\(23\\) spørgsmål? Hvordan skal svarene for partiet og for vælgeren se ud fra at få denne afstand?\nHvad er den størst mulige afstand, og hvordan skal svarene så se ud?\n\n\n\n\n\n\n\n\n\nOpgave 17\n\n\n\n\n\nPå figur 7 ses det, at siden angiver, at enigheden med Socialdemokratiet er på \\(79 \\%\\).\nOvervej, hvordan den afstand du udregnede i opgave 15 og den største mulige afstand, som du fandt i opgave 16, kan betyde, at enigheden er \\(79 \\%\\).\n\n\n\n\n\n\n\n\n\nFigur 7: På siden angives det, at enigheden med Socialdemokratiet er på \\(79 \\%\\).\n\n\n\n\n\n\n\n\n\nOpgave 18\n\n\n\n\n\nVend tilbage til dine egne svar på testen.\nBeregn afstand og procent i forhold til den kandidat, du var mest enig med, og den kandidat, du var mest uenig med.\nBeregn desuden afstand og procent til det parti, du var mest enig med, og til det parti, du var mest uenig med.\nPasser dine udregninger med sidens procenter?\n\n\n\n\n\n\n\n\n\nOpgave 19 (svær)\n\n\n\n\n\nDen kandidat, som svarene i opgave 15 var mest enig med, giver en procent på \\(76 \\%\\), så procenten for samtlige kandidater fra Socialdemokratiet er altså lavere end procenten for selve partiet.\nDet virker måske umiddelbart underligt. Overvej, hvorfor det faktisk er korrekt ud fra den metode, som siden anvender til beregningerne.\nDiskutér derefter, om procenten for partiet kunne være beregnet anderledes."
  },
  {
    "objectID": "apps.html",
    "href": "apps.html",
    "title": "AI apps",
    "section": "",
    "text": "Diverse apps til træning af kunstig intelligens.\n\n\n\n\n\n\n\n\n\n\nPerceptron app\n\n\nHer kan du træne en perceptron med dine egne data. Der er mulighed for at vælge forskellige aktiveringsfunktioner sammen med den kvadratiske tabsfunktion.\n\n\n\n\n\n\n\n\n\n\n\n\n\nLogistisk regression app\n\n\nHer kan du lave logistisk regrssion med dine egne data.\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "undervisningsforloeb/kNN_overvaagning_featureskalering.html",
    "href": "undervisningsforloeb/kNN_overvaagning_featureskalering.html",
    "title": "Feature-skalering på data fra overvågningsforløb",
    "section": "",
    "text": "Forudsætninger og tidsforbrug\n\n\n\n\n\n\nForløbet kræver, at man har gennemgået forløbet Overvågning i Monitorbian.\nStikprøvespredning.\n\nTidsforbrug: Ca. 90 minutter."
  },
  {
    "objectID": "undervisningsforloeb/kNN_overvaagning_featureskalering.html#de-konkrete-features",
    "href": "undervisningsforloeb/kNN_overvaagning_featureskalering.html#de-konkrete-features",
    "title": "Feature-skalering på data fra overvågningsforløb",
    "section": "De konkrete features",
    "text": "De konkrete features\nI datasættet er fodarealerne målt i \\(cm^2\\) med værdier fra 138 til 334, mens højderne er målt i \\(cm\\) med værdier fra 62 til 155. Så variationsbredden i fodarealer uden enhed er ca. 200, mens variationsbredden i højder uden enhed er ca. 100. Så når vi med kNN bestemmer nærmeste naboer, vil højden ofte betyde mere end fodarealet, da højderne ligger tættere på hinanden.\n\n\n\n\n\n\nOpgave 1: Illustration af de konkrete features\n\n\n\n\n\nDatasæt: Træningsdata.\n\nLav et punktplot, hvor datapunkterne for Fedtmule er røde, datapunkterne for Anders And er blå, og der desuden er et gråt punkt i \\((240 \\ cm^2, 88 \\  cm)\\). Dette kan f.eks. gøres ret let i GeoGebra, se evt. denne video . Hvis du hellere vil lave i det eget CAS-værktøj, men ikke helt ved hvordan, må du spørge din lærer.\nVurder, hvilke \\(6\\) punkter, der ligger tættest på det grå punkt, eventuelt ved at tilføje en cirkel med centrum i det grå punkt med en radius, så \\(6\\) af de øvrige punkter ligger i cirklen."
  },
  {
    "objectID": "undervisningsforloeb/kNN_overvaagning_featureskalering.html#enheden-på-data-ændres",
    "href": "undervisningsforloeb/kNN_overvaagning_featureskalering.html#enheden-på-data-ændres",
    "title": "Feature-skalering på data fra overvågningsforløb",
    "section": "Enheden på data ændres",
    "text": "Enheden på data ændres\nMen hvad ville der ske, hvis vi anvendte en anden enhed for eksempel for højderne. Hvad hvis vi i stedet målte højderne i \\(mm\\)? Så bliver variationsbredden i højderne ca. \\(1000\\), mens variationsbredden for fodarealerne stadig er ca. \\(200\\). Så vi må nu forvente, at fodarealerne betyder mere end højderne, når vi bestemmer nærmeste naboer, da fodarealerne nu ligger tættere på hinanden end højderne. Det skal vi se på i de følgende opgaver.\n\n\n\n\n\n\nOpgave 2: Illustration med højder i \\(mm\\)\n\n\n\n\n\n\nLav samme punktplot som før, men nu skal alle \\(y\\)-koordinaterne være 10 gange så store, da de skal regnes i \\(mm\\) (det gælder også det grå punkt).\nVurder igen, hvilke \\(6\\) punkter, der ligger tættest på det grå punkt, eventuelt ved hjælp af en cirkel.\nDiskuter og vurder, om det fik den betydning, at fodarealerne nu betyder mere end før i forhold til kNN.\n\n\n\n\nDet er naturligvis ikke praktisk, hvis den valgte enhed på data har betydning for, hvilke punkter der er tættest på hinanden."
  },
  {
    "objectID": "undervisningsforloeb/kNN_overvaagning_featureskalering.html#metode-til-at-give-begge-features-samme-vægt",
    "href": "undervisningsforloeb/kNN_overvaagning_featureskalering.html#metode-til-at-give-begge-features-samme-vægt",
    "title": "Feature-skalering på data fra overvågningsforløb",
    "section": "Metode til at give begge features samme vægt",
    "text": "Metode til at give begge features samme vægt\nSom du måske har gættet, vil det bedste nok være, at fodareal og højde betød lige meget.\nDet gøres i to trin. Først \"flyttes\" data, så både værdierne for fodarealer og værdierne for højder ligger omkring \\(0\\). På den måde vil værdier under gennemsnittet blive negative og værdier over gennemsnittet positive.\n\n\n\n\n\n\nOpgave 3: Data centreres omkring \\((0, 0)\\)\n\n\n\n\n\n\nBeregn middelværdien af fodarealerne fra de 20 datapunkter.\nTræk middelværdien fra værdierne for fodareal for alle 20 datapunkter og det grå punkt.\nBeregn tilsvarende middelværdien af højderne fra de 20 datapunkter.\nTræk middelværdien fra værdierne for højde for alle 20 datapunkter og det grå punkt.\n\n\n\n\nDernæst gøres variationsbredderne nogenlunde lige store. Man kunne dividere alle værdierne for fodarealer med variationsbredden for fodarealerne, og tilsvarende for højderne. Derved ville de to features begge få en variationsbredde på \\(1\\), og dermed være ens. Man vælger dog at gøre noget lidt anderledes, blandt andet fordi variationsbredden kun afhænger af to af punkterne og ikke dem alle. I stedet for at dividere med variationsbredden, divideres med spredningen, hvorefter de fleste dataværdier kommer til at ligge mellem \\(-2\\) og \\(2\\) for begge features.\n\n\n\n\n\n\nOpgave 4: Variationsbredden gøres nogenlunde ens\n\n\n\n\n\n\nBeregn stikprøvespredning af fodarealerne fra de 20 datapunkter.\nDivider de justerede fodarealer fra opgave 3 med spredningen, også værdien for det grå punkt.\nBeregn tilsvarende stikprøvespredningen af højderne fra de 20 datapunkter.\nDivider de justerede højder fra opgave 3 med spredningen, også værdien for det grå punkt.\n\n\n\n\nVi skal have set, hvordan det ser ud.\n\n\n\n\n\n\nOpgave 5: Illustration med justerede værdier for begge features\n\n\n\n\n\n\nLav samme punktplot som tidligere, men nu med de justerede værdier.\nVurder igen, hvilke \\(6\\) punkter, der ligger tættest på det grå punkt, eventuelt ved hjælp af en cirkel.\nSe, om værdierne for begge features nogenlunde ligger mellem \\(-2\\) og \\(2\\), som forventet.\n\n\n\n\nDenne metode er en kendt standard til at sørge for, at begge (eller alle, hvis der er flere) features vægtes lige meget, så man undgår at den valgte enhed afgør, om den ene eller anden anden feature bliver dominerende.\nFor eksempel bruger programmet Orange, som du anvendte i forløbet Overvågning i Monitorbian denne form for feature-skalering.\n\n\n\n\n\n\nOpgave 6: Ekstra\n\n\n\n\n\n\nOvervej, om centreringen i opgave 3 er nødvendig.\nOvervej, hvordan punkter og cirkel vil placere sig uden justeringen i opgave 3.\nLav illustrationen uden justeringen omkring \\((0,0)\\), men stadig med divisionen med spredningen for hver feature.\n\n\n\n\n\n\n\n\n\n\nÅben først efter opgave 6\n\n\n\n\n\nSå justeringen omkring \\((0,0)\\) er faktisk ikke nødvendig, men indgår alligevel ofte i feature-skalering, så data som standard ligger mellem -2 og 2."
  },
  {
    "objectID": "undervisningsforloeb/Opdatering_af_vægte_i_en_kunstig_neuron.html",
    "href": "undervisningsforloeb/Opdatering_af_vægte_i_en_kunstig_neuron.html",
    "title": "Opdatering af vægte i en kunstig neuron",
    "section": "",
    "text": "Forudsætninger og tidsforbrug\n\n\n\n\n\n\nSimple neurale netværk.\nSigmoid aktiveringsfunktion.\nGradientnedstigning.\n\nForudsætningerne kan for eksempel dækkes ved hjælp af noten om kunstige neuroner.\nTidsforbrug: Ca. 90 minutter."
  },
  {
    "objectID": "undervisningsforloeb/Opdatering_af_vægte_i_en_kunstig_neuron.html#et-meget-lille-datasæt",
    "href": "undervisningsforloeb/Opdatering_af_vægte_i_en_kunstig_neuron.html#et-meget-lille-datasæt",
    "title": "Opdatering af vægte i en kunstig neuron",
    "section": "Et meget lille datasæt",
    "text": "Et meget lille datasæt\nI neurale netværk er der ofte rigtige mange inputvariable (features), rigtigt mange vægte og rigtig mange træningsdata.\nVi vil se på følgende netværk:\n\n\n\n\n\nFor bedre at forstå, hvordan vægtene opdateres i et simpelt neuralt netværk, vil vi her se på et meget lille eksempel, så det manuelt er muligt at lave opdateringen af vægtene.\nKonkret vil vi se på to features \\(x_1\\) og \\(x_2\\) og en targetværdi \\(t\\) ud fra følgende tre træningseksempler:\n\n\n\n\\(x_1\\)\n\\(x_2\\)\n\\(t\\)\n\n\n\n\n-1\n2\nja = 1\n\n\n0\n4\nnej = 0\n\n\n1\n7\nja = 1\n\n\n\nVi vælger en learning rate på\n\\[\n\\eta = 0.1,\n\\]\nsigmoid-funktionen som aktiveringsfunktion \\[\\sigma(x)=\\frac{1}{1+e^{-x}}\\] og squared error som tabsfunktion \\[E(w_0, w_1, w_2) = \\frac{1}{2} \\sum_{m=1}^{3} \\left (t^{(m)}-\\sigma(w_0 + w_1 \\cdot x_1^{(m)} + w_2 \\cdot x_2^{(m)}) \\right)^2\\] Endeligt vælger vi startvægtene\n\\[w_0=0.1, \\qquad w_1=0.1, \\qquad w_2=0.1\n\\]"
  },
  {
    "objectID": "undervisningsforloeb/Opdatering_af_vægte_i_en_kunstig_neuron.html#første-opdatering-af-vægtene",
    "href": "undervisningsforloeb/Opdatering_af_vægte_i_en_kunstig_neuron.html#første-opdatering-af-vægtene",
    "title": "Opdatering af vægte i en kunstig neuron",
    "section": "Første opdatering af vægtene",
    "text": "Første opdatering af vægtene\nDu skal nu gå gennem de enkelte beregninger, som skal til for at opdatere vægtene. Der er efterfølgende facit til hver del.\n\n\n\n\n\n\nOpgave 1: Beregn værdien af tabsfunktionen\n\n\n\n\n\n\nUdregn først\n\\[s^{(1)} = w_0 + w_1 \\cdot x_1^{(1)} + w_2 \\cdot x_2^{(1)}\\]\nfor det første træningseksempel.\nUdregn så\n\\[o^{(1)} = \\sigma (s^{(1)})\\]\nUdregn derefter\n\\[e^{(1)} = (t^{(1)} - o^{(1)})^2,\\]\nhvilket giver det første træningseksempels bidrag til tabsfunktionen.\nGentag for hver af de to øvrige træningseksempler.\nLæg de 3 beregnede værdier sammen og divider med 2, så\n\\[E=\\frac{1}{2} \\cdot (e^{(1)}+e^{(2)}+e^{(3)}).\\]\n\n\n\n\n\n\n\n\n\n\nOpgave 2: Beregn de partielle afledede\n\n\n\n\n\n\nBeregn \\[\\frac{\\partial E}{\\partial w_0} = - \\sum_{m=1}^{3} \\left (t^{(m)}-o^{(m)} \\right) \\cdot o^{(m)}\\cdot (1-o^{(m)}) \\cdot 1\\]\nBeregn \\[\\frac{\\partial E}{\\partial w_1} = - \\sum_{m=1}^{3} \\left (t^{(m)}-o^{(m)} \\right) \\cdot o^{(m)}\\cdot (1-o^{(m)}) \\cdot x_1^{(m)}\\]\nBeregn \\[\\frac{\\partial E}{\\partial w_2} = - \\sum_{m=1}^{3} \\left (t^{(m)}-o^{(m)} \\right) \\cdot o^{(m)}\\cdot (1-o^{(m)}) \\cdot x_2^{(m)}\\]\n\n\n\n\n\n\n\n\n\n\nOpgave 3: Opdatér vægtene\n\n\n\n\n\nBeregn de opdaterede vægte \\[\n\\begin{aligned}\nw_0^{(\\textrm{ny})} \\leftarrow & w_0 - \\eta \\cdot \\frac{\\partial E}{\\partial w_0}   \\\\\n\\\\\nw_1^{(\\textrm{ny})} \\leftarrow & w_1 - \\eta \\cdot \\frac{\\partial E}{\\partial w_1}  \\\\\n\\\\\nw_2^{(\\textrm{ny})} \\leftarrow & w_2 - \\eta \\cdot \\frac{\\partial E}{\\partial w_2}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "undervisningsforloeb/Opdatering_af_vægte_i_en_kunstig_neuron.html#anden-opdatering-af-vægtene",
    "href": "undervisningsforloeb/Opdatering_af_vægte_i_en_kunstig_neuron.html#anden-opdatering-af-vægtene",
    "title": "Opdatering af vægte i en kunstig neuron",
    "section": "Anden opdatering af vægtene",
    "text": "Anden opdatering af vægtene\nOvervej, om du kan strømline dine beregninger, for eksempel i Excel eller i dit CAS værktøj, så det bliver hurtigere at opdatere vægtene en gang mere på samme måde.\n\n\n\n\n\n\nOpgave 4: Opdater vægtene anden gang\n\n\n\n\n\n\nBeregn tabsfunktionen.\nBeregn de opdaterede vægte.\n\n\n\n\nBemærk, at værdien af tabsfunktionen er blevet lidt mindre. Formålet er jo netop at minimere den gennem gradientnedstigning, så som regel bør værdien bliver mindre, hver gang vægtene opdateres."
  },
  {
    "objectID": "undervisningsforloeb/Opdatering_af_vægte_i_en_kunstig_neuron.html#app-til-simple-neurale-netværk",
    "href": "undervisningsforloeb/Opdatering_af_vægte_i_en_kunstig_neuron.html#app-til-simple-neurale-netværk",
    "title": "Opdatering af vægte i en kunstig neuron",
    "section": "App til simple neurale netværk",
    "text": "App til simple neurale netværk\nMed perceptron app’en kan du lave de samme beregninger bare automatisk.\n\n\n\n\n\n\nOpgave 5: Afprøv perceptron app’en\n\n\n\n\n\n\nLav et Excelark med feature- og targetværdierne.\nIndlæs data fra Excelarket i perceptron app’en.\nVælg de korrekte værdier i felterne på app’en. Herunder skal feature-skalering være slået fra.\nSe om app’en giver samme resultater for tabsfunktionen og vægtene, som du selv fik efter 1 iteration og efter 2 iterationer."
  },
  {
    "objectID": "undervisningsforloeb/Opdatering_af_vægte_i_en_kunstig_neuron.html#cross-entropy-som-tabsfunktion",
    "href": "undervisningsforloeb/Opdatering_af_vægte_i_en_kunstig_neuron.html#cross-entropy-som-tabsfunktion",
    "title": "Opdatering af vægte i en kunstig neuron",
    "section": "Cross-entropy som tabsfunktion",
    "text": "Cross-entropy som tabsfunktion\nDu kan læse om cross-entropy i noten om tabsfunktioner.\n\n\n\n\n\n\n(Ekstra) Opgave 6: Cross-entropy tabsfunktion\n\n\n\n\n\n\nGentag opgave 1-5 men med cross-entropy som tabsfunktion i stedet for squared error."
  },
  {
    "objectID": "undervisningsforloeb/Opdatering_af_vægte_i_en_kunstig_neuron.html#løsninger-til-opgaver",
    "href": "undervisningsforloeb/Opdatering_af_vægte_i_en_kunstig_neuron.html#løsninger-til-opgaver",
    "title": "Opdatering af vægte i en kunstig neuron",
    "section": "Løsninger til opgaver",
    "text": "Løsninger til opgaver\nFacitliste."
  },
  {
    "objectID": "undervisningsforloeb/Logistisk_regression.html",
    "href": "undervisningsforloeb/Logistisk_regression.html",
    "title": "Logistisk regression",
    "section": "",
    "text": "Forudsætninger og tidsforbrug\n\n\n\n\n\nForløbet kræver kendskab til:\n\nInvers funktion\nDen naturlige logaritme\n\nTidsforbrug: 10-12 timer."
  },
  {
    "objectID": "undervisningsforloeb/Logistisk_regression.html#introduktion",
    "href": "undervisningsforloeb/Logistisk_regression.html#introduktion",
    "title": "Logistisk regression",
    "section": "Introduktion",
    "text": "Introduktion\nDette forløb anvender i stor udstrækning følgende materiale Logistisk regression .\nForløbet er inddelt i 6 dele + et eksamensspørgsmål med en cirka tidsangivelse til hver del.\nTil sidst er der en kort lærervejledning, som elever kan ignorere."
  },
  {
    "objectID": "undervisningsforloeb/Logistisk_regression.html#logistisk-regression-og-odds",
    "href": "undervisningsforloeb/Logistisk_regression.html#logistisk-regression-og-odds",
    "title": "Logistisk regression",
    "section": "Logistisk regression og odds",
    "text": "Logistisk regression og odds\n\n\n\n\n\n\nDel 1 - logistisk regression\n\n\n\n\n\nForventet tid ca. 90 min.\n\nLæs afsnittet Logistisk regression og hjerte-kar-sygdom i materialet.\nHent Excelfilen med de 2000 datapunkter.\nGenskab figur 1 i materialet ud fra de første 100 punkter og overvej, hvorfor det er en dårlig ide at bruge alle 2000 punkter. Du kan enten gøre dette i dit eget CAS værktøj eller i Excel. Hvis du ikke er vant til at lave grafer i Excel, er det nok lettest at anvende det program, som du normalt bruger.\nInddel de 2000 datapunkter i intervaller som vist i tabel 1 i materialet. Dette kan f.eks. gøres vha. pivottabel i Excel som beskrevet nedenfor.\nLav lineær regression ud fra data i tabel 1 og genskab derved figur 3. Husk at bruge midtpunktet af hvert interval. Brug det program, du normalt anvender til regressionen.\n\n\n\n\n\n\n\n\n\n\nDel 1 - hjælp til Pivottabel i Excel\n\n\n\n\n\nHent Excel filen med de 2000 datapunkter.\nVælg “Indsæt pivottabel” i Excel og vælg dataområde og placering. Bemærk, at du skal gøre dette under menuen “Indsæt”, og hvis du finder “pivotdiagram” et sted, er det ikke det rigtige, det skal være pivottabel. Når du klikker på “Eksisterende regneark” skal du klikke det sted i regnearket, hvor du vil have pivottabellen placeret.\n\nIndstil pivottabellen som vist på figuren nedenfor. Bemærk, at du skal trække Blodtryk og Syg ned fra listen for oven til Kolonner, Rækker og Værdier i bunden. Under Værdier vil der i første omgang stå “Sum af Syg”, så klik på pilen, vælg “Værdifeltindstillinger” og ændr det til “Antal af syg”.\n\nHøjreklik på én af værdierne for blodtryk i pivottabellen, vælg “Grupper” og vælg indstillinger for intervallerne.\n\nHerefter skal det se således ud:\n\n\n\n\n\n\n\n\n\n\nDel 2 - Odds og første bevis\n\n\n\n\n\nForventet tid ca. 75 min\n\nLæs afsnittet “Odds” i materialet.\nLav de tilhørende opgaver i materialet, dog ikke bonusopgaven.\nLærergennemgang af, at \\(O(p)\\) er voksende vha. differentiation og monotoni."
  },
  {
    "objectID": "undervisningsforloeb/Logistisk_regression.html#regressionsmodel-og-logit",
    "href": "undervisningsforloeb/Logistisk_regression.html#regressionsmodel-og-logit",
    "title": "Logistisk regression",
    "section": "Regressionsmodel og logit",
    "text": "Regressionsmodel og logit\n\n\n\n\n\n\nDel 3 - Den logistiske regressionsmodel\n\n\n\n\n\nForventet tid ca. 45 min\n\nLæs afsnittet “Den logistiske regressionsmodel” i materialet.\nLav de tilhørende opgaver i materialet. Hint til sidste spørgsmål - start med at overveje, hvilken værdi \\(e^{-a\\cdot x+b}\\) skal have, og derefter hvilken værdi \\(a\\cdot x+b\\) skal have, og til sidst \\(x\\).\n\n\n\n\n\n\n\n\n\n\nDel 4 - Logit og andet bevis\n\n\n\n\n\nForventet tid ca. 90 min\n\nRepetition af, hvad en invers funktion er.\nLæs afsnittet i materialet med fokus på at kunne isolere \\(p(x)\\) i \\(logit(x)\\).\nEfterfølgende fælles gennemgang på tavlen, da beviset er med i eksamensspørgsmålet."
  },
  {
    "objectID": "undervisningsforloeb/Logistisk_regression.html#fortolkning-og-bestemmelse-af-parametrene",
    "href": "undervisningsforloeb/Logistisk_regression.html#fortolkning-og-bestemmelse-af-parametrene",
    "title": "Logistisk regression",
    "section": "Fortolkning og bestemmelse af parametrene",
    "text": "Fortolkning og bestemmelse af parametrene\n\n\n\n\n\n\nDel 5 - Fortolkning\n\n\n\n\n\nForventet tid ca. 60 min\n\nLæs det meste af afsnittet “Fortolkning af parametrene i den logistiske regressionsmodel” i materialet. Stop efter eksemplet, der ender med en vækst på 22%. Det er ikke afgørende, at du får helt styr på dette afsnit, men det er vigtigt, at du prøver at tilpasse \\(a\\) og \\(b\\), så grafen passer til punkterne, og har en forståelse for, hvad der sker.\nLav de tilhørende opgaver i materialet.\n\n\n\n\n\n\n\n\n\n\nDel 6 - Maximum Likelihood Estimation\n\n\n\n\n\nForventet tid ca. 120 min\n\nLærergennemgang af teorien.\nLæs derefter afsnittet “Bestemmelse af a og b med Excels problemløser-værktøj” i materialet.\nAnvend igen Excel arket med de 2000 datapunkter, og benyt problemløsning i Excel til at vise, at \\(a=0{,}022\\) og \\(b=-3{,}9\\) optimerer løsningen.\nLav de tilhørende opgaver i materialet.\n\n\n\n\n\n\n\n\n\n\nEksamensspørgsmål: Differentialregning og logistisk regression\n\n\n\n\n\nForventet tid ca. 120 min\nDifferentialregning og logistisk regression\n\nForklar om logistisk regression, herunder odds.\nDifferentier \\(O(p)= {p \\over (1-p)}\\) og vis derved, at \\(O(p)\\) er voksende.\nIsoler \\(p\\) i \\(logit(p)\\)."
  },
  {
    "objectID": "undervisningsforloeb/Logistisk_regression.html#lærervejledning",
    "href": "undervisningsforloeb/Logistisk_regression.html#lærervejledning",
    "title": "Logistisk regression",
    "section": "Lærervejledning",
    "text": "Lærervejledning\n\n\n\n\n\n\nTil læreren\n\n\n\n\n\nI del 1 kan inddelingen i intervaller givet også ske i eleverne eget CAS værktøj, hvis det foretrækkes. Der kan dog evt. være en pointe i at lade eleverne stifte bekendtskab med begrebet pivottabel i Excel uanset.\nI del 2 i beviset for, at \\(O(p)\\) er voksende, kan differentiationen laves på forskellige måder, som det måtte passe bedst ind for det konkrete hold:\n\nVha. produktreglen og sammensat, idet kvotienten først omskrives til et produkt. \\(O'(p) = p' \\cdot {1 \\over 1-p} + p \\cdot ({1 \\over 1-p})' = 1 \\cdot {1 \\over 1-p} + p \\cdot {-1 \\over (1-p)^2} \\cdot (-1) =  {1-p \\over (1-p)^2} + {p \\over (1-p)^2} = {1 \\over (1-p)^2} &gt; 0\\)\nVha. kvotientreglen (enten bevist eller blot gennemgået). \\(O'(p) = {p' \\cdot (1-p) - p \\cdot (1-p)' \\over (1-p)^2} = {1 \\cdot (1-p) - p \\cdot (-1) \\over (1-p)^2} = {1 \\over (1-p)^2} &gt; 0\\)\n\nI del 4 kan det overvejes, om eleverne selv, evt i grupper, skal læse udledningen, eller om den skal ske ved lærergennemgang.\nI del 5 er det ikke nødvendigt, at eleverne forstår alle detaljer, en rimelig forståelse af ideen kan være tilstrækkelig.\nI del 5 kan man godt lade eleverne læse hele afsnittet, men den sidste del er ikke så central, og ligner meget et kendt bevis fra eksponentielle udviklinger.\nI del 6 anvendes black-box, men der kan f.eks. sammenlignes med Newton-Raphsons metode til bestemmelse af nulpunkter."
  },
  {
    "objectID": "undervisningsforloeb/Opdatering_af_vægte_i_en_kunstig_neuron_løsninger.html",
    "href": "undervisningsforloeb/Opdatering_af_vægte_i_en_kunstig_neuron_løsninger.html",
    "title": "Løsninger til forløb om opdatering af vægte i en kunstig neuron",
    "section": "",
    "text": "Løsning til opgave 1\n\n\n\n\n\n\\[\n\\begin{aligned}\ns^{(1)}  & = 0.1 + 0.1 \\cdot -1 + 0.1 \\cdot 2   = 0.2 \\\\\n\\\\\no^{(1)} & = \\sigma (0.2)  \\approx 0.5498339973 \\\\\n\\\\\ne^{(1)} & = (1 - o^{(1)})^2  \\approx 0.2026494300 \\\\\n\\\\\n\\\\\ns^{(2)} & = 0.5 \\\\\n\\\\\no^{(2)} & \\approx 0.6224593311 \\\\\n\\\\\ne^{(2)} & \\approx 0.3874556189 \\\\\n\\\\\n\\\\\ns^{(3)} &  = 0.9 \\\\\n\\\\\no^{(3)} & \\approx 0.7109495025 \\\\\n\\\\\ne^{(3)} &  = \\approx 0.08355019010 \\\\\n\\\\\n\\\\\nE & = \\frac {1}{2}(e^{(1)}+e^{(2)}+e^{(3)}) \\approx 0.3368276195\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\n\nLøsning til opgave 2\n\n\n\n\n\n\\[\n\\begin{aligned}\nE_0^{(1)} & = (t_1-o^{(1)}) \\cdot o^{(1)} \\cdot (1-o^{(1)}) \\cdot 1 \\\\\n       & = (1-0.5498339973) \\cdot 0.5498339973 \\cdot (1-0.5498339973) \\cdot 1 \\\\\n       & \\approx 0.1114235461 \\\\\n       \\\\\nE_0^{(2)} & \\approx -0.1462802535 \\\\\n\\\\\nE_0^{(3)} &  \\approx 0.05939996609 \\\\\n\\\\\n\\frac{\\partial E}{\\partial w_0} & = -(E_0^{(1)}+E_0^{(2)}+E_0^{(3)}) \\\\\n      & = - (0.1114235461-0.1462802535+0.05939996609) \\\\\n      & \\approx -0.02454325869 \\\\\n\\\\\n\\\\\nE_1^{(1)} & \\approx -0.1114235461 \\\\\n\\\\\nE_1^{(2)} & = 0 \\\\\n\\\\\nE_1^{(3)} & \\approx 0.05939996609 \\\\\n\\\\\n\\frac{\\partial E}{\\partial w_1} & \\approx 0.05202358001 \\\\    \n\\\\\n\\\\\nE_2^{(1)} & \\approx 0.2228470922 \\\\\n\\\\\nE_2^{(2)} & \\approx -0.5851210140 \\\\\n\\\\\nE_2^{(3)} & \\approx 0.4157997626 \\\\\n\\\\\n\\frac{\\partial E}{\\partial w_2} & \\approx -0.0535258408\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\n\nLøsning til opgave 3\n\n\n\n\n\n\\[\n\\begin{aligned}\nw_0^{(\\textrm{ny})} & \\approx  0.1 - 0.1 \\cdot (-0.02454325869) \\approx 0.1024543259   \\\\\n\\\\\nw_1^{(\\textrm{ny})} & \\approx 0.09479764200  \\\\\n\\\\\nw_2^{(\\textrm{ny})} & \\approx 0.1053525841\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\n\nLøsning til opgave 4\n\n\n\n\n\n\\[\n\\begin{aligned}\nE & \\approx 0.3362680478 \\\\\n\\\\\nw_0^{(\\textrm{ny})} & \\approx 0.1045005370 \\\\\n\\\\\nw_1^{(\\textrm{ny})} & \\approx 0.08949754490 \\\\\n\\\\\nw_2^{(\\textrm{ny})} & \\approx 0.1086460194\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "undervisningsforloeb/kNN_forlob_overvaagning.html",
    "href": "undervisningsforloeb/kNN_forlob_overvaagning.html",
    "title": "Overvågning i Monitorbian",
    "section": "",
    "text": "Forudsætninger og tidsforbrug\n\n\n\n\n\nForløbet kræver kendskab til:\n\nKoordinatsystemer.\nPunkter og afstande mellem punkter.\nProcentregning.\n\nTidsforbrug: Ca. 90 minutter (uden brug af Orange)."
  },
  {
    "objectID": "undervisningsforloeb/kNN_forlob_overvaagning.html#velkommen-til-monitorbian",
    "href": "undervisningsforloeb/kNN_forlob_overvaagning.html#velkommen-til-monitorbian",
    "title": "Overvågning i Monitorbian",
    "section": "Velkommen til Monitorbian",
    "text": "Velkommen til Monitorbian\nLandet Monitorbian ønsker at blive en vaskeægte overvågningsstat! Men efterretningstjenesten i Monitorbian ved meget lidt om overvågning. Derfor har de ansat jer som intelligence officerer til at løse denne opgave. Tillykke med jeres nye job! Lad os smøge ærmerne op og komme i gang! 😄\nI Monitorbian findes der to forskellige slags indbyggere: Nogle nedstammer fra Anders And, mens andre nedstammer fra Fedtmule. På figur 1 kan du se, hvordan de forskellige indbyggere ser ud.\n\n\n\n\n\n\nFigur 1: Billede af de to slags indbyggere i Monitorbian. Indbyggeren til venstre nedstammer fra Anders And, mens indbyggeren til højre nedstammer fra Fedtmule.\n\n\n\n\nFeatures\nFor at overvåge indbyggerne er vi nødt til at identificere nogle egenskaber ved indbyggerne, som kan bruges til at adskille dem fra hinanden. Sådan en egenskab kaldes for en feature. En feature kunne for eksempel være en indbyggers vægt. Det vil være en god feature, hvis de to forskellige slags indbyggere har forholdsvis forskellig vægt. En anden feature kunne være øjenfarve, men hvis det ikke på en eller anden måde kan være med til at skelne de to slags indbyggere fra hinanden, så vil øjenfarve være et dårlig valg af feature i denne sammenhæng.\n\n\n\n\n\n\nOpgave 1: Features\n\n\n\n\n\nSe på billedet i figur 1 og find på nogle flere features.\n\n\n\n\n\nTræningsdata\nSom I lige har set i opgave 1, er der rigtig mange egenskaber ved indbyggerne, der kan bruges som features. Men som intelligence officerer er vi nødt til at træffe et valg og beslutte os for, hvad vi vil gå videre med. I har derfor netop været til møde i sikkerhedsudvalget, hvor det er blevet besluttet, at højde (målt i \\(cm\\)) og fodareal (målt i \\(cm^2\\)) er de to features, som I skal arbejde videre med. Disse to features er forholdsvis nemme at scanne, og fremadrettet bliver det derfor sådan, at hver gang en indbygger i Monitorbian går ind i en offentlig bygning, så bliver vedkommende scannet og højde og fodareal bliver målt.\nI skal nu have lavet en algoritme1, som kan forudsige, hvilken slags indbygger der er tale om – alene baseret på viden om en given indbyggers højde og fodareal. Man siger, at vi gerne vil klassificere indbyggerne – her i to klasser: Anders And og Fedtmule.\n1 Tænk på en algoritme som en slags opskrift, som kan bruges til at forudsige hvilken slags indbygger, der er tale om.2 Man siger også, at vi gerne vil prædiktere hvilken slags indbygger, der er tale om.For at gøre det har vi brug for træningsdata. Træningsdata består af en masse data fra forskellige indbyggere, hvor de to features er blevet målt samtidig med, at det for hver indbygger er angivet om vedkommende nedstammer fra Anders And eller fra Fedtmule. Denne sidste oplysning er jo lige præcis den oplysning, som vi gerne fremadrettet vil kunne forudsige2. I træningsdata angiver vi altså den værdi, som vi gerne vil prædiktere. Derfor kalder man også denne værdi for en targetværdi.\n\n\n\n\n\n\nOpgave 2: Træningsdata\n\n\n\n\n\nNedenstående viser en tabel med træningsdata3, men targetværdien mangler. Angiv targetværdien (\"Anders And\" eller \"Fedtmule\").\n\n\n\n\n\n\n\n\n\nIndbygger\nFodareal (\\(cm^2\\))\nHøjde (\\(cm\\))\nTargetværdi\n\n\n\n\n\n197\n123\n\n\n\n\n214\n155\n\n\n\n\n255\n115\n\n\n\n\n297\n96\n\n\n\n\n213\n74\n\n\n\n\n173\n138\n\n\n\n\n272\n115\n\n\n\n\n235\n94\n\n\n\n\n311\n99\n\n\n\n\n334\n116\n\n\n\n\n276\n151\n\n\n\n\n283\n92\n\n\n\n\n234\n132\n\n\n\n\n172\n97\n\n\n\n\n278\n74\n\n\n\n\n241\n75\n\n\n\n\n220\n62\n\n\n\n\n249\n86\n\n\n\n\n138\n96\n\n\n\n\n252\n93\n\n\n\n\n\n\n\n3 Billederne er i øvrigt genereret med en AI billedgenerator i programmet craiyon.\n\nNærmeste naboer (kNN)\nDer findes en lang række af metoder til at lave klassifikation, som er det, vi har brug for her. Nogle af dem bruger meget avanceret matematik og enorme computerkræfter og kan anvendes til diagnosticering af sygdomme, klassificere dokumenter i forskellig typer, genkende objekter i billeder og videoer. Helt så avancerede metoder får vi dog ikke brug for her.\nVi vil i stedet fokusere på én af de simpleste, men alligevel effektive metoder til at klassificere observationer. Metoden kaldes på engelsk k-nearest neighbors eller på dansk k-nærmeste naboer, og forkortes ofte som kNN. kNN er baseret på den simple antagelse, at observationer, som er tæt på hinanden, også ligner hinanden. I vores eksempel vil det være, at indbyggere, som har cirka samme højde og fodareal, vil vi antage, hører til i den samme klasse.\nFor at bestemme hvilke naboer, der ligger tæt på hinanden, er vi nødt til at kunne beregne afstanden mellem to punkter. Du husker nok, at afstanden \\(d\\) mellem punktet \\(P(x_1,y_1)\\) og punktet \\(Q(x_2,y_2)\\) er\n\\[\nd = \\sqrt{(x_2-x_1)^2+(y_2-y_1)^2}\n\\tag{1}\\]\nPå figur 2 nedenfor ser I de træningsdata, som I selv angav en targetværdi for i den foregående opgave. Måske var det for nogle af indbyggerne svært at afgøre oprindelsen alene ved at se på billedet – og måske var det nemt nok, men her ses i hvert tilfælde den korrekte klassificering4.\n4 Man kan forestille sig, at en sådan klassificering er baseret på yderligere test og undersøgelser, som man normalvis ikke vil have til rådighed.\n\n\n\n\n\nFigur 2: Datasættet med fodareal ud af \\(x\\)-aksen og højde op af \\(y\\)-aksen. De røde punkter svarer til Fedtmule-indbyggere, mens de blå svarer til Anders And-indbyggere.\n\n\n\n\n\n\n\n\n\nOpgave 3: Afstande\n\n\n\n\n\nBeregn afstanden fra det grå punkt til de syv punkter, som er markeret i figur 3 herunder. Sørg for at skrive de beregnede afstande ned – du skal bruge dem senere!\n\n\n\n\n\n\n\n\n\nFigur 3: Et udsnit af data med et nyt gråt punkt indsat. De røde punkter svarer til Fedtmule-indbyggere, mens de blå svarer til Anders And-indbyggere.\n\n\n\nNår \\(k\\)-nærmeste naboer bruges til at klassificere en ny indbygger benyttes en flertalsafstemning (også kaldet majoritetsbeslutning). Det vil sige, at en ny indbygger bliver prædikteret til at tilhøre den klasse, som de fleste af indbyggerens \\(k\\)-nærmeste naboer tilhører. Hvis for eksempel \\(k=5\\), og vi har en ny indbygger, som vi gerne vil afgøre klassen for, så ser vi simpelthen på de 5 nærmeste naboer til denne indbygger og tæller op, hvilke klasser de tilhører. Hvis to af dem nedstammer fra Anders And og tre fra Fedtmule, så vil en flertalsafstemning sige, at den nye indbygger nok er i Fedtmule-klassen. Man kan komme ud for, at præcis halvdelen af de \\(k\\) nærmeste naboer nedstammer fra Anders And, mens præcis den anden halvdel nedstammer fra Fedtmule. I det tilfælde vil vi sige, at klassifikationen er uafklaret.\nDenne idé vil vi nu bruge.\n\n\n\n\n\n\nOpgave 4: Afstand til ny og ukendt indbygger\n\n\n\n\n\nI figur 3 svarer det grå punkt til en ny indbygger, som skal klassificeres, og de nærmeste naboer svarer til de punkter, som du lige har beregnet afstanden til. Baseret på en flertalsafstemning blandt de fem nærmeste naboer (det vil sige, at \\(k=5\\)) vil du så sige, at den nye indbygger stammer fra Fedtmule eller fra Anders And?\n\n\n\n\n\n\n\n\n\nOpgave 5: Flertalsafstemning for forskellige værdier af \\(k\\)\n\n\n\n\n\nDer er ingen, som siger, at vi skal se på de fem nærmeste naboer. Vi kan lige så godt se på dén nærmeste nabo, på de to nærmeste naboer eller på de tre nærmeste naboer. Vi vil nu se på, hvad der sker, hvis vi ændrer på antallet af nærmeste naboer \\(k\\).\nSe igen på figur 3 og de afstande, som du beregnede i opgave 3. Du skal nu for forskellige værdier af \\(k\\) afgøre, om den nye indbygger skal klassificeres som en Fedtmule- eller en Anders And-indbygger.\nUdfyld en tabel som nedenstående (med \"andel\" mener vi den andel, som afgør flertalsafstemningen – hvis for eksempel der er tre ud af fire punkter, som er blå eller røde, skal andelen sættes til 3/4).\n\n\n\n\\(k\\)\nBlå/Rød/Uafklaret (prædiktion)\nAndel\n\n\n\n\n1\n\n\n\n\n2\n\n\n\n\n3\n\n\n\n\n4\n\n\n\n\n5\n\n\n\n\n\n\n\n\n\n\nValg af \\(k\\) og testdata\nSom du har set ovenfor, vil forskellige valg af \\(k\\) give forskellige resultater. Så hvordan vælger vi mon den bedst mulige værdi af \\(k\\)? For at afgøre det vil vi opdele vores data i to dele: træningsdata og testdata. Det kunne for eksempel være sådan, at af alle de data vi har, så bruger vi 80% som træningsdata. Det er træningsdata, som vi bruger til at lave prædiktionen med. De resterende 20% af data vil vi lade være testdata, hvor vi bruger testdata til at måle, hvor nøjagtig vores algoritme er.\nIdéen er nu denne:\n\nVi vælger en værdi af \\(k\\) – det kunne for eksempel være \\(k=5\\).\nVi ser så på hver eneste indbygger i testdata og lader som om, at vi ikke kender denne indbyggers oprindelse. Det vil sige, at vi lader som om, at vi ikke kender targetværdien. Vi vil nu bruge træningsdata til at lave en prædiktion for denne indbygger baseret på den valgte værdi af \\(k\\). Men da vi jo i virkeligheden godt kender denne indbyggers oprindelse, så får vi nu mulighed for at afgøre, om prædiktionen er rigtig eller forkert.\n\nLad os forestille os, at vi har 500 data i alt, og at vi lader 20% af disse være testdata. Det vil sige, at testdata består af 100 datapunkter. For hvert af disse datapunkter laver vi en prædiktion. Så enten prædikterer vi, at datapunktet er blåt eller rødt baseret på en flertalsafstemning af de \\(k\\) nærmeste naboer i træningsdatasættet. Holder vi denne prædiktion op mod den faktiske værdi, kan vi opstille en såkaldt confusion tabel. Et eksempel på en sådan ses her:\n\n\n\n\nPrædikteret blå\nPrædikteret rød\n\n\n\n\nFaktisk blå\n56\n9\n\n\nFaktisk rød\n7\n68\n\n\n\n\nDer er 140 datapunkter i alt, og vi kan her se, at 56 datapunkter blev prædikteret til at være blå og faktisk også er blå. Tilsvarende er 68 af datapunkterne prædikteret til at være røde, mens de faktiske også er røde. I alt 7+9=16 datapunkter har fået prædikteret en forkert farve sammenlignet med deres faktiske farve. Altså kan vi her se, at med den valgte værdi af \\(k\\) har vores kNN algoritme lavet en fejl i \\[\n\\frac{16}{140} \\approx 11.4 \\%\n\\] af tilfældene, mens den har prædikteret korrekt i \\[\n\\frac{56+68}{140} = \\frac{124}{140} \\approx 88.6 \\%\n\\] af tilfældene. Vi kan nu lave tilsvarende beregninger for forskellige værdier af \\(k\\) og helt enkelt vælge den værdi af \\(k\\), som giver den mindste fejlprocent, når vi tester på vores testdata.\nVi ser nu igen på vores simple datasæt, og deler det op i et træningsdatasæt og et testdatasæt. På figur 4 er testdata markeret med et kryds. Vi vil for forskellige værdier af \\(k\\) prædiktere farven på testdata (samtidig med at vi jo godt kender den faktiske værdi).\n\n\n\n\n\n\nFigur 4: Testdata er markeret med et kryds.\n\n\n\n\n\n\n\n\n\nOpgave 6: Valg af \\(k\\)\n\n\n\n\n\n\nBrug app’en herunder til at afgøre den prædikterede værdi af hvert testdata for \\(k=1, 2, 3, 4, 5\\). Du kan for hvert testdatapunkt få tegnet en cirkel rundt om (hvor du kan justere på radius), som kan hjælpe dig med at finde de nærmeste naboer. Udfyld en tabel som nedenstående (husk at den prædikterede farve kan være blå, rød eller uafklaret) – skriv den enten ned på et stykke papir eller brug Prædiktion for forskellige værdier af k.\n\n\n\n\n\n\n\n\n\n\n\n\n\nTestdata\nFaktisk\nPrædiktion \\(k=1\\)\nPrædiktion \\(k=2\\)\nPrædiktion \\(k=3\\)\nPrædiktion \\(k=4\\)\nPrædiktion \\(k=5\\)\n\n\n\n\n1\nRød\n\n\n\n\n\n\n\n2\nRød\n\n\n\n\n\n\n\n3\nBlå\n\n\n\n\n\n\n\n4\nBlå\n\n\n\n\n\n\n\n\n\nUdfyld for hver værdi af \\(k\\) en confusion tabel. Hvis den prædikterede farve er uafklaret, skal det tælle som en fejl. Skriv igen ned på papir eller brug Confusion tabeller.\nUdregn for hver værdi af \\(k\\) fejlprocenten. Hvilken værdi af \\(k\\) giver den mindste fejlprocent?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBonusopgave (svær og kan springes over): Hvilke muligheder er der?\n\n\n\n\n\nSe på tabellen i opgave 5 Flertalsafstemning for forskellige værdier af \\(k\\)  ovenfor.\n\nFår man altid den samme prædiktion for alle værdier af \\(k\\)?\n\nVi forestiller os nu, at vi har et nyt datasæt, som vi ikke har lavet beregninger på.\n\nEr det muligt, at der kommer til at stå blå ved \\(k=1\\) og samtidig rød ved \\(k=2\\)?\nFor hvilke værdier af \\(k\\) kan der stå uafklaret?\nHvilke mulige andele kan optræde i tabellen for \\(k=1, 2, 3, 4, 5\\)?\nPrøv at opstille alle muligheder for tabeller (for \\(k=1, 2, 3\\)).\n\n\n\n\n\n\nkNN i programmet Orange\nHer til sidst skal vi lege lidt med et program, som hedder Orange. Du kan få hjælp til at installere programmet her.\nStart med at se denne video:\n\n\n\n\n\n\n\nOpgave 7: kNN i Orange baseret på features\n\n\n\n\n\n\nInstaller Orange.\nOpbyg modellen, som det er vist i videoen ovenfor. For at gøre det får du brug for de træningsdata og testdata, som vi har brugt i det foregående.\nPrøv at ændre på værdien af \\(k\\) (\\(k=1, 2, 3, 4, 5\\)) og se om du i Orange kan genskabe resultaterne fra opgave 6.\n\n\n\n\nDet er også muligt at bruge kNN uden selv at udvælge features. I stedet kan man bruge billederne fra tabellen i opgave 2 direkte. Se her hvordan man gør det:\n\n\n\n\n\n\n\nOpgave 8: kNN i Orange baseret på billeder\n\n\n\n\n\n\nFind selv på en værdi som du gerne vil prædiktere ud fra billeder.\nTag billeder som kan bruges som træningsdata og opbyg en model, som det er vist i videoen ovenfor.\n\n\n\n\n\n\nVidere overvejelser\nDer er flere ting, man kunne overveje at arbejde videre med. For eksempel kunne man sagtens forestille sig, at det kunne give mening med mere end to features. Afstandsformlen i (1) kan faktisk sagtens udvides til flere dimensioner end to. Man finder eksempelvis afstanden mellem to punkter \\((x_1,y_1,z_1)\\) og \\((x_2,y_2,z_2)\\) i et tredimentionelt koordinatsystem på denne måde: \\[\nd = \\sqrt{(x_2-x_1)^2+(y_2-y_1)^2+(z_2-z_1)^2}\n\\] Og det er nok ikke svært at forestille sig, at man kan udvide denne formel yderligere. Det betyder, at man stadig kan bruge \\(k\\) nærmeste naboer som metode i det tilfælde, hvor man har mere end to features.\nEn anden ting at overveje er den skala, vi måler features på. Vi har for eksempel valgt at måle i \\(cm^2\\) og i \\(cm\\). Men hvad hvis vi havde målt i \\(m^2\\) og i \\(m\\)? Det er faktisk ikke helt ligegyldigt hvilken skala, man bruger, og derfor vælger man som regel også at skalere alle ens data, så de kommer på en sammenlignelig skala. Det kan du læse meget mere om i vores materiale om feature-skalering."
  },
  {
    "objectID": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_del1.html",
    "href": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_del1.html",
    "title": "Del 1: Aktiveringsfunktioner",
    "section": "",
    "text": "Forventet tid ca. 1-2 x 90 min.\nVi anbefaler, at alle arbejder med aktivitet 1 og 2. De resterende aktiviteter kan enten udelades eller bruges som ekstra udfordringer."
  },
  {
    "objectID": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_del1.html#aktivitet-1---hvad-er-ai",
    "href": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_del1.html#aktivitet-1---hvad-er-ai",
    "title": "Del 1: Aktiveringsfunktioner",
    "section": "Aktivitet 1 - Hvad er AI?",
    "text": "Aktivitet 1 - Hvad er AI?\nStart med at se denne video, hvor vi fortæller lidt om, hvad AI er.\n\nI videoen omtales aktiveringsfunktioner, som bruges i forbindelse med kunstige neurale netværk. Du har også hørt, at for at træne et kunstigt neuralt netværk så skal man minimere en tabsfunktion. Når en funktion skal minimeres, har vi brug for at kunne differentiere. Da aktiveringsfunktionerne indgår i tabsfunktionen, får vi derfor brug for at kunne differentiere aktiveringsfunktioner.\nI det følgende skal vi se på en række forskellige aktiveringsfunktioner og finde ud af, hvordan vi differentierer dem."
  },
  {
    "objectID": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_del1.html#aktivitet-2---sigmoid",
    "href": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_del1.html#aktivitet-2---sigmoid",
    "title": "Del 1: Aktiveringsfunktioner",
    "section": "Aktivitet 2 - Sigmoid",
    "text": "Aktivitet 2 - Sigmoid\nSigmoid-funktionen har forskrift\n\\[\nf(x)=\\frac{1}{1+e^{-x}},\n\\tag{1}\\]\nsom også kan skrives\n\\[\nf(x)=\\frac{e^x}{1+e^x},\n\\] hvilket ses med at gange med \\(e^x\\) i både tæller og nævner i (1).\nGrafen for Sigmoid-funktionen ses i figur 1.\n\n\n\n\n\n\nFigur 1: Grafen for sigmoid-funktionen.\n\n\n\nDet ser på figur 1 ud som om, at værdimængden for \\(f\\) er det åbne interval1 \\((0,1)\\). Det skrives\n1 Bemærk, at det åbne interval \\((0,1)\\) også kan skrives \\(]0,1[\\).\\[\nVm(f)=(0,1).\n\\]\nHvis du vil have et lidt bedre argument for det, kan du læse i boksen herunder.\n\n\n\n\n\n\nArgument for værdimængden for \\(f\\)\n\n\n\n\n\nVi vil her argumentere for, at værdimængden for \\(f\\) er \\((0,1)\\). Vi vil starte med at se, at funktionsværdierne for \\(f\\) ligger mellem \\(0\\) og \\(1\\).\nDa både tæller og nævner i (1) er positive, så må \\(f(x)&gt;0\\). Og da\n\\[\n1&lt;1+e^{-x}\n\\] så må\n\\[\n\\frac{1}{1+e^{-x}}&lt;\\frac{1+e^{-x}}{1+e^{-x}}=1.\n\\]\nDet vil sige, at \\[\n0 &lt; f(x) &lt; 1\n\\] og derfor må værdimængden for \\(f\\) være en del af intervallet \\((0,1)\\). Det kan skrives sådan her\n\\[\nVm(f) \\subseteq (0,1).\n\\] Vi vil nu vise, at vi kan komme lige så tæt på \\(0\\) og \\(1\\), som det skal være. Det vil med andre ord sige, at værdimængden for \\(f\\) \"fylder\" hele intervallet \\((0,1)\\) ud.\nPå figuren herunder ses grafen for \\(e^{-x}\\).\n\n\n\n\n\nDa \\(e^{-x}\\) er en aftagende eksponentialfunktion vil\n\\[\ne^{-x} \\rightarrow 0 \\quad \\textrm{når} \\quad x \\rightarrow \\infty\n\\] og\n\\[\ne^{-x} \\rightarrow \\infty \\quad \\textrm{når} \\quad x \\rightarrow -\\infty.\n\\]\nDet betyder, at \\[\n\\frac{1}{1+e^{-x}} \\rightarrow 1 \\quad \\textrm{når} \\quad x \\rightarrow \\infty\n\\]\nog\n\\[\n\\frac{1}{1+e^{-x}} \\rightarrow 0 \\quad \\textrm{når} \\quad x \\rightarrow -\\infty.\n\\]\nAlt i alt har vi altså argumenteret for, at værdimængden for \\(f\\) er \\((0,1)\\).\n\n\n\nDe følgende opgaver går ud på at vise, at\n\\[\nf'(x)= \\frac{e^{-x}}{(1+e^{-x})^2}\n\\] og at \\(f'(x)\\) kan udtrykkes ved hjælp af \\(f(x)\\) på denne måde\n\\[\nf'(x)= f(x)\\cdot (1-f(x)).\n\\]\n\n\n\n\n\n\nOpgave 1: Differentiation af sigmoid-funktionen\n\n\n\n\n\nVis, at \\[\nf'(x)= \\frac{e^{-x}}{(1+e^{-x})^2}.\n\\]\n\n\n\n\n\n\n\n\n\nHints til opgave 1\n\n\n\n\n\nVi skal starte med at se, at vi kan tænke på sigmoid-funktionen \\[\nf(x)=\\frac{1}{1+e^{-x}}.\n\\] som en \"dobbelt sammensat\" funktion. Sigmoid-funktionen består nemlig af en brøk på formen \\(\\frac{1}{x}\\) og af eksponentialfunktionen \\(e^{-x}\\).\nGør følgende:\n\nStart med at opskrive differentialkvotienten for \\[\\frac{1}{x} \\quad \\textrm{og} \\quad e^{-x}.\\]\nBrug ovenstående til at vise, at \\[\nf'(x)= \\frac{e^{-x}}{(1+e^{-x})^2}.\n\\]\n\n\n\n\n\n\n\n\n\n\nOpgave 2: Omskrivning af \\(f'(x)\\) for sigmoid-funktionen\n\n\n\n\n\nVis, at \\[\nf'(x)= f(x)\\cdot (1-f(x)).\n\\] når \\[\nf(x)=\\frac{1}{1+e^{-x}}.\n\\]\n\n\n\n\n\n\n\n\n\nHints til opgave 2\n\n\n\n\n\nDer er flere fremgangsmåder for at løse opgaven:\nFremgangsmåde 1\n\nIsolér \\(e^{-x}\\) i \\[\nf(x)=\\frac{1}{1+e^{-x}}.\n\\]\nIndsæt dette udtryk for \\(e^{-x}\\) i \\[\nf'(x)= \\frac{e^{-x}}{(1+e^{-x})^2}\n\\] og reducer.\nHint! Du får brug for at sætte på fælles brøkstreg. Husk også at man dividere med en brøk ved at gange med den omvendte.\n\nFremgangsmåde 2\n\nStart med at udregne \\[1-f(x).\\] Hint! Sæt på fælles brøkstreg ved at skrive \\(1\\) som \\(\\frac{1+e^{-x}}{1+e^{-x}}\\).\nVis nu at \\[\nf(x)\\cdot (1-f(x)) = \\frac{e^{-x}}{(1+e^{-x})^2}=f'(x).\n\\] Husk, at man ganger to brøker med hinanden ved at gange tæller med tæller og nævner med nævner."
  },
  {
    "objectID": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_del1.html#aktivitet-3---softsign",
    "href": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_del1.html#aktivitet-3---softsign",
    "title": "Del 1: Aktiveringsfunktioner",
    "section": "Aktivitet 3 - Softsign",
    "text": "Aktivitet 3 - Softsign\nSoftsign-funktionen har forskrift\n\\[\nf(x)=\\frac{x}{1+|x|}.\n\\] Husk på at \\(|x|\\) betyder den numeriske værdi af \\(x\\). Det vil sige\n\\[\n|x| =\n\\begin{cases}\nx & \\textrm{hvis } x \\geq 0 \\\\\n-x & \\textrm{hvis } x &lt; 0 \\\\\n\\end{cases}\n\\tag{2}\\] Det betyder for eksempel at \\(|7|=7\\) og \\(|-7|=7\\). Grafen for \\(|x|\\) ses i figur 2.\n\n\n\n\n\n\nFigur 2: Grafen for \\(|x|\\).\n\n\n\nGrafen for softsign-funktionen \\(f\\) ses i figur 3.\n\n\n\n\n\n\nFigur 3: Grafen for softsign-funktionen.\n\n\n\nDa den numeriske værdi af \\(x\\) indgår i forskriften, kunne man få den tanke, at \\(f\\) måske hverken er kontinuert eller differentiabel i \\(0\\). For eksempel kan man i figur 2 se, at \\(|x|\\) ikke er differentiabel i \\(0\\).\nMen bruger vi definitionen på \\(|x|\\), får vi\n\\[\nf(x) =\n\\begin{cases}\n\\frac{x}{1+x} & \\textrm{hvis } x \\geq 0 \\\\\n\\\\\n\\frac{x}{1-x} & \\textrm{hvis } x &lt; 0 \\\\\n\\end{cases}\n\\tag{3}\\]\nUd fra denne omskrivning kan man vise, at \\(f\\) rent faktisk er kontinuert i \\(0\\). Det kan du læse mere om i boksen herunder, hvis du har lyst.\nPå figur 3 ser det ud som om, at værdimængden for \\(f\\) er \\((-1,1)\\) (også det argumenterer vi for i boksen):\n\\[\nVm(f) = (-1,1).\n\\]\nDet vil sige, at hvis vi skal bruge softsign-funktionen som aktiveringsfunktion, så skal targetværdierne være \\(\\pm 1\\).\n\n\n\n\n\n\nArgument for kontinuitet i \\(0\\) og værdimængde for \\(f\\)\n\n\n\n\n\nLad os først argumentere for, at \\(f\\) er kontinuert i \\(0\\). For det første ser vi, at \\(f(0)=0/(1+0)=0\\) og \\(f(x) \\rightarrow 0\\), når \\(x\\) nærmer sig \\(0\\) både fra højre og venstre. Det betyder, at \\(f\\) er kontinuert i \\(0\\).\nVi vil herefter indse, at funktionsværdierne for \\(f\\) ligger i \\((-1,1)\\). Ser vi på definitionen i (3), kan vi se, at vi skal inddele i to tilfælde, nemlig \\(x \\geq 0\\) og \\(x&lt;0\\):\n\nTilfælde 1\nHvis \\(x \\geq 0\\), så er \\[\nf(x)= \\frac{x}{1+x}.\n\\] Her er både tæller og nævner positiv, og derfor vil \\(-1&lt;0&lt;f(x)\\). Da \\[\nx &lt; 1+x\n\\] og \\(1+x\\) er positiv vil \\[\nf(x)=\\frac{x}{1+x}&lt;\\frac{1+x}{1+x}=1.\n\\] Altså er \\(-1&lt;f(x)&lt;1\\) i det tilfælde, hvor \\(x \\geq 0\\).\nTilfælde 2\nHvis \\(x&lt;0\\), så er \\[\nf(x) = \\frac{x}{1-x}.\n\\] Her er tælleren negativ, mens nævneren er positiv. Det vil sige, at \\(f(x)&lt;0&lt;1\\). Nu er \\[\nx-1&lt;x&lt;0.\n\\] Da \\(x-1&lt;0\\), vil \\(-(x-1)&gt;0\\), og vi kan derfor dividere ovenstående igennem med \\(-(x-1)\\) uden at ændre på ulighedstegnet: \\[\n\\frac{x-1}{-(x-1)}&lt;\\frac{x}{-(x-1)}.\n\\] Da venstre side giver \\(-1\\) og \\(-(x-1)=1-x\\) får vi \\[\n-1 &lt; \\frac{x}{1-x}=f(x).\n\\] Alt i alt har vi altså også i dette tilfælde vist, at \\[\n-1 &lt; f(x) &lt; 1.\n\\]\n\nDet vil sige, at \\(Vm(f) \\subseteq (-1,1)\\).\nVi vil nu vise, at værdimængden for \\(f\\) \"fylder\" hele intervallet \\((-1,1)\\) ud. Vi ser, at for store positive værdier af \\(x\\) vil \\[\nf(x)= \\frac{x}{1+x} \\approx \\frac{x}{x}=1\n\\] og for store negative værdier af \\(x\\) vil \\[\nf(x)= \\frac{x}{1-x} \\approx \\frac{x}{-x}=-1\n\\] Det betyder, at \\[\nf(x) \\rightarrow 1 \\quad \\textrm{når} \\quad x \\rightarrow \\infty\n\\] og\n\\[\nf(x) \\rightarrow -1 \\quad \\textrm{når} \\quad x \\rightarrow - \\infty\n\\] hvilket stemmer fint overens med figur 3.\nVi har hermed vist, at \\(Vm(f) = (-1,1).\\)\n\n\n\nI nedenstående opgaver skal vi vise, at\n\\[\nf'(x)=\\frac{1}{\\left ( 1+ |x| \\right )^2}\n\\tag{4}\\]\nog at den afledte kan findes ved hjælp af funktionsværdien selv på denne måde\n\\[\nf'(x)=(1-|f(x)|)^2.\n\\tag{5}\\]\n\n\n\n\n\n\nOpgave 3: Differentiation af softsign-funktionen\n\n\n\n\n\nVis, at \\[\nf'(x)=\\frac{1}{\\left ( 1+ |x| \\right )^2}\n\\] ved at bruge en brøkregneregel til at omskrive funktionsudtrykket i (3):\n\\[\nf(x) =\n\\begin{cases}\nx \\cdot \\frac{1}{1+x} & \\textrm{hvis } x \\geq 0 \\\\\n\\\\\nx \\cdot \\frac{1}{1-x} & \\textrm{hvis } x &lt; 0 \\\\\n\\end{cases}\n\\tag{6}\\]\nTegn til sidst grafen for \\(f'\\). Synes du, at det ser ud som om, at \\(f'\\) er differentiabel?\n\n\n\n\n\n\n\n\n\nHints til opgave 3\n\n\n\n\n\n\nAntag først, at \\(x &gt; 0\\) og vis ved hjælp af produktreglen for differentiation, at \\[\nf'(x)=\\frac{1}{(1+x)^2} = \\frac{1}{(1+|x|)^2}.\n\\tag{7}\\] OBS! Du får på et tidspunkt brug for at sætte på fælles brøkstreg – fællesnævneren er her \\((1+x)^2\\).\nAntag nu, at \\(x&lt;0\\) og vis igen ved hjælp af produktreglen for differentiation at \\[\nf'(x)=\\frac{1}{(1-x)^2} = \\frac{1}{(1+|x|)^2}.\n\\tag{8}\\]\nAntag slutteligt, at \\(x=0\\) og indsæt \\(x=0\\) i både (7) og (8) og se, at du får det samme. Da \\(f'(0)\\) giver det samme for de to grene af funktionen, siger man, at funktionen også er differentiabel i \\(x=0\\).\n\n\n\n\n\n\n\n\n\n\nOpgave 4: Omskrivning af \\(f'(x)\\) for softsign-funktionen\n\n\n\n\n\nVis nu, at den afledede af softsign-funktionen kan udtrykkes ved hjælp af softsign-funktionen selv: \\[\nf'(x)=(1-|f(x)|)^2.\n\\]\n\n\n\n\n\n\n\n\n\nHints til opgave 4\n\n\n\n\n\n\nStart med at overvise dig selv om, at \\[\n|f(x)|=f(|x|)\n\\] ved at bruge definitionen i (2).\nVis at \\[\n(1-f(|x|))^2 = \\frac{1}{(1+|x|)^2}=f'(x)\n\\] Hint! Skriv \\(1\\) som \\(\\frac{1+|x|}{1+|x|}\\)."
  },
  {
    "objectID": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_del1.html#aktivitet-4---hyperbolsk-tangens",
    "href": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_del1.html#aktivitet-4---hyperbolsk-tangens",
    "title": "Del 1: Aktiveringsfunktioner",
    "section": "Aktivitet 4 - Hyperbolsk tangens",
    "text": "Aktivitet 4 - Hyperbolsk tangens\nFunktionen hyperbolsk tangens, \\(\\tanh\\), har forskrift \\[\n\\tanh(x) = \\frac{e^x-e^{-x}}{e^x+e^{-x}}\n\\]\nGrafen for hyperbolsk tangens er vist i figur 4.\n\n\n\n\n\n\nFigur 4: Grafen for hyperbolsk tangens.\n\n\n\nIfølge figuren ser det ud til, at \\(Vm(f)=(-1,1)\\). Det argumenterer vi nærmere for i boksen herunder.\n\n\n\n\n\n\nArgument for værdimængden for \\(\\tanh\\)\n\n\n\n\n\nVi starter med at vise, at\n\\[\n-1 &lt; \\tanh(x) &lt; 1.\n\\] Da \\[\n- e^x - e^{-x} &lt;e^x - e^{-x} &lt; e^x + e^{-x}\n\\] og \\(e^x + e^{-x}&gt;0\\) vil\n\\[\n-1 = \\frac{- e^x - e^{-x}}{e^x + e^{-x}} &lt; \\frac{e^x - e^{-x}}{e^x + e^{-x}} &lt; \\frac{e^x + e^{-x}}{e^x + e^{-x}} = 1.\n\\] Altså er \\(-1 &lt; \\tanh(x)&lt;1\\). Vi mangler kun at argumentere for, at værdimængden for \\(\\tanh\\) \"fylder\" hele intervallet \\((-1,1)\\) ud.\nPå figuren herunder ses grafen for den voksende eksponentialfunktion \\(e^x\\) (blå) og for den aftagende eksponentialfunktion \\(e^{-x}\\) (grøn).\n\n\n\n\n\nHer ses det, at for store positive værdier af \\(x\\) er \\(e^{-x} \\approx 0\\). Det vil sige, at for store positive værdier af \\(x\\) er\n\\[\n\\tanh(x)=\\frac{e^x-e^{-x}}{e^x+e^{-x}} \\approx \\frac{e^x-0}{e^x+0}=\\frac{e^x}{e^x}=1.\n\\]\nOmvendt gælder for store negative værdier af \\(x\\) er \\(e^x \\approx 0\\). Det vil sige, at for store negative værdier af \\(x\\) er\n\\[\n\\tanh(x)=\\frac{e^x-e^{-x}}{e^x+e^{-x}} \\approx \\frac{0-e^{-x}}{0+e^{-x}}=\\frac{-e^{-x}}{e^{-x}}=-1.\n\\] Det betyder, at \\[\n\\tanh(x) \\rightarrow 1 \\quad \\textrm{når} \\quad x \\rightarrow \\infty\n\\] og\n\\[\n\\tanh(x) \\rightarrow -1 \\quad \\textrm{når} \\quad x \\rightarrow - \\infty\n\\] hvilket stemmer fint overens med figur 4. Man siger for øvrigt, at linjerne med ligning \\(y=-1\\) og \\(y=1\\) er vandrette asymptoter.\nAltså har vi vist, at \\[\nVm(\\tanh)=(-1,1).\n\\]\n\n\n\nI nedenstående opgave skal vi vise, at \\(\\tanh\\) differentieret er\n\\[\n\\tanh'(x)=1-\\left ( \\tanh(x) \\right )^2.\n\\]\nFor at bevise det er det nemmeste at bruge kvotientreglen for differentiation. Måske har du hørt om den – måske har du ikke. Men her kommer den:\n\nKvotientreglen for differentiation \n\\[\n\\left ( \\frac{f}{g}\\right)'(x) = \\frac{f'(x) \\cdot g(x)-f(x) \\cdot g'(x)}{(g(x))^2}, \\quad g(x) \\neq 0\n\\]\n\n\n\n\n\n\n\nOpgave 5: Differentiation af tanh-funktionen og omskrivning\n\n\n\n\n\nVis, at tangens hyperbolsk \\[\n\\tanh(x)=\\frac{e^x-e^{-x}}{e^x+e^{-x}}\n\\] differentieret er \\[\n\\tanh'(x)=1-\\left ( \\tanh(x) \\right )^2.\n\\]\n\n\n\n\n\n\n\n\n\nHints til opgave 5\n\n\n\n\n\n\nBrug kvotientreglen for differentiation til at vise, at \\[\n\\tanh'(x)= 1 - \\left (\\frac{e^x-e^{-x}}{e^x+e^{-x}} \\right)^2\n\\] Hint! På et tidspunkt får du brug for brøkregnereglen \\(\\frac{a+b}{c}=\\frac{a}{c}+\\frac{b}{c}\\).\nBrug definitionen af tangens hyperbolsk til at indse at \\[\n\\tanh'(x)=1-\\left ( \\tanh(x) \\right )^2.\n\\]"
  },
  {
    "objectID": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_del1.html#aktivitet-5---relu",
    "href": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_del1.html#aktivitet-5---relu",
    "title": "Del 1: Aktiveringsfunktioner",
    "section": "Aktivitet 5 - ReLU",
    "text": "Aktivitet 5 - ReLU\nAktiveringsfunktionen ReLU som står for Reflected Linear Unit har forskrift\n\\[\nf(x) =\n\\begin{cases}\nx & \\textrm{hvis } x &gt; 0 \\\\\n0 & \\textrm{hvis } x \\leq 0 \\\\\n\\end{cases}\n\\] og grafen for ReLU-funktionen ses i figur 5.\n\n\n\n\n\n\nFigur 5: Grafen for ReLU-funktionen.\n\n\n\nVærdimængden for ReLU-funktionen er \\([0, \\infty)\\).\nDet er ret tydeligt, at ReLU-funktionen ikke er differentiabel i \\(0\\). Men hvis vi definerer, at \\(f'(0)\\) skal være \\(0\\) så ses det nemt, at\n\\[\nf'(x) =\n\\begin{cases}\n1 & \\textrm{hvis } x &gt; 0 \\\\\n0 & \\textrm{hvis } x \\leq 0 \\\\\n\\end{cases}.\n\\]\nReLU-funktionen adskiller sig fra de andre aktiveringsfunktioner ved, at værdimængden er ubegrænset. Hvis man ønsker at bruge aktiveringsfunktionen til at modellere en sandsynlighed, som beskrevet tidligere, så dur det selvfølgelig ikke. Men i praksis viser ReLU-funktionen sig at være utrolig anvendelig som aktiveringsfunktion i de skjulte lag i kunstige neurale netværk. For det første kan nogle af de andre aktiveringsfunktioner resultere i det, vi i afsnittet om valg af tabsfunktion i noten om kunstige neurale netværk, kalder for slow learning. Det betyder kort sagt, at det går for langsomt med at finde minimum for tabsfunktionen. Dét problem har ReLU-funktionen ikke. For det andet er det meget hurtigt og nemt at udregne både ReLU-funktionen selv og også dens afledede. Det er for eksempel til sammenligning beregningsmæssigt tungere at udregne sigmoid-funktionen og dennes afledede. Hvis man har et netværk med millioner af neuroner, så er denne beregningsmæssige forskel ikke uvæsentlig."
  },
  {
    "objectID": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_forside.html",
    "href": "undervisningsforloeb/neurale_net_langt_forloeb/neurale_net_forside.html",
    "title": "Kunstige neurale netværk",
    "section": "",
    "text": "Formål\nDette længere forløb handler om kunstige neurale netværk, som er en vigtig metode indenfor kunstig intelligens.\nForløbet indeholder også et forslag til et spørgsmål til mundtlig eksamen, og kan derfor dække kravet på stx A om, at mindst ét spørgsmål skal stilles med udgangspunkt i det supplerende stof.\n\n\nForudsætninger og tidsforbrug\nForløbet kræver kendskab til:\n\nDifferentialregning.\n\nTidsforbrug: 10-12 timer.\n\n\nForløbet\nForløbet består af følgende dele:\nDel 1: Aktiveringsfunktioner\nDel 2: Kunstige neuroner\nDel 3: Simple kunstige neurale netværk\nDel 4: Tabsfunktioner\n\n\nForslag til materiale som kan danne udgangspunkt for en SRP\nBrug listing\nEksamensspørgsmål\n\n\nTil læreren\nHerunder findes diverse fif til læreren.\nTil læreren"
  },
  {
    "objectID": "undervisningsforloeb/opklar_et_mord.html",
    "href": "undervisningsforloeb/opklar_et_mord.html",
    "title": "Opklar et mord!",
    "section": "",
    "text": "Forudsætninger og tidsforbrug\n\n\n\n\n\nForløbet kræver kendskab til:\n\nDifferentialregning.\nOptimering.\n\nTidsforbrug: Ca. 90 minutter."
  },
  {
    "objectID": "undervisningsforloeb/opklar_et_mord.html#hvad-er-et-kunstigt-neuralt-netværk",
    "href": "undervisningsforloeb/opklar_et_mord.html#hvad-er-et-kunstigt-neuralt-netværk",
    "title": "Opklar et mord!",
    "section": "Hvad er et kunstigt neuralt netværk?",
    "text": "Hvad er et kunstigt neuralt netværk?\nStart med at se denne video, hvor vi fortæller lidt om, hvad AI er."
  },
  {
    "objectID": "undervisningsforloeb/opklar_et_mord.html#hvem-har-afsat-fingeraftryk-i-de-forskellige-lokaler",
    "href": "undervisningsforloeb/opklar_et_mord.html#hvem-har-afsat-fingeraftryk-i-de-forskellige-lokaler",
    "title": "Opklar et mord!",
    "section": "Hvem har afsat fingeraftryk i de forskellige lokaler?",
    "text": "Hvem har afsat fingeraftryk i de forskellige lokaler?\nI alt 10 elever er under mistanke. Det drejer sig om:\n\n\nAlexander\nBent\nCecilie\nHugo\nKaroline\nMette\nSigne\nSigurd\nValdemar\nVictoria\n\nPolitiet har taget syv forskellige fingeraftryk fra hver elev (data stammer oprindeligt fra FVS2000 - Fingerprint Verification Competition). På skolen har man i forskellige lokaler også fundet fingeraftryk - man ved bare ikke, hvem fingeraftrykkene stammer fra.\nAlle fingeraftryk, som er fundet i lokalerne, er nummeret fra 101-110. Fingeraftrykkene er fundet i følgende lokaler:\n\n\n\nFysik\nKemi\nBiotek\nMatematik\nBiologi\n\n\n\n\n107\n102\n101\n104\n103\n\n\n109\n106\n105\n108\n110\n\n\n\nI skal nu ud fra fingeraftrykkene hjælpe politiet med at afgøre, hvem der har befundet sig i de forskellige lokaler.\nVi skal gøre opmærksom på, at det, vi gør her, ikke er sådan politiet arbejder med fingeraftryk. Dette er flot for at vise, hvordan man kunne bruge kunstig intelligens. \n\n\n\n\n\n\nOpgave 1: Træn forskellige neurale netværk\n\n\n\n\n\n\nInstaller programmet Orange. Du kan få hjælp her, hvis det driller.\nSe denne video, som handler om, hvordan man træner et kunstigt neuralt netværk i Orange.\n\n\n\nVed hjælp af træningsdata skal I træne forskellige neurale netværk, som kan prædiktere hvem et givent fingeraftryk tilhører. Prøv med forskellige neurale netværk af forskellig dybde (dvs. et varierende antal skjulte lag) og forskellig antal neuroner i hvert skjult lag.\nSammenlign jeres forskellige modeller vha. ”Test and Score” (brug krydsvalidering - og husk at CA skal være tæt på 1). ”Test and Score” skal som input have billederne fra træningsdata og de forskellige modeller (dvs. de forskellige neurale netværk).\n\n\n\n\n\n\n\n\n\n\nOpgave 2: Lav en prædiktion på baggrund af den valgte model\n\n\n\n\n\n\nSe denne video som viser, hvordan man kan prædiktere i Orange ud fra en valgt model.\n\n\n\nVælg den bedste model og brug den til at prædiktere hvem de ti forskellige fingeraftryk (101-110) stammer fra. Brug ”Predictions” - ”Predictions” skal som input have den valgte model (og den valgte model skal have billederne som input) samt billederne i testdatasættet.\n\n\n\n\n\n\n\n\n\n\nOpgave 3: Hvem har været hvor?\n\n\n\n\n\n\nNoter her hvem der er hvem:\n\n\n\n\nLokale\nNummer\nNavn\n\n\n\n\nFysik\n107\n\n\n\nFysik\n109\n\n\n\nKemi\n102\n\n\n\nKemi\n106\n\n\n\nBiotek\n101\n\n\n\nBiotek\n105\n\n\n\nMatematik\n104\n\n\n\nMatematik\n108\n\n\n\nBiologi\n103\n\n\n\nBiologi\n110\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpgave 4: Hvem er morderen?\n\n\n\n\n\nPolitiet kan nu oplyse, at mordet blev begået i matematik… 😱\nTager du nummeret for hver af de to personer, som befandt sig i matematik, trækker 100 fra og dividerer med 2, så har du antallet af bogstaver i morderens navn.\n\nHvem er morderen?"
  },
  {
    "objectID": "undervisningsforloeb/aktiveringsfunktioner.html",
    "href": "undervisningsforloeb/aktiveringsfunktioner.html",
    "title": "Aktiveringsfunktioner",
    "section": "",
    "text": "Forudsætninger og tidsforbrug\n\n\n\n\n\nForløbet kræver kendskab til:\n\nDifferentialregning herunder differentiation af sammensatte funktioner og produktreglen.\n\nTidsforbrug: Ca. 1-2 x 90 minutter alt efter hvor mange aktiveringsfunktioner, I ønsker at arbejde med. I kan også arbejde i grupper og lade hver gruppe arbejde med hver sin aktiveringsfunktion."
  },
  {
    "objectID": "undervisningsforloeb/aktiveringsfunktioner.html#introduktion",
    "href": "undervisningsforloeb/aktiveringsfunktioner.html#introduktion",
    "title": "Aktiveringsfunktioner",
    "section": "Introduktion",
    "text": "Introduktion\nNår man træner en AI model, sker det som regel ved, at man forsøger at minimere de fejl, som modellen laver, når den anvendes på data, hvor man allerede kender svaret.\nFor at blive lidt mere konkret så minimerer man en såkaldt tabsfunktion \\(E\\) (\\(E\\) for error function), som har til formål at \"måle\", hvor god en AI model1 er. En tabsfunktion \\(E\\) har altid den egenskab, at \\(E \\geq 0\\), og at en lille værdi af \\(E\\) svarer til en god model (der er et lille tab), mens en stor værdi af \\(E\\) svarer til en mindre god model. Derfor vælger man den model, som giver den mindste værdi af tabsfunktionen.\n1 Med AI model tænker vi her på en perceptron, et simplet neuralt netværk, et generelt neuralt netværk eller en anden form for funktion, som kan bruges til at prædiktere et eller andet.AI modellen trænes altså ved at finde minimum for tabsfunktionen. Det gøres ofte ved hjælp af gradientnedstigning – men den konkrete metode er ikke så vigtig lige nu. Det vigtige er her at forstå, at hvis man skal finde minimum for en funktion, så har man brug for at kunne differentiere.\nTabsfunktionen er en sammensat funktion. Den er sammensat af lineære funktioner, som vi kender rigtig godt fra tidligere, andengradspolynomier, og en særlig klasse af funktioner, som kaldes for aktiveringsfunktioner. Og det giver nok mening, at hvis man skal differentiere selve tabsfunktionen, så må man også kunne differentiere den anvendte aktiveringsfunktion \\(f\\).\nDesuden viser det sig vigtigt, at det ikke må være alt for beregningsmæssigt tungt at beregne funktionsværdierne \\(f(x)\\) og \\(f'(x)\\). Det skal simpelthen gøres så mange gange – derfor dur det ikke, at det tager for lang tid. Det er derfor ønskværdigt, hvis en aktiveringsfunktions afledede funktion \\(f'(x)\\) kan beregnes forholdvis simpelt ved hjælp af \\(f(x)\\). Det betyder nemlig, at hvis vi allerede har udregnet \\(f(x)\\), så kræver det ikke ret meget også at udregne \\(f'(x)\\). Det kan illustreres med et eksempel:\n\nEksempel 1 Funktionen\n\\[\nf(x)=e^{kx}\n\\]\nhar afledede funktion\n\\[\nf'(x)=k \\cdot e^{kx}\n\\]\nDet vil sige, at vi kan udtrykke \\(f'(x)\\) ved hjælp af \\(f(x)\\) på denne måde:\n\\[\nf'(x)= k \\cdot f(x).\n\\] Det betyder, at hvis man allerede har udregnet funktionsværdien \\(f(x_0)\\), så kan man meget nemt udregne tangenthældningen \\(f'(x_0)\\) i punktet \\((x_0,f(x_0))\\) ved at gange \\(f(x_0)\\) med \\(k\\).\n\nMen ikke alle funktioner har denne egenskab, hvilket det næste eksempel illustrerer:\n\nEksempel 2 Grafen for funktionen\n\\[\nf(x)=2x^3-3x^2-4x+5\n\\] ses i figur 1.\n\n\n\n\n\n\nFigur 1: Grafen for funktionen \\(f(x)=2x^3-3x^2-4x+5\\).\n\n\n\nPå grafen er der markeret tre punkter, hvor funktionsværdien er \\(2\\). I disse tre punkter er tangenten til grafen også indtegnet (som stiplede linjer). Her ses det tydeligt, at disse tangenters hældninger ikke er ens. Det betyder derfor, at \\(f'(x)\\) ikke kan beregnes simpelt alene ud fra funktionsværdien \\(f(x)\\).\n\nHvis du vil vide lidt mere om, hvad det der AI egentlig går ud på, så kan du se denne video:\n\nI det nedenstående vil vi nu behandle en række af de mest anvendte aktiveringsfunktioner. Vi finder deres afledede funktioner, og vi vil se, hvordan de afledede funktioner alle kan udtrykkes ved hjælp af den oprindelig aktiveringsfunktion."
  },
  {
    "objectID": "undervisningsforloeb/aktiveringsfunktioner.html#sigmoid",
    "href": "undervisningsforloeb/aktiveringsfunktioner.html#sigmoid",
    "title": "Aktiveringsfunktioner",
    "section": "Sigmoid",
    "text": "Sigmoid\nSigmoid-funktionen har forskrift\n\\[\nf(x)=\\frac{1}{1+e^{-x}},\n\\tag{1}\\]\nsom også kan skrives\n\\[\nf(x)=\\frac{e^x}{1+e^x},\n\\] hvilket ses med at gange med \\(e^x\\) i både tæller og nævner i (1).\nGrafen for Sigmoid-funktionen ses i figur 2.\n\n\n\n\n\n\nFigur 2: Grafen for sigmoid-funktionen.\n\n\n\nDet ser på figur 2 ud som om, at værdimængden for \\(f\\) er det åbne interval2 \\((0,1)\\). Det skrives\n2 Bemærk, at det åbne interval \\((0,1)\\) også kan skrives \\(]0,1[\\).\\[\nVm(f)=(0,1).\n\\]\nHvis du vil have et lidt bedre argument for det, kan du læse i boksen herunder.\n\n\n\n\n\n\nArgument for værdimængden for \\(f\\)\n\n\n\n\n\nVi vil her argumentere for, at værdimængden for \\(f\\) er \\((0,1)\\). Vi vil starte med at se, at funktionsværdierne for \\(f\\) ligger mellem \\(0\\) og \\(1\\).\nDa både tæller og nævner i (1) er positive, så må \\(f(x)&gt;0\\). Og da\n\\[\n1&lt;1+e^{-x}\n\\] så må\n\\[\n\\frac{1}{1+e^{-x}}&lt;\\frac{1+e^{-x}}{1+e^{-x}}=1.\n\\]\nDet vil sige, at \\[\n0 &lt; f(x) &lt; 1\n\\] og derfor må værdimængden for \\(f\\) være en del af intervallet \\((0,1)\\). Det kan skrives sådan her\n\\[\nVm(f) \\subseteq (0,1).\n\\] Vi vil nu vise, at vi kan komme lige så tæt på \\(0\\) og \\(1\\), som det skal være. Det vil med andre ord sige, at værdimængden for \\(f\\) \"fylder\" hele intervallet \\((0,1)\\) ud.\nPå figuren herunder ses grafen for \\(e^{-x}\\).\n\n\n\n\n\nDa \\(e^{-x}\\) er en aftagende eksponentialfunktion vil\n\\[\ne^{-x} \\rightarrow 0 \\quad \\textrm{når} \\quad x \\rightarrow \\infty\n\\] og\n\\[\ne^{-x} \\rightarrow \\infty \\quad \\textrm{når} \\quad x \\rightarrow -\\infty.\n\\]\nDet betyder, at \\[\n\\frac{1}{1+e^{-x}} \\rightarrow 1 \\quad \\textrm{når} \\quad x \\rightarrow \\infty\n\\]\nog\n\\[\n\\frac{1}{1+e^{-x}} \\rightarrow 0 \\quad \\textrm{når} \\quad x \\rightarrow -\\infty.\n\\]\nAlt i alt har vi altså argumenteret for, at værdimængden for \\(f\\) er \\((0,1)\\).\n\n\n\nDe følgende opgaver går ud på at vise, at\n\\[\nf'(x)= \\frac{e^{-x}}{(1+e^{-x})^2}\n\\] og at \\(f'(x)\\) kan udtrykkes ved hjælp af \\(f(x)\\) på denne måde\n\\[\nf'(x)= f(x)\\cdot (1-f(x)).\n\\]\n\n\n\n\n\n\nOpgave 1: Differentiation af sigmoid-funktionen\n\n\n\n\n\nVis, at \\[\nf'(x)= \\frac{e^{-x}}{(1+e^{-x})^2}.\n\\]\n\n\n\n\n\n\n\n\n\nHints til opgave 1\n\n\n\n\n\nVi skal starte med at se, at vi kan tænke på sigmoid-funktionen \\[\nf(x)=\\frac{1}{1+e^{-x}}.\n\\] som en \"dobbelt sammensat\" funktion. Sigmoid-funktionen består nemlig af en brøk på formen \\(\\frac{1}{x}\\) og af eksponentialfunktionen \\(e^{-x}\\).\nGør følgende:\n\nStart med at opskrive differentialkvotienten for \\[\\frac{1}{x} \\quad \\textrm{og} \\quad e^{-x}.\\]\nBrug ovenstående til at vise, at \\[\nf'(x)= \\frac{e^{-x}}{(1+e^{-x})^2}.\n\\]\n\n\n\n\n\n\n\n\n\n\nOpgave 2: Omskrivning af \\(f'(x)\\) for sigmoid-funktionen\n\n\n\n\n\nVis, at \\[\nf'(x)= f(x)\\cdot (1-f(x)).\n\\] når \\[\nf(x)=\\frac{1}{1+e^{-x}}.\n\\]\n\n\n\n\n\n\n\n\n\nHints til opgave 2\n\n\n\n\n\nDer er flere fremgangsmåder for at løse opgaven:\nFremgangsmåde 1\n\nIsolér \\(e^{-x}\\) i \\[\nf(x)=\\frac{1}{1+e^{-x}}.\n\\]\nIndsæt dette udtryk for \\(e^{-x}\\) i \\[\nf'(x)= \\frac{e^{-x}}{(1+e^{-x})^2}\n\\] og reducer.\nHint! Du får brug for at sætte på fælles brøkstreg. Husk også at man dividere med en brøk ved at gange med den omvendte.\n\nFremgangsmåde 2\n\nStart med at udregne \\[1-f(x).\\] Hint! Sæt på fælles brøkstreg ved at skrive \\(1\\) som \\(\\frac{1+e^{-x}}{1+e^{-x}}\\).\nVis nu at \\[\nf(x)\\cdot (1-f(x)) = \\frac{e^{-x}}{(1+e^{-x})^2}=f'(x).\n\\] Husk, at man ganger to brøker med hinanden ved at gange tæller med tæller og nævner med nævner."
  },
  {
    "objectID": "undervisningsforloeb/aktiveringsfunktioner.html#softsign",
    "href": "undervisningsforloeb/aktiveringsfunktioner.html#softsign",
    "title": "Aktiveringsfunktioner",
    "section": "Softsign",
    "text": "Softsign\nSoftsign-funktionen har forskrift\n\\[\nf(x)=\\frac{x}{1+|x|}.\n\\] Husk på at \\(|x|\\) betyder den numeriske værdi af \\(x\\). Det vil sige\n\\[\n|x| =\n\\begin{cases}\nx & \\textrm{hvis } x \\geq 0 \\\\\n-x & \\textrm{hvis } x &lt; 0 \\\\\n\\end{cases}\n\\tag{2}\\] Det betyder for eksempel at \\(|7|=7\\) og \\(|-7|=7\\). Grafen for \\(|x|\\) ses i figur 3.\n\n\n\n\n\n\nFigur 3: Grafen for \\(|x|\\).\n\n\n\nGrafen for softsign-funktionen \\(f\\) ses i figur 4.\n\n\n\n\n\n\nFigur 4: Grafen for softsign-funktionen.\n\n\n\nDa den numeriske værdi af \\(x\\) indgår i forskriften, kunne man få den tanke, at \\(f\\) måske hverken er kontinuert eller differentiabel i \\(0\\). For eksempel kan man i figur 3 se, at \\(|x|\\) ikke er differentiabel i \\(0\\).\nMen bruger vi definitionen på \\(|x|\\), får vi\n\\[\nf(x) =\n\\begin{cases}\n\\frac{x}{1+x} & \\textrm{hvis } x \\geq 0 \\\\\n\\\\\n\\frac{x}{1-x} & \\textrm{hvis } x &lt; 0 \\\\\n\\end{cases}\n\\tag{3}\\]\nUd fra denne omskrivning kan man vise, at \\(f\\) rent faktisk er kontinuert i \\(0\\). Det kan du læse mere om i boksen herunder, hvis du har lyst.\nPå figur 4 ser det ud som om, at værdimængden for \\(f\\) er \\((-1,1)\\) (også det argumenterer vi for i boksen):\n\\[\nVm(f) = (-1,1).\n\\]\nDet vil sige, at hvis vi skal bruge softsign-funktionen som aktiveringsfunktion, så skal targetværdierne være \\(\\pm 1\\).\n\n\n\n\n\n\nArgument for kontinuitet i \\(0\\) og værdimængde for \\(f\\)\n\n\n\n\n\nLad os først argumentere for, at \\(f\\) er kontinuert i \\(0\\). For det første ser vi, at \\(f(0)=0/(1+0)=0\\) og \\(f(x) \\rightarrow 0\\), når \\(x\\) nærmer sig \\(0\\) både fra højre og venstre. Det betyder, at \\(f\\) er kontinuert i \\(0\\).\nVi vil herefter indse, at funktionsværdierne for \\(f\\) ligger i \\((-1,1)\\). Ser vi på definitionen i (3), kan vi se, at vi skal inddele i to tilfælde, nemlig \\(x \\geq 0\\) og \\(x&lt;0\\):\n\nTilfælde 1\nHvis \\(x \\geq 0\\), så er \\[\nf(x)= \\frac{x}{1+x}.\n\\] Her er både tæller og nævner positiv, og derfor vil \\(-1&lt;0&lt;f(x)\\). Da \\[\nx &lt; 1+x\n\\] og \\(1+x\\) er positiv vil \\[\nf(x)=\\frac{x}{1+x}&lt;\\frac{1+x}{1+x}=1.\n\\] Altså er \\(-1&lt;f(x)&lt;1\\) i det tilfælde, hvor \\(x \\geq 0\\).\nTilfælde 2\nHvis \\(x&lt;0\\), så er \\[\nf(x) = \\frac{x}{1-x}.\n\\] Her er tælleren negativ, mens nævneren er positiv. Det vil sige, at \\(f(x)&lt;0&lt;1\\). Nu er \\[\nx-1&lt;x&lt;0.\n\\] Da \\(x-1&lt;0\\), vil \\(-(x-1)&gt;0\\), og vi kan derfor dividere ovenstående igennem med \\(-(x-1)\\) uden at ændre på ulighedstegnet: \\[\n\\frac{x-1}{-(x-1)}&lt;\\frac{x}{-(x-1)}.\n\\] Da venstre side giver \\(-1\\) og \\(-(x-1)=1-x\\) får vi \\[\n-1 &lt; \\frac{x}{1-x}=f(x).\n\\] Alt i alt har vi altså også i dette tilfælde vist, at \\[\n-1 &lt; f(x) &lt; 1.\n\\]\n\nDet vil sige, at \\(Vm(f) \\subseteq (-1,1)\\).\nVi vil nu vise, at værdimængden for \\(f\\) \"fylder\" hele intervallet \\((-1,1)\\) ud. Vi ser, at for store positive værdier af \\(x\\) vil \\[\nf(x)= \\frac{x}{1+x} \\approx \\frac{x}{x}=1\n\\] og for store negative værdier af \\(x\\) vil \\[\nf(x)= \\frac{x}{1-x} \\approx \\frac{x}{-x}=-1\n\\] Det betyder, at \\[\nf(x) \\rightarrow 1 \\quad \\textrm{når} \\quad x \\rightarrow \\infty\n\\] og\n\\[\nf(x) \\rightarrow -1 \\quad \\textrm{når} \\quad x \\rightarrow - \\infty\n\\] hvilket stemmer fint overens med figur 4.\nVi har hermed vist, at \\(Vm(f) = (-1,1).\\)\n\n\n\nI nedenstående opgaver skal vi vise, at\n\\[\nf'(x)=\\frac{1}{\\left ( 1+ |x| \\right )^2}\n\\tag{4}\\]\nog at den afledte kan findes ved hjælp af funktionsværdien selv på denne måde\n\\[\nf'(x)=(1-|f(x)|)^2.\n\\tag{5}\\]\n\n\n\n\n\n\nOpgave 3: Differentiation af softsign-funktionen\n\n\n\n\n\nVis, at \\[\nf'(x)=\\frac{1}{\\left ( 1+ |x| \\right )^2}\n\\] ved at bruge en brøkregneregel til at omskrive funktionsudtrykket i (3):\n\\[\nf(x) =\n\\begin{cases}\nx \\cdot \\frac{1}{1+x} & \\textrm{hvis } x \\geq 0 \\\\\n\\\\\nx \\cdot \\frac{1}{1-x} & \\textrm{hvis } x &lt; 0 \\\\\n\\end{cases}\n\\tag{6}\\]\nTegn til sidst grafen for \\(f'\\). Synes du, at det ser ud som om, at \\(f'\\) er differentiabel?\n\n\n\n\n\n\n\n\n\nHints til opgave 3\n\n\n\n\n\n\nAntag først, at \\(x &gt; 0\\) og vis ved hjælp af produktreglen for differentiation, at \\[\nf'(x)=\\frac{1}{(1+x)^2} = \\frac{1}{(1+|x|)^2}.\n\\tag{7}\\] OBS! Du får på et tidspunkt brug for at sætte på fælles brøkstreg – fællesnævneren er her \\((1+x)^2\\).\nAntag nu, at \\(x&lt;0\\) og vis igen ved hjælp af produktreglen for differentiation at \\[\nf'(x)=\\frac{1}{(1-x)^2} = \\frac{1}{(1+|x|)^2}.\n\\tag{8}\\]\nAntag slutteligt, at \\(x=0\\) og indsæt \\(x=0\\) i både (7) og (8) og se, at du får det samme. Da \\(f'(0)\\) giver det samme for de to grene af funktionen, siger man, at funktionen også er differentiabel i \\(x=0\\).\n\n\n\n\n\n\n\n\n\n\nOpgave 4: Omskrivning af \\(f'(x)\\) for softsign-funktionen\n\n\n\n\n\nVis nu, at den afledede af softsign-funktionen kan udtrykkes ved hjælp af softsign-funktionen selv: \\[\nf'(x)=(1-|f(x)|)^2.\n\\]\n\n\n\n\n\n\n\n\n\nHints til opgave 4\n\n\n\n\n\n\nStart med at overvise dig selv om, at \\[\n|f(x)|=f(|x|)\n\\] ved at bruge definitionen i (2).\nVis at \\[\n(1-f(|x|))^2 = \\frac{1}{(1+|x|)^2}=f'(x)\n\\] Hint! Skriv \\(1\\) som \\(\\frac{1+|x|}{1+|x|}\\)."
  },
  {
    "objectID": "undervisningsforloeb/aktiveringsfunktioner.html#hyperbolsk-tangens",
    "href": "undervisningsforloeb/aktiveringsfunktioner.html#hyperbolsk-tangens",
    "title": "Aktiveringsfunktioner",
    "section": "Hyperbolsk tangens",
    "text": "Hyperbolsk tangens\nFunktionen hyperbolsk tangens, \\(\\tanh\\), har forskrift \\[\n\\tanh(x) = \\frac{e^x-e^{-x}}{e^x+e^{-x}}\n\\]\nGrafen for hyperbolsk tangens er vist i figur 5.\n\n\n\n\n\n\nFigur 5: Grafen for hyperbolsk tangens.\n\n\n\nIfølge figuren ser det ud til, at \\(Vm(f)=(-1,1)\\). Det argumenterer vi nærmere for i boksen herunder.\n\n\n\n\n\n\nArgument for værdimængden for \\(\\tanh\\)\n\n\n\n\n\nVi starter med at vise, at\n\\[\n-1 &lt; \\tanh(x) &lt; 1.\n\\] Da \\[\n- e^x - e^{-x} &lt;e^x - e^{-x} &lt; e^x + e^{-x}\n\\] og \\(e^x + e^{-x}&gt;0\\) vil\n\\[\n-1 = \\frac{- e^x - e^{-x}}{e^x + e^{-x}} &lt; \\frac{e^x - e^{-x}}{e^x + e^{-x}} &lt; \\frac{e^x + e^{-x}}{e^x + e^{-x}} = 1.\n\\] Altså er \\(-1 &lt; \\tanh(x)&lt;1\\). Vi mangler kun at argumentere for, at værdimængden for \\(\\tanh\\) \"fylder\" hele intervallet \\((-1,1)\\) ud.\nPå figuren herunder ses grafen for den voksende eksponentialfunktion \\(e^x\\) (blå) og for den aftagende eksponentialfunktion \\(e^{-x}\\) (grøn).\n\n\n\n\n\nHer ses det, at for store positive værdier af \\(x\\) er \\(e^{-x} \\approx 0\\). Det vil sige, at for store positive værdier af \\(x\\) er\n\\[\n\\tanh(x)=\\frac{e^x-e^{-x}}{e^x+e^{-x}} \\approx \\frac{e^x-0}{e^x+0}=\\frac{e^x}{e^x}=1.\n\\]\nOmvendt gælder for store negative værdier af \\(x\\) er \\(e^x \\approx 0\\). Det vil sige, at for store negative værdier af \\(x\\) er\n\\[\n\\tanh(x)=\\frac{e^x-e^{-x}}{e^x+e^{-x}} \\approx \\frac{0-e^{-x}}{0+e^{-x}}=\\frac{-e^{-x}}{e^{-x}}=-1.\n\\] Det betyder, at \\[\n\\tanh(x) \\rightarrow 1 \\quad \\textrm{når} \\quad x \\rightarrow \\infty\n\\] og\n\\[\n\\tanh(x) \\rightarrow -1 \\quad \\textrm{når} \\quad x \\rightarrow - \\infty\n\\] hvilket stemmer fint overens med figur 5. Man siger for øvrigt, at linjerne med ligning \\(y=-1\\) og \\(y=1\\) er vandrette asymptoter.\nAltså har vi vist, at \\[\nVm(\\tanh)=(-1,1).\n\\]\n\n\n\nI nedenstående opgave skal vi vise, at \\(\\tanh\\) differentieret er\n\\[\n\\tanh'(x)=1-\\left ( \\tanh(x) \\right )^2.\n\\]\nFor at bevise det er det nemmeste at bruge kvotientreglen for differentiation. Måske har du hørt om den – måske har du ikke. Men her kommer den:\n\nKvotientreglen for differentiation \n\\[\n\\left ( \\frac{f}{g}\\right)'(x) = \\frac{f'(x) \\cdot g(x)-f(x) \\cdot g'(x)}{(g(x))^2}, \\quad g(x) \\neq 0\n\\]\n\n\n\n\n\n\n\nOpgave 5: Differentiation af tanh-funktionen og omskrivning\n\n\n\n\n\nVis, at tangens hyperbolsk \\[\n\\tanh(x)=\\frac{e^x-e^{-x}}{e^x+e^{-x}}\n\\] differentieret er \\[\n\\tanh'(x)=1-\\left ( \\tanh(x) \\right )^2.\n\\]\n\n\n\n\n\n\n\n\n\nHints til opgave 5\n\n\n\n\n\n\nBrug kvotientreglen for differentiation til at vise, at \\[\n\\tanh'(x)= 1 - \\left (\\frac{e^x-e^{-x}}{e^x+e^{-x}} \\right)^2\n\\] Hint! På et tidspunkt får du brug for brøkregnereglen \\(\\frac{a+b}{c}=\\frac{a}{c}+\\frac{b}{c}\\).\nBrug definitionen af tangens hyperbolsk til at indse at \\[\n\\tanh'(x)=1-\\left ( \\tanh(x) \\right )^2.\n\\]"
  },
  {
    "objectID": "undervisningsforloeb/aktiveringsfunktioner.html#relu",
    "href": "undervisningsforloeb/aktiveringsfunktioner.html#relu",
    "title": "Aktiveringsfunktioner",
    "section": "ReLU",
    "text": "ReLU\nAktiveringsfunktionen ReLU som står for Reflected Linear Unit har forskrift\n\\[\nf(x) =\n\\begin{cases}\nx & \\textrm{hvis } x &gt; 0 \\\\\n0 & \\textrm{hvis } x \\leq 0 \\\\\n\\end{cases}\n\\] og grafen for ReLU-funktionen ses i figur 6.\n\n\n\n\n\n\nFigur 6: Grafen for ReLU-funktionen.\n\n\n\nVærdimængden for ReLU-funktionen er \\([0, \\infty)\\).\nDet er ret tydeligt, at ReLU-funktionen ikke er differentiabel i \\(0\\). Men hvis vi definerer, at \\(f'(0)\\) skal være \\(0\\) så ses det nemt, at\n\\[\nf'(x) =\n\\begin{cases}\n1 & \\textrm{hvis } x &gt; 0 \\\\\n0 & \\textrm{hvis } x \\leq 0 \\\\\n\\end{cases}.\n\\]\nReLU-funktionen adskiller sig fra de andre aktiveringsfunktioner ved, at værdimængden er ubegrænset. Hvis man ønsker at bruge aktiveringsfunktionen til at modellere en sandsynlighed, som beskrevet tidligere, så dur det selvfølgelig ikke. Men i praksis viser ReLU-funktionen sig at være utrolig anvendelig som aktiveringsfunktion i de skjulte lag i kunstige neurale netværk. For det første kan nogle af de andre aktiveringsfunktioner resultere i det, vi i afsnittet om valg af tabsfunktion i noten om kunstige neurale netværk, kalder for slow learning. Det betyder kort sagt, at det går for langsomt med at finde minimum for tabsfunktionen. Dét problem har ReLU-funktionen ikke. For det andet er det meget hurtigt og nemt at udregne både ReLU-funktionen selv og også dens afledede. Det er for eksempel til sammenligning beregningsmæssigt tungere at udregne sigmoid-funktionen og dennes afledede. Hvis man har et netværk med millioner af neuroner, så er denne beregningsmæssige forskel ikke uvæsentlig.\nFor yderligere læsning henviser vi til referencerne i afsnittet videre læsning."
  },
  {
    "objectID": "undervisningsforloeb/aktiveringsfunktioner.html#overblik",
    "href": "undervisningsforloeb/aktiveringsfunktioner.html#overblik",
    "title": "Aktiveringsfunktioner",
    "section": "Overblik",
    "text": "Overblik\nI tabellen herunder finder du et overblik over de forskellige aktiveringsfunktioner, som vi har behandlet ovenfor.\n\n\n\n\n\n\n\n\n\n\n\nNavn\n\\(f(x)\\)\nGraf\n\\(Vm(f)\\)\n\\(f'(x)\\)\n\n\n\n\n\nSigmoid\n\\(\\frac{1}{1+e^{-x}}\\)\n\n\\((0,1)\\)\n\\(f(x)\\cdot(1-f(x))\\)\n\n\n\nSoftsign\n\\(\\frac{x}{1+|x|}\\)\n\n\\((-1,1)\\)\n\\((1-|f(x)|)^2\\)\n\n\n\nHyperbolsk tangens\n\\(\\frac{e^x-e^{-x}}{e^x+e^{-x}}\\)\n\n\\((-1,1)\\)\n\\(1-\\left ( \\tanh(x) \\right )^2\\)\n\n\n\nReLU\n\\(\\begin{cases}\nx & \\textrm{hvis } x &gt; 0 \\\\\n0 & \\textrm{hvis } x \\leq 0 \\\\\n\\end{cases}\\)\n\n\\([0,\\infty)\\)\n\\(\\begin{cases}\n1 & \\textrm{hvis } x &gt; 0 \\\\\n0 & \\textrm{hvis } x \\leq 0 \\\\\n\\end{cases}\\)"
  },
  {
    "objectID": "undervisningsforloeb/aktiveringsfunktioner.html#sec-videre",
    "href": "undervisningsforloeb/aktiveringsfunktioner.html#sec-videre",
    "title": "Aktiveringsfunktioner",
    "section": "Videre læsning",
    "text": "Videre læsning\n\nActivation Functions in Neural Networks: With 15 examples\nRELU and SIGMOID Activation Functions in a Neural Network"
  },
  {
    "objectID": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del2.html",
    "href": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del2.html",
    "title": "Del 2: Odds",
    "section": "",
    "text": "Forventet tid ca. 75 min."
  },
  {
    "objectID": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del2.html#aktivitet-1",
    "href": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del2.html#aktivitet-1",
    "title": "Del 2: Odds",
    "section": "Aktivitet 1",
    "text": "Aktivitet 1\nStart med at se denne video (eller læs afsnittet odds):"
  },
  {
    "objectID": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del2.html#aktivitet-2",
    "href": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del2.html#aktivitet-2",
    "title": "Del 2: Odds",
    "section": "Aktivitet 2",
    "text": "Aktivitet 2\nLav nedenstående opgave.\n\n\n\n\n\n\nOpgave 1\n\n\n\n\n\n\nLad \\(p=4/7\\). Hvad er de tilhørende odds?\nAntag at oddsene er \\(O=3/2\\). Hvad er den tilsvarende sandsynlighed?\n\nFodboldholdene AFC og BFC spiller mod hinanden. Der spilles med forlænget spilletid og straffesparkskonkurrence indtil, der er fundet en vinder. Det er dobbelt så sandsynligt, at AFC vinder som, at BFC vinder.\n\nHvad er (de matematiske) odds for at AFC vinder?\nHvad er sandsynligheden for at AFC vinder?\n\n\n\n\n\n\n\n\n\n\nLærergennemgang\n\n\n\n\n\n\nDin lærer vil vise, at oddsfunktionen \\(O(p)\\) er voksende ved at differentiere og indse at \\(O'(p)&gt;0\\). Hvis du ikke kan vente, kan du jo prøve selv!"
  },
  {
    "objectID": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_laereren.html",
    "href": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_laereren.html",
    "title": "Til læreren",
    "section": "",
    "text": "Dette forløb bygger på noten om logistisk regression. Hver enkel del i forløbet består typisk af en video, som skal ses (eller alternativt kan det tilhørende afsnit i noten læses). Herefter følger en række opgaver, som støtter op om teorien.\nDet meste af forløbet er tænkt, så eleverne selv kan arbejde med stoffet. Enkelte gange er det tanken, at læreren gennemgår noget. Det er markeret på denne måde:\n\n\n\n\n\n\nLærergennemgang\n\n\n\n\n\n\nDin lærer vil vise, at …\n\n\n\n\nHer følger en række fif til de enkelte dele:\nI del 1 kan inddelingen i intervaller også laves i elevernes eget CAS værktøj, hvis det foretrækkes. Der kan dog eventuelt være en pointe i at lade eleverne stifte bekendtskab med begrebet pivottabel i Excel uanset.\nI del 2 i beviset for, at \\(O(p)= \\frac{p}{1-p}\\) er voksende, kan differentiationen laves på forskellige måder, som det nu passer bedst ind for det konkrete hold. Det kan for eksempel ske ved hjælp af:\n\nProduktreglen og reglen for at differentiere sammensatte funktioner, idet kvotienten først omskrives til et produkt:\n\n\\[\n\\begin{aligned}\nO'(p) &= p' \\cdot {1 \\over 1-p} + p \\cdot ({1 \\over 1-p})' \\\\& = 1 \\cdot {1 \\over 1-p} + p \\cdot {-1 \\over (1-p)^2} \\cdot (-1) \\\\ &=  {1-p \\over (1-p)^2} + {p \\over (1-p)^2} \\\\ &= {1 \\over (1-p)^2} &gt; 0\n\\end{aligned}\n\\]\n\nKvotientreglen (enten bevist eller blot gennemgået): \\[\n\\begin{aligned}\nO'(p) &= {p' \\cdot (1-p) - p \\cdot (1-p)' \\over (1-p)^2} \\\\ &= {1 \\cdot (1-p) - p \\cdot (-1) \\over (1-p)^2} \\\\ &= {1 \\over (1-p)^2} &gt; 0\n\\end{aligned}\n\\]\n\nI del 4 kan det overvejes, om eleverne selv – eventuelt i grupper – skal læse udledningen, eller om den skal ske ved lærergennemgang.\nI del 5 er det ikke nødvendigt, at eleverne forstår alle detaljer, en rimelig forståelse af idéen kan være tilstrækkelig.\nI del 5 kan man godt lade eleverne læse hele afsnittet, men den sidste del er ikke så central, og ligner meget et kendt bevis fra eksponentielle udviklinger.\nI del 6 anvendes black-box, men der kan for eksempel sammenlignes med Newton-Raphsons metode til bestemmelse af nulpunkter.\nDel 7 kan eventuelt springes over."
  },
  {
    "objectID": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del6.html",
    "href": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del6.html",
    "title": "Del 6: Maximum likelihood estimation",
    "section": "",
    "text": "Forventet tid ca. 120 min."
  },
  {
    "objectID": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del6.html#aktivitet-1",
    "href": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del6.html#aktivitet-1",
    "title": "Del 6: Maximum likelihood estimation",
    "section": "Aktivitet 1",
    "text": "Aktivitet 1\nStart med at se denne video (eller læs afsnittet maksimum likelihood estimation):"
  },
  {
    "objectID": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del6.html#aktivitet-2",
    "href": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del6.html#aktivitet-2",
    "title": "Del 6: Maximum likelihood estimation",
    "section": "Aktivitet 2",
    "text": "Aktivitet 2\nFra afsnittet Maksimum likelihood estimation fandt vi frem til, at log-likelihoodfunktionen kan skrives på denne måde:\n\\[\n\\begin{aligned}\nl(a,b) =\\sum_{i=1}^n\\big( {y_i}\\cdot \\ln(p(x_i))+(1-y_i)\\cdot \\ln(1-p(x_i)) \\big),\n\\end{aligned}\n\\tag{1}\\]\nhvor\n\\[\np(x_i)  = \\frac{ 1}{1 + e^{-(ax_i  + b)}}=\\frac{e^{ax_i + b}}{1+e^{ax_i +b}}.\n\\tag{2}\\]\n\nBestemmelse af \\(a\\) og \\(b\\) med Excels problemløser-værktøj\nVi vil nu finde estimater for \\(a\\) og \\(b\\) ved hjælp af Excel. Først og fremmest skal man sørge for, at man har aktiveret problemløser-værktøjet. Det gøres på følgende måde:\n\nGå op under filer og vælg indstillinger.\nVælg derefter tilføjelsesprogrammer.\nNederst vælges Excel-tilføjelsesprogrammer. Tryk på udfør.\nVælg til sidst tilføjelsesprogrammet problemløser fra en liste.\n\n\n\n\nIllustration af Excel ark til bestemmelse af a og b samt brug af problemløser.\n\n\nPå billedet ses, hvordan man kan lave et lille regneark til at beregne de relevante størrelser. Der er lavet et par celler til de ukendte parametre \\(a\\) og \\(b\\), som med fordel kan sættes til 0 fra starten for at undgå numeriske problemer i Excel. Det oprindelige datasæt indsættes i søjlerne \\(x_i\\) og \\(y_i\\). I de næste søjler beregnes odds, \\(p(x_i)\\) og \\(\\ln(p_i)\\) med formlerne1 \\[\\begin{align*}\nodds &= e^{ax_i + b}\\\\\np(x_i) &= \\frac{e^{ax_i + b}}{1+e^{ax_i +b}} = \\frac{odds}{1+odds}\\\\\n\\ln(p_i)&= {y_i}\\cdot \\ln(p(x_i))+(1-y_i)\\cdot \\ln(1-p(x_i)).\n\\end{align*}\\]\n1 I Excel på dansk fås eksponentialfunktionen ved at skrive EKSP (og EXP i den engelske version). For at få den naturlige logaritmen skriver man LN i begge tilfælde.Her er det vigtigt, at cellerne, der indeholder værdien af \\(a\\) og \\(b\\), benyttes når oddsene beregnes (det vil være smart med fastlåsning af referencerne, hvor man har $ foran både tal og bogstav ved reference). Til sidst finder man \\(l(a,b)\\) i det blå felt ved at beregne summen af alle \\(\\ln(p_i)\\), som i formlen (1).\nNu mangler man bare at benytte problemløseren til at finde de værdier af \\(a\\) og \\(b\\), der gør værdien i det blå felt maksimal. På billedet er der vist med rød, hvor man finder problemløseren, og hvad der skal justeres. Målsætningen er den blå celle, der indeholder summen. Variabelcellerne er de to, der indeholder \\(a\\) og \\(b\\). Sørg for ikke at sætte flueben i boksen \"Gør variabler uden begrænsninger ikke-negative\". Tryk på løs.\n\n\n\n\n\n\nOpgave 1\n\n\n\n\n\nAntag, at vi har tre observationer nedenfor.\n\nOpskriv et udtryk for likelihoodfunktionen \\(L(a,b)\\).\n\n\n\n\n\\(x\\)\n1\n2\n3\n\n\n\n\n\\(y\\)\n1\n1\n0\n\n\n\nEn nyhedshjemmeside ønsker at målrette en biografreklame til brugerne. De har derfor registreret om 10 af hjemmesidens brugere har klikket på reklamen (\\(y=1\\) hvis de har klikket, \\(y=0\\) ellers) og hvor mange gange \\(x\\), de har læst kulturnyheder den sidste måned. Datasættet er givet i nedenstående tabel. Firmaet bag hjemmesiden ønsker at modellere sandsynligheden \\(p(x)\\) for at klikke på reklamen som funktion af \\(x\\), så de kan målrette reklamen mod de brugere, der har størst sandsynlighed for at klikke på den.\n\nBrug Excel til at finde \\(a\\) og \\(b\\).\nTegn grafen for \\(p(x)\\).\nSkal firmaet vælge at vise reklamen til brugere, der ofte eller sjældent læser kulturnyheder?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n\ny\n0\n0\n1\n0\n0\n1\n1\n1\n1\n1\n\n\n\n\n\n\n\n\n\n\n\n\nOpgave 2\n\n\n\n\n\n\nBrug datasættet med de 2000 datapunkter og benyt problemløsning i Excel til at vise, at \\(a=0{,}022\\) og \\(b=-3{,}9\\) optimerer løsningen."
  },
  {
    "objectID": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del1.html",
    "href": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del1.html",
    "title": "Del 1: Logistisk regression",
    "section": "",
    "text": "Forventet tid ca. 90 min."
  },
  {
    "objectID": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del1.html#aktivitet-1",
    "href": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del1.html#aktivitet-1",
    "title": "Del 1: Logistisk regression",
    "section": "Aktivitet 1",
    "text": "Aktivitet 1\nStart med at se denne video (eller læs afsnittet logistisk regression og hjerte-kar-sygdom):"
  },
  {
    "objectID": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del1.html#aktivitet-2",
    "href": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del1.html#aktivitet-2",
    "title": "Del 1: Logistisk regression",
    "section": "Aktivitet 2",
    "text": "Aktivitet 2\nHent datasættet med de 2000 datapunkter."
  },
  {
    "objectID": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del1.html#aktivitet-3",
    "href": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del1.html#aktivitet-3",
    "title": "Del 1: Logistisk regression",
    "section": "Aktivitet 3",
    "text": "Aktivitet 3\nGenskab denne figur\n\n\n\n\n\n\n\n\n\nfra afsnittet logistisk regression og hjerte-kar-sygdom ud fra de første 100 punkter og overvej, hvorfor det er en dårlig ide at bruge alle 2000 punkter. Du kan enten gøre det i dit eget CAS værktøj eller i Excel.\nHvis du ikke er vant til at lave grafer i Excel, er det nok lettest at anvende det program, som du normalt bruger."
  },
  {
    "objectID": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del1.html#aktivitet-4",
    "href": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del1.html#aktivitet-4",
    "title": "Del 1: Logistisk regression",
    "section": "Aktivitet 4",
    "text": "Aktivitet 4\nInddel de 2000 datapunkter i intervaller som vist i denne tabel:\n\n\n\n\n\n\n\n\nBlodtryk\nRask\nSyg\nAndel syge\n\n\n\n\n(75,100]\n168\n29\n0.147\n\n\n(100,125]\n195\n45\n0.188\n\n\n(125,150]\n143\n63\n0.306\n\n\n(150,175]\n152\n105\n0.409\n\n\n(175,200]\n93\n135\n0.592\n\n\n(200,225]\n57\n136\n0.705\n\n\n(225,250]\n46\n179\n0.796\n\n\n(250,275]\n25\n204\n0.891\n\n\n(275,300]\n19\n206\n0.916\n\n\n\n\n\n\nTabel 1: Tabel over syge og raske inden for forskellige blodtryksintervaller.\n\n\n\n\nDette kan for eksempel gøres ved hjælp af en pivottabel i Excel som beskrevet nedenfor.\n\n\n\n\n\n\nHjælp til Pivottabel i Excel\n\n\n\n\n\n\nVælg “Indsæt pivottabel” i Excel og vælg dataområde og placering. Bemærk, at du skal gøre dette under menuen “Indsæt”, og hvis du finder “pivotdiagram” et sted, er det ikke det rigtige, det skal være pivottabel. Når du klikker på “Eksisterende regneark” skal du klikke det sted i regnearket, hvor du vil have pivottabellen placeret.\n\n\n\nIndstil pivottabellen som vist på figuren nedenfor. Bemærk, at du skal trække Blodtryk og Syg ned fra listen for oven til \"Kolonner\", \"Rækker\" og \"Værdier\" i bunden. Under \"Værdier\" vil der i første omgang stå \"Sum af Syg\", så klik på pilen, vælg \"Værdifeltindstillinger\" og ændr det til \"Antal af syg\".\n\n\n\nHøjreklik på én af værdierne for blodtryk i pivottabellen, vælg \"Grupper\" og vælg indstillinger for intervallerne.\n\n\nHerefter skal det se således ud:"
  },
  {
    "objectID": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del1.html#aktivitet-5",
    "href": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del1.html#aktivitet-5",
    "title": "Del 1: Logistisk regression",
    "section": "Aktivitet 5",
    "text": "Aktivitet 5\nLav lineær regression ud fra data i tabel 1 og genskab derved denne figur:\n\n\n\n\n\n\n\n\nFigur 1: Grafen for \\(p(x)\\) tilnærmet med en ret linje.\n\n\n\n\n\nHusk at bruge midtpunktet af hvert interval. Brug det program, du normalt anvender til at lave lineære regression."
  },
  {
    "objectID": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del5.html",
    "href": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del5.html",
    "title": "Del 5: Fortolkning",
    "section": "",
    "text": "Forventet tid ca. 60 min."
  },
  {
    "objectID": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del5.html#aktivitet-1",
    "href": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del5.html#aktivitet-1",
    "title": "Del 5: Fortolkning",
    "section": "Aktivitet 1",
    "text": "Aktivitet 1\nStart med at se denne video (eller læs afsnittet fortolkning af parametrene i den logistiske regressionsmodel – du behøver kun at læse indtil sætningen Altså vokser odds med ca. 22%, når \\(x\\) vokser med 1 i modellen.):"
  },
  {
    "objectID": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del5.html#aktivitet-2",
    "href": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del5.html#aktivitet-2",
    "title": "Del 5: Fortolkning",
    "section": "Aktivitet 2",
    "text": "Aktivitet 2\nI app’en herunder ser du grafen for \\(f(x)=\\frac{1}{1+e^{-(ax+b)}}\\). Hvis du trækker i skyderne for \\(a\\) og \\(b\\), kan du se, hvordan kurven ændrer form. Den stiplede linje har ligning \\(x=\\frac{-b}{a}\\) og svarer altså til den vandrette forskydning af grafen for den standard logistiske funktion. På figuren er der desuden 9 punkter, som du kan få grafen til at passe bedst muligt med.\n\nEksperimenter med \\(a\\) og \\(b\\) for at forstå deres betydning for grafen.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigur 1: Eksperimenter med a og b for at forstå deres betydning for grafen. Når du har klikket på en skyder med musen, kan værdien også ændres med piletasterne, hvilket kan ske mere præcist."
  },
  {
    "objectID": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del5.html#aktivitet-3",
    "href": "undervisningsforloeb/log_reg_langt_forloeb/log_reg_del5.html#aktivitet-3",
    "title": "Del 5: Fortolkning",
    "section": "Aktivitet 3",
    "text": "Aktivitet 3\nLav nedenstående opgave.\n\n\n\n\n\n\nOpgave 1\n\n\n\n\n\nI et (fiktivt) dataeksempel ser vi på sandsynligheden \\(p(x)\\) for, at en kunde i et supermarked vælger at købe den økologiske mælk frem for den konventionelle som funktion af kundens årlige indtægt \\(x\\) (i 100.000 kr). Vi kommer frem til følgende logistiske regressionsmodel \\[\n\\text{logit}(p(x))= -1.3+0.5x.\n\\]\n\nHvor mange procent stiger odds for at vælge økologisk, når årsindtægten stiger med 100.000 kr (\\(x\\) vokser med 1)?\nTegn grafen for \\(p(x)\\).\nIndse ved hjælp af figur 1, at grafen for den generelle logistiske funktion med forskrift \\[\nf(x)=\\frac{1}{1+e^{-(ax+b)}}\n\\] er stejlest, når funktionsværdien er \\(f(x)=1/2\\).\nHvilken værdi af \\(x\\) svarer til en funktionsværdi på \\(1/2\\) (isoler \\(x\\) udtrykt ved hjælp af \\(a\\) og \\(b\\))?\n\nHint til sidste spørgsmål: Start med at overveje, hvilken værdi \\(e^{-a\\cdot x+b}\\) skal have, og derefter hvilken værdi \\(a\\cdot x+b\\) skal have, og til sidst \\(x\\)."
  },
  {
    "objectID": "undervisningsforloeb/Opdatering_af_vægte_i_NN_med_1_skjult_lag.html",
    "href": "undervisningsforloeb/Opdatering_af_vægte_i_NN_med_1_skjult_lag.html",
    "title": "Opdatering af vægte i et simpelt neuralt netværk med ét skjult lag (men med cross-entropy som tabsfunktion)",
    "section": "",
    "text": "Forudsætninger og tidsforbrug\n\n\n\n\n\n\nNeurale netværk.\nSigmoid aktiveringsfunktion.\nGradientnedstigning.\nCross-entropy tabsfunktion.\n\nForudsætningerne kan med fordel dækkes ved hjælp af noten om simple neurale netværk, da notationen derfra vil blive anvendt i dette forløb, samt noten om tabsfunktioner.\nDette forløb ligner forløbet om opdatering af vægte i neuralt netværk med to skjulte lag, men er lidt sværere, da man desuden skal modificere nogle elementer i forhold til noten om simple neurale netværk.\nTidsforbrug: Ca. 90 minutter."
  },
  {
    "objectID": "undervisningsforloeb/Opdatering_af_vægte_i_NN_med_1_skjult_lag.html#et-meget-lille-datasæt",
    "href": "undervisningsforloeb/Opdatering_af_vægte_i_NN_med_1_skjult_lag.html#et-meget-lille-datasæt",
    "title": "Opdatering af vægte i et simpelt neuralt netværk med ét skjult lag (men med cross-entropy som tabsfunktion)",
    "section": "Et meget lille datasæt",
    "text": "Et meget lille datasæt\nI neurale netværk er der ofte rigtige mange inputvariable (features), rigtigt mange vægte og rigtig mange træningsdata.\nFor bedre at forstå, hvor vægtene opdateres i et neuralt netværk, vil vi her se på et meget lille eksempel, så det manuelt er muligt at lave opdateringen af vægtene.\nVi vil lave et netværk med 2 inputvariable (\\(x_1\\) og \\(x_2\\)), 1 neuron i det skjulte lag (\\(y\\)) og 1 neuron i outputlaget (\\(o\\)). Netværket er illustreret i figur 1.\n\n\n\n\n\n\nFigur 1: Grafisk illustration af et neuralt netværk med 2 inputvariable og ét skjulte lag, som består af én neuron.\n\n\n\nKonkret vil vi se på to features \\(x_1\\) og \\(x_2\\) og en targetværdi \\(t\\) ud fra følgende træningsdatasæt:\n\n\n\n\\(x_1\\)\n\\(x_2\\)\n\\(t\\)\n\n\n\n\n1\n2\n0\n\n\n2\n3\n1\n\n\n3\n7\n0\n\n\n\nVi vælger en learning rate på\n\\[\\eta = 0.1,\\]\nsigmoid-funktionen som aktiveringsfunktion\n\\[\\sigma(x)=\\frac{1}{1+e^{-x}}\\]\nog cross-entropy som tabsfunktion \\[\nE =  - \\sum_{m=1}^{M} \\left( (t^{(m)} \\cdot \\ln(o^{(m)}) + (1-t^{(m)}) \\cdot \\ln(1-o^{(m)}) \\right)\n\\] Endeligt vælger vi startvægtene fra inputlaget til det skjulte lag som\n\\[\nr_0=0.5 \\textrm{ (bias)},\\qquad r_1=0.5,\\qquad r_2=0.5\n\\]\nog fra det skjulte lag til outputlaget som\n\\[\nw_0=0.5 \\textrm{ (bias)}, \\qquad  w_1=0.5\n\\]"
  },
  {
    "objectID": "undervisningsforloeb/Opdatering_af_vægte_i_NN_med_1_skjult_lag.html#plan",
    "href": "undervisningsforloeb/Opdatering_af_vægte_i_NN_med_1_skjult_lag.html#plan",
    "title": "Opdatering af vægte i et simpelt neuralt netværk med ét skjult lag (men med cross-entropy som tabsfunktion)",
    "section": "Plan",
    "text": "Plan\nPlanen er nu følgende:\n\nLav feedforward fra \\(x\\) laget til \\(y\\) laget.\nLav feedforward fra \\(y\\) laget til \\(o\\) laget.\nOpskriv opdateringsregler for \\(w\\)-vægtene.\nOpdatér \\(w\\)-vægtene.\nOpskriv opdateringsregler for \\(r\\)-vægtene.\nOpdatér \\(r\\)-vægtene."
  },
  {
    "objectID": "undervisningsforloeb/Opdatering_af_vægte_i_NN_med_1_skjult_lag.html#opgaver",
    "href": "undervisningsforloeb/Opdatering_af_vægte_i_NN_med_1_skjult_lag.html#opgaver",
    "title": "Opdatering af vægte i et simpelt neuralt netværk med ét skjult lag (men med cross-entropy som tabsfunktion)",
    "section": "Opgaver",
    "text": "Opgaver\n\n\n\n\n\n\nOpgave 1: Feedforward fra \\(x\\) til \\(y\\) lag\n\n\n\n\n\n\nUdregn\n\\[r_0 + r_1 \\cdot x_1^{(m)} + r_2 \\cdot x_2^{(m)}\\]\nfor hver af de 3 træningseksempler.\nUdregn\n\\[y^{(m)}=\\sigma(r_0 + r_1 \\cdot x_1^{(m)} + r_2 \\cdot x_2^{(m)})\\]\nfor hver af de 3 træningseksempler.\n\n\n\n\n\n\n\n\n\n\nOpgave 2: Feedforward fra \\(y\\) til \\(o\\) lag\n\n\n\n\n\n\nUdregn på tilsvarende vis \\(o^{(m)}\\) for hver af de 3 træningseksempler.\n\n\n\n\n\n\n\n\n\n\nOpgave 3: Opskriv opdateringsregler for \\(w\\)-vægtene\n\n\n\n\n\n\nOpskriv opdateringsreglen for \\(w_0\\) og \\(w_1\\). Husk, at\n\nsigmoid-funktionen har følgende egenskab: \\(\\sigma'(x)=\\sigma(x) \\cdot (1-\\sigma(x))\\)\ntabsfunktionen er cross-entropy.\n\n\n\n\n\n\n\n\n\n\n\nOpgave 4: Opdatér \\(w\\)-vægtene\n\n\n\n\n\n\nUdregn\n\\[\\delta_w^{(m)} = t^{(m)}-o^{(m)}\\]\nUdregn\n\\[\\sum_{m=1}^{3} \\delta_w^{(m)}\\]\nOpdatér \\(w_0\\)-vægten\n\\[w_0^{ny} \\leftarrow w_0 + \\eta \\cdot \\sum_{m=1}^{3} \\delta_w^{(m)}\\]\nUdregn\n\\[\\sum_{m=1}^{3} \\delta_w^{(m)} \\cdot y^{(m)}\\]\nOpdatér \\(w_1\\)-vægten\n\\[w_1^{ny} \\leftarrow w_1 + \\eta \\cdot \\sum_{m=1}^3 \\delta_w^{(m)} \\cdot y^{(m)}\\]\n\n\n\n\n\n\n\n\n\n\nOpgave 5: Opskriv opdateringsregler for \\(r\\)-vægtene\n\n\n\n\n\n\nOpskriv opdateringsreglen for \\(r_0, r_1\\) og \\(r_2\\).\n\n\n\n\n\n\n\n\n\n\nOpgave 6: Opdatér \\(r\\)-vægtene\n\n\n\n\n\n\nLav udregninger tilsvarende dem i opgave 4 og opdatér af \\(r\\)-vægtene.\n\n\n\n\n\n\n\n\n\n\nOpgave 7: Udregn værdien af tabsfunktionen\n\n\n\n\n\n\nUdregn værdien af tabsfunktionen inden opdateringen.\nUdregn værdien af tabsfunktionen efter opdateringen.\n\nVærdien skulle meget gerne være blevet mindre med opdateringen."
  },
  {
    "objectID": "undervisningsforloeb/Opdatering_af_vægte_i_NN_med_1_skjult_lag.html#anden-opdatering-af-vægtene",
    "href": "undervisningsforloeb/Opdatering_af_vægte_i_NN_med_1_skjult_lag.html#anden-opdatering-af-vægtene",
    "title": "Opdatering af vægte i et simpelt neuralt netværk med ét skjult lag (men med cross-entropy som tabsfunktion)",
    "section": "Anden opdatering af vægtene",
    "text": "Anden opdatering af vægtene\nOvervej, om du kan strømline dine beregninger, eventuelt i Excel eller i dit CAS værktøj, så det bliver hurtigere at opdatere vægtene en gang mere på samme måde.\n\n\n\n\n\n\nOpgave 8: Opdater vægtene anden gang\n\n\n\n\n\n\nBeregn de opdaterede vægte.\nBeregn tabsfunktionen på de opdaterede vægte.\n\n\n\n\nBemærk, at værdien af tabsfunktionen er blevet lidt mindre. Formålet er jo netop at minimere den gennem gradientnedstigning, så som regel bør værdien bliver mindre, hver gang vægtene opdateres."
  },
  {
    "objectID": "undervisningsforloeb/Opdatering_af_vægte_i_NN_med_1_skjult_lag.html#løsninger-til-opgaver",
    "href": "undervisningsforloeb/Opdatering_af_vægte_i_NN_med_1_skjult_lag.html#løsninger-til-opgaver",
    "title": "Opdatering af vægte i et simpelt neuralt netværk med ét skjult lag (men med cross-entropy som tabsfunktion)",
    "section": "Løsninger til opgaver",
    "text": "Løsninger til opgaver\nFacitliste."
  },
  {
    "objectID": "undervisningsforloeb/screeningsprogrammer/screeningsprogrammer_matematik.html",
    "href": "undervisningsforloeb/screeningsprogrammer/screeningsprogrammer_matematik.html",
    "title": "Screeningsprogrammer - matematik",
    "section": "",
    "text": "I dette forløb tages der udgangspunkt i artiklen Novel Blood-Based, Five-Gene Biomarker Set for the Detection of Colorectal Cancer, som du kan finde arbejdsspørgsmål til under bioteknologi delen - modul 3.\nKort fortalt handler artiklen om screening for tarmkræft ved brug af fem genetiske markører, som samlet set har vist sig at være tilstrækkeligt forskellige fra syge til raske personer til at kunne danne baggrund for et screeningsprogram.\nArtiklen er meget teknisk, men den præsenterer også nogle relevante overvejelser omkring screeningsprogrammer generelt. De behøver ikke være ufejlbarlige på individniveau for at forbedre folkesundheden, men skal fange mange syge tidligt i forløbet, så behandling er mulig. De skal også være enkle og helst ikke invasive, så mange vælger screeningen til.\nVi har ikke tid og ressourcer til at etablere et datagrundlag fra en stor klinisk undersøgelse af mange mennesker, så vi vil kunstigt og med brug af matematik generere et tilsvarende datamateriale, som vi kan bruge som eksempel. Vi vil i den forbindelse bruge de indbyrdes forhold mellem syge og raske for de fem udvalgte genetiske markører fra artiklens tabel 2. Det giver forhåbentlig et realistisk bud på, hvor store forskelle mellem raske og syge, man kan forvente at finde ved genundersøgelser i forbindelse med andre alvorlige sygdomme.\nFra artiklens tabel 2 har vi følgende forhold syge/raske for de fem udvalgte genetiske markører:\n\n\n\n\n\n\nGenmarkør\nForhold syge/raske\n\n\n\n\nGen1\n\\(0.43\\)\n\n\nGen2\n\\(0.42\\)\n\n\nGen3\n\\(1.34\\)\n\n\nGen4\n\\(1.29\\)\n\n\nGen5\n\\(0.42\\)\n\n\n\n\n\nTabel 1: Tabel med forholdet mellem syge og raske for de fem udvalgte genetiske markører.\n\n\n\nBemærk, at nogle i gennemsnit er højere for de syge og nogle er lavere (fra \\(0.42\\) til \\(1.34\\)).\nVi vil generere talværdier for genmarkørerne ved at sample fra en normalfordeling, hvor vi har valgt en middelværdi som den gennemsnitlige værdi for den pågældende genmarkør og en spredning som et mål for den biologiske variation.\n\n\n\n\n\n\nAktivitet 1 - Generering af fiktive kliniske data\n\n\n\n\n\nFor raske vælger vi, at bruge middelværdien \\(\\mu=10\\) og spredningen \\(\\sigma=5\\) – altså normalfordelingen \\(N(10,5)\\).\nFor syge ændrer vi middelværdien afhængig af det angivne forhold i tabel 1 for den pågældende genmarkør, men beholder en spredning på \\(5\\). Det ser sådan her ud:\n\n\n\nGenmarkør\nAnvendt fordeling\n\n\n\n\nGen1\n\\(N(4.3,5)\\)\n\n\nGen2\n\\(N(4.2,5)\\)\n\n\nGen3\n\\(N(13.4,5)\\)\n\n\nGen4\n\\(N(12.9,5)\\)\n\n\nGen5\n\\(N(4.2,5)\\)\n\n\n\nVi kan nu generere vores kunstige kliniske data ved at sample fra disse normalfordelinger.\n\nBrug denne app til at generere kunstige kliniske data for 800 raske patienter og for 200 syge ved at sample fra normalfordelingerne ovenfor. Datasættet skal samles i én Excel-fil, hvor I tilføjer en kolonne \"Syg\", som har værdien 0 for de raske patienter og værdien 1 for de syge (den værdi kaldes for en targetværdi), og data kaldes for træningsdata.\n\n\n\n\nBemærk, at vi har valgt at bruge normalfordelingerne \\(N(10,5)\\) som udgangspunkt. Det er blot for at illustrere metoden. Det har altså ikke afsæt i kendte biologiske parametre. At sætte middelværdien til \\(10\\) svarer blot til at vælge en enhed, hvor talværdien bliver \\(10\\), så det er ret uproblematisk. At sætte spredningen til \\(5\\) kan være mere problematisk, da det svarer til at angive information om den biologiske variation for den pågældende genmarkør. Hvilken betydning det har, kommer vi tilbage til senere.\nI en virkelig anvendelse med brug af rigtige kliniske data for raske og for syge ville man sikkert se, at normalfordelinger er en god model for de kliniske data, men at middelværdi og spredning er forskellig for hver af de fem genmarkører.\nInden næste aktivitet skal I se denne video, hvor vi fortæller lidt om, hvad AI og kunstige neurale netværk er.\n\n\n\n\n\n\n\nAktivitet 2 - Træning af kunstigt neuralt netværk\n\n\n\n\n\n\nSe denne video, som viser, hvordan man træner et kunstigt neuralt netværk i Orange:\n\n\n\nTræn forskellige kunstige neurale netværk (vælg forskellige antal skjulte lag og forskellige antal neuroner i de skjulte lag).\nBrug femfolds krydsvalidering og klassifikationsnøjagtigheden (CA) til at vurdere de netværk, som I har trænet.\nLav en confusion matrix for alle de netværk, som I har trænet.\nForklar med dine egne ord hvorfor en klassifikationsnøjagtighed på \\(0.8\\) ikke er imponerende.\nHvad er den højeste klassifikationsnøjagtighed, som I kan få?\n\n\n\n\nI den foregående aktivitet har I måske været heldige og fundet en model med en klassifikationsnøjagtighed på omkring \\(0.91\\)? Men formentlig ikke ret meget højere. I den næste aktivitet vil vi undersøge, hvorfor det er tilfældet.\n\n\n\n\n\n\nAktivitet 3 - Vurdering af træningsdata\n\n\n\n\n\n\nFor hver af de fem genmarkører skal I i samme figur tegne to boksplots: et boksplot som viser fordelingen af den pågældende genmarkør for de raske og et tilsvarende boksplot for de syge.\nHvad kan I konkludere på baggrund af disse boksplots?\nFor hver af de fem genmarkører skal I også i samme figur tegne graferne for tæthedsfunktionen hørende til normalfordelingen \\(N(10,5)\\) (svarende til de raske) og for den normalfordeling som hører til de syge. Husk at forskriften for tæthedsfunktionen for en \\(N(\\mu,\\sigma)\\)-normalfordeling er:\n\\[f(x)=\\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma} \\right)^2} \\]\nHvad kan I konkludere på baggrund af disse grafer?\nKan det forklare, hvorfor I ikke kan finde en model med en klassifikationsnøjagtighed, som er tæt på \\(1\\)?\n\n\n\n\n\n\n\n\n\n\nAktivitet 4 - Lav jeres eget screeningsprogram\n\n\n\n\n\nVi forestiller os nu, at sundhedsmyndighederne stiller dette testdatasæt til rådighed.\n\nSe denne video, som viser, hvordan man laver prædiktioner i Orange:\n\n\n\nBrug det bedste kunstige neurale netværk som I fandt i aktivitet 3 (trænet på jeres eget træningsdata) til at prædiktere om patienterne i testdatasættet er syge eller raske.\nLav en confusion matrix og bestem klassifikationsnøjagtigheden.\nHvilken gruppe har lavet det bedste screeningsprogram?\n\n\n\n\n\n\n\n\n\n\nAktivitet 5 - Hvad skal der til for at få en bedre model?\n\n\n\n\n\nI aktivitet 1 genererede I fiktive kliniske data ved at sample fra normalfordelinger med forskellige middelværdier, men alle med en spredning på \\(5\\).\n\nPrøv nu at generere data, hvor spredningen er sat ned fra \\(5\\) til \\(2\\). Det bør give en større forskel på de kliniske data for syge og for raske. Overvej hvorfor.\nGentag aktivitet 2 til 4 for disse data. Kan I ramme en højere eller lavere klassifikationsnøjagtighed? Overvej hvorfor det forholder sig sådan."
  },
  {
    "objectID": "undervisningsforloeb/screeningsprogrammer/screeningsprogrammer_bioteknologi.html",
    "href": "undervisningsforloeb/screeningsprogrammer/screeningsprogrammer_bioteknologi.html",
    "title": "Screeningsprogrammer - bioteknologi",
    "section": "",
    "text": "Der tages udgangspunkt i afsnittet om kræft i Bioteknologi A - bind 3, men en tilsvarende bog om emnet kan selvfølgelig anvendes.\n\n\n\n\n\n\nModul 1 - Hvad er kræft?\n\n\n\n\n\n\nMateriale\n\nBioteknologi A - bind 3, side 226\nBioteknologi A - bind 3, side 213\nBioteknologi A - bind 3, side 214\n\n\n\nArbejdsspørgsmål til teksten\n\nHvad er forskellen mellem en godartet og en ondartet svulst?\nHvordan spreder godartede svulster sig i kroppen sammenlignet med ondartede svulster?\nHvordan er godartede svulster ofte omkredset, og hvad betyder det for deres behandling?\nHvordan kan ondartede svulster sprede sig i kroppen, hvad kaldes denne proces?\nHvilken behandlingsudfordring står læger over for, når det kommer til ondartede svulster, som ikke er til stede ved godartede svulster?\nHvorfor kan det være svært at fjerne alle kræftceller ved en operation, når der er metastaser til stede?\nHvilke alternative behandlingsformer kan anvendes til at bekæmpe kræft, når operation ikke er tilstrækkelig?\nHvad er betydningen af at opdage kræft tidligt for patientens overlevelseschancer?\nHvordan opstår kræft gradvist ifølge beskrivelsen?\nHvilken rolle spiller mutationer i udviklingen af kræft?\nHvordan påvirker hver ny mutation cellens vækstmønster?\nHvordan ændrer cellens udseende sig over tid – inddrag figur 416 og 417?\nHvordan adskiller kræftceller sig fra normale celler – inddrag figur 417?\nHvordan bidrager den reducerede tid i G1-fasen af cellecyklussen til cellens mindre størrelse?\nHvordan påvirker fejlregulerede gener, såsom oncogener og tumorsuppressorgener, udviklingen af kræft?\nHvordan kan forståelsen af disse geners funktion bidrage til kræftscreeninger?\n\n\n\n\n\n\n\n\n\n\n\nModul 2 - Genetik?\n\n\n\n\n\n\nMateriale\n\nBioteknologi A - bind 3, side 215\nBioteknologi A - bind 3, side 216\n\n\n\nArbejdsspørgsmål til teksten\n\nHvad adskiller et oncogen fra et proto-oncogen?\nHvordan kan mutationer i proto-oncogenet føre til dannelse af et oncogen?\nHvad er restriktionspunktet, hvordan påvirker ændringer i kontrol af dette punkt udviklingen af kræft?\nHvordan kan kromosomtranslokationer eller genamplifikationer føre til dannelse af oncogener?\nHvad er RAS-proteiner?\nHvordan påvirker aktiverende mutationer i RAS-proto-oncogener udviklingen af kræft?\nHvordan påvirker mutationer i MYC-gener celledelinger og regulering af restriktionspunktet?\nHvordan fungerer Myc som en transskriptionsfaktor?\nHvordan kan forståelsen af oncogener som RAS og MYC bidrage til udviklingen af kræftbehandling?\nHvad er funktionen af et tumorsuppressorgen?\nHvad sker der, hvis et tumorsuppressorgen inaktiveres?\nHvilken genetiske ændring skal der til for at et tumorsuppressorgen mister sin funktion?\nHvad er p53, og hvorfor er det et vigtigt protein i forbindelse med kræft?\nHvad er de tre hovedfunktioner af p53?\nHvordan aktiveres p53 – inddrag figur 422?\nHvordan reguleres nedbrydningen af p53 normalt?\nHvorfor betragtes p53 som \"genomets vogter\"?\n\n\n\n\n\n\n\n\n\n\n\nModul 3 - Artiklens metode og resultater\n\n\n\n\n\n\nMateriale\nNovel Blood-Based, Five-Gene Biomarker Set for the Detection of Colorectal Cancer\n\n\nArbejdsspørgsmål til teksten\n\nHvor mange personer blev inkluderet i studiet?\nHvordan blev de fordelt mellem kontrolgruppen og CRC-patientgruppen?\nHvad var formålet med at opdele prøverne i tre sæt?\nHvordan blev gener med forskelligt grad af udtryk identificeret i mikroarray-dataene?\nHvordan blev ændringer i genudtryk beregnet for PCR-resultaterne?\nHvilke forskelle sås mellem kontrol- og CRC-patientgrupper?\nHvilke fordele er der ved at bruge fx fem markører – hvilke ulemper kan der være ved at have flere eller færre?\nOvervej hvilken betydning det kan have, at der er falske negative resultater\n\nFor den enkelte.\nFor samfundet.\n\n\n\n\n\n\n\n\n\n\n\n\nModul 4 - Samlet opgave\n\n\n\n\n\nI dette modul samles sammen på indholdet fra de foregående timer, og der skrives en kort opgave med følgende opgaveformulering:\n\nRedegør for hvordan kræft kan opstå, og hvilke genetiske ændringer der ses i forbindelse med udvikling af tumorer.\nKom ind på betydningen af tidlig diagnosticering og i denne sammenhæng screeningsprogrammer.\nVurdér hvilke fordele og ulemper der er ved artiklens metode i forhold til tidligere metoder til at screene for CRC.\nAnalyser artiklens resultater og diskuter om genetisk test kan stå alene eller skal være et supplement."
  },
  {
    "objectID": "undervisningsforloeb/aktiveringsfunktioner/sigmoid.html",
    "href": "undervisningsforloeb/aktiveringsfunktioner/sigmoid.html",
    "title": "AI MAT - matematikken bag magien",
    "section": "",
    "text": "Sigmoid-funktionen har forskrift\n\\[\nf(x)=\\frac{1}{1+e^{-x}},\n\\tag{1}\\]\nsom også kan skrives\n\\[\nf(x)=\\frac{e^x}{1+e^x},\n\\] hvilket ses med at gange med \\(e^x\\) i både tæller og nævner i (1).\nGrafen for Sigmoid-funktionen ses i figur 1.\n\n\n\n\n\n\nFigur 1: Grafen for sigmoid-funktionen.\n\n\n\nDet ser på figur 1 ud som om, at værdimængden for \\(f\\) er det åbne interval1 \\((0,1)\\). Det skrives\n1 Bemærk, at det åbne interval \\((0,1)\\) også kan skrives \\(]0,1[\\).\\[\nVm(f)=(0,1).\n\\]\nHvis du vil have et lidt bedre argument for det, kan du læse i boksen herunder.\n\n\n\n\n\n\nArgument for værdimængden for \\(f\\)\n\n\n\n\n\nVi vil her argumentere for, at værdimængden for \\(f\\) er \\((0,1)\\). Vi vil starte med at se, at funktionsværdierne for \\(f\\) ligger mellem \\(0\\) og \\(1\\).\nDa både tæller og nævner i (1) er positive, så må \\(f(x)&gt;0\\). Og da\n\\[\n1&lt;1+e^{-x}\n\\] så må\n\\[\n\\frac{1}{1+e^{-x}}&lt;\\frac{1+e^{-x}}{1+e^{-x}}=1.\n\\]\nDet vil sige, at \\[\n0 &lt; f(x) &lt; 1\n\\] og derfor må værdimængden for \\(f\\) være en del af intervallet \\((0,1)\\). Det kan skrives sådan her\n\\[\nVm(f) \\subseteq (0,1).\n\\] Vi vil nu vise, at vi kan komme lige så tæt på \\(0\\) og \\(1\\), som det skal være. Det vil med andre ord sige, at værdimængden for \\(f\\) \"fylder\" hele intervallet \\((0,1)\\) ud.\nPå figuren herunder ses grafen for \\(e^{-x}\\).\n\n\n\n\n\nDa \\(e^{-x}\\) er en aftagende eksponentialfunktion vil\n\\[\ne^{-x} \\rightarrow 0 \\quad \\textrm{når} \\quad x \\rightarrow \\infty\n\\] og\n\\[\ne^{-x} \\rightarrow \\infty \\quad \\textrm{når} \\quad x \\rightarrow -\\infty.\n\\]\nDet betyder, at \\[\n\\frac{1}{1+e^{-x}} \\rightarrow 1 \\quad \\textrm{når} \\quad x \\rightarrow \\infty\n\\]\nog\n\\[\n\\frac{1}{1+e^{-x}} \\rightarrow 0 \\quad \\textrm{når} \\quad x \\rightarrow -\\infty.\n\\]\nAlt i alt har vi altså argumenteret for, at værdimængden for \\(f\\) er \\((0,1)\\).\n\n\n\nDe følgende opgaver går ud på at vise, at\n\\[\nf'(x)= \\frac{e^{-x}}{(1+e^{-x})^2}\n\\] og at \\(f'(x)\\) kan udtrykkes ved hjælp af \\(f(x)\\) på denne måde\n\\[\nf'(x)= f(x)\\cdot (1-f(x)).\n\\]\n\n\n\n\n\n\nOpgave 1: Differentiation af sigmoid-funktionen\n\n\n\n\n\nVis, at \\[\nf'(x)= \\frac{e^{-x}}{(1+e^{-x})^2}.\n\\]\n\n\n\n\n\n\n\n\n\nHints til opgave 1\n\n\n\n\n\nVi skal starte med at se, at vi kan tænke på sigmoid-funktionen \\[\nf(x)=\\frac{1}{1+e^{-x}}.\n\\] som en \"dobbelt sammensat\" funktion. Sigmoid-funktionen består nemlig af en brøk på formen \\(\\frac{1}{x}\\) og af eksponentialfunktionen \\(e^{-x}\\).\nGør følgende:\n\nStart med at opskrive differentialkvotienten for \\[\\frac{1}{x} \\quad \\textrm{og} \\quad e^{-x}.\\]\nBrug ovenstående til at vise, at \\[\nf'(x)= \\frac{e^{-x}}{(1+e^{-x})^2}.\n\\]\n\n\n\n\n\n\n\n\n\n\nOpgave 2: Omskrivning af \\(f'(x)\\) for sigmoid-funktionen\n\n\n\n\n\nVis, at \\[\nf'(x)= f(x)\\cdot (1-f(x)).\n\\] når \\[\nf(x)=\\frac{1}{1+e^{-x}}.\n\\]\n\n\n\n\n\n\n\n\n\nHints til opgave 2\n\n\n\n\n\nDer er flere fremgangsmåder for at løse opgaven:\nFremgangsmåde 1\n\nIsolér \\(e^{-x}\\) i \\[\nf(x)=\\frac{1}{1+e^{-x}}.\n\\]\nIndsæt dette udtryk for \\(e^{-x}\\) i \\[\nf'(x)= \\frac{e^{-x}}{(1+e^{-x})^2}\n\\] og reducer.\nHint! Du får brug for at sætte på fælles brøkstreg. Husk også at man dividere med en brøk ved at gange med den omvendte.\n\nFremgangsmåde 2\n\nStart med at udregne \\[1-f(x).\\] Hint! Sæt på fælles brøkstreg ved at skrive \\(1\\) som \\(\\frac{1+e^{-x}}{1+e^{-x}}\\).\nVis nu at \\[\nf(x)\\cdot (1-f(x)) = \\frac{e^{-x}}{(1+e^{-x})^2}=f'(x).\n\\] Husk, at man ganger to brøker med hinanden ved at gange tæller med tæller og nævner med nævner."
  },
  {
    "objectID": "undervisningsforloeb/aktiveringsfunktioner/ReLU.html",
    "href": "undervisningsforloeb/aktiveringsfunktioner/ReLU.html",
    "title": "AI MAT - matematikken bag magien",
    "section": "",
    "text": "Aktiveringsfunktionen ReLU som står for Reflected Linear Unit har forskrift\n\\[\nf(x) =\n\\begin{cases}\nx & \\textrm{hvis } x &gt; 0 \\\\\n0 & \\textrm{hvis } x \\leq 0 \\\\\n\\end{cases}\n\\] og grafen for ReLU-funktionen ses i figur 1.\n\n\n\n\n\n\nFigur 1: Grafen for ReLU-funktionen.\n\n\n\nVærdimængden for ReLU-funktionen er \\([0, \\infty)\\).\nDet er ret tydeligt, at ReLU-funktionen ikke er differentiabel i \\(0\\). Men hvis vi definerer, at \\(f'(0)\\) skal være \\(0\\) så ses det nemt, at\n\\[\nf'(x) =\n\\begin{cases}\n1 & \\textrm{hvis } x &gt; 0 \\\\\n0 & \\textrm{hvis } x \\leq 0 \\\\\n\\end{cases}.\n\\]\nReLU-funktionen adskiller sig fra de andre aktiveringsfunktioner ved, at værdimængden er ubegrænset. Hvis man ønsker at bruge aktiveringsfunktionen til at modellere en sandsynlighed, som beskrevet tidligere, så dur det selvfølgelig ikke. Men i praksis viser ReLU-funktionen sig at være utrolig anvendelig som aktiveringsfunktion i de skjulte lag i kunstige neurale netværk. For det første kan nogle af de andre aktiveringsfunktioner resultere i det, vi i afsnittet om valg af tabsfunktion i noten om kunstige neurale netværk, kalder for slow learning. Det betyder kort sagt, at det går for langsomt med at finde minimum for tabsfunktionen. Dét problem har ReLU-funktionen ikke. For det andet er det meget hurtigt og nemt at udregne både ReLU-funktionen selv og også dens afledede. Det er for eksempel til sammenligning beregningsmæssigt tungere at udregne sigmoid-funktionen og dennes afledede. Hvis man har et netværk med millioner af neuroner, så er denne beregningsmæssige forskel ikke uvæsentlig."
  },
  {
    "objectID": "undervisningsforloeb/test_for_sygdomme.html",
    "href": "undervisningsforloeb/test_for_sygdomme.html",
    "title": "Test for sygdomme",
    "section": "",
    "text": "Forudsætninger og tidsforbrug\n\n\n\n\n\nForløbet kræver kendskab til:\n\nSandsynlighedsregning\nBetingede sandsynligheder\n\nTidsforbrug: Ca. 2 x 90 minutter."
  },
  {
    "objectID": "undervisningsforloeb/test_for_sygdomme.html#sensitivitet-og-specificitet",
    "href": "undervisningsforloeb/test_for_sygdomme.html#sensitivitet-og-specificitet",
    "title": "Test for sygdomme",
    "section": "Sensitivitet og specificitet",
    "text": "Sensitivitet og specificitet\nNår man tester for en sygdom, så vil man måske umiddelbart tænke, at hvis testen er positiv, så er man syg, og hvis testen er negativ, så er man rask. Men det behøver faktisk ikke at være tilfældet. Man kan godt være rask, selvom testen er positiv (det kalder man for en falsk positiv), og man kan godt være syg, som testen er negativ (det kalder man for en falsk negativ). Det er fordi, at der ikke findes nogen test, som er helt perfekt!\nDet vil sige, at resultatet af en test vil falde i én af følgende fire kategorier:\n\n\n\n\nSyg\nRask\n\n\n\n\nPositiv test\nSand positiv (SP)\nFalsk positiv (FP)\n\n\nNegativ test\nFalsk negativ (FN)\nSand negativ (SN)\n\n\n\nDet er klart, at man selvfølgelig helst vil have en test, hvor flest mulige lander i diagonalen med sande positiver og sande negativer.\nEn god test skal derfor have følgende egenskaber:\n\nHvis testen anvendes på en syg person, så skal sandsynligheden for at testen bliver positiv være høj.\nHvis testen anvendes på en rask person, så skal sandsynligheden for at testen bliver negativ være høj.\n\nDisse to betingede sandsynligheder kaldes for henholdsvis sensitivitet og specificitet og kan skrives matematisk sådan her:\n\\[\n\\mathrm{sensitivitet } = P(\\textrm{positiv test } | \\textrm{ syg})\n\\] og\n\\[\n\\mathrm{specificitet } = P(\\textrm{negativ test } | \\textrm{ rask})\n\\]\n\n\n\n\n\n\nOpgave 1: Sensitivitet og specificitet\n\n\n\n\n\nVælg en sygdom som du vil arbejde med (eller som din lærer har bestemt, at du skal arbejde med!). Det kan for eksempel være corona, klamydia, RS virus eller influenza.\n\nUndersøg sensitivitet og specificitet for forskellige tests for den sygdom, som du har valgt.\nKan du lave en test hvor sensitiviteten er 100% (du behøver ikke at bekymre dig om specificiteten)?\nKan du lave en test hvor specificiteten er 100% (du behøver ikke at bekymre dig om sensitiviteten)?\n\n\n\n\nDet er klart, at hvis en test skal være god, så ønsker vi, at både sensitiviteten og specificiteten er tæt på 100%."
  },
  {
    "objectID": "undervisningsforloeb/test_for_sygdomme.html#prævalens",
    "href": "undervisningsforloeb/test_for_sygdomme.html#prævalens",
    "title": "Test for sygdomme",
    "section": "Prævalens",
    "text": "Prævalens\nBlandt alle dem, vi tester, vil en vis andel i virkeligheden være syge. Det kaldes for sygdommens prævalens. Det vil sige:\n\\[\n\\mathrm{prævalens } = P(\\textrm{syg})\n\\]\n\n\n\n\n\n\nOpgave 2: Prævalens\n\n\n\n\n\n\nUndersøg prævalensen for den sygdom, som du arbejder med.\n\n\n\n\n\n\n\n\n\n\nOpgave 3: Sensitivitet, specificitet og prævalens\n\n\n\n\n\nVi forestiller os nu, at du tester 10000 personer for den sygdom, som du arbejder med og lad os sige, at følgende er oplyst (du må også gerne bruge de tal, som du har fundet i de foregående opgaver):\nPrævalens: \\(P(\\textrm{syg})= 5 \\%\\)\nSensitivitet: \\(P(\\textrm{positiv test } | \\textrm{ syg}) = 86 \\%\\)\nSpecificitet: \\(P(\\textrm{negativ test } | \\textrm{ rask}) = 92 \\%\\)\n\nUdfyld nedenstående tabel (start med at bestemme det samlede antal syge og raske):\n\n\n\n\n\nSyg\nRask\nI alt\n\n\n\n\nPositiv test\n\n\n\n\n\nNegativ test\n\n\n\n\n\nI alt"
  },
  {
    "objectID": "undervisningsforloeb/test_for_sygdomme.html#positiv-og-negativ-prædiktiv-værdi",
    "href": "undervisningsforloeb/test_for_sygdomme.html#positiv-og-negativ-prædiktiv-værdi",
    "title": "Test for sygdomme",
    "section": "Positiv og negativ prædiktiv værdi",
    "text": "Positiv og negativ prædiktiv værdi\nHvis du bliver testet for en sygdom, så vil du enten stå med en positiv eller en negativ test, og du er dybest set slet ikke interesseret i ovenstående sandsynligheder (sensitivitet, specificitet og prævalens)! Du vil i stedet stille dig selv ét af følgende to spørgsmål:\n\nMin test er positiv - hvad er sandsygligheden for, at jeg rent faktisk er syg?\n\neller\n\nMin test er negativ - hvad er sandsygligheden for, at jeg rent faktisk er rask?\n\nDu vil jo gerne undgå, at din test enten er falsk positiv eller falsk negativ.\nOvenstående sandsynligheder kaldes for den positive prædiktive værdi og den negative prædiktive værdi. Skrevet som en betinget sandsynlighed bliver det:\n\\[\n\\text{positiv prædiktiv værdi } = P(\\textrm{syg } | \\textrm{ positiv test})\n\\] og\n\\[\n\\text{negativ prædiktiv værdi } = P(\\textrm{rask } | \\textrm{ negativ test})\n\\]\n\n\n\n\n\n\nOpgave 4: Positiv og negativ prædiktiv værdi\n\n\n\n\n\nHvis du har brugt oplysningerne fra den forrige opgave, skulle du gerne have fået følgende tabel:\n\n\n\n\nSyg\nRask\nI alt\n\n\n\n\nPositiv test\n\\(430\\)\n\\(760\\)\n\\(1190\\)\n\n\nNegativ test\n\\(70\\)\n\\(8740\\)\n\\(8810\\)\n\n\nI alt\n\\(500\\)\n\\(9500\\)\n\\(10000\\)\n\n\n\n\nBenyt ovenstående tabel til at udregne den positive og negative prædiktive værdi.\n\n\n\n\nDu undrer dig måske over, at den positive prædiktive værdi er så forholdsvis lav (36.1%), mens den negative prædiktive værdi er så tæt på 100% (99.2%). Men det er fordi, at den positive og negative prædiktive værdi ikke kun afhænger af testens sensitivitet og specificitet, men også af prævalensen af sygdommen (i den gruppe vi tester iblandt). Hvis vi ser på, hvad vi ved, inden vi overhovedet begynder at teste (det kaldes for prior sandsynligheder), så er det følgende:\n\\[P(\\textrm{syg})= 5 \\%\\]\nog dermed også at\n\\[P(\\textrm{rask})= 95 \\%\\] Det vil sige, at inden vi har taget testen, er vi ret sikre på, at vi er raske. Får vi så (som forventet) en negativ test, så bliver vi bare endnu mere sikre på, at vi er raske (svarende til en negativ prædiktiv værdi på 99.2%). Får vi derimod en positiv test, så bliver vi lidt mere sikre på, at vi er syge. Vi opjusterer altså fra en prior sandsynlighed på 5% til en positiv prædiktiv værdi på 36.1%. Men fordi at sandsynligheden for at være syg på forhånden er så lille, så vil en positiv test stadig efterlade en vis chance for, at vi rent faktisk ikke er syge alligevel!\nDet virker måske underligt, men forestil dig, at vi laver graviditetstest blandt mænd. Da ingen test er perfekt (sensitivitet og specificitet vil altid være under 100%), så vil der før eller siden ske det, at en af mændene tester positiv. Men her er det ret tydeligt, at prævalensen (det vil sige sandsynligheden for at være gravid) blandt dem vi tester (det vil sige mænd) er 0%. Derfor bliver den positive prædiktive værdi også 0%, selvom testen er positiv! Men det er selvfølgelig også lidt åndsvagt at lave graviditetstest blandt mænd…!\nHvis vi tester en hel befolkning for eksempelvis corona, så vil prævalensen være forholdsvis lav. Tester vi derimod kun blandt personer, som har symptomer på corona, så vil prævalens straks være højere. Vi skal nu undersøge, hvilken betydning det har på den positive og negative prædiktive værdi.\n\n\n\n\n\n\nOpgave 5: Positiv og negativ prædiktiv værdi og forskellige prævalenser\n\n\n\n\n\nVi forestiller os igen, at vi tester 10000 personer for den sygdom, som vi arbejder med og lad os sige, at sensitivitet og specificitet er som før, men at prævalensen varierer, som angivet nedenfor:\nPrævalens: \\(P(\\textrm{syg})\\) på henholdsvis \\(1 \\%\\), \\(5 \\%\\), \\(20 \\%\\) og \\(40 \\%\\).\nSensitivitet: \\(P(\\textrm{positiv test } | \\textrm{ syg}) = 86 \\%\\)\nSpecificitet: \\(P(\\textrm{negativ test } | \\textrm{ rask}) = 92 \\%\\)\n\nUdfyld tabeller som nedenstående for hver af de fire forskellige prævalenser (husk at du allerede har tabellen for prævalensen på 5% fra opgave 3!):\n\n\n\n\n\nSyg\nRask\nI alt\n\n\n\n\nPositiv test\n\n\n\n\n\nNegativ test\n\n\n\n\n\nI alt\n\n\n\n\n\n\n\nBeregn positiv prædiktiv værdi (\\(P(\\textrm{syg } | \\textrm{ positiv test})\\)) og negativ prædiktiv værdi (\\(P(\\textrm{rask } | \\textrm{ negativ test})\\)) for de fire forskellige prævalenser og udfyld denne tabel:\n\n\n\n\nPrævalens\nPositiv prædiktiv værdi\nNegativ prædiktiv værdi\n\n\n\n\n\\(1 \\%\\)\n\n\n\n\n\\(5 \\%\\)\n\n\n\n\n\\(20 \\%\\)\n\n\n\n\n\\(40 \\%\\)\n\n\n\n\n\n\nHvad sker der med henholdsvis den positive og den negative prædiktive værdi, når prævalensen stiger? Hvordan giver det mening?\n\n\n\n\n\n\n\n\n\n\nOpgave 6: Hurtigtest for corona\n\n\n\n\n\nLæs artiklen Antigentest gav 47% falsk negative svar.\n\nUdfyld på baggrund af artiklen tabellen med antal raske/syge og positive/negative.\nUdregn testens sensitivitet og specificitet.\nUdregn prævalensen.\nUdregn den positive og negative prædiktive værdi."
  },
  {
    "objectID": "undervisningsforloeb/test_for_sygdomme.html#bayes-formel-mest-for-a-niveau",
    "href": "undervisningsforloeb/test_for_sygdomme.html#bayes-formel-mest-for-a-niveau",
    "title": "Test for sygdomme",
    "section": "Bayes formel (mest for A-niveau)",
    "text": "Bayes formel (mest for A-niveau)\nHvis du har læst med her (link til Allans note om Bayes klassificer - eller måske vi skal have splittet de generelle afsnit om betingede sandsynligheder og Bayes formel ud i en note for sig selv?) så ved du, at en betinget sandsynlighed er defineret på følgende måde:\n\\[\nP(A | B) = \\frac{P(A,B)}{P(B)}\n\\]\n(er det ok at skrive \\(A,B\\) i stedet for fællesmængden - der er alligevel ingen mængdelære tilbage i gymnasiet?). Og du har lært, at hvis man bruger det lidt smart, så kan man bevise Bayes’ sætning, som siger, at\n\\[\nP(A | B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\n\\]\nDet vil vi nu udnytte til at opskrive et udtryk for den positive prædiktive værdi:\n\\[\nP(\\text{syg } | \\text{ positiv test}) = \\frac{P(\\text{positiv test } | \\text{ syg}) \\cdot P(\\text{syg})}{P(\\text{positiv test})}\n\\]\nUdnytter vi definitionen af sensitivitet og prævalens, så kan vi omskrive tælleren til\n\\[\nP(\\text{syg } | \\text{ positiv test}) = \\frac{\\text{sensitivitet} \\cdot \\text{prævalens}}{P(\\text{positiv test})}\n\\tag{1}\\]\nNu mangler vi at finde et udtryk for nævneren. Der må gælde, at\n\\[\nP(\\text{positiv test}) = P(\\text{positiv test, syg}) + P(\\text{positiv test, rask})\n\\] Bruger vi definitionen på betingede sandsynligheder, kan vi skrive ovenstående som\n\\[\nP(\\text{positiv test}) = P(\\text{positiv test } | \\text{ syg} ) \\cdot P(\\text{syg}) + P(\\text{positiv test } | \\text{ rask}) \\cdot P(\\text{rask})\n\\]\nVi udnytter nu, at \\[P(\\text{rask})+P(\\text{syg})=1\\] og dermed at \\[P(\\text{rask}) = 1- P(\\text{syg})\\] Tilsvarende er også \\[P(\\text{positiv test } | \\text{rask}) = 1-P(\\text{syg test } | \\text{rask})\\] Derfor er\n\\[\nP(\\text{positiv test}) = P(\\text{positiv test } | \\text{ syg} ) \\cdot P(\\text{syg}) + \\left ( 1 - P(\\text{negativ test } | \\text{ rask}) \\right )  \\cdot \\left ( 1- P(\\text{syg}) \\right )\n\\]\nMen nu er sandsynligheden for at teste positiv alene udtrykt ved hjælp af sensitiviteten, specificiteten og prævalensen:\n\\[\nP(\\text{positiv test}) = \\text{sensitivitet} \\cdot \\text{prævalens} + \\left ( 1 - \\text{specificitet} \\right )  \\cdot \\left ( 1- \\text{prævalens} \\right )\n\\] Indsætter vi dette i (1), får vi\n\\[\nP(\\text{syg } | \\text{ positiv test}) = \\frac{\\text{sensitivitet} \\cdot \\text{prævalens}}{\\text{sensitivitet} \\cdot \\text{prævalens} + \\left ( 1 - \\text{specificitet} \\right )  \\cdot \\left ( 1- \\text{prævalens} \\right )}\n\\tag{2}\\]\nBruger vi denne formel til at udregne den positive prædiktive værdi i det tilfælde, hvor prævalensen er 5%, sensitiviteten er 86% og specificiteten er 92%, får vi\n\\[\nP(\\text{syg } | \\text{ positiv test}) = \\frac{0.86 \\cdot 0.05}{0.86 \\cdot 0.05 + (1-0.92) \\cdot (1-0.05)} = 0.361=36.1 \\%\n\\]\nDet skulle meget gerne stemme med det, du har fået i opgave 4 (men hvor den positive prædiktive værdi blev beregner på baggrund af tabelværdier).\n\n\n\n\n\n\nOpgave 7: Beregning af positiv prædiktiv værdi for forskellige prævalenser\n\n\n\n\n\nAntag, at vi bruger den samme sensitivitet, specificitet og prævalenser som tidligere:\nPrævalens: \\(P(\\textrm{syg})\\) på henholdsvis \\(1 \\%\\), \\(5 \\%\\), \\(20 \\%\\) og \\(40 \\%\\).\nSensitivitet: \\(P(\\textrm{positiv test } | \\textrm{ syg}) = 86 \\%\\)\nSpecificitet: \\(P(\\textrm{negativ test } | \\textrm{ rask}) = 92 \\%\\)\n\nBrug nu formlen i (2) til at beregn den positive prædiktiv værdi (\\(P(\\textrm{syg } | \\textrm{ positiv test})\\)) for de fire forskellige prævalenser og udfyld denne tabel:\n\n\n\n\nPrævalens\nPositiv prædiktiv værdi\n\n\n\n\n\\(1 \\%\\)\n\n\n\n\\(5 \\%\\)\n\n\n\n\\(20 \\%\\)\n\n\n\n\\(40 \\%\\)\n\n\n\n\n\nKontroller at dit resultat stemmer med det, du fik i opgave 5.\n\n\n\n\n\n\n\n\n\n\nOpgave 8: Formel for negative prædiktiv værdi (svær)\n\n\n\n\n\n\nOpstil en formel for udregning af den negative prædiktive værdi ved at følge udledningen af formlen for den positive prædiktive værdi ovenfor.\nBrug din formel til at udregne negativ prædiktiv værdi for prævalenserne fra opgave 7.\nKontroller at dit resultat stemmer med det du fik i opgave 5."
  },
  {
    "objectID": "undervisningsforloeb/test_for_sygdomme.html#videre-læsning",
    "href": "undervisningsforloeb/test_for_sygdomme.html#videre-læsning",
    "title": "Test for sygdomme",
    "section": "Videre læsning",
    "text": "Videre læsning\nEpidemimatematik: Test for smitte og sygdomme"
  },
  {
    "objectID": "materialer/krydsvalidering/krydsvalidering.html",
    "href": "materialer/krydsvalidering/krydsvalidering.html",
    "title": "Overfitting, modeludvælgelse og krydsvalidering",
    "section": "",
    "text": "Hvordan vælger man den bedste model til beskrivelse af data? Skal man bare vælge den mest komplicerede? Eller kan der mon gå noget galt? Det handler overfitting og krydsvalidering om.\nMere præcis handler denne note om, hvad man kan gøre, når man har flere forskellige modeller for data at vælge imellem og gerne vil vælge den bedste. Noten introducerer først polynomiel regression, der bruges som gennemgående eksempel. Mod slutningen diskuteres, hvordan de samme principper kan bruges i forbindelse med nogle af de andre algoritmer, der er gennemgået her på siden."
  },
  {
    "objectID": "materialer/krydsvalidering/krydsvalidering.html#polynomiel-regression",
    "href": "materialer/krydsvalidering/krydsvalidering.html#polynomiel-regression",
    "title": "Overfitting, modeludvælgelse og krydsvalidering",
    "section": "Polynomiel regression",
    "text": "Polynomiel regression\n\nLineær regression\nFra gymnasieundervisningen kender I lineær regression. Lad os sige, at vi har datapunkter \\((x_i,y_i)\\), hvor \\(i=1,2,\\ldots,n\\). Vi vil gerne finde den rette linje, der bedst beskriver punkterne. I denne note kalder vi linjens skæring for \\(a_0\\) og hældningen for \\(a_1\\). Linjen har altså funktionsforskriften1\n1 Du er vant til, at forskriften for en lineær funktion er på formen \\(f(x)=ax+b\\). Men lige om lidt viser skrivemåden \\(f(x)=a_0+a_1x\\) sig nyttig. I forhold til det, du kender, svarer det til, at \\(a_0=b\\) og \\(a_1=a\\).\\[f(x) = a_0 + a_1x.\\]\nFor at finde den bedste linje til at beskrive vores data, søger vi de værdier \\(a_0\\) og \\(a_1\\), som gør, at \\(a_0 + a_1x_i\\) er så tæt på \\(y_i\\) som muligt. Vi vil altså gerne gøre afvigelserne fra linjen \\(y_i - (a_0 + a_1 x_i)\\) så små som muligt. Disse afvigelser svarer til det, man kalder for residualerne:\n\\[\nr_i=y_i - (a_0 + a_1 x_i).\n\\]\nSom et samlet mål for hvor store disse afvigelser er for alle vores punkter, kigger vi på kvadratsummen af afvigelserne/residualerne\n\\[\n\\begin{aligned}\nE &= \\left(y_1 - (a_0 + a_1 x_1) \\right)^2 + \\left(y_2 - (a_0 + a_1 x_2) \\right)^2 + \\cdots + \\left(y_n - (a_0 + a_1 x_n) \\right)^2 \\\\\n& = r_1^2 + r_2^2 + \\cdots + r_n^2\n\\end{aligned}\n\\]\nNu er det lidt omstændeligt at skrive summen ud, som vi har gjort det ovenfor. I matematik vil man ofte skrive en sådan sum lidt mere kompakt ved hjælp af et summationstegn. Gør vi det, ser det sådan her ud:\n\\[\n\\begin{aligned}\nE &=\\sum_{i=1}^n \\left(y_i - (a_0 + a_1x_i) \\right)^2 \\\\\n&= \\sum_{i=1}^n r_i^2 .\n\\end{aligned}\n\\]\nVi vælger så de værdier \\(a_0\\) og \\(a_1\\), der gør \\(E\\) mindst mulig. Dette kaldes mindste kvadraters metode.\n\n\nKvadratisk regression\nHvad nu hvis det slet ikke ligner, at der er en lineær sammenhæng, når vi tegner vores datapunkter ind i et koordinatsystem? Er det så overhovedet en god idé at forsøge med en lineær regression? På figur 1 ser det for eksempel ikke ud til at punkterne følger en ret linje.\n\n\n\n\n\n\n\n\nFigur 1: Til venstre ses et punktplot af et datasæt. Til højre er den bedste rette linje indtegnet.\n\n\n\n\n\n\n\n\n\n\n\nDatasættet\n\n\n\n\n\nDatasættet fra figur 1 ses i tabellen herunder, hvis du selv vil prøve at lave lineær regression på data. Data kan også hentes som en Excel-fil her.\n\n\n\n\n\n\n\n\n\n\\(x\\)\n\\(y\\)\n\n\n\n\n0.125\n1.71\n\n\n0.25\n1.95\n\n\n0.375\n1.877\n\n\n0.5\n1.914\n\n\n0.625\n2.341\n\n\n0.75\n1.692\n\n\n0.875\n2.473\n\n\n1\n2.217\n\n\n1.125\n2.199\n\n\n1.25\n1.962\n\n\n1.375\n2.125\n\n\n1.5\n2.595\n\n\n1.625\n2.021\n\n\n1.75\n1.894\n\n\n1.875\n1.309\n\n\n2\n1.545\n\n\n2.125\n0.7685\n\n\n2.25\n0.638\n\n\n2.375\n0.7456\n\n\n2.5\n0.1396\n\n\n\n\n\n\n\n\nI figur 2 ses et såkaldt residualplot. Her kan vi tydeligt se, at der er et mønster i den måde, residualerne fordeler sig omkring \\(x\\)-aksen. Det er altså tegn på, at en ret linje ikke er velegnet til at beskrive datapunkterne.\n\n\n\n\n\n\n\n\nFigur 2: Residualplottet for den bedste rette linje indtegnet i figur 1.\n\n\n\n\n\nNår \\(x\\) ligger mellem 0 og 1, kunne der godt se ud til at være en svagt stigende tendens i figur 1, mens der ser ud til at være en aftagende tendens for \\(x&gt;1.5\\). Det svarer til, at residualerne i figur 2 først er negative, så positive og dernæst negative igen. Den rette linje i figur 1 ser heller ikke ud til at følge punkterne særlig godt. Måske en parabel passer bedre på data?\n\n\n\n\n\n\n\n\nFigur 3: Datasættet fra figur 1, men nu med en parabel indtegnet.\n\n\n\n\n\nDet ser ud til, at parablen i figur 3 følger datapunkterne langt bedre. Vi kunne således prøve at modellere \\(y\\) ved hjælp af et andengradspolynomium i \\(x\\). Lad \\(f\\) betegne andengradspolynomiet2\n2 I gymnasiet skriver vi som regel forskriften for et andengradspolynomium på formen \\(f(x)=ax^2+bx+c\\). Med notationen, som vi bruger her, svarer det til, at \\(a_0=c, a_1=b\\) og \\(a_2=a\\).\\[\nf(x) = a_0 + a_1x + a_2x^2\n\\]\nmed koefficienter \\(a_0,a_1,a_2\\in \\mathbb{R}\\).\nHvordan finder man så det andengradspolynomium, der bedst beskriver datapunkterne? Tilgangen er faktisk den samme som den mindste kvadraters metode, I kender fra lineær regression. Vi søger de værdier \\(a_0, a_1\\) og \\(a_2\\), som gør, at \\(f(x_i)\\) kommer så tæt på \\(y_i\\) som muligt. Vi vil altså gerne gøre forskellene \\(y_i - f(x_i)\\) så små som muligt. Vi kigger derfor på kvadratsummen af disse forskelle \\[E=\\sum_{i=1}^n (y_i - f(x_i))^2 = \\sum_{i=1}^n \\left(y_i - (a_0 + a_1x_i + a_2x_i^2)\\right)^2.\\] Vi søger så de værdier \\(a_0,a_1\\) og \\(a_2\\), der minimerer \\(E\\).\nGør man det i vores lille dataeksempel, fås netop den parabel, der er tegnet ind i koordinatsystemet i figur 3. Vi ser, at den beskriver data langt bedre end den rette linje.\nEksemplet viser vigtigheden af at tegne et residualplot for at vurdere anvendeligheden af den lineære model. Ellers kan man nemt komme til at overse en eventuel ikke-lineær sammenhæng.\n\n\nPolynomiel regression generelt\nMen hvordan kan vi nu vide, at et andengradspolynomium er det bedste til at beskrive data? Måske et polynomium af endnu højere grad ville være bedre? Man kan tilpasse tredje- og højeregradspolynomier til data på en helt tilsvarende måde. Vi kan for eksempel prøve at tilpasse et tredjegradspolynomium\n\\[\nf(x) = a_0 + a_1x + a_2x^2 +a_3x^3.\n\\]\nDet bedste tredjegradspolynomium er igen det, der minimerer kvadratsummen \\[E=\\sum_{i=1}^n (y_i - f(x_i))^2 = \\sum_{i=1}^n \\left(y_i - (a_0 + a_1x_i + a_2x_i^2 + a_3x_i^3 )\\right)^2.\\] Grafen for det bedste tredjegradspolynomium er indtegnet med grøn for vores dataeksempel i figur 4. Andengradspolynomiet er indtegnet med rød til sammenligning.\n\n\n\n\n\n\n\n\nFigur 4: Et andengradspolynomium (rød) og et tredjegradspolynomium (grøn) fittet til data.\n\n\n\n\n\nDet er ikke så let at se forskel. De to polynomier ser ud til at passe nogenlunde lige godt på vores data. Men i figur 5 har vi zoomet ud på figuren ovenfor, og her er der en klar forskel:\n\n\n\n\n\n\n\n\nFigur 5: Plottet fra figur 4, men hvor der nu er zoomet lidt ud. Her ses det tydeligt, at der i “enderne” bliver stor forskel på anden- og tredjegradspolynomiet.\n\n\n\n\n\nSelv om der ikke var stor forskel på anden- og tredjegradspolynomiet på intervallet \\([0;2,5]\\) hvor alle \\(x\\)-værdierne i vores datasæt lå, så er der stor forskel, når vi kommer uden for dette interval. Man skal derfor passe på med at drage konklusioner om \\(x\\)-værdier uden for intervallet, hvor \\(x\\)-værdierne i vores datasæt ligger (det kaldes at ekstrapolere), da disse kan være meget følsomme over for, hvilken grad vi har valgt for vores polynomium. En fornuftig ekstrapolation vil derfor ofte kræve et forudgående kendskab til den sammenhæng, man modellerer ved valget af graden af polynomiet.\n\n\nVIDEO: Polynomiel regression\nI denne video forklarer vi, hvad polynomiel regression er."
  },
  {
    "objectID": "materialer/krydsvalidering/krydsvalidering.html#overfitting",
    "href": "materialer/krydsvalidering/krydsvalidering.html#overfitting",
    "title": "Overfitting, modeludvælgelse og krydsvalidering",
    "section": "Overfitting",
    "text": "Overfitting\nDet er altså svært at afgøre med det blotte øje, om anden- eller tredjegradspolynomiet passer bedst til punkterne. Hvordan vælger vi så, hvad der er bedst? Som mål for, hvor tæt polynomiet er på data, kan vi kigge på kvadratsummen af afvigelserne \\(y_i - f(x_i)\\), altså \\[E=\\sum_{i=1}^n (y_i - f(x_i))^2.\\] For andengradspolynomiet får vi en kvadratsum på \\(E=1.14\\), mens vi får \\(E=1.10\\) for tredjegradspolynomiet. Tredjegradspolynomiet kommer altså tættere på data end andengradspolynomiet. Det er på den anden side ikke så overraskende, for ved at sætte \\(a_3=0\\) i et tredjegradspolynomium fås et andengradspolynomium. Andengradspolynomier er altså specialtilfælde af tredjegradspolynomier. Vi vil derfor altid kunne tilpasse data mindst lige så godt med et tredjegradspolynomium som med et andengradspolynomium.\nKan det så altid betale sig at bruge et polynomium af højere grad? Lad os prøve med et syvendegradspolynomium. Vi søger \\[f(x) = a_0 + a_1x + a_2x^2 +a_3x^3 + a_4x^4 + a_5x^5 +a_6x^6 +a_7x^7,\\] der minimerer kvadratsummen \\[E=\\sum_{i=1}^n (y_i - f(x_i))^2 .\\] Det bedste syvendegradspolynomium i vores lille dataeksempel er indtegnet med blå på figur 6 nedenfor:\n\n\n\n\n\n\n\n\nFigur 6: Et andengradspolynomium (rød) og et syvendegradspolynomium (blå) fittet til data.\n\n\n\n\n\nKvadratsummen er på kun \\(E=0.90\\), så umiddelbart virker det til at være en meget bedre model. Der er dog visse problemer. Det ses, at grafen bugter sig meget for at komme så tæt som muligt på datapunkterne. Dels virker det urealistisk, at den faktiske sammenhæng mellem \\(x\\) og \\(y\\) skulle være så kompliceret. Dels opstår der et problem, hvis vi kommer med nye datapunkter. I figur 7 er polynomierne fra før tegnet sammen med 20 nye datapunkter i grøn (som stammer fra den samme underliggende fordeling). Nu beskriver syvendegradspolynomiet pludselig ikke datapunkterne så godt længere.\n\n\n\n\n\n\n\n\nFigur 7: Andengradspolynomiet (rød) og syvendegradspolynomiet (blå) fra figur 6 sammen med 20 nye datapunkter (grøn), som kommer fra den samme underliggende fordeling, som de sorte datapunkter fra figur 6.\n\n\n\n\n\nDet, der sker her, er et eksempel på det fænomen, der kaldes overfitting: syvendegradspolynomiet havde tilpasset sig for godt til lige netop de sorte datapunkter. Når graden bliver for høj, begynder polynomiet at tilpasse sig nogle strukturer i data, som i virkeligheden bare skyldes tilfældigheder. Det fungerer rigtig godt til at beskrive det oprindelige data, men til gengæld er det dårligt til at forudsige nye dataværdier.\nJo højere grad man vælger, at polynomiet skal have, desto bedre kan man tilnærme data. Med \\(n\\) datapunkter (som alle have forskellige \\(x\\)-værdier), kan man faktisk altid finde et polynomium af grad \\(n-1\\), der går igennem alle datapunkterne, men nye datapunkter vil ikke nødvendigvis følger dette polynomium særlig godt.\n\nModelfleksibilitet\nDet, vi så ovenfor, var, at vi havde forskellige modeller for data (polynomier af forskellig grad). Modellerne havde forskellig fleksibilitet (høj grad gjorde polynomiet meget fleksibelt). Når vi brugte en model med for lav fleksibilitet (lineær regression), kunne vi ikke tilpasse modellen godt nok til data. Når vi valgte en model med for høj fleksibilitet (polynomium af grad syv), opstod der problemer med overfitting, og modellen var ikke god til at beskrive nye data.\nDet tilsvarende problem opstår også i andre sammenhænge, når man har flere forskellige modeller at vælge imellem. Nogle vil være for ufleksible til at beskrive data ordentligt. Andre vil være for fleksible og føre til overfitting. Så hvordan finder vi et godt kompromis? Det handler det følgende om.\n\n\nVIDEO: Overfitting\nI videoen herunder forklarer vi, hvad overfitting handler om."
  },
  {
    "objectID": "materialer/krydsvalidering/krydsvalidering.html#trænings--og-testdata",
    "href": "materialer/krydsvalidering/krydsvalidering.html#trænings--og-testdata",
    "title": "Overfitting, modeludvælgelse og krydsvalidering",
    "section": "Trænings- og testdata",
    "text": "Trænings- og testdata\nNår vi har et datasæt og prøver at tilpasse en polynomiel regressionsmodel, siger vi, at vi træner modellen. Datasættet, vi bruger til at træne modellen, kaldes træningsdata. Som vi så ovenfor, indebærer det en risiko for overfitting, når vi træner modellen. Hvis vi kommer med et nyt datasæt af samme type, passer modellen ikke nødvendigvis særlig godt.\nFor at vurdere hvilken grad af polynomiet der passer bedst, kan vi se på, hvilken model der er bedst til at forudsige (også kaldet prædiktere) \\(y\\)-værdierne i et nyt datasæt. Det nye datasæt kaldes testdata. Lad os kalde testdatapunkterne for \\((x_i^{test},y^{test}_i)\\), hvor \\(i=1,\\ldots,m\\). Man kan måle, hvor godt modellen forudsiger testdata ved at se på forskellene \\(y_i^{test}-f(x_i^{test})\\) mellem de observerede værdier \\(y_i^{test}\\) og dem, der forudsiges af polynomiet \\(f(x_i^{test})\\). Som samlet mål for, hvor godt modellen forudsiger testdata, beregner vi kvadratsummen af disse forskelle \\[E^{test} = \\sum_{i=1}^{m} \\left(y_i^{test} - {f}\\left(x_i^{test}\\right)\\right)^2.\\] Man kalder \\(E^{test}\\) for tabsfunktionen.\nI praksis har man typisk kun et datasæt til rådighed, og man er derfor nødt til først at dele data i to. Hele processen med at inddele data og først træne modellen og derefter teste den er, som følger:\n\nVælg en polynomiumsgrad \\(p\\).\nDatasættet inddeles i to dele, én del der bruges som træningsdata, og én del der bruges som testdata. Vi vil betegne punkterne i træningsdata med \\((x_i^{træn},y_i^{træn})\\), \\(i=1,\\ldots,n\\), og punkterne i testdata med \\((x_i^{test},y_i^{test})\\), \\(i=1,\\ldots,m\\).\nVi træner modellen på træningsdatasættet og finder det \\(p\\)’te-gradspolynomium \\[f(x)=a_0 + a_1 x + \\dotsm + a_px^p\\] der passer bedst på data. Mindste kvadraters metode benyttes til at bestemme \\(a_0,\\ldots,a_p\\) som de tal, der minimerer \\[E^{træn}(p)=\\sum_{i=1}^{n} (y_i^{træn} - {f}(x_i^{træn}))^2.\\] Det bedste polynomium kalder vi \\(\\hat{f}\\).\nNår vi har valgt funktionen \\(\\hat{f}\\) på baggrund af træningsdataet, tester vi den på testdataet ved at beregne \\[E^{test}(p)=\\sum_{i=1}^{m} (y_i^{test} - \\hat{f}(x_i^{test}))^2.\\] Jo mindre \\(E^{test}(p)\\) er, des bedre passer \\(\\hat{f}\\) på testdata.\n\nDenne procedure kan gentages for forskellige værdier af polynomiumsgraden \\(p\\). Det \\(p\\), der giver den mindste værdi af \\(E^{test}(p)\\) svarer altså til den model, der er bedst til at forudsige værdierne i vores testdata, og vi vælger derfor at bruge dette \\(p\\).\nI vores eksempel ovenfor får vi \\(E^{test}(2)=1.82\\) og \\(E^{test}(7)=2.29\\), når vi bruger de sorte datapunkter som træningsdata og de grønne datapunkter som testdata. Andengradspolynomiet er altså bedre end syvendegradspolynomiet til at forudsige testdata. Bemærk, at i begge tilfælde er \\(E^{test}\\) langt større end \\(E^{træn}\\), fordi modellen kun er tilpasset til træningsdata.\nNår det bedst mulige \\(p\\) er valgt, kan man så træne modellen igen på alt dataet, både test- og træningsdata, for at få et mere præcist bud på det bedste polynomium. Dette er så vores endelige model for data. I vores eksempel finder man, at \\(p=2\\) giver lavest \\(E^{test}\\). Vi slår så de sorte og grønne datapunkter sammen til et datasæt og bruger dem til at finde det bedste andengradspolynomium. Det giver vores endelige model for sammenhængen mellem \\(x\\) og \\(y\\), som bliver \\[\nf(x) = 1.36 + 1.72x - 0.87x^2.\n\\]"
  },
  {
    "objectID": "materialer/krydsvalidering/krydsvalidering.html#sec-krydsvalidering",
    "href": "materialer/krydsvalidering/krydsvalidering.html#sec-krydsvalidering",
    "title": "Overfitting, modeludvælgelse og krydsvalidering",
    "section": "Krydsvalidering",
    "text": "Krydsvalidering\nDer er et problem med tilgangen ovenfor. Når man træner en model, er det altid en fordel at have så meget data som muligt, da man så har mulighed for at træne modellen meget præcist. Problemet er, at hvis man bruger det meste af data som træningsdata, er der ikke meget tilbage til at teste på, og vi risikerer overfitting.\nKrydsvalidering løser dette problem på snedig vis ved at gentage trænings- og testproceduren flere gange. For at lave \\(k\\)-fold krydsvalidering deler man data op i \\(k\\) lige store og tilfældige dele. I første fold træner man modellen på alt data undtagen den første del og bruger første del som testdata. Det given en tabsfunktion \\(E_1(p)\\). Dette gentages så \\(k\\) gange, hvor man i den \\(i\\)’te fold bruger den \\(i\\)’te del af data som testdata og resten som træningsdata og får en tabsfunktion \\(E_i(p)\\). Idéen er illustreret i figur 8.\n\n\n\n\n\n\n\n\nFigur 8: Illustration af idéen ved \\(5\\)-fold krydsvalidering.\n\n\n\n\n\nSom et samlet mål for, hvor god modellen er, bruges summen af tabsfunktionerne fra de \\(k\\) fold \\[E(p)=E_1(p) + E_2(p) + \\dotsm + E_k(p).\\] Man vælger så den model, der giver den mindste værdi af \\(E(p)\\).\nFordelen ved krydsvalidering er, at man i hver fold bruger det meste af data til at træne modellen på. Samtidig bliver hvert datapunkt alt i alt brugt præcis én gang til at teste på. På den måde får man udnyttet data bedre end, hvis man bare laver en enkelt opdeling af data. Typisk vælger man \\(k=5\\) eller \\(k=10\\).\n\nVIDEO: Trænings- og testdata samt krydsvalidering\nI denne video forklarer vi, hvad trænings- og testdata er samt hvad krydsvalidering går ud på.\n\n\n\nKrydsvalidering i andre sammenhænge\nKrydsvalidering kan bruges i et væld af andre sammenhænge, hvor der skal vælges mellem flere forskellige prædiktionsmodeller.\nHvis det, der skal prædikteres, er en talværdi, kan man gøre som ovenfor. Algoritmen trænes på træningsdataet og bruges derefter til lave prædiktioner \\(\\hat{y}_i^{test}\\), \\(i=1,\\ldots ,m\\), af værdierne i testdatasættet. Disse sammenlignes med de faktiske værdier \\(y_i^{test}\\) ved at se på forskellene \\(y_i^{test} - \\hat{y}_i^{test}\\) og beregne tabsfunktionen \\[E^{test} = \\sum_{i=1}^m(y_i^{test}-\\hat{y}_i^{test})^2.\\] Modellen med lavest \\(E^{test}\\) er bedst til at lave nye prædiktioner.\nHvis der derimod er tale om et klassifikationsproblem, hvor der skal prædikteres en klasse (fx mand/kvinde, rød blok/blå blok, almindelig mail/spam), skal man definere tabsfunktionen lidt anderledes. Som før trænes algoritmen på træningsdataet og derefter bruges den til lave prædiktioner af klasserne \\(\\hat{y}_i^{test}\\), \\(i=1,\\ldots ,m\\), i testdatasættet. Disse sammenholdes med de faktiske klasser, og vi bruger så fejlraten som tabsfuntion. Fejlraten angiver andelen af observationerne i testdataet, der bliver klassificeret forkert, det vil sige\n\\[\nE^{test} =  \\frac{1}{m}\\cdot (\\text{antal fejlklassifikationer i testdata}).\n\\tag{1}\\]\nModellen med lavest \\(E^{test}\\) har færrest fejlklassifikationer og vælges derfor som den bedste.\nEksempler her fra siden, hvor krydsvalidering kan benyttes:\n\nI forløbet Hvem ligner du mest sammenligner man et gråt punkt med alle punkter inden for en radius \\(r\\) for at forudsige farven. Det er ikke oplagt, hvordan man skal vælge denne radius. En mulighed er at komme med nogle gode bud \\(r_1,\\ldots, r_N\\) på radier og så bruge krydsvalidering til at vælge den bedste. Én mulighed er at vælge \\(k=n\\). Så får man det, der kaldes leave-one-out krydsvalidering. I hver fold bliver der så kun et datapunkt i testdata, mens resten bruges som træningsdata. Det ene testdatapunkt farves gråt, og farven prædikteres ud fra de øvrige datapunkter, der ligger inden for den valgte radius. Prædiktionen sammenlignes med punktets rigtige farve. Dette gentages for alle datapunkter og fejlraten (1) beregnes til sidst. Vi vælger så den radius, der har lavest fejlrate.\nI noten om Kunstige neurale nerværk beskrives det, hvordan man træner et kunstigt neuralt netværk. Men når man gør det, skal man på forhånd have besluttet sig for, hvor mange skjulte lag der skal være i netværket, og hvor mange neuroner, der skal være i hvert skjult lag. Jo flere skjulte lag og jo flere neuroner – desto større fleksibilitet. Her vil krydsvalidering være oplagt til at afgøre, hvor fleksibelt netværket skal være samtidig med, at man undgår overfitting."
  },
  {
    "objectID": "materialer/krydsvalidering/krydsvalidering.html#relaterede-forløb",
    "href": "materialer/krydsvalidering/krydsvalidering.html#relaterede-forløb",
    "title": "Overfitting, modeludvælgelse og krydsvalidering",
    "section": "Relaterede forløb",
    "text": "Relaterede forløb\n\n\n\n\n\nForløb\n\n\nKort beskrivelse\n\n\n\n\n\n\nOverfitting og krydsvalidering med polynomiel regression\n\n\nIntroduktion til begreberne overfitting og krydsvalidering vha. polynomiel regression. Som eksempel ses på en fiktiv sammenhæng mellem antal biografbesøg og antal venner på de sociale medier.\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "materialer/afstande/afstand.html",
    "href": "materialer/afstande/afstand.html",
    "title": "Afstande, nærmest, størst, mindst",
    "section": "",
    "text": "Når vi adskiller eller samler data bygger vi på en form for afstand. De \\(k\\) nærmeste naboer er dem, der ligger tættest på i én eller anden forstand. Hvis det drejer sig om dem, hvis højder er tætte på hinanden eller måske dem, der vejer nogenlunde det samme, er det klart, hvad man mener. Der er tal, man umiddelbart kan sammenligne. Men hvad med at sammenligne både vægt og højde? Hvad betyder så mest? Er der lige langt mellem en person A, der vejer 80 kg og er 1,80 m høj og en anden, B, der vejer 90 kg og er 2,00 m eller mellem A og C, der vejer 70 kg og er 1,60 m? Det er ikke klart, selvom vi da kan plotte de tre punkter i et (vægt, højde) koordinatsystem og endda bruge Pythagoras og få den samme afstand.1 Udregner man BMI, er \\(A\\) tættere på \\(B\\) end på \\(C\\). Det kommer nok også an på, hvad vi gerne vil udtale os om: Er de nogenlunde lige gode til at løbe langt? Eller hurtigt? Mere kompliceret bliver det, hvis vi også vil inddrage øjenfarve, skostørrelse eller måske, om de køber rigtig meget mælk. Der er mange eksempler på afstande, som ikke umiddelbart er fysisk afstand. For eksempel mellem ord (LINK) eller mellem DNA (Link)\n1 Afstanden bliver \\(10^2+0,2^2\\). Bemærk, at det er udregnet udfra vægt i kg og højde i meter. Med højde i cm ville det være \\(10^2+20^2\\), men stadig samme afstand fra A til B som fra A til C. Se Afstand udfra Data for mere info om effekten af at skifte enheder. Det kan godt lave om på, hvilke punkter, der ligger nærmest."
  },
  {
    "objectID": "materialer/afstande/afstand.html#hierarkisk-clustering",
    "href": "materialer/afstande/afstand.html#hierarkisk-clustering",
    "title": "Afstande, nærmest, størst, mindst",
    "section": "Hierarkisk clustering",
    "text": "Hierarkisk clustering\nHer kender vi alle parvise afstande. Og ikke andet.\nUdfra den information laver vi et dendogram, hvor i første omgang par af datapunkter \"mødes\" i den højde, der svarer til deres afstand. Men der er mere: Hvornår skal datapunktet \\(p\\) mødes med \\(qr\\), som mødtes tidligere? Hvornår skal \\(pqr\\) mødes med \\(ab\\)? Det er linkage-reglerne.\n\nSingle linkage: \\(pqr\\) mødes med \\(ab\\) i den højde, hvor minimumsafstanden mellem de to grupper af punkter nås:\nMinimum af \\(d(a,p),d(a,q), d(a,r), d(b,p), d(b,q), d(p,r)\\)\nComplete linkage: \\(pqr\\) mødes med \\(ab\\), når den maksimale afstand mellem punkter i de to grupper er nået.\nMaksimum af \\(d(a,p),d(a,q), d(a,r), d(b,p), d(b,q), d(p,r)\\)\nMiddelafstand- average linkage: Når den gennemsnitlige afstand er nået. \\(\\frac{1}{2\\cdot 3}(d(a,p)+d(a,q)+ d(a,r)+ d(b,p)+ d(b,q)+ d(p,r))\\)\n\n(OBS: Her skal være tegninger og diagrammer -dendrogrammer. Og eksempler på, hvad forskellen er på de forskellige linkagekrav)\nKlyngeanalyse af DNA eller for eksempel mRNA giver anledning til dendrogrammer, som kaldes de phylogenetiske træer for de arter/sygdomme,... der svarer til den analyserede DNA.\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC2859286/\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC6130602/"
  },
  {
    "objectID": "materialer/afstande/afstand.html#k-means-clustering",
    "href": "materialer/afstande/afstand.html#k-means-clustering",
    "title": "Afstande, nærmest, størst, mindst",
    "section": "k-means clustering",
    "text": "k-means clustering\nVores data er punkter med \\(d\\) koordinater. Afstanden er Euklidisk. Vi vælger \\(k\\), det antal clusters, det skal ende med. Målet er at opdele data i \\(k\\) dele, \\(S_1, S_2,\\ldots , S_k\\) så den samlede gennemsnitlige kvadratiske afstand \\[\\Sigma_{i=1}^{k}\\Sigma_{p,q\\in S_i}\\frac{1}{2|S_i|}\\|p-q\\|^2\\] indenfor de \\(k\\) clusters er mindst mulig."
  },
  {
    "objectID": "materialer/afstande/AfstandeMellemStrenge.html",
    "href": "materialer/afstande/AfstandeMellemStrenge.html",
    "title": "Afstande mellem ord",
    "section": "",
    "text": "Et ord er en følge eller en streng af bogstaver eller tal. Det kunne for eksempel være 12DvbdN34fdg eller hnaikgoh (nej, det behøver ikke give mening). Det kunne også være en DNA-sekvens, et ord i en tekst eller noget helt andet1. Man siger, at længden af en streng er antallet af bogstaver i strengen.\n1 Ofte gør man det desuden binært, så det er en streng af \\(0\\) og \\(1\\) såsom \\(00110110.\\) Det er fornuftigt nok, eftersom computere opererer med den slags strenge.Vi vil i det følgende se på såkaldte edit-afstande, som basalt set tæller, hvor mange ændringer, man skal lave, for at komme fra den ene streng til den anden. Det kommer naturligvis til at afhænge af, hvilke typer ændringer, man tillader. Lad os her se på nogle af dem.\n\nHammingafstanden\nHammingafstanden mellem to lige lange strenge er antallet af pladser, hvor de to strenge er forskellige. Afstanden fra sne til sno er derfor \\(1\\). Afstanden fra sne til neg er \\(3\\), fordi de to strenge er forskellige på alle pladser. Det svarer til, at man må ændre et bogstav ad gangen:\n\\[ sne \\rightarrow nne \\rightarrow nee \\rightarrow neg\\] Dette er illustreret i figur 1 ved de tre grønne kanter fra sne til neg.\n\n\n\n\n\n\nFigur 1: Hver knude i figuren svarer til et ord. En kant imellem to knuder svarer til, at der findes et \"move\" mellem de to ord enten ved hjælp af Hamming-, Levenshtein- eller Damerau-Levenshteinafstanden (angivet med henholdsvis grøn, lilla og pink).\n\n\n\n\n\nLevenshteinafstanden\nLevenshteinafstanden har flere tilladte ændringer: Man må ændre bogstaver, som i Hamming, men man må også indsætte og fjerne bogstaver. Levenshteinafstanden er det mindste antal sådanne ændringer, man skal lave for at nå fra det ene ord til det andet. Ordene/strengene behøver ikke have samme længde - man kan jo indsætte og fjerne bogstaver.\nSe på figur 1:\n\nAfstanden fra sne til see er \\(1\\), ligesom Hammingafstanden.\nAfstanden fra sne til sneg er også \\(1\\), fordi vi blot har tilføjet et g – og her er Hammingafstanden slet ikke meningsfuld. Den er simpelthen ikke defineret.\nAfstanden fra sne til neg er \\(2\\) – via disse ændringer:\n\\[sne \\rightarrow sneg \\rightarrow neg\\]\nHammingafstanden, som vi fandt ovenfor, er \\(3\\).\n\nBemærk, at vi i ovenstående eksempel også kunne have valgt\n\\[sne \\rightarrow ne \\rightarrow neg\\] som også har \\(2\\) \"moves\".\nJo flere tilladte ændringer, jo kortere afstand. Der er algoritmer, der finder den mindste vej mellem to ord – det er dog ikke helt så klart, hvordan man regner den ud, som det er for Hammingafstanden.\n\n\nDamerau-Levenshteinafstanden\nDamerau-Levenshteinafstanden er som Levenshtein, men man tillader nu også ombytning af to bogstaver, som står ved siden af hinanden. Hvis man skriver teskt på en telefon eller pc, er det let at bytte om på den måde. Hvis man så har en liste over ord, der giver mening, kan man opdage, at teskt ikke giver mening, men at ordet tekst ligger meget tæt på - afstand \\(1\\) i Damerau-Levenshteinafstand – og \\(2\\) i Hamming- eller Levenshteinafstand. Ordet teske har også Hammingafstand \\(1\\) til teskt, så man kan ikke være sikker på, hvad det oprindelige var.\nI figur 2 ses et eksempel på hvilke \"moves\", der er tilladt mellem forskellige ord ved hjælp af Hamming-, Levenshtein- eller Damerau-Levenshteinafstanden.\n\n\n\n\n\n\nFigur 2: Hver knude i figuren svarer til et ord. En kant imellem to knuder svarer til, at der findes et \"move\" mellem de to ord enten ved hjælp af Hamming-, Levenshtein- eller Damerau-Levenshteinafstanden (angivet med henholdsvis grøn, lilla og pink).\n\n\n\n\n\nAfstande mellem navne\nNavne som Peter, Pieter, Pietro, Petrus, Peder, Per, Pelle, Pekka, Peer, Petur, Pedro, Pierre, Pjotr, Pyotr, Petar eller måske Katarina, Katharina, Katrina, Katrine, Katrin, Cathryn, Kathryn, Catherine har samme oprindelse. Der er stor forskel på, hvor hyppigt, de optræder i forskellige lande. Overvej, om edit-afstandene ovenfor kan bruges til for eksempel at afsløre, hvor tæt på hinanden lande med Peter som hyppigst, er på lande med Pyotr."
  },
  {
    "objectID": "materialer/afstande/feature_scaling.html",
    "href": "materialer/afstande/feature_scaling.html",
    "title": "Feature-skalering",
    "section": "",
    "text": "Hvis de data, man arbejder med, måler vidt forskellige ting – måske endda på vidt forskellige skalaer – så vil man som oftest have brug for at \"justere\" data, så de er på samme skala."
  },
  {
    "objectID": "materialer/afstande/feature_scaling.html#afstand-med-hovedet-under-armen",
    "href": "materialer/afstande/feature_scaling.html#afstand-med-hovedet-under-armen",
    "title": "Feature-skalering",
    "section": "Afstand med hovedet under armen",
    "text": "Afstand med hovedet under armen\nDet er ikke altid helt klart, hvordan man skal bestemme afstanden mellem to datapunkter, hvis koordinaterne i hvert datapunkter beskriver vidt forskellige ting. Vi vil her se nærmere på, hvilke problemer, der kan opstå, hvis man ikke tænker sig om – og hvad man kan gøre for at løse dem.\nLad os forestille os, at data består af vægt og højde for nogle personer, så hvert datapunkt er på formen \\[(v,h)\\] hvor \\(v\\) er den pågældende persons vægt og \\(h\\) er højden. Her er det faktisk ikke klart, hvad afstanden mellem to punkter \\((v_1,h_1)\\) og \\((v_2,h_2)\\) skal være. Altså, hvornår to punkter ligger tæt på hinanden.\nEt første bud kunne være at bestemme den euklidiske afstand mellem de to punkter – det der bare svarer til at bruge Pythagoras. Gør vi det får vi følgende afstandsmål mellem punkterne \\((v_1,h_1)\\) og \\((v_2,h_2)\\):\n\\[\\sqrt{(v_2-v_1)^2+(h_2-h_1)^2}\\]\nVi prøver at regne lidt på det, og forestiller os, at tre personer er givet som datapunkter i nedenstående tabel.\n\n\n\nPerson\n(vægt, højde)\n\n\n\n\nA\n\\((70 \\ kg, 165 \\ cm)\\)\n\n\nB\n\\((90 \\ kg, 180 \\ cm)\\)\n\n\nC\n\\((80 \\ kg, 190 \\ cm)\\)\n\n\n\nBruger vi Pythagoras på tallene, der står her, er:\n\\[\\begin{align*}\n&\\text{Afstanden mellem A og B: } \\sqrt{20^2+15^2}=25 \\\\\n&\\text{Afstanden mellem A og C: } \\sqrt{10^2+25^2}\\simeq 27 \\\\\n&\\text{Afstanden mellem B og C: } \\sqrt{10^2+10^2}\\simeq 14\n\\end{align*}\\]\nMed dette afstandsmål er der altså længst fra \\(A\\) til \\(C\\).\nSkifter vi nu enhed og udtrykker højden i meter får vi følgende datapunkter:\n\n\n\nPerson\n(vægt, højde)\n\n\n\n\nA\n\\((70 \\ kg, 1.65 \\ m)\\)\n\n\nB\n\\((90 \\ kg, 1.80 \\ m)\\)\n\n\nC\n\\((80 \\ kg, 1.90 \\ m)\\)\n\n\n\nNu er\n\\[\\begin{align*}\n&\\text{Afstanden mellem A og B: } \\sqrt{20^2+0.15^2} \\simeq 20 \\\\\n&\\text{Afstanden mellem A og C: } \\sqrt{10^2+0.25^2} \\simeq 10 \\\\\n&\\text{Afstanden mellem B og C: } \\sqrt{10^2+0.10^2} \\simeq 10\n\\end{align*}\\]\nDer er nu længst fra \\(A\\) til \\(B\\).\nDet er ikke ret smart. Skal man finde de datapunkter, som ligger tættest på hinanden, er svaret tilsyneladende som vinden blæser og afhængig af hvilken enhed, vi har valgt at måle i.\nMen selv hvis begge variable er i samme enhed, kan Pythagoras brugt med hovedet under armen være uheldigt, som nedenstående eksempel illustrerer.\nVi forestiller os, at vi har data for, hvor meget familierne \\(A\\), \\(B\\) og \\(C\\) bruger på bolig og på mælk om måneden. Begge variable kan være i kroner. I tabellen ses et eksempel:\n\n\n\nFamilie\n(bolig, mælk)\n\n\n\n\nA\n\\((7500 \\ kr, 200 \\ kr)\\)\n\n\nB\n\\((7500 \\ kr, 1700 \\ kr)\\)\n\n\nC\n\\((6000 \\ kr, 200 \\ kr)\\)\n\n\n\nDet vil altså for eksempel sige, at familie \\(A\\) bruger \\(7500\\) kr på bolig og \\(200\\) kr på mælk. Her er afstanden udregnet med Pythagoras:\n\\[\\begin{align*}\n&\\text{Afstanden mellem A og B: } \\sqrt{0^2+1500^2} = 1500 \\\\\n&\\text{Afstanden mellem A og C: } \\sqrt{1500^2+0^2} = 1500 \\\\\n&\\text{Afstanden mellem B og C: } \\sqrt{1500^2+1500^2} \\simeq 2121\n\\end{align*}\\]\nAltså er der samme afstand fra \\(A\\) til \\(B\\) som fra \\(A\\) til \\(C\\), men vi vil nok mene, at \\(B\\) afviger mere fra \\(A\\) end \\(C\\) gør, fordi mælkeforbruget i familie \\(B\\) er usædvanligt.\nHar vi data for mange familier, kan vi kvantificere idéen om, hvad der er usædvanligt og bruge det til at lave en mere passende afstand."
  },
  {
    "objectID": "materialer/afstande/feature_scaling.html#første-naive-tilgang-min-max-skalering",
    "href": "materialer/afstande/feature_scaling.html#første-naive-tilgang-min-max-skalering",
    "title": "Feature-skalering",
    "section": "Første naive tilgang: Min-Max skalering",
    "text": "Første naive tilgang: Min-Max skalering\nEksemplet ovenfor illustrerer, at det nok vil være smart at prøve at inddrage i hvilket interval \\(x\\)- og \\(y\\)-værdierne varierer. For eksempel er et udsving på \\(500\\) kr i boligudgifter ikke lige så voldsomt, som et udsving på \\(500\\) kr i mælkeudgifter. Problemet er, at den absolutte forskel på henholdsvis \\(x\\)- og \\(y\\)-værdierne ikke er sammenlignelige her.\nLad os sige, at vi betragter datapunkter \\((x_i,y_i)\\) i planen, hvor \\(x\\)-værdierne ligger mellem \\(a\\) og \\(b\\), mens \\(y\\)-værdierne ligger mellem \\(c\\) og \\(d\\). Situationen er illustreret i figur 1.\n\n\n\n\n\n\nFigur 1: Datapunkter i planen, hvor \\(x\\)-værdierne ligger mellem \\(a\\) og \\(b\\), mens \\(y\\)-værdierne ligger mellem \\(c\\) og \\(d\\).\n\n\n\nIdéen er nu, at vi skalerer, så afstandene langs \\(x\\)-aksen får samme vægt som afstandene langs \\(y\\)-aksen.\nDet vil sige, at vi definerer afstanden fra \\((x_1,y_1)\\) til \\((x_2,y_2)\\) som\n\\[\\sqrt{\\left ( \\frac{x_2-x_1}{b-a} \\right )^2+ \\left ( \\frac{y_2-y_1}{d-c} \\right )^2} \\tag{1}\\]\nDet får den betydning, at hvis \\(x\\)-værdierne f.eks. kan varierer i et langt bredere interval end \\(y\\)-værdierne (dvs. at \\(b-a&gt;d-c\\)), så bliver forskellen på \\(x\\)-værdierne i ovenstående afstandsmål skaleret mere ned (fordi vi kommer til at dividere med et større tal).\nEn anden måde at forstå dette afstandsmål på, er ved at erstatte hvert punkt \\((x_i,y_i)\\) med et nyt skaleret punkt:\n\\[(x_i,y_i)_{Norm}=\\left(\\frac{x_i-a}{b-a}, \\frac{y_i-c}{d-c}\\right) \\tag{2}\\]\nResultatet af at lave denne skalering af punkterne fra figur 1 ses i figur 2.\n\n\n\n\n\n\nFigur 2: Datapunkterne fra figur 1, men hvor alle punkter er blevet min-max skaleret ved at bruge formlen i (2).\n\n\n\nBemærk, at datapunkterne nu er skaleret på en sådan måde, at alle \\(x\\)- og \\(y\\)-værdier ligger mellem \\(0\\) og \\(1\\). Derfor giver det mening, at bruge Pythagoras på disse skalerede punkter – og gør vi det, får vi\n\\[\\sqrt{\\left(\\frac{x_2-a}{b-a}-\\frac{x_1-a}{b-a}\\right)^2 +\\left(\\frac{y_2-c}{d-c}-\\frac{y_1-c}{d-c}\\right)^2}=\\sqrt{\\left(\\frac{x_2-x_1}{b-a}\\right)^2+\\left(\\frac{y_2-y_1}{d-c}\\right)^2}\\]\nBemærk, at det præcis er afstandsmålet i (1), som vi startede ud med."
  },
  {
    "objectID": "materialer/afstande/feature_scaling.html#mindre-naivt-mere-bøvlet-feature-skaling",
    "href": "materialer/afstande/feature_scaling.html#mindre-naivt-mere-bøvlet-feature-skaling",
    "title": "Feature-skalering",
    "section": "Mindre naivt, mere bøvlet: Feature-skaling",
    "text": "Mindre naivt, mere bøvlet: Feature-skaling\nDen skalering vi har præsenteret i (2) benytter ikke som sådan information om data, men kun om den mindste og største værdi, som henholdsvis \\(x\\)- og \\(y\\)-værdierne ligger imellem (nemlig \\(a\\) og \\(b\\) for \\(x\\)-værdierne og \\(c\\) og \\(d\\) for \\(y\\)-værdierne).\nEt alternativ til dette er at bruge alle data til at bestemme skaleringen (og ikke kun den største og den mindste værdi). Dette kaldes for feature-skaling, når vi arbejder med perceptroner eller neurale netværk.\nHvis de data, der skal læres fra – det vil sige træningsdata – er \\[(x_1,y_1), (x_2,y_2),\\ldots, (x_n,y_n)\\] så skalerer vi langs førsteaksen ved, at\n\nudregne et estimat for middelværdien af \\(x\\): \\[\\bar{x}=\\frac{x_1 + x_2 + \\cdots + x_n}{n}=\\frac{\\Sigma_{i=1}^nx_i}{n} \\tag{3}\\]\nog et estimat for denne variabels spredning: \\[s_x=\\sqrt{\\frac{\\Sigma_{i=1}^n(x_i-\\bar{x})^2}{n-1}} \\tag{4}\\]\n\nFeature-skaling af \\(x_i\\) er da \\[\\hat{x}_i=\\frac{x_i-\\bar{x}}{s_x} \\tag{5}\\]\nTilsvarende estimeres middelværdi og spredning for \\(y\\) og feature-skaling udregnes: \\[\\hat{y}_i= \\frac{y_i-\\bar{y}}{s_y} \\tag{6}\\]\nResultatet af at lave denne feature skalering af punkterne fra figur 1 ses i figur 3.\n\n\n\n\n\n\nFigur 3: Datapunkterne fra figur 1, men hvor alle punkter er blevet feature skaleret ved at bruge formlerne i (5) og (6).\n\n\n\nBemærk, hvordan de feature skalerede datapunkter har \\(x\\)- og \\(y\\)-værdier, som alle1 ligger mellem \\(-2\\) og \\(2\\).\n1 I virkelighedens verden kan der godt være værdier, som er mindre end \\(-2\\) eller større end \\(2\\), men som oftest vil det være sådan, at omkring \\(95 \\%\\) af værdierne vil ligge mellem \\(-2\\) og \\(2\\) efter feature skalering.Da alle \\(x\\)- og \\(y\\)-værdier nu er på samme skala, giver det igen mening at beregne den euklidiske afstand mellem disse nye punkter. Betragter vi de skalerede punkter \\((\\hat{x}_1,\\hat{y}_1)\\) og \\((\\hat{x}_2,\\hat{y}_2)\\) så bliver den euklidiske afstand mellem dem\n\\[\\begin{align*}\n\\sqrt{(\\hat{x}_2-\\hat{x}_1)^2+(\\hat{y}_2-\\hat{y}_1)^2} &= \\sqrt{\\left(\\frac{x_2-\\bar{x}}{s_x}-\\frac{x_1-\\bar{x}}{s_x}\\right)^2 +\\left(\\frac{y_2-\\bar{y}}{s_y}-\\frac{y_1-\\bar{y}}{s_y}\\right)^2}\\\\\n& =\\sqrt{\\left(\\frac{x_2-x_1}{s_x}\\right)^2+\\left(\\frac{y_2-y_1}{s_y}\\right)^2}\n\\end{align*}\\]\nHvis vi sammenligner med den naive tilgang i (1), er den ikke helt skæv. Der skal bare skaleres med \\(s_x\\) i stedet for \\(b-a\\) og med \\(s_y\\) i stedet for \\(c-d\\).\nBemærk, at den feature skalering, som foretages i (5) og (6), svarer til at standardisere en normalfordelt stokastisk variabel \\(X \\sim N(\\mu, \\sigma)\\):\n\\[ Z = \\frac{X-\\mu}{\\sigma}\\] Derfor vil det også være sådan, at hvis de oprindelige data er normalfordelte, så vil de nye feature skalerede data være standard normalfordelte (dvs. normalfordelte med middelværdi \\(0\\) og spredning \\(1\\)). Heraf følger også, at cirka \\(95 \\%\\) af de feature skalerede data vil ligge mellem \\(-2\\) og \\(2\\), som bemærket ovenfor."
  },
  {
    "objectID": "materialer/afstande/feature_scaling.html#eksempel-min-max-og-feature-skalering",
    "href": "materialer/afstande/feature_scaling.html#eksempel-min-max-og-feature-skalering",
    "title": "Feature-skalering",
    "section": "Eksempel: Min-max og feature skalering",
    "text": "Eksempel: Min-max og feature skalering\nVi vil prøve at se på et udvidet eksempel om udgifter til bolig og mælk. Se nedenstående tabel:\n\n\n\n\n\n\nFamilie\n(bolig, mælk)\n\n\n\n\nA\n\\((7500 \\ kr, 200 \\ kr)\\)\n\n\nB\n\\((7500 \\ kr, 1700 \\ kr)\\)\n\n\nC\n\\((6000 \\ kr, 200 \\ kr)\\)\n\n\nD\n\\((5200 \\ kr, 300 \\ kr)\\)\n\n\nE\n\\((8100 \\ kr, 250 \\ kr)\\)\n\n\nF\n\\((6200 \\ kr, 350  \\ kr)\\)\n\n\nG\n\\((7700 \\ kr, 400 \\ kr)\\)\n\n\nH\n\\((5800 \\ kr, 350 \\ kr)\\)\n\n\nI\n\\((7200 \\ kr, 250 \\ kr)\\)\n\n\nJ\n\\((6800 \\ kr, 400  \\ kr)\\)\n\n\n\n\n\nTabel 1: Udvidet eksempel om udgifter til bolig og mælk.\n\n\n\nDatapunkterne fra tabellen ses indtegnet i figur 4. De tre første familier \\(A\\), \\(B\\) og \\(C\\) fra det tidligere eksempel er markeret. Bemærk, at vi tidligere har beregnet, at afstanden mellem \\(A\\) og \\(B\\) er den samme som afstanden mellem \\(A\\) og \\(C\\), hvilket også fremgår af figur 4.\n\n\n\n\n\n\nFigur 4: Datapunkterne fra eksemplet i tabel 1 omkring udgifter til bolig og mælk.\n\n\n\nVi vil nu lave både min-max skalering samt feature skalering af punkterne i tabel 1. For at lave min-max skalering får vi brug for mindste- og størsteværdi for både \\(x\\)- (bolig) og \\(y\\)-værdierne (mælk). De er: \\[\\begin{align}\na&=5200 \\quad  &\\text{og} \\quad \\quad &b=8100 \\\\\nc&=200 \\quad  &\\text{og} \\quad \\quad &d=1700 \\\\\n\\end{align}\\] Bruges disse værdier samt formlerne i (2) fås punkterne som ses i figur 5.\n\n\n\n\n\n\nFigur 5: Datapunkterne fra eksemplet omkring udgifter til bolig og mælk efter min-max skalering.\n\n\n\nLæg mærke til hvordan afstanden mellem \\(A\\) og \\(C\\) med denne skalering er blevet mindre end afstanden mellem \\(A\\) og \\(B\\), som ønsket.\nVi vil nu prøve at lave en feature skalering af punkterne i tabel 1. Vi får derfor brug for et estimat for middelværdien af henholdvis \\(x\\) og \\(y\\). De kan beregnes ved hjælp af (3) til:\n\\[\\begin{align}\n\\bar{x} &= 6800 \\\\\n\\bar{y} &= 440\n\\end{align}\\]\nBruges (4) fås et estimat for spredningen for henholdsvis \\(x\\) og \\(y\\):\n\\[\\begin{align}\n\\bar{s_x} &= 954.52 \\\\\n\\bar{s_y} &= 448.95\n\\end{align}\\]\nAnvendes formlerne i (5) og (6) til feature skalering af punkterne i tabel 1 fås punkterne, som ses i figur 6.\n\n\n\n\n\n\nFigur 6: Datapunkterne fra eksemplet omkring udgifter til bolig og mælk efter feature skalering.\n\n\n\nLæg her mærke til at afstanden mellem \\(A\\) og \\(B\\) nu er blevet endnu større end afstanden mellem \\(A\\) og \\(C\\). Det ses også, at \\(y\\)-værdien for det skalerede punkt for familie \\(B\\) er cirka \\(2.8\\). Sammenlignes dette med standard normalfordelingen, kan vi se, at der er tale om en forholdsvis ekstrem værdi2. Det vil sige, at vi ud fra de skalerede værdier kan se, at familien \\(B\\)’s mælkeforbrug på \\(1700\\) kroner rent faktisk er usædvanligt sammenlignet med de andre families mælkeforbrug.\n\n\n2 Husk på at for en standard normalfordelt stokastisk variabel vil omkring \\(95 \\%\\) af værdierne ligge mellem \\(-2\\) og \\(2\\)."
  },
  {
    "objectID": "materialer/ROC/ROC.html",
    "href": "materialer/ROC/ROC.html",
    "title": "Sensitivitet, specificitet, ROC-kurver og AUC",
    "section": "",
    "text": "Langt de fleste algoritmer, som vi behandler her på siden, handler om, hvordan AI kan bruges til klassifikation. Det kan være alt fra at prædiktere, om man vil stemme på rød eller blå blok ved næste valg baseret på svarene af en række spørgsmål til at prædiktere, om en patient har kræft baseret på forskellige diagnostiske test.\nNår man skal vælge en god algoritme, som kan anvendes til den form for klassifikation, har man brug for at kunne sammenligne, hvor godt forskellige algoritmer prædikterer. Man er derfor nødt til at have et mål for, hvor god en algoritme er til at forudsige klasser (fx rød eller blå blok). Det mest oplagte er at tælle, hvor mange observationer algoritmen klassificerer forkert. Man kan så beregne, hvor stor en andel af alle observationerne, der klassificeres forkert. Denne andel kaldes fejlklassifikationsraten. Det er dog ikke altid det bedste mål at bruge. Det handler denne note om.\nSom eksempel ser vi på et lille dataeksempel med \\(20\\) datapunkter, der kan have klasserne rød og blå, hvor rød er meget sjældnere end blå. Desuden er der målt en inputvariabel \\(x\\). Vi ønsker at finde en algoritme, der kan prædiktere farven på en observation på baggrund af \\(x\\). Datapunkternes klasser og \\(x\\)-værdier er angivet på figur 1. Ud fra figuren kunne det godt se ud til, at sandsynligheden for den røde klasse stiger, når \\(x\\) stiger. Der er dog også flest blå med meget høje \\(x\\)-værdier.\nFigur 1: Et lille dataeksempel med 20 datapunkter.\nMange prædiktionsalgoritmer benytter en tærskelværdi \\(t\\), således at klassen prædikteres som rød, når \\(x&gt; t\\), og blå når \\(x\\leq t\\). På figur 2 ses et eksempel med \\(t=10\\). De første \\(10\\) observationer klassificeres korrekt til at være blå. De næste \\(10\\) observationer prædikteres røde, selv om kun \\(3\\) af dem faktisk er røde. Vi får altså \\(7\\) fejlklassifikationer i alt. Det giver en fejlklassifikationsrate på \\(7/20=0.35\\).\nFigur 2: Klassifikation med tærskelværdi \\(t=10\\). Observationer i det blå område prædikteres blå, mens observationer i det røde område prædikteres røde. Udfyldte cirkler angiver korrekte klassifikationer. Åbne cirkler angiver fejlklassifikationer.\nVi kan gøre det samme for forskellige værdier af \\(t\\)  og tælle antallet af fejlklassifikationer. Resultatet ses i tabel 1.\nDen laveste fejlklassifikationsrate får vi ved at vælge \\(t=20\\), sådan at alle observationer prædikteres til at være blå. Men hvis vi er ude på at identificere de sjældne røde, så er sådan en test jo ikke meget værd, fordi vi aldrig vil prædiktere nogle observationer som røde. I ovenstående eksempel kunne man i stedet have valgt at sætte \\(t=12\\). Så får man ganske vist \\(5\\) fejlklassifikationer i stedet for \\(3\\). Til gengæld finder man alle de røde. Det virker som et mere fornuftigt valg i vores eksempel.\nHvordan vælger man så den bedste tærskelværdi? Det vil sige, hvordan finder man en god balance mellem ikke at lave for mange fejl og samtidig fange så mange som muligt fra den sjældne klasse? Her får vi brug for et mål for, hvor godt algoritmen prædikterer hver af de to klasser. Sensitivitet og specificitet er sådanne mål."
  },
  {
    "objectID": "materialer/ROC/ROC.html#sensitivitet-og-specificitet",
    "href": "materialer/ROC/ROC.html#sensitivitet-og-specificitet",
    "title": "Sensitivitet, specificitet, ROC-kurver og AUC",
    "section": "Sensitivitet og specificitet",
    "text": "Sensitivitet og specificitet\nLad os igen se på situationen, hvor vi har en prædiktionsalgoritme, der prædikterer klasserne rød og blå. For at få et overblik over, hvor godt algoritmen prædikterer, kan man lave en confusion matrix, som skitseret på figur 3, hvor et positivt resultat svarer til klassen rød1. Diagonalen (de grønne celler) svarer til observationer, der er klassificeret korrekt. En god algoritme skal have så mange observationer som muligt på diagonalen.\n1 Ordene positiv og negativ stammer fra medicin, hvor man bruger en test til at klassificere patienter som syge eller raske. En positiv test indikerer, at patienten er syg. I andre sammenhænge svarer et positivt resultat til, at man har prædikteret den sjældne klasse.\n\n\n\n\n\n\n\nFigur 3: Illustration af confusion matrix.\n\n\n\n\n\nHvis vi udelukkende er interesseret i, hvor god algoritmen er til at prædiktere den røde klasse, kan vi kigge på sensitiviteten. Dette er sandsynligheden for, at en observation, hvis sande farve er rød, faktisk bliver klassificeret som rød, altså\n\\[\n\\textrm{sensitivitet} = P(\\textrm{ en sand rød observation prædikteres som rød })\n\\tag{1}\\]\nTilsvarende kan man måle, hvor god en algoritme er til at prædiktere den blå klasse ved at se på specificiteten. Dette er sandsynligheden for, at en sand blå observation faktisk bliver klassificeret som blå. Det kan udtrykkes som\n\\[\n\\textrm{specificitet} = P(\\textrm{ en sand blå observation prædikteres som blå } ).\n\\]\nLad os se på eksemplet fra figur 1 igen, hvor vi sætter tærskelværdien til \\(t=15\\). Vi udfylder confusion matricen med antallet af observationer i hver celle.\n\n\n\n\n\n\n\n\nFigur 4: Confusion matrix med \\(t=15\\).\n\n\n\n\n\nSensitiviteten beregnes som andelen af det samlede antal sande røde, der bliver prædikteret røde. Ved at se på første søjle i figur 4 finder vi, at der er \\(2+1=3\\) sande røde, hvoraf \\(2\\) bliver prædikteret røde. Det giver sensitiviteten\n\\[\n\\textrm{sensitivitet} = \\frac{\\textrm{antal røde der prædikteres røde}}{\\textrm{antal sande røde}} = \\frac{2}{3} = 0.667.\n\\tag{2}\\]\nTilsvarende kan vi beregne specificiteten ved at se på anden søjle.\n\\[\n\\textrm{specificitet} = \\frac{\\textrm{antal blå der prædikteres blå}}{\\textrm{antal sande blå}} = \\frac{14}{3+14}= 0.824.\n\\]\nAlgoritmen er altså bedst til at finde blå, da specificiteten er højere end sensitiviteten. Lad os prøve, om vi kan få højere sensitivitet med en anden værdi af \\(t\\). Værdien \\(t=12\\) var den største værdi, der kunne finde alle de røde – se igen figur 1. Det giver os confusion matricen i figur 5.\n\n\n\n\n\n\n\n\nFigur 5: Confusion matrix med \\(t=12\\).\n\n\n\n\n\nVi beregner igen sensitiviteten og specificiteten \\[\\textrm{sensitivitet} = \\frac{\\textrm{antal røde der prædikteres røde}}{\\textrm{antal sande røde}} = \\frac{3}{3} = 1\\] og \\[\\textrm{specificitet} = \\frac{\\textrm{antal blå der prædikteres blå}}{\\textrm{antal sande blå}} = \\frac{12}{5+12}= 0.706.\\] Vi ser altså, at prisen for at få en højere sensitivitet er en lavere specificitet.\nEndelig kan vi prøve med værdien \\(t=20\\), som var den, der gav den laveste fejlklassifikationsrate. Denne værdi giver confusion matricen i figur 6.\n\n\n\n\n\n\n\n\nFigur 6: Confusion matrix med \\(t=20\\).\n\n\n\n\n\nVi finder sensitiviteten \\[\n\\textrm{sensitivitet} = \\frac{\\textrm{antal røde der prædikteres røde}}{\\textrm{antal sande røde}} = \\frac{0}{3}= 0\n\\] og specificiteten \\[\n\\textrm{specificitet} = \\frac{\\textrm{antal blå der prædikteres blå}}{\\textrm{antal sande blå}} = \\frac{17}{17}= 1.\n\\] Testen er altså rigtig god til at finde blå klasser, men elendig til at finde røde klasser.\n\n\n\n\n\n\nSensitivitet og specificitet som betingede sandsynligheder\n\n\n\n\n\nSensitivitet og specificitet kan beskrives ved hjælp af betingede sandsynligheder. Lad \\(A\\) og \\(B\\) være to hændelser, således at \\(B\\) har positiv sandsynlighed \\(P(B)&gt;0\\). Den betingede sandsynlighed for \\(A\\) givet \\(B\\) betegnes \\(P(A|B)\\) og er defineret som\n\\[\nP(A|B) = \\frac{P(A\\cap B)}{P(B)}.\n\\tag{3}\\]\nHer er \\(A\\cap B\\) fælleshændelsen, det vil sige hændelsen, at \\(A\\) og \\(B\\) forekommer samtidig. Vi fortolker \\(P(A|B)\\) som sandsynligheden for, at hændelsen \\(A\\) indtræffer, hvis vi ved, at hændelsen \\(B\\) er indtruffet. Dette giver mening i forhold til definitionen (3), idet brøken angiver, hvor stor en andel af sandsynligheden for \\(B\\), der udgøres af sandsynligheden for, at \\(A\\) indtræffer samtidig med \\(B\\).\nLad os se på et eksempel, hvor vi slår to gange med en terning. Lad \\(A\\) være hændelsen, at vi slår to seksere, og lad \\(B\\) hændelsen, at den første terning viser seks. Da er\n\\[\nP(A)=P(\\textrm{to seksere})=1/36\n\\] og \\[\nP(B)=P(\\textrm{første terning viser seks})=1/6.\n\\] Intuitivt vil man forvente, at sandsynligheden for to seksere vokser, hvis den første terning viser en sekser. Det kan vi bekræfte ved hjælp at betingede sandsynligheder. \\[\nP(\\textrm{to seksere} | \\textrm{første terning viser seks}) = P(A|B) =  \\frac{P(A\\cap B)}{P(B)} = \\frac{1/36}{1/6} = \\frac{1}{6}.\n\\] Her har vi udnyttet, at \\(A\\cap B=A\\), da første terning er nødt til at vise seks for, at vi kan få to seksere. Vi ser altså, at \\[\nP(\\textrm{to seksere} | \\textrm{første terning viser seks}) = \\frac{1}{6} \\neq \\frac{1}{36} = P(\\textrm{to seksere}).\n\\]\nTerningeksemplet viser et eksempel, hvor \\(P(A)\\neq P(A|B)\\), altså hvor sandsynligheden for \\(A\\) ændrer sig, hvis vi ved, at \\(B\\) er indtruffet. Dette er ofte tilfældet. Nogle gange kan vi dog have at \\(P(A|B)=P(A)\\), altså at vi ikke får nogen ny viden om sandsynligheden for \\(A\\) ud fra vores viden om \\(B.\\) I dette tilfælde siger vi, at \\(A\\) og \\(B\\) er uafhængige.\nSensitiviteten kan defineres formelt ved hjælp af betingede sandsynligheder som sandsynligheden for at få en rød prædiktion, givet at den sande klasse er rød, altså \\[\n\\begin{aligned}\n\\textrm{sensitivitet} &= P(\\textrm{ prædiktionen er rød }|\\textrm{ den sande klasse er rød }) \\\\ \\\\\n&= \\frac{P(\\textrm{ den sande klasse er rød og prædiktionen er rød })}{P(\\textrm{ den sande klasse er rød })}.\n\\end{aligned}\n\\] I praksis estimerer vi sandsynligheden for en sand rød som antallet af sande røde divideret med det samlede antal observationer. Sandsynligheden for, at en observation både er rød og klassificeres som rød, estimeres som antallet, der både er røde og klassificeres røde, divideret med det samlede antal observationer. Vi kan derfor estimere sensitiviteten ved \\[\n\\begin{aligned}\n\\textrm{sensitivitet} &= \\frac{(\\textrm{antal røde der prædikteres røde})/(\\textrm{samlet antal})}{(\\textrm{antal røde})/(\\textrm{samlet antal})} \\\\ \\\\\n&= \\frac{\\textrm{antal røde der prædikteres røde}}{\\textrm{antal røde}}.\n\\end{aligned}\n\\] Det var netop den formel, vi brugte til at udregne sensitiviteten i (1).\nSpecificiteten kan tilsvarende defineres som \\[\n\\begin{aligned}\n\\textrm{specificitet} &= P(\\textrm{ prædiktionen er blå }|\\textrm{ den sande klasse er blå }) \\\\ \\\\\n&= \\frac{P(\\textrm{ den sande klasse er blå og prædiktionen er blå })}{P(\\textrm{ den sande klasse er blå })}.\n\\end{aligned}\n\\] Man kan som ovenfor regne sig frem til, at specificiteten kan estimeres ved \\[\n\\begin{aligned}\\textrm{specificitet} = \\frac{\\textrm{antal blå der prædikteres blå}}{\\textrm{antal blå}}.\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "materialer/ROC/ROC.html#roc-kurver",
    "href": "materialer/ROC/ROC.html#roc-kurver",
    "title": "Sensitivitet, specificitet, ROC-kurver og AUC",
    "section": "ROC-kurver",
    "text": "ROC-kurver\nI praksis har man brug for at finde en tærskelværdi \\(t\\), som giver en god afvejning mellem sensitivitet og specificitet. Det kan afhænge af anvendelsen, hvor højt man vægter de to. Hvis man er ude på at diagnosticere en sjælden sygdom, er det umiddelbart vigtigst, at sensitiviteten er høj, så man finder alle de syge. Dog er det problematisk, hvis specificiteten bliver for lav, da man så kommer til at diganosticere mange raske som syge, hvilket kan medføre unødvendige undersøgelser og behandlinger for patienten.\nSå hvordan vælger man en tærskelværdi, der giver en god afvejning mellem sensitivitet og specificitet? Som en hjælp kunne man udregne sensitivitet og specificitet for forskellige mulige værdier af \\(t\\). Det er for vores eksempel gjort i tabel 2.\n\n\n\n\n\n\nTærskelværdi \\(t\\)\nSensitivitet\nSpecificitet\n\n\n\n\n1\n1\n0.059\n\n\n2\n1\n0.118\n\n\n3\n1\n0.176\n\n\n4\n1\n0.235\n\n\n5\n1\n0.294\n\n\n6\n1\n0.353\n\n\n7\n1\n0.412\n\n\n8\n1\n0.471\n\n\n9\n1\n0.529\n\n\n10\n1\n0.588\n\n\n11\n1\n0.647\n\n\n12\n1\n0.706\n\n\n13\n0.667\n0.706\n\n\n14\n0.667\n0.765\n\n\n15\n0.667\n0.824\n\n\n16\n0.333\n0.824\n\n\n17\n0.333\n0.882\n\n\n18\n0\n0.882\n\n\n19\n0\n0.941\n\n\n20\n0\n1\n\n\n\n\n\nTabel 2: Sensitivitet og specificitet for forskellige tærskelværdier.\n\n\n\nMan kan så gå ind i tabel 2 og lede efter et godt \\(t\\), hvor både sensitivitet og specificitet er høj. En tabel som ovenfor bliver dog hurtigt uoverskuelig, hvis man har et stort datasæt. For at få overblik kan man i stedet vælge at tegne samhørende værdier af sensitivitet og specificitet ind i et koordinatsystem. Traditionelt vælger man at have \\(1-\\textrm{specificitet}\\) på \\(x\\)-aksen og \\(\\textrm{sensitivitet}\\) på \\(y\\)-aksen. Den kurve, der fremkommer, når punkterne forbindes, kaldes en ROC-kurve2. På figur 7 er ROC-kurven fra dataeksemplet i figur 1 indtegnet.\n2 ROC står for Receiver Operating Characteristic.\n\n\n\n\n\n\n\nFigur 7: ROC-kurve for dataeksemplet i figur 1.\n\n\n\n\nVi vil gerne have både sensitivitet og specificitet til at være så tæt på \\(1\\) som muligt. Det betyder derfor, at vi gerne vil have \\(1-\\textrm{specificitet}\\) så tæt på \\(0\\) som muligt. Vi søger derfor samlet set et punkt på ROC-kurven, der ligger tæt på punktet \\((0,1)\\). Ud fra ROC-kurven kunne punktet \\((0.176,0.667)\\) ligne et godt bud. Ifølge tabel 2 svarer det til en tærskelværdi på \\(t=15\\).\nTil sammenligning kunne vi forestille os en algoritme, der laver en hel tilfældig prædiktion, hvor hver observation bliver klassificeret som rød med sandsynlighed \\(p\\) og blå med sandsynlighed \\(1-p\\) uden at tage højde for værdien af \\(x\\). For sådan en algoritme er sandsynligheden for, at en sand rød prædikteres rød altså også \\(p\\), så\n\\[\\textrm{sensitivitet} = P(\\textrm{ en sand rød prædikteres rød }) = P(\\textrm{ rød prædiktion }) = p.\\] Tilsvarende kan vi beregne specificiteten \\[\n\\textrm{specificitet} = P(\\textrm{ en sand blå prædikteres blå }) = P(\\textrm{ blå prædiktion }) = 1- p\n\\] og derfor\n\\[1-\\textrm{specificitet} = 1-( 1- p) =  p.\\] For sådan en test får vi altså et punkt på den tilhørende ROC-kurve med koordinatsæt\n\\[\n(1-\\textrm{specificitet},\\textrm{sensitivitet}) = (p,p).\n\\] Alle punkter hvor første- og andenkoordinaten er ens ligger på identitetslinjen \\(y=x\\). Alt i alt viser dette, at punkterne på identitetslinjen svarer til helt tilfældig prædiktion. På figur 7 er identitetslinjen \\(y=x\\) også indtegnet. En prædiktionsalgoritme skal derfor helst give et punkt, der ligger over identitetslinjen. Ellers er den ikke bedre end et tilfældigt gæt."
  },
  {
    "objectID": "materialer/ROC/ROC.html#auc",
    "href": "materialer/ROC/ROC.html#auc",
    "title": "Sensitivitet, specificitet, ROC-kurver og AUC",
    "section": "AUC",
    "text": "AUC\nHvis vi har brug for at sammenligne forskellige prædiktionsalgoritmer, kan det godt være svært at sammenligne deres fulde ROC-kurver. Det er nemmere at sammenligne et enkelt tal, der opsummerer, hvor god ROC-kuven er. Her kan AUC bruges.\nHusk på, at ROC-kurven gerne skulle ligge så tæt op mod punktet \\((0,1)\\) og så langt over identitetslinjen som muligt. Vi kan derfor bruge arealet under ROC-kurven, også kaldet AUC3, som mål for hvor meget ROC-kurven er strakt opad mod \\((0,1)\\).\n3 AUC står for Area Under Curve.Optimalt set skulle ROC-kurven stige lodret op til punktet \\((0,1)\\) og derefter fortsætte vandret over mod \\((1,1)\\) (den orange kurve på figur 8), svarende til, at der er en \\(t\\)-værdi, der giver perfekt prædiktion. I denne situation er \\(AUC=1\\). Omvendt så vi, at identitetslinjen (den grønne kurve på figur 8) svarer til fuldstændig tilfældig prædiktion uden brug af \\(x\\). Dette svarer til \\(AUC=1/2\\). En fornuftig algoritme skal således gerne have et \\(AUC\\) mellem \\(1/2\\) og \\(1\\), hvor høje tal er bedst. I vores dataeksempel (den sorte kurve på figur 8) kan man udregne \\(AUC=0.804\\).\n\n\n\n\n\n\n\n\nFigur 8: AUC for perfekt klassifikation (orange), tilfældig klassifikation (grøn) og vores dataeksempel (sort).\n\n\n\n\n\nMan kan vise, at AUC har en konkret fortolkning. Hvis man tager et vilkårligt element fra den blå klasse og et fra den røde klasse, så vil AUC-værdien være sandsynligheden for, at \\(x\\)-værdien for den røde klasse er højere end \\(x\\)-værdien for den blå klasse. Hvis man prøver at gætte, hvilken af de to klasser der er rød ud fra \\(x\\)-værdien, er AUC altså sandsynligheden for, at man gætter rigtigt."
  },
  {
    "objectID": "materialer/ROC/ROC.html#forskellige-overvejelser",
    "href": "materialer/ROC/ROC.html#forskellige-overvejelser",
    "title": "Sensitivitet, specificitet, ROC-kurver og AUC",
    "section": "Forskellige overvejelser",
    "text": "Forskellige overvejelser\n\nHvornår skal man bruge sensitivitet og specificitet?\nVi så i dataeksemplet fra figur 1, at fejlklassifikationsraten ikke egner sig som mål for, hvor godt en algoritme prædikterer, når en af klasserne er meget små. Her er det ofte en fordel at tillade flere fejlklassifikationer for at opnå en højere sensitivitet. Desuden kan det være en fordel at kigge på sensitivitet og specificitet i en situation, hvor man er mere interesseret i den ene klasse end i den anden. Det kunne fx være i forbindelse med test for sygdom under en epidemi, hvor det er vigtigere at finde alle de syge, så de kan komme i karantæne, end at man undgår at sende raske i karantæne.\n\n\nFlere inputvariable\nOfte har man i praksis mere end én inputvariabel \\(x\\) at prædiktere ud fra. Lad os sige, at vi har målt variablene \\(x_1,x_2,\\ldots,x_p\\). Mange algoritmer (blandt andet perceptronen, simple neurale netværk, neurale netværk og logistisk regression) laver på en eller anden måde prædiktionerne ud fra en vægtet sum af variablene: \\[w_0+w_1x_1 + w_2x_2 + \\dotsm +w_p x_p\\] hvor \\(w_0, w_1, w_2,\\ldots,w_p \\in \\mathbb{R}\\) er konstanter. Man prædikterer så den ene klasse når \\[w_0+w_1x_1 + w_2x_2 + \\dotsm +w_p x_p &gt; t\\] og den anden klasse når \\[w_0+w_1x_1 + w_2x_2 + \\dotsm +w_p x_p \\leq t\\] hvor \\(t\\) er en passende tærskelværdi. Ofte bruger algoritmen som udgangspunkt \\(t=0\\). Som i tilfældet med én inputvariabel kan det dog give mening at vælge et andet \\(t\\) for at få bedre sensitivitet og specificitet. Igen kan man beregne confusion matricen, sensitivitet og specificitet for forskellige værdier af \\(t\\) og tegne ROC-kurven for at finde et godt \\(t\\). Vil man sammenligne flere algoritmer, kan man desuden beregne deres AUC ud fra ROC-kurven.\n\n\nOverfitting\nI eksemplet fra figur 1 fandt vi, at \\(t=15\\) virkede som et fornuftigt valg. Det var i hvert fald et \\(t\\), der passede godt på det datasæt, vi havde. Det betyder dog ikke, at det er det \\(t\\), der generaliserer bedst til nye data. Lad os sige, at vi får et nyt datasæt og gerne vil bruge prædiktionsalgoritmen på det. På figur 9 ses et eksempel på, hvordan et nyt datasæt kunne se ud.\n\n\n\n\n\n\n\n\nFigur 9: Det oprindelige data fra figur 1 og et nyt datasæt klassificeret ud fra tærskelværdien \\(t=15\\).\n\n\n\n\n\nMed \\(t=15\\) får vi fejlklassificeret \\(3\\) ud af \\(4\\) røde i det nye datasæt, så sensitiviteten er \\(1/4=0.25\\). Tilsvarende får vi fejlklassificeret \\(4\\) ud af \\(17\\) blå i det nye data, så specificiteten er \\(13/17 = 0.765\\). Da vi brugte det oprindelige data fik vi sensitiviteten \\(0.667\\) og specificiteten \\(0.824\\). Både sensitivitet og specificitet er altså markant lavere for det nye data. Det sker, fordi \\(t\\) er valgt til at give høj sensitivitet og specificitet på lige præcis det oprindelige data. Det garanterer imidlertid ikke, at det passer lige så godt til nye data. Vi siger, at algoritmen er overfittet til det oprindelige data. Sensitivitet og specificitet giver altså ikke et retvisende mål for, hvor godt algoritmen prædikterer på nye data. Du kan læse mere om overfitting her."
  },
  {
    "objectID": "materialer/ROC/ROC.html#ekstra-positiv-og-negativ-prædiktiv-værdi",
    "href": "materialer/ROC/ROC.html#ekstra-positiv-og-negativ-prædiktiv-værdi",
    "title": "Sensitivitet, specificitet, ROC-kurver og AUC",
    "section": "Ekstra: Positiv og negativ prædiktiv værdi",
    "text": "Ekstra: Positiv og negativ prædiktiv værdi\nSensitivitet og specificitet bruges til at afgøre, hvor god en prædiktionsalgoritme er til at ramme rigtigt inden for hver klasse. Hvis vi for eksempel er ude på at prædiktere sygdom, så måler sensitiviteten sandsynligheden for, at en syg erklæres syg, og specificiteten måler sandsynligheden for, at en rask erklæres rask. En patient vil dog ofte være mere interesseret i det omvendte spørgsmål: “Jeg har fået en positiv test. Hvad er sandsynligheden for, at jeg faktisk er syg?” Det kan lyde som næsten det samme, men det er faktisk et helt andet spørgsmål.\nLad os igen kigge på eksemplet med den røde og den blå klasse. Sensitiviteten var sandsynligheden for, at en sand rød observation bliver prædikteret som rød. Her tager vi altså udgangspunkt i, at den sande klasse er rød og kigger på sandsynligheden for, at observationen bliver klassificeret korrekt. I stedet kunne man kigge på sandsynligheden for, at en rød prædiktion faktisk betyder, at den sande klasse er rød. Her tager vi udgangspunkt i, at prædiktionen er rød og beregner sandsynligheden for, at den sande klasse er rød. Dette kaldes den positive prædiktive værdi, som altså er givet ved \\[\n\\textrm{positiv prædiktiv værdi} = P(\\textrm{ en rød prædiktion er faktisk rød } ).\n\\] I praksis beregnes den positive prædiktive værdi ved formlen \\[\n\\textrm{positiv prædiktiv værdi} = \\frac{\\textrm{antal røde prædiktioner som faktisk er røde}}{\\textrm{antal røde prædiktioner}}.\n\\] Bemærk, at tælleren er den samme, som når vi beregner sensitivitet (2), mens nævneren er forskellig. Generelt vil sensitivitet og positiv prædiktiv værdi altså være forskellige tal.\nLad os igen se på vores lille dataeksempel med tærsklen \\(t=15\\), der gav anledning til confusion matricen på figur 4. De røde prædiktioner findes i første række. Der er \\(5\\) røde prædiktioner i alt, hvoraf \\(2\\) faktisk er røde. Den positive prædiktive værdi kan udregnes til \\[\n\\textrm{positiv prædiktiv værdi} = \\frac{\\textrm{ antal røde prædiktioner som faktisk er røde }}{\\textrm{ antal røde prædiktioner }}\\] \\[= \\frac{2}{5} = 0.4.\n\\tag{4}\\] Det betyder altså, at hvis vi har en rød prædiktion, så er sandsynligheden for, at den sande klasse er rød kun \\(0.4\\). Det er tilfældet på trods af, at både sensitivitet og specificitet var høje. Kort fortalt er grunden, at den røde klasse er så sjælden, at det er usandsynligt, at den sande klasse er rød, uanset om prædiktionen er rød eller blå. En mere præcis forklaring kan du finde i boksen nederst på siden.\nMan kan selvfølgelig definere den negative prædiktive værdi tilsvarende. \\[\n\\textrm{negativ prædiktiv værdi} = P(\\textrm{ en blå prædiktion er faktisk blå } ).\n\\] Den negative prædiktive værdi kan beregnes ved \\[\n\\textrm{negativ prædiktiv værdi} = \\frac{\\textrm{antal blå prædiktioner som faktisk er blå}}{\\textrm{antal blå prædiktioner}}.\n\\]\nLad os igen se på vores lille dataeksempel med \\(t=15\\) svarende til confusion matricen på figur 4. For at finde den negative prædiktive værdi, bruger vi formlen \\[\n\\begin{aligned}\n\\textrm{negativ prædiktiv værdi} &= \\frac{\\textrm{ antal blå prædiktioner som faktisk er blå }}{\\textrm{ antal blå prædiktioner}}\\\\\n&= \\frac{14}{15} = 0.933\n\\end{aligned}\n\\] Får man en blå prædiktion, kan man altså være \\(93.3\\%\\) sikker på, at den er korrekt, mens man kun kunne være \\(40\\%\\) sikker på en rød prædiktion.\nBemærk, at når vi beregner sensitivitet og specificitet, er det henholdsvis første og anden søjle i confusion matricen, vi bruger, mens det er henholdsvis første og anden række i confusion matricen, vi bruger til at beregne positiv og negativ prædiktiv værdi.\nEn væsentlig forskel på sensitivitet/specificitet og positiv/negativ prædiktiv værdi er, at sensitivitet og specificitet er faste egenskaber ved prædiktionsalgoritmen. De kan beregnes ved at teste algoritmen på en gruppe blå og en gruppe røde observationer og se, hvor ofte vi rammer plet. Positiv og negativ prædiktiv værdi afhænger derimod af hyppigheden af klasserne4. Det betyder for eksempel, at hvis man forsøger at prædiktere sygdom under en epidemi, så ændrer sandsynligheden for sygdom sig hele tiden, og det gør den positive og negative prædiktive værdi derfor også.\n4 De matematiske detaljer er givet i boksen nedenfor.\n\n\n\n\n\nTeori om sammenhængen mellem sensitivitet og positiv prædiktiv værdi\n\n\n\n\n\nSensitiviteten var sandsynligheden for, at en sand rød blev klassificeret som rød. Udtrykt ved betingede sandsynligheder var det \\[\n\\textrm{sensitivitet} = P(\\textrm{ prædiktionen er rød }|\\textrm{ den sande klasse er rød }).\n\\] Den positive prædiktive værdi kan tilsvarende udtrykkes ved hjælp af betingede sandsynligheder som \\[\n\\textrm{positiv prædiktiv værdi} = P(\\textrm{ den sande klasse er rød }|\\textrm{ prædiktionen er rød }).\n\\] De to formler minder meget om hinanden. Der er bare byttet om på de to hændelser i den betingede sandsynlighed.\nHvis \\(A\\) og \\(B\\) er to hændelser med \\(P(A)&gt;0\\) og \\(P(B)&gt;0\\), så er \\(P(A|B)\\) og \\(P(B|A)\\) relateret via Bayes’ formel \\[P(A|B) = P(B|A)\\cdot\\frac{P(A)}{P(B)}\\] For at se, hvorfor det gælder, bruger vi først definitionen af \\(P(A|B)\\) \\[P(A|B) = \\frac{P(A\\cap B)}{P(B)}\\] Vi forlænger brøken med \\(P(A)\\) og bruger en brøkregneregel \\[P(A|B) = \\frac{P(A\\cap B)\\cdot P(A)}{P(B)\\cdot P(A)} =\\frac{P(A\\cap B)}{P(A)}\\cdot \\frac{P(A)}{P(B)}\\] Endelig bruger vi, at \\(P(B|A)=\\frac{P(A\\cap B)}{P(A)}\\). Det giver \\[P(A|B) = P(B|A)\\cdot\\frac{P(A)}{P(B)}.\\] Vi har hermed bevist Bayes’ formel.\nLader vi \\(A=\\{\\textrm{sand rød}\\}\\) og \\(B=\\{\\textrm{rød prædiktion}\\}\\) i Bayes’ formel, får vi følgende sammenhæng mellem positiv prædiktiv værdi og sensitivitet \\[\n\\textrm{positiv prædiktiv værdi} = P(\\textrm{ sand rød }| \\textrm{ rød prædiktion })\\] \\[= P( \\textrm{ rød prædiktion }| \\textrm{ sand rød })\\cdot \\frac{P(\\textrm{ sand rød })}{P(\\textrm{ rød prædiktion })}\\] \\[= \\textrm{sensitivitet}\\cdot \\frac{P(\\textrm{ sand rød })}{P(\\textrm{ rød prædiktion })}.\n\\tag{5}\\] Formlen (5) viser, at hvis sandsynligheden for at tilhøre den røde klasse er meget lav i forhold til sandsynligheden for at lave en rød prædiktion, vil den positive prædiktive værdi være meget lavere end sensitiviteten.\nLad os se lidt nærmere på nævneren i (5), det vil sige \\(P(B)=P(\\textrm{rød prædiktion})\\). Husk på at \\(A=\\{\\textrm{sand rød}\\}\\). Komplementærhændelsen til \\(A\\) er hændelsen, at \\(A\\) ikke indtræffer, og betegnes \\(A^c\\). I vores tilfælde er \\(A^c=\\{\\textrm{ikke sand rød}\\}=\\{\\textrm{sand blå}\\}\\). Hændelsen \\(B\\), at prædiktionen er rød, kan opnås ved, at prædiktionen er rød, og den underliggende klasse er rød, svarende til \\(B \\cap A\\), eller ved at prædiktionen er rød, og den sande klasse er blå, svarende til \\(B\\cap A^c\\). Vi kan derfor beregne sandsynligheden for \\(B\\) som summen \\[P(B) = P(B\\cap A) + P(B\\cap A^c) \\tag{6}\\] Vi bemærker nu, at definitionen af betinget sandsynlighed \\[P(B|A)=\\frac{P(B\\cap A)}{P(A)}\\] kan omskrives til \\[P(B|A)P(A) = P(B\\cap A)\\] På samme vis fås \\(P(B|A^c)P(A^c) = P(B \\cap A^c)\\). Dette kan vi indsætte i (6) og få \\[P(B) = P(B\\cap A) + P(B\\cap A^c) = P(B | A)P(A) + P(B|A^c)P(A^c).\\] Denne formel kaldes loven om den totale sandsynlighed.\nBruger vi loven om den totale sandsynlighed på formlen for positiv prædiktiv værdi (5), får vi \\[\\textrm{positiv prædiktiv værdi} = \\textrm{sensitivitet}\\cdot \\frac{P(\\textrm{sand rød})}{P(\\textrm{rød prædiktion})}\\] \\[\n\\begin{aligned}\n= &\\textrm{sensitivitet}\\cdot \\\\ &\\frac{P(\\textrm{sand rød})}{P(\\textrm{rød prædiktion} |\\textrm{sand rød})P(\\textrm{sand rød}) + P(\\textrm{rød prædiktion}|\\textrm{sand blå})P(\\textrm{sand blå}) }\n\\end{aligned}\n\\]\n\\[= \\textrm{sensitivitet}\\cdot \\frac{P(\\textrm{sand rød})}{\\textrm{sensitivitet}\\cdot P(\\textrm{sand rød}) + (1-\\textrm{specificitet})\\cdot P(\\textrm{sand blå}) }\n\\tag{7}\\] Vi ser, at hvis specificiteten ikke er meget høj, og sandsynligheden for sand rød er lav (og dermed sandsynligheden for sand blå høj), så er tælleren i (7) lille i forhold til nævneren. Den positive prædiktive værdi vil derfor være væsentligt lavere end sensitiviteten. Det var det, der skete i eksemplet (4).\nFormlen (7) viser desuden, at den positive prædiktive værdi afhænger af ikke bare sensitivitet og specificitet, men også af fordelingen mellem de to klasser (altså sandsynligheden for sand rød og sand blå). Hvis fordelingen ændrer sig, så den røde klasse for eksempel bliver mere sandsynlig, så ændrer den positive prædiktive værdi sig også. Dette er illustreret i figuren herunder. Her er det vist, hvordan den positive prædiktive værdi ændrer sig som en funktion af \\(P(\\textrm{ sand rød })\\) i et eksempel hvor sensitiviteten er \\(0.9\\) og specificiteten er \\(0.6\\). Her ses det tydeligt, at jo større sandsynligheden for sand rød er, desto større bliver også den positive prædiktive værdi."
  },
  {
    "objectID": "materialer/perceptron/perceptron.html",
    "href": "materialer/perceptron/perceptron.html",
    "title": "Perceptroner",
    "section": "",
    "text": "Historisk set er forløberen til kunstige neurale netværk de såkaldte perceptroner. Vi vil her forklare, hvad en perceptron er, og vi vil se på opdateringsalgoritmerne perceptron learning algoritmen og ADALINE (adaptive linear neuron). For at gøre det tager vi udgangspunkt i et eksempel om kandidattests."
  },
  {
    "objectID": "materialer/perceptron/perceptron.html#sec-kandidattest",
    "href": "materialer/perceptron/perceptron.html#sec-kandidattest",
    "title": "Perceptroner",
    "section": "Eksempel: Hvem skal jeg stemme på ved næste valg?",
    "text": "Eksempel: Hvem skal jeg stemme på ved næste valg?\nDe senere år er det blevet populært, at diverse medier laver forskellige kandidattests. Sådan nogle tests kan laves på mange forskellige måder - man kunne blandt andet bruge perceptroner! Testene fungerer som regel på den måde, at man bliver stillet en række forskellige spørgsmål og så skal man svare på en skala fra meget uenig til meget enig. Disse kategorier af svar kunne f.eks. oversættes til matematik på denne måde:\n\n\n\n\n\n\n\n\n\n\n\n\nHelt enig\nOvervejende enig\nHverken/eller\nOvervejende uenig\nHelt uenig\n\n\n\n\n2\n1\n0\n-1\n-2\n\n\n\n\n\nLad os prøve at gøre det helt simpelt. I stedet for at komme med et bud på hvem man skal stemme på, så vil vi blot forsøge at komme med et bud på, om man skal stemme på rød eller blå blok (det er sikkert en håbløs simplificering, men det må du tale med din samfundsfagslærer om ).\nLad os sige at vi vil basere vores bud på to spørgsmål:\n\nJeg synes, at indkomstskatten skal sættes ned.\nJeg synes ikke, at danske virksomheder skal pålægges en CO2-afgift.\n\nVi kan sikkert hurtigt blive enige om, at hvis man er meget enig i begge spørgsmål, så hører man formentlig til i blå blok og modsat, hvis man er meget uenig i begge spørgsmål, så hører man nok mere hjemme i rød blok. Så at lave en perceptron, som kan hjælpe os med at forudsige det, er nok ikke raketvidenskab, men det kan ikke desto mindre hjælpe os med at forstå de bagvedliggende principper og hvordan disse sidenhen kan generaliseres.\nLad os prøve at blive lidt mere specifikke og indføre to variable \\(x_1\\) og \\(x_2\\), hvor\n\n\\(x_1\\): svaret på Jeg synes, at indkomstskatten skal sættes ned angivet på en skala fra -2 til 2\n\n\\(x_2\\): svaret på Jeg synes ikke, at danske virksomheder skal pålægges en CO2-afgift angivet på en skala fra -2 til 2.\n\nVores beslutning vil vi nu også kvantificere vha. en variabel \\(t\\), som kan antage to værdier, nemlig \\(-1\\) og \\(1\\). Hvis vi hører hjemme i blå blok, vil vi sætte \\(t=1\\), mens vi vil sætte \\(t=-1\\), hvis vi vil sætte vores krydset ved et rødt parti. Altså:\n\\[\n\\begin{aligned}\nt&=-1: &\\text{Rød blok} \\\\\nt&=1: &\\text{Blå blok} \\\\\n\\end{aligned}\n\\]\nNu forestiller vi os, at vi har bedt seks personer (som godt ved, hvem de vil stemme på - måske er det ligefrem politikere vi har spurgt) om at svare på de to spørgsmål og samtidig tilkendegive, om de vil stemme på blå eller rød blok. Lad os f.eks. sige, at den første person er meget enig i at indkomstskatten skal sættes ned (dvs. \\(x_1=2\\)), og at denne person er overvejende enig i at danske virksomheder ikke skal pålægges en CO2-afgift (dvs. \\(x_2=1\\)). Desuden oplyser denne person, at han/hun vil stemme på blå blok (dvs. \\(t=1\\)). Det kan udtrykkes sådan her: \\[\n(x_1,x_2)=(2,1) \\quad \\Rightarrow \\quad  t=1\n\\tag{1}\\]\nOg sådan kunne man opstille andre eksempler: \\[\n\\begin{aligned}\n&(x_1,x_2)=(-1,1) \\quad \\Rightarrow \\quad  t=-1 \\\\\n&(x_1,x_2)=(-1,-1) \\quad \\Rightarrow \\quad  t=-1 \\\\\n&(x_1,x_2)=(1,1) \\quad \\Rightarrow \\quad  t=1 \\\\\n&(x_1,x_2)=(2,2) \\quad \\Rightarrow \\quad  t=1 \\\\\n&(x_1,x_2)=(-2,-1) \\quad \\Rightarrow \\quad t=-1 \\\\\n\\end{aligned}\n\\] Det første eksempel siger for eksempel, at en person har været overvejende uenig i at sætte indkomstskatten ned (\\(x_1=-1\\)), overvejende enig i at danske virksomheder ikke skal pålægges en CO2-afgift (\\(x_2=1\\)) og samtidig vil denne person stemme på rød blok (\\(t=-1\\)).\nVi kan prøve at indtegne \\((x_1,x_2)\\)-punkterne i et koordinatsystem og samtidig angive den tilhørende værdi af \\(t\\) med en farve. Det vil se sådan her ud:\n\n\n\n\n\n\n\n\nFigur 1: Illustration af svaret på spørgsmål 1 (\\(1.\\) aksen) og spørgsmål 2 (\\(2.\\) aksen) med en markering af om man vil stemme på rød eller blå blok.\n\n\n\n\n\nDet kunne godt se ud som om, at det vil være muligt at indtegne en ret linje på en sådan måde, at alle punkter som ligger over linjen skulle farves blå (svarende til \"her stemmer vi på blå blok\"), mens alle punkter under linjen skulle farves røde (svarende til \"her stemmer vi på rød blok\"). En tilfældig indtegnet linje ses på figur 2.\n\n\n\n\n\n\n\n\nFigur 2: Illustration af svaret på spørgsmål 1 (\\(1.\\) aksen) og spørgsmål 2 (\\(2.\\) aksen) med en markering af om man vil stemme på rød eller blå blok. En tilfældig linje er indtegnet.\n\n\n\n\n\nHerunder ser du et bud på en linje, som ser ud til at være god til at adskille de blå punkter fra de røde – faktisk er der jo uendeligt mange linjer, som vil kunne adskille de blå punkter fra de røde:\n\n\n\n\n\n\n\n\nFigur 3: Illustration af svaret på spørgsmål 1 (\\(1.\\) aksen) og spørgsmål 2 (\\(2.\\) aksen) med en markering af om man vil stemme på rød eller blå blok. Her er indtegnet en linje, som kan separere de blå punkter fra de røde.\n\n\n\n\n\nLinjen på figur 3 har ligning \\[\\begin{aligned}\ny=-1.2 \\cdot x+1.5.\\end{aligned}\\] Men nu kaldte vi jo faktisk ikke de to variable for \\(x\\) og \\(y\\), men derimod for \\(x_1\\) og \\(x_2\\). Med denne notation får vi altså, at \\[\n\\begin{aligned}\nx_2=-1.2 \\cdot x_1+1.5\n\\end{aligned}\n\\] Hvis vi bruger denne ligning til at skelne imellem blå og røde punkter, så vil vi sige, at alle punkter, som ligger over linjen skal være blå. Det vil være det samme som at sige, at alle de blå punkter opfylder uligheden \\[\n\\begin{aligned}\nx_2&gt;-1.2 \\cdot x_1+1.5.\n\\end{aligned}\n\\] Eller skrevet på en anden måde: \\[\n\\begin{aligned}\n1.2 \\cdot x_1+ 1 \\cdot x_2&gt;1.5.\n\\end{aligned}\n\\] Her kalder man værdi \\(1.5\\) på højreside for threshold værdien (på dansk: tærskelværdi), fordi det er denne værdi, som afgør, om vi skal farve et punkt rødt eller blåt. Værdierne \\(1.2\\) og \\(1\\) kaldes for vægte, fordi de bestemmer, hvor meget inputværdierne \\(x_1\\) og \\(x_2\\) skal vægtes i forhold til hinanden.\nEn helt tredje måde at skrive det samme på vil være \\[\n\\begin{aligned}\n-1.5+1.2 \\cdot x_1+ 1 \\cdot x_2&gt;0.\n\\end{aligned}\n\\] Nu kalder man så bare værdien \\(-1.5\\) for en bias, men i virkeligheden er det jo bare threshold værdien med modsat fortegn1.\n1 Der er forskellige overvejelser i forhold til valget af denne skrivemåde. For det første er vi gået væk fra \\(x\\) og \\(y\\) og over til \\(x_1\\) og \\(x_2\\). Det giver mening, fordi vi ofte tænker på \\(y\\) som den afhængige variabel og \\(x\\) som den uafhængige variabel. Denne fortolkning af de to variable giver ikke mening i denne sammenhæng. Derudover kan vi beskrive en vilkårlig linje i planen ved hjælp af ligningen \\(ax_1+bx_2+c=0\\) – også de lodrette linjer. Holder vi derimod fast i \\(y=ax+b\\), så kan vi ikke “fange” de lodrette linjer.Vi har nu faktisk udledt en regel, som for tid og evighed kan hjælpe os med at afgøre, om vi skal stemme på rød eller blå blok. Den kan opsummeres sådan her:\n\n\n\n\n\n\nHvem skal jeg stemme på?\n\n\n\n\n\nSvar på en skala fra -2 til 2 på følgende spørgsmål:\n\\(x_1\\): \"Jeg synes, at indkomstskatten skal sættes ned\"\n\\(x_2\\): \"Jeg synes ikke, at danske virksomheder skal pålægges en CO2-afgift\"\nhvor 2 svarer til \"Meget enig\" og -2 svarer til \"Meget uenig\".\nBeregn nu \\(o\\) (for outputværdi) på denne måde \\[\\begin{aligned}\no = \\begin{cases}\n1 & \\text{hvis } -1.5+1.2 \\cdot x_1+ 1 \\cdot x_2 \\geq 0 \\\\\n-1 & \\text{hvis } -1.5+1.2 \\cdot x_1+ 1 \\cdot x_2 &lt; 0. \\\\\n\\end{cases}\\end{aligned}\\] Reglen er nu: \\[\\begin{aligned}\n&\\text{Hvis } o=1: \\quad &\\text{Stem blå blok.}\\\\\n&\\text{Hvis } o=-1: \\quad &\\text{Stem rød blok.}\\\\\\end{aligned}\\]\n\n\n\nMan siger også, at man på baggrund af inputværdierne kan lave en klassificering (eller kategorisering). Det betyder, at vi på baggrund af inputværdierne kan beregne, om vi er i kategorien \"Blå blok\" (\\(o=1\\)) eller i kategorien \"Rød blok\" (\\(o=-1\\)). Grafisk svarer det til, at man indtegner sit \\((x_1, x_2)\\)-punkt i koordinatsystemet i figur 3 og ser så på om punkt ligger over eller under linjen (ligger det over skal vi stemme blå blok).\n\nEksempel 1 Lad os sige at en vælger hverken er enig eller uenig i, at indkomstskatten skal sættes ned. Det vil sige, at \\(x_1=0\\). Samtidig er denne vælger meget enig i, at danske virksomheder ikke skal pålægges en CO2-afgift. Altså er \\(x_2=2\\). Vi udregner nu: \\[\n-1.5+1.2 \\cdot x_1+x_2=-1.5+1.2 \\cdot 0+2=0.5\n\\] Og da denne værdi er større end \\(0\\), sætter vi \\(o=1\\). Det vil sige, at vi vil anbefale denne vælger at stemme blå blok.\n\nDet er da smart! Og det her er faktisk lige præcis idéen bag perceptroner. Vi vil her definere perceptronen ved, at den kan modtage input\n\\[\n\\begin{aligned}\nx_1, x_2, \\dots, x_n,\n\\end{aligned}\n\\] hvor hver enkel inputværdi i princippet kan være et vilkårligt reelt tal. I vores eksempel har vi dog begrænset inputværdierne til \\(x_1, x_2 \\in \\{-2,-1,0,1,2 \\}\\). Vi beregner så en outputværdi \\(o\\) vha. vægtene \\(w_1, w_2, \\dots, w_n\\) og en biasværdi, som vi her vil kalde for \\(w_0\\) på denne måde: \\[\n\\begin{aligned}\no = \\begin{cases}\n1 & \\text{hvis } w_0 + w_1 \\cdot x_1 + \\cdots + w_n \\cdot x_n \\geq 0 \\\\\n-1 & \\text{hvis } w_0 + w_1 \\cdot x_1 + \\cdots + w_n \\cdot x_n &lt; 0. \\\\\n\\end{cases}\n\\end{aligned}\n\\] Grafisk kan det illustreres sådan her:\n\n\n\n\n\n\nFigur 4: Grafisk illustration af en perceptron.\n\n\n\nHer illustrerer sumtegnet i cirklen, at vi tager en vægtet sum af alle inputværdierne (inklusiv et input (\\(x_0\\)), som altid er \\(1\\), og som vægtes med \\(w_0\\) svarende til, at vi får vores bias med), mens grafen af trappefunktionen i firkanten viser, at vi diskretiserer denne vægtede sum, sådan at outputværdien enten er \\(-1\\) eller \\(1\\)."
  },
  {
    "objectID": "materialer/perceptron/perceptron.html#video-hvad-er-en-perceptron",
    "href": "materialer/perceptron/perceptron.html#video-hvad-er-en-perceptron",
    "title": "Perceptroner",
    "section": "VIDEO: Hvad er en perceptron?",
    "text": "VIDEO: Hvad er en perceptron?\nI denne video forklarer vi ovenstående, men med udgangspunkt i et andet eksempel."
  },
  {
    "objectID": "materialer/perceptron/perceptron.html#video-perceptron-learning-algoritmen",
    "href": "materialer/perceptron/perceptron.html#video-perceptron-learning-algoritmen",
    "title": "Perceptroner",
    "section": "VIDEO: Perceptron Learning Algoritmen",
    "text": "VIDEO: Perceptron Learning Algoritmen\nI denne video forklarer vi perceptron learning algoritmen."
  },
  {
    "objectID": "materialer/perceptron/perceptron.html#video-perceptron-learning-versus-adaline",
    "href": "materialer/perceptron/perceptron.html#video-perceptron-learning-versus-adaline",
    "title": "Perceptroner",
    "section": "VIDEO: Perceptron Learning versus ADALINE",
    "text": "VIDEO: Perceptron Learning versus ADALINE\nI denne video forklarer vi idéen bag ADALINE og indfører tabsfunktionen (vær opmærksom på, at notationen i forbindelse med træningsdata er en lille smule anderledes i videoen)."
  },
  {
    "objectID": "materialer/perceptron/perceptron.html#sec-ADALINE_gradientnedstigning",
    "href": "materialer/perceptron/perceptron.html#sec-ADALINE_gradientnedstigning",
    "title": "Perceptroner",
    "section": "Gradientnedstigning",
    "text": "Gradientnedstigning\nFor at gøre det bruges en metode, som kaldes for gradientnedstigning. For at forklare hvad det går ud på, er det nemmest at se på en tabsfunktion, som kun afhænger af to vægte \\(w_0\\) og \\(w_1\\). I det tilfælde får vi \\[\n\\begin{aligned}\nE(w_0, w_1) = \\frac{1}{2} \\sum_{m=1}^{M} \\left (t^{(m)}-\n(w_0 + w_1 \\cdot x_1^{(m)}) \\right)^2.\n\\end{aligned}\n\\] Da tabsfunktionenkun afhænger af to variable, kan vi tegne grafen for den. Et eksempel herpå ses i figur 9.\n\n\n\n\n\n\nFigur 9: Grafen for en tabsfunktion som afhænger af vægtene \\(w_0\\) og \\(w_1\\).\n\n\n\nIdéen er nu, at vi gerne vil bestemme vægtene \\(w_0\\) og \\(w_1\\), sådan at tabsfunktionen minimeres. Tænk lidt over det. Det giver god mening, at bestemme vægtene sådan at den samlede fejl, perceptronen begår på træningsdata, bliver så lille som mulig. Vi ved faktisk godt, hvordan man bestemmer minimum for en funktion af to variable. Løs ligningerne \\[\n\\begin{aligned}\n\\frac{\\partial E}{\\partial w_0} = 0 \\quad \\text{og} \\quad \\frac{\\partial E}{\\partial w_1} = 0.\\end{aligned}\n\\] Det er en overkommelig opgave at finde de partielle afledede og sætte dem lig med \\(0\\) i det tilfælde, hvor tabsfunktionen kun afhænger af to vægte. Men vi skal senere se, at perceptroner bliver fundamentale byggesten i kunstige neurale netværk, og her viser det sig, at denne fremgangsmåde med at sætte de partielle afledede lig \\(0\\), er helt håbløs! Derfor bruger man gradientnedstigning.\nForestil dig at grafen for tabsfunktionen i figur 9 er et landskab med en dal. Dit mål er at finde ned i dalen. Du er blevet placeret et tilfældigt sted i landskabet svarende til tilfældige værdier af \\(w_0\\) og \\(w_1\\). Hvad gør du? Jo, du kommer i tanke om, at du har lært, at hvis du går i gradientens \\[\n\\begin{aligned}\n\\nabla E(w_0,w_1) = \\begin{pmatrix} \\frac{\\partial E }{\\partial w_0}(w_0,w_1) \\\\ \\\\ \\frac{\\partial E }{\\partial w_1}(w_0,w_1) \\end{pmatrix}\n\\end{aligned}\n\\] retning, så kommer du til at gå i den retning, hvor det går allermest opad bakke! Men hov det er jo ikke det, vi vil! Vi vil gå allermest nedad bakke, så vi ender i dalen. Hvad gør vi så? Vi vender os da bare \\(180^{\\circ}\\) og går i den modsatte retning - så ender vi nede i dalen! Det vil sige, at vi går i retning af minus gradienten: \\[\n\\begin{aligned}\n- \\nabla E(w_0,w_1) = \\begin{pmatrix} - \\frac{\\partial E }{\\partial w_0}(w_0,w_1) \\\\ \\\\ - \\frac{\\partial E }{\\partial w_1}(w_0,w_1) \\end{pmatrix}\n\\end{aligned}\n\\] Fremgangsmåden bliver derfor den, at vi starter i nogle tilfældige \\((w_0, w_1)\\)-værdier og så bevæger vi os et lille skridt i den negative gradients retning. Så ender vi i et nyt punkt, hvor vi igen beregner gradienten og går igen et lille skridt i den negative gradients retning. Sådan fortsætter vi indtil værdien af tabsfunktionen ikke rigtig ændrer sig mere – det svarer til, at vi har ramt dalen. Derfor bliver vores opdateringsregler med denne metode \\[\n\\begin{aligned}\nw_0^{(\\textrm{ny})} \\leftarrow & w_0 - \\eta \\cdot \\frac{\\partial E }{\\partial w_0} \\\\\nw_1^{(\\textrm{ny})} \\leftarrow & w_1 - \\eta \\cdot \\frac{\\partial E }{\\partial w_1} \\\\\n&\\vdots  \\\\\nw_n^{(\\textrm{ny})} \\leftarrow & w_n - \\eta \\cdot \\frac{\\partial E }{\\partial w_n} \\\\\n\\end{aligned}\n\\] Her er \\(\\eta\\) igen en learning rate f.eks. \\(0.05\\), som sørger for, at vi hele tiden bare tager et lille skridt i den negative gradients retning. Man vælger værdien af \\(\\eta\\) lille for ikke at lave alt for store justeringer af vægtene ad gangen. Det svarer grafisk til, at vi lige så stille går ned af den bakke, som tabsfunktionen giver (se figur 9). Hvis vi tager for store skridt, risikerer vi helt, at komme til at “træde forbi” det minimum, som vi gerne vil lande i. Omvendt vil alt for små skridt føre til, at vi alt for langsomt nærmer os minimum. Så værdien af \\(\\eta\\) angiver altså, hvor meget vi er villige til at justere vægtene og dermed hvor hurtige eller hvor langsomme, vi bevæger os ned mod minimum. Af den grund giver det god mening, at \\(\\eta\\) kaldes for en learning rate - fordi den afgører, hvor hurtigt vi lærer af vores træningsdata.\nNu mangler vi bare at få bestemt de partielle afledede. Ved at bruge sumreglen og kædereglen for differentiation får vi fra (3), at \\[\n\\begin{aligned}\n\\frac{\\partial E}{\\partial w_i} &= \\frac{1}{2} \\sum_{m=1}^{M} \\frac{\\partial}{\\partial w_i}\\left (t^{(m)}-\n(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)}) \\right)^2 \\\\\n&= \\frac{1}{2} \\sum_{m=1}^{M} 2 \\cdot \\left (t^{(m)}-\n(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)}) \\right) \\\\ & \\quad  \\quad \\quad  \\quad \\quad  \\quad \\cdot \\frac{\\partial}{\\partial w_i} \\left (t^{(m)}-\n(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)} ) \\right) \\\\\n&= \\sum_{m=1}^{M} \\left (t^{(m)}-\n(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)}) \\right) \\cdot \\left (-x_i^{(m)} \\right)\n\\end{aligned}\n\\] for \\(i \\in \\{1, 2, \\dots, n\\}\\).\nLæg mærke til at når vi differentierer den indre funktion \\[\n\\begin{aligned}\nt^{(m)}-(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)})\n\\end{aligned}\n\\] med hensyn til \\(w_i\\), så vil alle led være at betragte som konstanter bortset fra leddet \\[\n\\begin{aligned}\n-w_i \\cdot x_i^{(m)}\n\\end{aligned}\n\\] og når vi differentierer dette led med hensyn til \\(w_i\\) får vi netop \\(- x_i^{(m)}\\). Læg også mærke til at hvis vi differentierer med hensyn til \\(w_0\\), så får vi, \\[\n\\begin{aligned}\n\\frac{\\partial E}{\\partial w_0} = \\sum_{m=1}^{M} \\left (t^{(m)}-\n(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)}) \\right) \\cdot \\left (-1 \\right).\n\\end{aligned}\n\\] Altså bliver vores opdateringsregler \\[\n\\begin{aligned}\nw_0^{(\\textrm{ny})} \\leftarrow & w_0 + \\eta \\cdot \\sum_{m=1}^{M} \\left (t^{(m)}-\n(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)}) \\right)  \\\\\nw_1^{(\\textrm{ny})} \\leftarrow & w_1 + \\eta \\cdot  \\sum_{m=1}^{M} \\left (t^{(m)}-\n(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)}) \\right) \\cdot \\left (x_1^{(m)} \\right)\\\\\n&\\vdots  \\\\\nw_n^{(\\textrm{ny})} \\leftarrow & w_n + \\eta \\cdot  \\sum_{m=1}^{M} \\left (t^{(m)}-\n(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)}) \\right) \\cdot \\left (x_n^{(m)} \\right)\\\\\n\\end{aligned}\n\\] Vi kan altså sammenfatte gradientnedstigningsalgoritmen (ADALINE) på denne måde:\n\n\n\n\n\n\nADALINE\n\n\n\n\n\n\nSæt alle vægte \\(w_0, w_1, \\dots, w_n\\) til et tilfældigt tal (f.eks. \\(0.5\\)).\nVælg en værdi af \\(\\eta\\) (f.eks. \\(0.05\\)).\nUdregn på baggrund af alle træningsdata fejlene: \\[\n\\begin{aligned}\nerror_0 &= \\sum_{m=1}^{M} \\left (t^{(m)}-(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)}) \\right) \\\\\nerror_1 &= \\sum_{m=1}^{M} \\left (t^{(m)}-(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)}) \\cdot x_1^{(m)} \\right) \\\\\n&\\vdots \\\\\nerror_n &= \\sum_{m=1}^{M} \\left (t^{(m)}-(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)}) \\cdot x_n^{(m)} \\right)\n\\end{aligned}\n\\]\nOpdatér alle vægtene: \\[\n\\begin{aligned}\nw_0^{(\\textrm{ny})}  \\leftarrow & w_0 + \\eta \\cdot error_0 \\\\\nw_1^{(\\textrm{ny})}  \\leftarrow & w_1 + \\eta \\cdot error_1 \\\\\n& \\vdots \\\\\nw_n^{(\\textrm{ny})}  \\leftarrow & w_n + \\eta \\cdot error_n\n\\end{aligned}\n\\]\nStart forfra indtil værdien af tabsfunktionen ikke ændrer sig (særlig meget)."
  },
  {
    "objectID": "materialer/perceptron/perceptron.html#eksempel-på-gradientnedstigning",
    "href": "materialer/perceptron/perceptron.html#eksempel-på-gradientnedstigning",
    "title": "Perceptroner",
    "section": "Eksempel på gradientnedstigning",
    "text": "Eksempel på gradientnedstigning\nLad os prøve at bruge gradientnedstigning på vores eksempel omkring kandidattest. I dette simple eksempel bliver vores opdateringsregler nu \\[\n\\begin{aligned}\nw_0^{(\\textrm{ny})} \\leftarrow & w_0 + \\eta \\cdot \\sum_{m=1}^{6} \\left (t^{(m)}-\n(w_0 + w_1 \\cdot x_1^{(m)} + w_2 \\cdot x_2^{(m)}) \\right)  \\\\\nw_1^{(\\textrm{ny})} \\leftarrow & w_1 + \\eta \\cdot  \\sum_{m=1}^{6} \\left (t^{(m)}-\n(w_0 + w_1 \\cdot x_1^{(m)} + w_2 \\cdot x_2^{(m)}) \\right) \\cdot \\left (x_1^{(m)} \\right)\\\\\nw_2^{(\\textrm{ny})} \\leftarrow & w_2 + \\eta \\cdot  \\sum_{m=1}^{6} \\left (t^{(m)}-\n(w_0 + w_1 \\cdot x_1^{(m)}  + w_2 \\cdot x_2^{(m)}) \\right) \\cdot \\left (x_2^{(m)} \\right)\n\\end{aligned}\n\\] Hvis man bruger disse opdateringsregler på dataene fra tabel 1, så ender man med følgende værdier af vægtene \\[\n\\begin{aligned}\nw_0 =-0.0769 , w_1=0.6410, w_2=-0.0598\n\\end{aligned}\n\\] hvor vi startede med værdierne \\(w_0=0.5, w_1=0.5\\), \\(w_2=0.5\\) og \\(\\eta=0.05\\). Perceptronen kan trænes ved hjælp af denne app (sæt stop-kriteriet til \\(0\\), maksimalt antal iterationer til \\(200\\) og vælg identitet som aktiveringsfunktion).\nDette svarer til linjen med ligning \\[\n\\begin{aligned}\n-0.0769 + 0.6410 \\cdot x_1 - 0.0598 \\cdot x_2 = 0.\n\\end{aligned}\n\\] Linjen er indtegnet sammen med træningsdata i figur 10.\n\n\n\n\n\n\n\n\nFigur 10: Ilustration af svaret på spørgsmål 1 (\\(1.\\) aksen) og spørgsmål 2 (\\(2.\\) aksen) med en markering af om man vil stemme på rød eller blok blå. Her er den linje indtegnet, som stammer fra gradientnedstigningsalgoritmen (med startværdier \\(w_0=0.5, w_1=0.5, w_2=0.5\\) og \\(\\eta=0.05\\)).\n\n\n\n\n\nBemærk, at til forskel fra perceptron learning algoritmen så ender man med de samme værdier af vægtene, selvom man vælger andre startværdier. Det er fordi, vi finder et globalt minimum for tabsfunktionen, som er uafhængig af det punkt, hvor vi starter med at lede. Det svarer til, at ligegyldigt hvor du bliver placeret i landskabet i figur 9, så vil du til sidst ende i dalen, hvis du hele tiden går små skridt i den negative gradients retning.\n\nEksempel 3 Vi ser igen på eksempel 1 og eksempel 2, hvor \\(x_1=0\\) og \\(x_2=1\\). Baseret på vægtene fra gradientnedstigning, får vi: \\[\n\\begin{aligned}\n-0.0769+0.6410 \\cdot x_1 &-0.0598 \\cdot x_2= \\\\&-0.0769+0.6410 \\cdot 0 -0.0598 \\cdot 1=-0.1367\n\\end{aligned}\n\\] Da denne værdi er mindre end \\(0\\), sætter vi \\(o=-1\\). Altså er vi tilbage til at anbefale vælgeren at stemme på rød blok."
  },
  {
    "objectID": "materialer/perceptron/perceptron.html#forskel-på-perceptron-learning-og-gradientnedstigning",
    "href": "materialer/perceptron/perceptron.html#forskel-på-perceptron-learning-og-gradientnedstigning",
    "title": "Perceptroner",
    "section": "Forskel på perceptron learning og gradientnedstigning",
    "text": "Forskel på perceptron learning og gradientnedstigning\nDer er flere forskelle på perceptron learning algoritmen og gradientnedstigning. Vi har allerede været inde på, at perceptron learning algoritmen går i kuk, hvis data ikke er lineært separable, som i figur 8. Mere formelt vil perceptron learning algoritmen ikke konvergere. I det tilfælde vil gradientnedstigning alligevel komme med et bud på værdier af vægtene, som kan bruges til at kategorisere træningsdata, selvom alle træningsdata ikke vil blive klassificeret korrekt (fordi de netop ikke er lineært separable). En anden forskel ligger i hvornår vægtene opdateres. I perceptron learning algoritmen opdateres vægtene efter hvert træningseksempel. I gradientnedstigning bruger man alle træningsdata for at lave en enkelt opdatering af vægtene. Hvis man har mange træningsdata, kan det godt blive lidt tungt. Så kan man i stedet for vælge at bruge et mindre, tilfældigt udvalg af data (for eksempel \\(10\\%\\)) til hver opdatering og så til næste opdatering bruge et nyt tilfældigt udvalg af data. Denne fremgangsmåde kaldes for stokastisk gradientnedstigning. En anden mulighed er at lave online gradientnedstigning, hvor man opdaterer vægtene for hvert træningseksempel, som i perceptron learning algoritmen. Selvom det kun er en tilnærmelse til rigtig gradientnedstigning, så har det alligevel en række fordele: 1) Det er meget hurtigere at opdatere vægtene. 2) I nogle anvendelser vil man have brug for løbende at opdatere vægtene på baggrund af nye træningsdata. I stedet for at gemme alle de mange træningsdata kan man bare opdatere vægtene, hver gang man får et nyt træningseksempel til rådighed og så eventuelt slette træningseksemplet igen, når vægtene er blevet opdateret. Det er både hurtigere og mere pladsbesparende."
  },
  {
    "objectID": "materialer/perceptron/perceptron.html#video-adaline",
    "href": "materialer/perceptron/perceptron.html#video-adaline",
    "title": "Perceptroner",
    "section": "VIDEO: ADALINE",
    "text": "VIDEO: ADALINE\nI denne video forklarer vi, hvad gradientnedstigning går ud på, og hvordan gradientnedstigning bruges til at opdatere vægtene i ADALINE (vær opmærksom på, at notationen i forbindelse med træningsdata er en lille smule anderledes i videoen)."
  },
  {
    "objectID": "materialer/baggrund.html",
    "href": "materialer/baggrund.html",
    "title": "Baggrundsmateriale",
    "section": "",
    "text": "Baggrundsmateriale\nPå denne side finder du baggrundsmateriale, som bruges i de forskellige noter om AI. Noterne varierer i sværhedsgrad og i matematisk fokus.\nNoterne er skrevet til elever i gymnasiet. Det er en fordel af læse noten om funktioner af flere variable, inden noten om graditentnedstigning læses. Noten om afstande kan læses uafhængigt af de to andre noter.\nSværhedsgraden af noterne er klassificeret fra \"forholdvis nem\" (*) til \"svær\" (****).\n\n\n\nFunktioner af flere variable\n\n\n\nI noten om funktioner af flere variable behandles først funktioner af to variable – herunder snitfunktioner og snitkurver, partielle afledede, gradienten samt betydningen af denne. Herefter gives en kort introduktion til, hvordan dette kan udvides til funktioner af mere end to variable.\nSværhedsgrad: **\n\n\n\n\n\n\nGradientnedstigning\n\nI noten om gradientnedstigning indføres de retningsafledede og det forklares, hvordan de retningsafledede kan udtrykkes som et prikprodukt mellem gradientvektoren og en enhedsvektor i den betragtede retning. Dette leder frem til, hvordan man kan lave optimering ved hjælp af gradientnedstigning.\nSværhedsgrad: **\n\n\n\n\n\nAfstande og feature-skalering\n\n\n\nHer findes en samling af flere noter, hvor afstande er omdrejningspunktet. Vi behandler feature-skalering, forskellige afstande mellem punkter i planen, afstande mellem ord og mellem DNA- og RNA-strenge. Desuden er der en note om det abstrakte afstandbegreb – herunder definitionen af en metrik.\nSværhedsgrad: *"
  },
  {
    "objectID": "materialer/simple_neurale_net/simple_neurale_net.html",
    "href": "materialer/simple_neurale_net/simple_neurale_net.html",
    "title": "Simple kunstige neurale netværk",
    "section": "",
    "text": "Et generelt kunstigt neuralt netværk består af en masse neuroner, som er sat sammen i en række lag. Det kunne for eksempel se ud som i figur 1, hvor de grønne neuroner i midten repræsenterer de såkaldte skjulte lag.\nI denne note vil vi se på et mere simpelt tilfælde, som det er vist i figur 2. Her er der kun to skjulte lag, og hver af disse lag består kun af én neuron. Sådanne netværk, hvor de skjulte lag netop kun består af én neuron, vil vi her kalde for simple kunstige neurale netværk. På den måde befinder disse netværk sig begrebsmæssigt \"in between\" perceptroner og kunstige neuroner på den ene side og generelle kunstige neurale netværk1 på den anden. De simple kunstige neurale netværk har den fordel, at de giver en fin forståelse af, hvad neurale netværk er – herunder hvad feedforward og backpropagation går ud på – men samtidig uden, at det bliver alt for matematisk svært.\nSå lad os komme i gang! Udgangspunktet er et eksempel om at lave en simpel vejrudsigt."
  },
  {
    "objectID": "materialer/simple_neurale_net/simple_neurale_net.html#kan-vi-forudsige-vejret",
    "href": "materialer/simple_neurale_net/simple_neurale_net.html#kan-vi-forudsige-vejret",
    "title": "Simple kunstige neurale netværk",
    "section": "Kan vi forudsige vejret?",
    "text": "Kan vi forudsige vejret?\n\n\n\n\n\nForestil dig, at du gerne vil kunne forudsige, om det bliver regnvejr i morgen. Det er selvfølgelig ikke nogen helt simpel opgave, men man kunne forestille sig, at der vil være en række variable, som kan hjælpe med at lave den forudsigelse. Det kunne for eksempel være:\n\\[\n\\begin{aligned}\n&x_1: \\textrm{Er det regnvejr i dag? Hvis 'ja' er } x_1=1 \\textrm{ og } 0 \\textrm{ ellers.} \\\\\n&x_2: \\textrm{Luftfugtigheden i dag.} \\\\\n&x_3: \\textrm{Temperaturen i dag.} \\\\\n&x_4: \\textrm{Lufttrykket i dag.} \\\\\n\\end{aligned}\n\\tag{1}\\]\nOg der vil sikkert være en masse andre variable, som også kunne give mening. Disse variable \\(x_1, x_2, \\dots, x_n\\) kaldes for inputvariable.\nVi vil nu se på, hvordan man ved hjælp af sådanne inputvariable kan prædiktere, om det bliver regnvejr i morgen."
  },
  {
    "objectID": "materialer/simple_neurale_net/simple_neurale_net.html#feedforward",
    "href": "materialer/simple_neurale_net/simple_neurale_net.html#feedforward",
    "title": "Simple kunstige neurale netværk",
    "section": "Feedforward",
    "text": "Feedforward\nVi starter med at se på det mere generelle tilfælde, hvor vi har \\(n\\) inputvariable:\n\\[\nx_1, x_2, \\dots, x_n.\n\\] Disse inputvariable sender vi nu ind i et forholdsvis simpelt neuralt netværk, som vist i figur 2.\n\n\n\n\n\n\nFigur 2: Grafisk illustration af et neuralt netværk med \\(n\\) inputvariable og to skjulte lag, som hver består af én neuron.\n\n\n\nDe grønne og blå cirkler i figur 2 kaldes for neuroner. Idéen er, at vi på baggrund af inputværdierne (her vist som de lilla cirkler til venstre) i sidste ende vil beregne en outputværdi \\(o\\) (som er illustreret ved den blå cirkel længst til højre). Outputværdien skal i dette eksempel være et tal mellem \\(0\\) og \\(1\\), som skal kunne fortolkes som sandsynligheden for, at det bliver regnvejr i morgen baseret på inputværdierne \\(x_1, x_2, \\dots, x_n\\). Herefter kunne man forestille sig følgende vejrudsigt:\n\\[\n\\textrm{Det bliver regnvejr i morgen: }\n\\begin{cases}\n\\textrm{Ja} & \\textrm{hvis } o \\geq 0.5\\\\\n\\textrm{Nej} & \\textrm{hvis } o &lt; 0.5\\\\\n\\end{cases}\n\\] Lad os derfor se på, hvordan \\(o\\) kan beregnes. Det sker ved hjælp af en række vægte, som er repræsenteret ved pilene i figur 2. Inputværdierne sendes frem til den første neuron (vist som en lysegrøn cirkel i figur 2). Her beregnes den vægtede2 sum:\n2 Strengt taget er der ikke tale om en vægtet sum på grund af konstantleddet \\(r_0\\). Men hvis man tilføjer en inputværdi \\(x_0\\), som altid er \\(1\\), så kan udtrykket skrives \\(r_0 \\cdot x_0 + r_1 \\cdot x_1 + r_2 \\cdot x_2 + \\cdots + r_n \\cdot x_n.\\) I det tilfælde kan man tale om en vægtet sum af inputværdierne \\(x_0, x_1, \\dots, x_n\\).\\[\nr_0 + r_1 \\cdot x_1 + r_2 \\cdot x_2 + \\cdots + r_n \\cdot x_n.\n\\]\nBemærk her, at der er \\(n+1\\) vægte, da der er inkluderet et konstantled \\(r_0\\).\nHerefter benyttes en såkaldt aktiveringsfunktion på den vægtede sum. En ofte anvendt aktiveringsfunktion er sigmoid-funktionen \\(\\sigma\\):\n\\[\n\\sigma (x) = \\frac{1}{1+e^{-x}}.\n\\tag{2}\\]\nDet vil sige, at vi beregner\n\\[\n\\begin{aligned}\ny &= h(x_1, x_2, \\dots, x_n) \\\\\n&=\\sigma (r_0 + r_1 \\cdot x_1 + r_2 \\cdot x_2 + \\cdots + r_n \\cdot x_n) \\\\\n&= \\frac{1}{1+e^{-(r_0 + r_1 \\cdot x_1 + r_2 \\cdot x_2 + \\cdots + r_n \\cdot x_n)}}.\n\\end{aligned}\n\\]\nGrafen for sigmoid-funktionen ses i figur 3.\n\n\n\n\n\n\nFigur 3: Grafen for sigmoid-funktionen.\n\n\n\nHer anskueliggøres det, at sigmoid-funktionen tager et vilkårligt reelt tal som input og giver et tal i intervallet \\(]0,1[\\) som output. Det kan skrives sådan her:\n\\[\n\\sigma : \\mathbb{R} \\rightarrow ]0,1[.\n\\]\nDet næste, der sker, er, at den første (lysegrønne) neuron i figur 2 sender værdien \\(y\\) videre i netværket, hvor \\(0&lt;y&lt;1\\). Ved den næste neuron i figur 2 (repræsenteret ved den mørkegrønne cirkel), beregnes først \\(v_0 + v_1 \\cdot y\\) og herefter anvendes igen aktiveringsfunktionen:\n\\[\nz = g(y) = \\sigma (v_0 + v_1 \\cdot y).\n\\]\nDenne værdi sendes nu frem til den sidste neuron i outputlaget og outputværdien \\(o\\) beregnes på tilsvarende måde\n\\[\no = f(z) = \\sigma(w_0 + w_1 \\cdot z).\n\\]\nHele denne proces med at udregne outputværdien \\(o\\) på baggrund af inputværdierne \\(x_1, x_2, \\dots, x_n\\) kaldes for feedforward og er opsummeret herunder:\n\n\n\n\n\n\nFeedforward-udtryk\n\n\n\n\n\nPå baggrund af inputværdierne \\(x_1, x_2, \\dots, x_n\\) beregnes outputværdien \\(o\\) på følgende måde.\nFørst beregnes:\n\\[\ny = h(x_1, x_2, \\dots, x_n) = \\sigma (r_0 + r_1 \\cdot x_1 + r_2 \\cdot x_2 + \\cdots + r_n \\cdot x_n)\n\\tag{3}\\]\nDernæst beregnes:\n\\[\nz = g(y)=\\sigma (v_0 + v_1 \\cdot y)\n\\tag{4}\\]\nOg til sidst kan outputværdien \\(o\\) beregnes:\n\\[\no = f(z)=\\sigma(w_0 + w_1 \\cdot z)\n\\tag{5}\\]\n\n\n\n\n\n\n\n\nBemærk, at outputværdien \\(o\\) beregnes ved hjælp af sigmoid-funktionen, og derfor er et tal mellem \\(0\\) og \\(1\\), som tidligere ønsket – altså kan \\(o\\) fortolkes som en sandsynlighed.\nMed udgangspunkt i feedforward-udtrykkene, kan vi også skrive outputværdien \\(o\\) direkte som en funktion af inputværdierne \\(x_1, x_2, \\dots, x_n\\). Vi starter med at indsætte udtrykket for \\(z\\) i (4) i udtrykket for \\(o\\) i (5):\n\\[\n\\begin{aligned}\no &= f(z)=f(g(y)) \\\\\n&=\\sigma(w_0 + w_1 \\cdot (\\sigma (v_0 + v_1 \\cdot y)))\n\\end{aligned}\n\\]\nHerefter erstatter vi \\(y\\) med udtrykket i (3):\n\\[\n\\begin{aligned}\no &= f(z)=f(g(y))=f(g(h(x_1, x_2, \\dots, x_n))) \\\\&= \\sigma(w_0 + w_1 \\cdot (\\sigma (v_0 + v_1 \\cdot (\\sigma (r_0 + r_1 \\cdot x_1 + r_2 \\cdot x_2 + \\cdots + r_n \\cdot x_n) ))))\n\\end{aligned}\n\\]\nHer bliver det meget tydeligt, at\n\nOutputværdien afhænger af inputværdierne \\(x_1, x_2, \\dots, x_n\\):\n\\[\no = \\sigma(w_0 + w_1 \\cdot (\\sigma (v_0 + v_1 \\cdot (\\sigma (r_0 + r_1 \\cdot {\\color{#F288B9} x_1} + r_2 \\cdot      {\\color{#F288B9} x_2} + \\cdots + r_n \\cdot {\\color{#F288B9} x_n}) ))))\n\\]\nDet er den måde, vi forstår feedforward-udtrykkene på: Vi beregner outputværdien \\(o\\) ud fra inputværdierne \\(x_1, x_2, \\dots, x_n\\). Vi kan altså her tænke på outputværdien som en funktion af inputværdierne \\(x_1, x_2, \\dots, x_n\\).\nOutputværdien afhænger også af alle vægtene \\(w_0, w_1, v_0, v_1, r_0, r_1, \\dots, r_n\\): \\[\no =\\sigma({\\color{#8086F2} w_0} + {\\color{#8086F2} w_1} \\cdot (\\sigma ({\\color{#8086F2} v_0} + {\\color{#8086F2} v_1} \\cdot (\\sigma ({\\color{#8086F2} r_0} + {\\color{#8086F2} r_1} \\cdot x_1 + {\\color{#8086F2} r_2} \\cdot x_2 + \\cdots + {\\color{#8086F2} r_n} \\cdot x_n) ))))\n\\] Her tænker vi på \\(o\\) som en funktion af vægtene \\(w_0, w_1, v_0, v_1, r_0, r_1, \\dots, r_n\\). Det er denne tankegang, vi skal bruge, når vi skal i gang med at træne netværket. Her er inputværdierne nemlig givet, mens vi ønsker at justere på vægtene, så netværk bliver så godt som muligt til at forudsige vejret.\n\nog\n\nOutputværdien \\(o\\) kan udtrykkes ved hjælp af flere sammensatte funktioner (her markeret med gult).\n\\[\no ={\\color{#F2B33D} \\sigma}({w_0} + {w_1} \\cdot ({\\color{#F2B33D} \\sigma} ({v_0} + {v_1} \\cdot ({\\color{#F2B33D} \\sigma} ({r_0} + {r_1} \\cdot x_1 + {r_2} \\cdot x_2 + \\cdots + {r_n} \\cdot x_n) ))))\n\\]\nDet er årsagen til, at vi senere får brug for kædereglen, når vi skal i gang med at differentiere ovenstående med hensyn til vægtene.\n\nBortset fra det er feedforward-udtrykkene ovenfor nok nemmere at overskue!\nFint nok – nu har vi altså en model, som kan bruges til at forudsige vejret. Men måske er du skeptisk. Det bør du i hvert tilfælde være! For hvem siger, at outputværdien \\(o\\) siger noget som helst om sandsynligheden for, at det bliver regnvejr i morgen? Det korte svar er: Det gør den heller ikke nødvendigvis! I hvert tilfælde ikke sådan uden videre. Det kræver nemlig, at alle vægtene er \"indstillet\" sådan, at den beregnede outputværdi rent faktisk kan fortolkes som en sandsynlighed for, at det bliver regnvejr i morgen. For at lave denne \"indstilling\" skal vi bruge to ting: 1) træningsdata og 2) en tabsfunktion. Det kommer her."
  },
  {
    "objectID": "materialer/simple_neurale_net/simple_neurale_net.html#træningsdata-og-tabsfunktion",
    "href": "materialer/simple_neurale_net/simple_neurale_net.html#træningsdata-og-tabsfunktion",
    "title": "Simple kunstige neurale netværk",
    "section": "Træningsdata og tabsfunktion",
    "text": "Træningsdata og tabsfunktion\nNu tænker vi os, at du registrerer de fire størrelser i (1) på en række forskellige dage, ligesom du også den efterfølgende dag registrerer, om det regner eller ej. Denne sidste registrering kunne for eksempel ske på denne måde:\n\\[\nt=\n\\begin{cases}\n1 & \\textrm{hvis det regner den efterfølgende dag} \\\\\n0 & \\textrm{hvis det ikke regner den efterfølgende dag} \\\\\n\\end{cases}\n\\] Variablen \\(t\\) kaldes for en targetvariabel. Det er netop denne værdi, vi gerne vil kunne forudsige. Man kan derfor tænke på variablen \\(t\\), som en slags facitliste. Man siger også, vi gerne vil prædiktere \\(t\\).\nHvis vi for eksempel laver denne registrering på 10 forskellige dage kan vi skrive det op på denne måde:\n\\[\n\\begin{aligned}\n&\\text{Dag 1:} \\quad (x_1^{(1)}, x_2^{(1)}, x_3^{(1)}, x_4^{(1)}, t^{(1)}) \\\\\n&\\text{Dag 2:} \\quad (x_1^{(2)}, x_2^{(2)}, x_3^{(2)}, x_4^{(2)}, t^{(2)}) \\\\\n&  \\quad  \\vdots \\\\\n&\\text{Dag 10:} \\quad (x_1^{(10)}, x_2^{(10)}, x_3^{(10)}, x_4^{(10)}, t^{(10)}) \\\\\n\\end{aligned}\n\\]\nDet hævede tal i parentes angiver altså nummeret på dagen. For eksempel angiver \\(x_3^{(2)}\\) temperaturen på dag 2, mens \\(t^{(2)}\\) er 1, hvis det regner dagen efter dag 2 og 0 ellers. Bemærk, at dagene ikke behøver at komme efter hinanden. Det kan tværtimod være en fordel, hvis dagene er spredt ud, så der ikke kommer afhængigheder mellem værdierne.\nOvenstående kaldes for træningsdata. Helt generelt med \\(n\\) inputvariable og \\(M\\) observationer i træningsdata vil vi opskrive træningsdatasættet sådan her:\n\\[\n\\begin{aligned}\n&\\text{Træningseksempel 1:} \\quad (x_1^{(1)}, x_2^{(1)}, \\dots, x_n^{(1)}, t^{(1)}) \\\\\n&  \\quad \\quad \\quad \\quad \\vdots \\\\\n&\\text{Træningseksempel m:} \\quad (x_1^{(m)}, x_2^{(m)}, \\dots, x_n^{(m)}, t^{(m)}) \\\\\n&  \\quad \\quad \\quad \\quad \\vdots \\\\\n&\\text{Træningseksempel M:} \\quad (x_1^{(M)}, x_2^{(M)}, \\dots, x_n^{(M)}, t^{(M)}) \\\\\n\\end{aligned}\n\\]\nVi kan nu tage hvert træningsdataeksempel og sende det ind i netværket i figur 2. Det gør vi ved hjælp af feedforward-udtrykkene i (3), (4) og (5). Vi får derfor for hvert træningseksempel beregnet en outputværdi \\(o\\). Outputværdien for det \\(m\\)’te træningseksempel vil vi kalde for \\(o^{(m)}\\).\nHvis netværket er godt – det vil sige, hvis vi har fundet nogle \"gode\" værdier af vægtene, så vil outputværdien \\(o\\) kunne fortolkes som sandsynligheden for, om det bliver regnvejr i morgen.\nDet betyder, at et godt netværk har denne egenskab:\n\nHvis \\(t=1\\), så er \\(o \\approx 1\\).\nHvis \\(t=0\\), så er \\(o \\approx 0\\).\n\nI begge tilfælde betyder det, at \\[\nt-o \\approx 0.\n\\]\nDet er præcis denne differens, som vi vil bruge som et mål for, hvor godt netværket er.\nNu kan denne differens både være positiv og negativ. Derfor vil vi se på den kvadrerede differens:\n\\[\n(t-o)^2.\n\\]\nHvis netværket er godt, vil denne kvadrerede differens stadig være tæt på \\(0\\). Samtidig vil der jo også være en differens for hvert træningsdataeksempel:\n\\[\n(t^{(1)}-o^{(1)})^2, (t^{(2)}-o^{(2)})^2, \\dots, (t^{(M)}-o^{(M)})^2.\n\\]\nDet er summen af alle disse differenser (ganget3 med \\(1/2\\)), som vi vil bruge som mål for, hvor godt netværket er:\n3 At vi ganger med \\(1/2\\) er ikke så vigtigt – du ser senere, hvorfor det er smart.\\[\nE = \\frac{1}{2} \\sum_{m=1}^M (t^{(m)}-o^{(m)})^2\n\\]\nDenne funktion er den, som vi kalder for en tabsfunktion (eller på engelsk error function – deraf \\(E\\)’et). Som vi har argumenteret for ovenfor, så er vi netop på jagt efter de værdier af vægtene, som minimerer tabsfunktionen.\nTabsfunktionen ovenfor kan også omskrives en smule:\n\\[\n\\begin{aligned}\nE &= \\frac{1}{2} \\sum_{m=1}^M (t^{(m)}-o^{(m)})^2 \\\\\n&= \\sum_{m=1}^M \\frac{1}{2} (t^{(m)}-o^{(m)})^2 \\\\\n&= \\sum_{m=1}^M E^{(m)},\n\\end{aligned}\n\\tag{6}\\]\nhvor\n\\[\nE^{(m)} = \\frac{1}{2} (t^{(m)}-o^{(m)})^2\n\\tag{7}\\]\ner det bidrag til tabsfunktionen, som stammer fra det \\(m\\)’te træningseksempel.\nFor at finde værdier af vægtene som minimerer tabsfunktionen bruges en metode, som kaldes for backpropagation. Det forklarer vi lige om lidt, men vi kan allerede nu afsløre, at vi får brug for at kunne differentiere tabsfunktionen. Vi har tidligere set, at alle outputværdierne \\(o^{(m)}\\) er en sammensat funktion. Derfor bliver tabsfunktionen også en sammensat funktion. Det betyder, at vi får brug for at kunne differentiere sammensatte funktioner, og det siger kædereglen noget om. Men først skal vi se, hvordan kædereglen kan opskrives på en smart måde, hvilket vi skal bruge i forbindelse med backpropagation."
  },
  {
    "objectID": "materialer/simple_neurale_net/simple_neurale_net.html#kædereglen",
    "href": "materialer/simple_neurale_net/simple_neurale_net.html#kædereglen",
    "title": "Simple kunstige neurale netværk",
    "section": "Kædereglen",
    "text": "Kædereglen\nDu kender godt de sammensatte funktioner. Det kunne for eksempel være en funktion4 \\(k\\):\n4 Bemærk her, at vi kalder en funktion for \\(k\\), men det er altså ikke at veksle med en konstant, som vi også ofte kalder for \\(k\\)!\\[\nk(x)= f(g(x))\n\\]\nFunkionen \\(k\\) afhænger af \\(x\\), men det sker via den indre funktion \\(g\\) og den ydre funktion \\(f\\). Altså \\(k\\) er sammensat af en indre og en ydre funktion:\n\nIndre funktion: \\(u=g(x)\\)\nYdre funktion: \\(f(u)\\)\n\nIdéen er illustreret i figur 4.\n\n\n\n\n\n\nFigur 4: Illustration af funktionen \\(k\\) som er sammensat af den indre funktion \\(g\\) og den ydre funktion \\(f\\).\n\n\n\nFor at beregne \\(k(x)\\) \"sender\" vi først \\(x\\) ind i \"funktionsmaskinen\" for \\(g\\). Her bliver \\(g(x)\\) beregnet. Denne værdi \"sendes\" så ind i \"funktionsmaskinen\" for \\(f\\) og dermed bliver \\(f(g(x))\\) beregnet, som netop er \\(k(x)\\).\nHvis vi skal differentiere funktionen \\(k\\), så skal vi bruge reglen for at differentiere sammensatte funktioner:\n\\[\nk'(x)=f'(g(x)) \\cdot g'(x)\n\\tag{8}\\]\nDet er altså den ydre funktion differentieret taget på den indre5 gange den indre funktion differentieret.\n5 Det betyder, at der står \\(f'(g(x))\\) og for eksempel ikke \\(f'(x)\\).Hvis vi erstatter \\(g(x)\\) med \\(u\\) kan det skrives:\n\\[\nk'(x)=f'(u) \\cdot g'(x)\n\\]\nDu har måske også lært, at man i stedet for at bruge mærker til at angive, at man har differentieret, kan skrive sådan her (kært barn har som bekendt mange navne):\n\\[\n\\frac{dk}{dx} = \\frac{df}{du} \\cdot \\frac{du}{dx}\n\\]\nDenne måde at skrive reglen for at differentiere sammensatte funktioner på kaldes for kædereglen6. Navnet kædereglen kommer af, at de diffenrentialkvotienter, som indgår på højre side bliver \"kædet\" sammen. Det er nemmest at illustrere med farver:\n6 Bemærk, at denne måde at skrive en differentialkvotient på (\\(\\frac{dk}{dx}\\)) ikke er en egentlig brøk, selvom det ligner. Det svarer derimod til grænseværdien af en brøk (nemlig grænseværdien af en differenskvotient).\\[\n\\frac{dk}{dx} = \\frac{df}{\\color{#8086F2} du} \\color{black}\\cdot \\frac{\\color{#8086F2} du \\color{black}}{dx}\n\\]\nBemærk, at denne notation jo er noget kortere end udtrykket i (8), men vi har også \"fejet noget ind under gulvtæppet\". Det er nemlig ikke tydeligt, hvad de afledede funktioner skal evalueres i. I (8) ses det tydeligt, at \\(f'\\) skal evalueres i \\(g(x)\\), mens \\(g'\\) skal evalueres i \\(x\\). Denne information er underforstået, når vi bruger \"kæderegelsnotationen\" ovenfor. Hvis man vil, kan man pakke kædereglen lidt mere ud, så det bliver tydeligere:\n\\[\n\\frac{dk}{dx} (x) = \\frac{df}{du} (u) \\cdot \\frac{du}{dx} (x),\n\\]\nhvor\n\\[\nu = g(x).\n\\] Selvom denne måde at skrive det på er mere korrekt, vil vi alligevel for enkelthedens skyld holde fast i notationen i (8).\nKædereglen bliver endnu tydeligere, hvis vi ser på en funktion, som er sammensat af ikke bare to, men tre funktioner:\n\\[\nk(x) = f(g(h(x)))\n\\] Denne funktion er sammensat af tre funktioner:\n\nIndre funktion: \\(y=h(x)\\)\nIndre funktion: \\(z=g(y)\\)\nYdre funktion: \\(f(z)\\)\n\nFor at differentiere \\(k\\) må vi først bruge kædereglen én gang:\n\\[\nk'(x)= f'(g(h(x))) \\cdot \\left ( g(h(x))\\right)'\n\\] For at differentiere den sidste faktor må vi bruge kædereglen endnu en gang:\n\\[\n\\left ( g(h(x))\\right)' = g'(h(x)) \\cdot h'(x)\n\\]\nDet vil sige, at vi samlet set ender med:\n\\[\nk'(x)= f'(g(h(x))) \\cdot g'(h(x)) \\cdot h'(x)\n\\] Bruger vi notation med \\(dk/dx\\) og husker på, at\n\\[\nz = g(y) \\qquad \\textrm{og} \\qquad y = h(x)\n\\]\nkan ovenstående skrives som:\n\\[\n\\frac{dk}{dx} = \\frac{df}{dz} \\cdot \\frac{dz}{dy} \\cdot \\frac{dy}{dx}\n\\]\nOg med farver bliver det tydeligt, hvorfor der er tale om en kæderegel:\n\\[\n\\frac{dk}{dx} = \\frac{df}{\\color{#8086F2} dz} \\cdot \\frac{\\color{#8086F2} dz}{\\color{#F288B9} dy} \\cdot \\frac{\\color{#F288B9} dy}{dx}\n\\]\nDenne måde at skrive kædereglen på får vi brug for i det følgende."
  },
  {
    "objectID": "materialer/simple_neurale_net/simple_neurale_net.html#backpropagation",
    "href": "materialer/simple_neurale_net/simple_neurale_net.html#backpropagation",
    "title": "Simple kunstige neurale netværk",
    "section": "Backpropagation",
    "text": "Backpropagation\nHusk på at vi gerne vil bestemme de værdier af vægtene, så tabsfunktionen i (6) bliver minimeret. Når man skal minimere en funktion af flere variable kan man egentlig bare sætte alle de partielle afledede lig med 0. Det vil give lige så mange ligninger, som der er vægte (og alle ligninger vil være koblet til hinanden). I vores simple eksempel her vil det ikke være noget problem at løse de ligninger. Men i virkelighedens verden, hvor de kunstige neurale netværk afhænger af millioner eller milliarder af vægte, er denne fremgangsmåde beregningsmæssigt alt for tung. Det vil dels tage alt for lang tid, og det vil dels tage for meget plads på computeren.\nMan bruger derfor en anden metode, som kaldes for backpropagation. I backpropagation bruger man for det første gradientnedstigning, så den tager vi lige først.\nVi forestiller os, at vi har en funktion \\(f\\), som afhænger af \\(x_1, x_2, \\dots, x_n\\). Vi \"stiller\" os nu et tilfældigt sted på grafen for \\(f\\) og udregner gradienten\n\\[\n\\nabla f(x_1, x_2, \\dots, x_n) =\n\\begin{pmatrix}\n\\frac{\\partial f}{\\partial x_1} \\\\\n\\frac{\\partial f}{\\partial x_2} \\\\\n\\vdots \\\\\n\\frac{\\partial f}{\\partial x_n}\n\\end{pmatrix}.\n\\]\nSå viser det sig, at gradienten peger i den retning, hvor funktionsværdien vokser mest. Derfor vil minus gradienten pege i den retning, hvor funktionsværdien aftager mest. Visuelt kan man forestille sig, at man står i et bakkelandskab, hvor man gerne vil ned i en dal. Så kan man tænke på den negative gradient, som den retning vi skal bevæge os i, hvis vi gerne vil gå allermest nedad bakke (og det er jo smart, hvis man gerne vil ende i dalen). Man udregner derfor gradienten og går et lille stykke i den negative gradients retning. Nu er det jo ikke sikkert, at man hele tiden skal gå i den samme retning, så derfor er man nødt til at udregne gradienten igen på det nye sted, man nu står og så korrigere sin retning i forhold det næste lille skridt, man tager.\nDet er altså idéen, hvis man gerne vil bestemme minimum. Man stiller sig simpelthen et tilfældigt sted på grafen for \\(f\\) og udregner gradienten. Så bevæger man sig et lille stykke i den negative gradients retning. I det nye punkt udregner man gradienten igen og går et lille stykke i den nye negative gradients retning. Sådan fortsætter man, indtil funktionsværdien ikke ændrer sig ret meget, og man er landet i et minimum (eventuelt kun lokalt).\nNu hedder vores funktion ikke \\(f\\), men \\(E\\) (det var tabsfunktionen). \\(E\\) afhænger af vægtene \\(r_0, r_1, \\dots, r_n, v_0, v_1, w_0\\) og \\(w_1\\). Vi vælger derfor nogle tilfældige værdier af disse vægte og udregner gradienten. Så opdaterer vi alle vægtene ved at gå et lille stykke \\(\\eta\\) i den negative gradients retning. For at beregne den nye værdi af \\(w_1\\), som vi her vil kalde for \\(w_1^{\\textrm{ny}}\\), vil det for eksempel se sådan her ud:\n\\[\nw_1^{\\textrm{ny}} \\leftarrow w_1 - \\eta \\cdot \\frac{\\partial E}{\\partial w_1}\n\\]\nDet lille stykke \\(\\eta\\), som vi går i den negative gradients retning, kaldes også for en learning rate. Her er \\(w_1\\) den \"nuværende\" værdi af vægten, og pilen til venstre betyder, at der foretages en opdatering. Den nye værdi af vægten kaldes, som sagt, for \\(w_1^{\\textrm{ny}}\\).\nI backpropagation opdateres vægtene ved at bruge ovenstående opdateringsregel, men det gøres på en snedig måde. Nemlig ved at opdatere vægtene tættest på outputlaget først – det vil sige \\(w_0\\) og \\(w_1\\). Dernæst går man en skidt længere tilbage i netværket i figur 2 og opdaterer \\(v_0\\) og \\(v_1\\) og endelig opdaterer man til sidst vægtene tættest på inputlaget \\(r_0, r_1, \\dots, r_n\\). Vi skal nok forklare, hvorfor det er smart, men det er altså årsagen til, at metoden kaldes for backpropagation: Fordi vægtene opdateres fra outputlaget og bagud.\nInden opdateringen af vægtene går i gang sættes alle vægtene til en tilfældig værdi. Herefter tager vi alle \\(M\\) træningsdata og sender ind i netværket. Det vil sige, at vi på baggrund af feedforward-udtrykkene i (3), (4) og (5) udregner følgende for det \\(m\\)’te træningsdataeksempel:\n\\[\ny^{(m)} = \\sigma (r_0 + r_1 \\cdot x_1^{(m)} + r_2 \\cdot x_2^{(m)} + \\cdots + r_n \\cdot x_n^{(m)})\n\\tag{9}\\]\n\\[\nz^{(m)} = \\sigma (v_0 + v_1 \\cdot y^{(m)})\n\\tag{10}\\]\n\\[\no^{(m)} = \\sigma(w_0 + w_1 \\cdot z^{(m)})\n\\tag{11}\\]\nog det gør vi altså for alle \\(M\\) træningsdata \\(m \\in \\{1, 2, \\dots, M\\}\\). Alle disse værdier af \\(y^{(m)}\\), \\(z^{(m)}\\) og \\(o^{(m)}\\) får vi nemlig brug for, når vi skal i gang med at opdatere vægtene.\nVi er nu klar til at opdatere vægtene \\(w\\)-vægtene, som ligger tættest på outputlaget.\n\nOpdatering af \\(w\\)-vægtene\nVed at bruge gradientnedstigning bliver opdateringsligningerne for \\(w\\)-vægtene følgende:\n\\[\n\\begin{aligned}\nw_0^{\\textrm{ny}} &\\leftarrow w_0 - \\eta \\cdot \\frac{\\partial E}{\\partial w_0} \\\\\nw_1^{\\textrm{ny}} &\\leftarrow w_1 - \\eta \\cdot \\frac{\\partial E}{\\partial w_1}\n\\end{aligned}\n\\tag{12}\\]\nVi skal altså differentiere tabsfunktionen\n\\[\n\\begin{aligned}\nE = \\sum_{m=1}^M \\frac{1}{2} (t^{(m)}-o^{(m)})^2 = \\sum_{m=1}^M E^{(m)},\n\\end{aligned}\n\\] hvor\n\\[\nE^{(m)} = \\frac{1}{2} (t^{(m)}-o^{(m)})^2\n\\] med hensyn til \\(w_0\\) og \\(w_1\\). Lad os starte med \\(w_1\\). For det første skal vi huske, at man kan differentiere ledvist (det er sumreglen). Det giver:\n\\[\n\\frac{\\partial E}{\\partial w_1} =  \\sum_{m=1}^M \\frac{\\partial E^{(m)}}{\\partial w_1}\n\\]\nFor det andet får vi brug for kædereglen, da \\(E^{(m)}\\) jo er en sammensat funktion. På figur 2 kan man se, at tabsfunktionen afhænger af \\(w_1\\) via outputværdien \\(o^{(m)}\\). Derfor giver kædereglen:\n\\[\n\\frac{\\partial E}{\\partial w_1} =  \\sum_{m=1}^M \\frac{\\partial E^{(m)}}{\\partial o^{(m)}} \\cdot \\frac{\\partial o^{(m)}}{\\partial w_1}\n\\tag{13}\\]\nVi ser nu på hver faktor i denne sum for sig. For at bestemme \\(\\frac{\\partial E^{(m)}}{\\partial o^{(m)}}\\) skal vi bruge definitionen i (7):\n\\[\nE^{(m)} = \\frac{1}{2} (t^{(m)}-o^{(m)})^2\n\\]\nHer bruger vi også kædereglen. Det giver\n\\[\n\\begin{aligned}\n\\frac{\\partial E^{(m)}}{\\partial o^{(m)}} &= \\frac{1}{2} \\cdot 2 \\cdot (t^{(m)}-o^{(m)}) \\cdot  (-1) \\\\\n&= - (t^{(m)}-o^{(m)})\n\\end{aligned}\n\\tag{14}\\]\nBemærk for øvrigt, at \\(\\frac{1}{2}\\) og \\(2\\) forkorter ud. Det var derfor, at vi gangede tabsfunktionen i (6) med \\(\\frac{1}{2}\\).\nFor at finde \\(\\frac{\\partial o^{(m)}}{\\partial w_1}\\) skal vi bruge feedforward-ligningen i (11):\n\\[\no^{(m)} = \\sigma(w_0 + w_1 \\cdot z^{(m)})\n\\]\nDet er også en sammensat funktion, og bruger vi kædereglen på dette udtryk, får vi\n\\[\n\\frac{\\partial o^{(m)}}{\\partial w_1} = \\sigma'(w_0 + w_1 \\cdot z^{(m)}) \\cdot z^{(m)},\n\\]\nidet den indre funktion \\(w_0 + w_1 \\cdot z^{(m)}\\) differentieret med hensyn til \\(w_1\\) bare giver \\(z^{(m)}\\). Af ovenstående fremgår det, at vi får brug for at differentiere sigmoid-funktionen. Det viser sig, at den afledede sigmoid-funktion kan udtrykkes simpelt ved hjælp af sigmoid-funktionen selv på denne måde7:\n7 Se eventuelt mere i opgave 2 her.\nDen afledede sigmoid-funktion\n\\[\n\\sigma'(x) = \\sigma(x) \\cdot (1-\\sigma(x))\n\\tag{15}\\]\n\n\nBruger vi denne særlige egenskab, får vi\n\\[\n\\frac{\\partial o^{(m)}}{\\partial w_1} = \\sigma(w_0 + w_1 \\cdot z^{(m)}) \\cdot (1-\\sigma(w_0 + w_1 \\cdot z^{(m)})) \\cdot z^{(m)}\n\\]\nOg da \\(o^{(m)}=\\sigma(w_0 + w_1 \\cdot z^{(m)})\\) kan dette skrives som\n\\[\n\\frac{\\partial o^{(m)}}{\\partial w_1} = o^{(m)} \\cdot (1-o^{(m)}) \\cdot z^{(m)}\n\\tag{16}\\]\nHvis vi indsætter udtrykket i (14) og (16) i (13), får vi\n\\[\n\\frac{\\partial E}{\\partial w_1}= - \\sum_{m=1}^M (t^{(m)}-o^{(m)}) \\cdot o^{(m)} \\cdot (1-o^{(m)}) \\cdot z^{(m)}\n\\]\nIndsættes dette i (12) bliver opdateringsreglen for \\(w_1\\):\n\\[\nw_1^{\\textrm{ny}} \\leftarrow w_1 + \\eta \\cdot \\sum_{m=1}^M (t^{(m)}-o^{(m)}) \\cdot o^{(m)} \\cdot (1-o^{(m)}) \\cdot z^{(m)}\n\\]\nHvis vi lader\n\\[\n\\delta_w^{(m)} = (t^{(m)}-o^{(m)} ) \\cdot o^{(m)}  \\cdot (1-o^{(m)})\n\\tag{17}\\]\nkan det skrives kort som\n\\[\nw_1^{\\textrm{ny}} \\leftarrow w_1 + \\eta \\cdot \\sum_{m=1}^M \\delta_w^{(m)} \\cdot z^{(m)}\n\\]\nPå helt tilsvarende vis kan opdateringsreglen for \\(w_0\\) udledes, og vi ender med:\n\n\n\n\n\n\nOpdateringsregler for \\(w\\)-vægtene\n\n\n\n\n\n\\[\n\\begin{aligned}\nw_0^{\\textrm{ny}} \\leftarrow & w_0 + \\eta \\cdot \\sum_{m=1}^{M} \\delta_w^{(m)} \\cdot 1\\\\\nw_1^{\\textrm{ny}} \\leftarrow & w_1 + \\eta \\cdot \\sum_{m=1}^{M} \\delta_w^{(m)} \\cdot z^{(m)}\\\\\n\\end{aligned}\n\\] hvor \\[\n\\delta_w^{(m)} = (t^{(m)}-o^{(m)} ) \\cdot o^{(m)}  \\cdot (1-o^{(m)})\n\\]\n\n\n\nBemærk her, at fordi vi allerede ved hjælp af feedforward-udtrykkene har beregnet \\(z^{(m)}\\) og \\(o^{(m)}\\), så alle størrelser, som indgår i ovenstående opdateringsregler, er allerede udregnet.\n\n\nOpdatering af \\(v\\)-vægtene\nVi træder nu et skridt tilbage i netværket i figur 2 og opdaterer \\(v\\)-vægtene. Gradientnedstigning giver helt generelt følgende opdateringsregler:\n\\[\n\\begin{aligned}\nv_0^{\\textrm{ny}} &\\leftarrow v_0 - \\eta \\cdot \\frac{\\partial E}{\\partial v_0} \\\\\nv_1^{\\textrm{ny}} &\\leftarrow v_1 - \\eta \\cdot \\frac{\\partial E}{\\partial v_1}\n\\end{aligned}\n\\tag{18}\\]\nVi vælger at udlede den sidste regel og skal derfor finde \\(\\frac{\\partial E}{\\partial v_1}\\). Det kan ses på figur 2, at \\(v\\)-vægtene påvirker tabsfunktionen \\(E\\) først via værdien \\(z\\) og dernæst via outputværdien \\(o\\). Når vi skal differentiere tabsfunktionen i (6) med hensyn til \\(v_1\\) kan du derfor igen bruge kædereglen sådan her:\n\\[\n\\begin{aligned}\n\\frac{\\partial E}{\\partial v_1} &=  \\sum_{m=1}^M \\frac{ \\partial E^{(m)}}{\\partial v_1} \\\\\n&= \\sum_{m=1}^M \\frac{ \\partial E^{(m)}}{\\partial o^{(m)}} \\cdot \\frac{ \\partial o^{(m)}}{\\partial z^{(m)} } \\cdot \\frac{ \\partial z^{(m)}}{\\partial v_1}\n\\end{aligned}\n\\tag{19}\\]\nVi har allerede i (14) fundet ud af, at\n\\[\n\\frac{ \\partial E^{(m)}}{\\partial o^{(m)}}  = -(t^{(m)}-o^{(m)})\n\\]\nBruger vi feedforward-ligningen i (11):\n\\[\no^{(m)} = \\sigma(w_0 + w_1 \\cdot z^{(m)})\n\\] hvor vi nu differentierer med hensyn til \\(z^{(m)}\\) får vi:\n\\[\n\\begin{aligned}\n\\frac{ \\partial o^{(m)}}{\\partial z^{(m)} } &= \\sigma'(w_0 + w_1 \\cdot z^{(m)}) \\cdot w_1 \\\\\n&= o^{(m)} \\cdot (1-o^{(m)}) \\cdot w_1\n\\end{aligned}\n\\tag{20}\\]\nHer har vi igen brugt den særlige egenskab i (15).\nNu mangler vi blot at bestemme \\(\\frac{ \\partial z^{(m)}}{\\partial v_1}\\), og her får vi brug for feedward ligningen i (10)\n\\[\nz^{(m)} = \\sigma (v_0 + v_1 \\cdot y^{(m)}).\n\\]\nDerfor er\n\\[\n\\begin{aligned}\n\\frac{ \\partial z^{(m)}}{\\partial v_1} &= \\sigma' (v_0 + v_1 \\cdot y^{(m)}) \\cdot y^{(m)} \\\\\n&= z^{(m)} \\cdot (1-z^{(m)}) \\cdot y^{(m)}\n\\end{aligned}\n\\tag{21}\\]\nIgen på grund af (15).\nVi kan nu indsætte (14), (20) og (21) i (19) og få\n\\[\n\\begin{aligned}\n\\frac{\\partial E}{\\partial v_1} &=  \\sum_{m=1}^M \\underbrace{-(t^{(m)}-o^{(m)})}_{\\frac{\\partial E^{(m)}}{\\partial o^{(m)}}} \\cdot \\underbrace{o^{(m)} \\cdot (1-o^{(m)}) \\cdot w_1}_{\\frac{ \\partial o^{(m)}}{\\partial z^{(m)} }} \\cdot \\underbrace{z^{(m)} \\cdot (1-z^{(m)}) \\cdot y^{(m)}}_{\\frac{ \\partial z^{(m)}}{\\partial v_1}} \\\\\n&= - \\sum_{m=1}^M \\delta_w^{(m)} \\cdot w_1 \\cdot z^{(m)} \\cdot (1-z^{(m)}) \\cdot y^{(m)}\n\\end{aligned}\n\\]\nda \\[\n\\delta_w^{(m)} = (t^{(m)}-o^{(m)} ) \\cdot o^{(m)}  \\cdot (1-o^{(m)}).\n\\]\nPå tilsvarende vis kan man vise, at\n\\[\n\\frac{\\partial E}{\\partial v_1} = - \\sum_{m=1}^M \\delta_w^{(m)} \\cdot w_1 \\cdot z^{(m)} \\cdot (1-z^{(m)}) \\cdot 1\n\\]\nIndsættes i (18) får vi altså disse opdateringsregler:\n\n\n\n\n\n\nOpdateringsregler for \\(v\\)-vægtene\n\n\n\n\n\n\\[\n\\begin{aligned}\nv_0^{\\textrm{ny}} \\leftarrow & v_0 + \\eta \\cdot \\sum_{m=1}^{M} \\delta_w^{(m)}\\cdot w_1 \\cdot z^{(m)} \\cdot (1-z^{(m)})\\cdot 1\\\\\nv_1^{\\textrm{ny}} \\leftarrow & v_1 + \\eta \\cdot \\sum_{m=1}^{M} \\delta_w^{(m)} \\cdot w_1 \\cdot z^{(m)} \\cdot (1-z^{(m)})\\cdot y^{(m)}\\\\\n\\end{aligned}\n\\] hvor \\[\n\\delta_w^{(m)} = (t^{(m)}-o^{(m)} ) \\cdot o^{(m)}  \\cdot (1-o^{(m)})\n\\]\n\n\n\nHer kan vi igen se, at vi på grund af feedforward allerede har beregnet \\(y^{(m)}\\), \\(z^{(m)}\\) og \\(o^{(m)}\\).\n\n\nOpdatering af \\(r\\)-vægtene\nVi er nu nået til det sidste lag i netværket, som er tættest på inputlaget. Her bliver de generelle opdateringsregler:\n\\[\n\\begin{aligned}\nr_0^{\\textrm{ny}} &\\leftarrow r_0 - \\eta \\cdot \\frac{\\partial E}{\\partial r_0} \\\\\nr_1^{\\textrm{ny}} &\\leftarrow r_1 - \\eta \\cdot \\frac{\\partial E}{\\partial r_1} \\\\\n& \\quad \\vdots \\\\\nr_n^{\\textrm{ny}} &\\leftarrow r_n - \\eta \\cdot \\frac{\\partial E}{\\partial r_n}\n\\end{aligned}\n\\tag{22}\\]\nPå figur 2 ses det, at tabsfunktionen afhænger af disse \\(r\\)-vægte via \\(o^{(m)}\\), \\(z^{(m)}\\) og \\(y^{(m)}\\). Der kommer derfor lidt mere fut i kædereglen nu. Den partielle afledede med hensyn til \\(r_i\\) (hvor \\(i \\in \\{1, 2, \\dots, n\\}\\)) bliver\n\\[\n\\begin{aligned}\n\\frac{\\partial E}{\\partial r_i} &=  \\sum_{m=1}^M \\frac{ \\partial E^{(m)}}{\\partial r_i} \\\\\n&= \\sum_{m=1}^M \\frac{ \\partial E^{(m)}}{\\partial o^{(m)}} \\cdot \\frac{ \\partial o^{(m)}}{\\partial z^{(m)} } \\cdot \\frac{ \\partial z^{(m)}}{\\partial y^{(m)}} \\cdot \\frac{ \\partial y^{(m)}}{\\partial  r_i}\n\\end{aligned}\n\\tag{23}\\]\nNu er vi heldige, for vi har allerede udregnet de to første faktorer i denne sum i (14) og (20):\n\\[\n\\frac{\\partial E^{(m)}}{\\partial o^{(m)}} = - (t^{(m)}-o^{(m)})\n\\]\nog\n\\[\n\\frac{ \\partial o^{(m)}}{\\partial z^{(m)} } = o^{(m)} \\cdot (1-o^{(m)}) \\cdot w_1\n\\]\nNu mangler vi bare de to sidste faktorer i (23). Feedforward-ligningen i (10) giver\n\\[\n\\begin{aligned}\n\\frac{\\partial z^{(m)}}{\\partial y^{(m)}} &= \\sigma ' (v_0 + v_1 \\cdot y^{(m)}) \\cdot v_1 \\\\\n&= z^{(m)} \\cdot (1-z^{(m)})\\cdot v_1.\n\\end{aligned}\n\\tag{24}\\]\nHer har vi endnu en gang brugt (15).\nVed hjælp af feedforward-ligningen i (9) kan vi bestemme\n\\[\n\\begin{aligned}\n\\frac{\\partial y^{(m)}}{\\partial r_i} &= \\sigma '(r_0 + r_1 \\cdot x_1^{(m)} + r_2 \\cdot x_2^{(m)} + \\cdots + r_n \\cdot x_n^{(m)}) \\cdot x_i^{(m)} \\\\\n&= y^{(m)} \\cdot (1-y^{(m)}) \\cdot x_i^{(m)}.\n\\end{aligned}\n\\tag{25}\\]\nSidste lighedstegn følger af (15) og at\n\\[\ny^{(m)} = \\sigma(r_0 + r_1 \\cdot x_1^{(m)} + r_2 \\cdot x_2^{(m)} + \\cdots + r_n \\cdot x_n^{(m)}).\n\\]\nBemærk her, at hvis vi differentierer med hensyn til \\(r_0\\), så bliver\n\\[\n\\frac{\\partial y^{(m)}}{\\partial r_0}=y^{(m)} \\cdot (1-y^{(m)}) \\cdot 1.\n\\]\nVi kan nu som tidligere indsætte (14), (20), (24) og (25) i (23):\n\\[\n\\begin{aligned}\n\\frac{\\partial E}{\\partial r_i} =   \\sum_{m=1}^M \\underbrace{-(t^{(m)}-o^{(m)})}_{\\frac{\\partial E^{(m)} }{\\partial o^{(m)}}} \\cdot &\\underbrace{o^{(m)} \\cdot (1-o^{(m)}) \\cdot w_1}_{\\frac{\\partial o^{(m)}}{\\partial z^{(m)}}} \\cdot \\\\ &\\underbrace{z^{(m)} \\cdot (1-z^{(m)})\\cdot v_1}_{\\frac{\\partial z^{(m)}}{\\partial y^{(m)}}} \\cdot \\underbrace{y^{(m)} \\cdot (1-y^{(m)}) \\cdot x_i^{(m)}}_{\\frac{\\partial y^{(m)}}{\\partial r_i}}\n\\end{aligned}\n\\]\nDefinitionen af \\(\\delta_w^{(m)}\\) i (17) tillader os at forkorte ovenstående en smule:\n\\[\n\\frac{\\partial E}{\\partial r_i} =   - \\sum_{m=1}^M \\delta_w^{(m)} \\cdot w_1 \\cdot z^{(m)} \\cdot (1-z^{(m)})\\cdot v_1 \\cdot y^{(m)} \\cdot (1-y^{(m)}) \\cdot x_i^{(m)}\n\\] Opdateringsreglen for \\(r_i\\) bliver derfor ifølge (22):\n\\[\nr_i^{\\textrm{ny}} \\leftarrow r_i + \\eta \\cdot \\sum_{m=1}^M \\delta_w^{(m)} \\cdot w_1 \\cdot z^{(m)} \\cdot (1-z^{(m)})\\cdot v_1 \\cdot y^{(m)} \\cdot (1-y^{(m)}) \\cdot x_i^{(m)}\n\\] Og for samtlige \\(r\\)-vægte ender vi med følgende:\n\n\n\n\n\n\nOpdateringsregler for \\(r\\)-vægtene\n\n\n\n\n\n\\[\n\\begin{aligned}\nr_0^{\\textrm{ny}} &\\leftarrow r_0 + \\eta \\cdot \\sum_{m=1}^M \\delta_w^{(m)} \\cdot w_1 \\cdot z^{(m)} \\cdot (1-z^{(m)})\\cdot v_1 \\cdot y^{(m)} \\cdot (1-y^{(m)}) \\cdot 1 \\\\\nr_1^{\\textrm{ny}} &\\leftarrow r_1 + \\eta \\cdot \\sum_{m=1}^M \\delta_w^{(m)} \\cdot w_1 \\cdot z^{(m)} \\cdot (1-z^{(m)})\\cdot v_1 \\cdot y^{(m)} \\cdot (1-y^{(m)}) \\cdot x_1^{(m)} \\\\\n& \\quad \\vdots \\\\\nr_n^{\\textrm{ny}} &\\leftarrow r_n + \\eta \\cdot \\sum_{m=1}^M \\delta_w^{(m)} \\cdot w_1 \\cdot z^{(m)} \\cdot (1-z^{(m)})\\cdot v_1 \\cdot y^{(m)} \\cdot (1-y^{(m)}) \\cdot x_n^{(m)} \\\\\n\\end{aligned}\n\\]\nhvor \\[\n\\delta_w^{(m)} = (t^{(m)}-o^{(m)} ) \\cdot o^{(m)}  \\cdot (1-o^{(m)})\n\\]\n\n\n\nIgen har vi – fordi vi forud for opdateringen af vægtene har lavet en feedforward i netværket – udregnet \\(y^{(m)}\\), \\(z^{(m)}\\) og \\(o^{(m)}\\), som skal bruges for at beregne ovenstående opdateringer.\n\n\nOpsummering af backpropagation\nVi vil nu lave en samlet opsummering af de tre forskellig opdateringsregler for at få et bedre overblik over, hvad der egentlig sker, når man laver backpropagation.\nOpdateringsreglerne for laget tættest på outputlaget (\\(w\\)-vægtene) er:\n\\[\n\\begin{aligned}\nw_0^{\\textrm{ny}} \\leftarrow & w_0 + \\eta \\cdot \\sum_{m=1}^{M} \\delta_w^{(m)} \\cdot 1\\\\\nw_1^{\\textrm{ny}} \\leftarrow & w_1 + \\eta \\cdot \\sum_{m=1}^{M} \\delta_w^{(m)} \\cdot z^{(m)}\\\\\n\\end{aligned}\n\\] hvor \\[\n\\delta_w^{(m)} = (t^{(m)}-o^{(m)} ) \\cdot o^{(m)}  \\cdot (1-o^{(m)})\n\\]\nTræder vi et skridt bagud i netværket opdateres \\(v\\)-vægtene således:\n\\[\n\\begin{aligned}\nv_0^{\\textrm{ny}} \\leftarrow & v_0 + \\eta \\cdot \\sum_{m=1}^{M} \\delta_w^{(m)}\\cdot w_1 \\cdot z^{(m)} \\cdot (1-z^{(m)})\\cdot 1\\\\\nv_1^{\\textrm{ny}} \\leftarrow & v_1 + \\eta \\cdot \\sum_{m=1}^{M} \\delta_w^{(m)} \\cdot w_1 \\cdot z^{(m)} \\cdot (1-z^{(m)})\\cdot y^{(m)}\\\\\n\\end{aligned}\n\\]\nVi ser nu, at \\(\\delta_w^{(m)}\\cdot w_1 \\cdot z^{(m)} \\cdot (1-z^{(m)})\\) går igen i begge opdateringsregler. Vi sætter derfor\n\\[\n\\delta_v^{(m)} = \\delta_w^{(m)}\\cdot w_1 \\cdot z^{(m)} \\cdot (1-z^{(m)}).\n\\tag{26}\\]\nOpdateringen af \\(v\\)-vægtene kan derfor skrives på denne måde:\n\\[\n\\begin{aligned}\nv_0^{\\textrm{ny}} \\leftarrow & v_0 + \\eta \\cdot \\sum_{m=1}^{M} \\delta_v^{(m)}\\cdot 1\\\\\nv_1^{\\textrm{ny}} \\leftarrow & v_1 + \\eta \\cdot \\sum_{m=1}^{M} \\delta_v^{(m)}\\cdot y^{(m)}\\\\\n\\end{aligned}\n\\]\nDe sidste opdateringsregler for \\(r\\)-vægtene ser sådan her ud:\n\\[\nr_i^{\\textrm{ny}} \\leftarrow r_i + \\eta \\cdot \\sum_{m=1}^M \\delta_w^{(m)} \\cdot w_1 \\cdot z^{(m)} \\cdot (1-z^{(m)})\\cdot v_1 \\cdot y^{(m)} \\cdot (1-y^{(m)}) \\cdot x_i^{(m)}\n\\]\nIndsætter vi udtrykket i (26) kan det forkortes til:\n\\[\nr_i^{\\textrm{ny}} \\leftarrow r_i + \\eta \\cdot \\sum_{m=1}^M \\delta_v^{(m)} \\cdot v_1 \\cdot y^{(m)} \\cdot (1-y^{(m)}) \\cdot x_i^{(m)}\n\\] Og lader vi\n\\[\n\\delta_r^{(m)} = \\delta_v^{(m)} \\cdot v_1 \\cdot y^{(m)} \\cdot (1-y^{(m)})\n\\]\nender vi med\n\\[\nr_i^{\\textrm{ny}} \\leftarrow r_i + \\eta \\cdot \\sum_{m=1}^M \\delta_r^{(m)} \\cdot x_i^{(m)}\n\\]\nDet fine er, at det nu er blevet meget tydeligt, at alle opdateringsregler faktisk minder ret meget om hinanden. Vi kan derfor sammenfatte opdateringsreglener på denne måde:\n\n\n\n\n\n\nBackpropagation\n\n\n\n\n\nBackpropagation foregår samlet set på denne måde:\n\nSæt alle vægtene til en tilfældig værdi og vælg en værdi for learning raten \\(\\eta\\).\nFor alle træningsdataeksempler udregnes \\(y^{(m)}\\), \\(z^{(m)}\\) og \\(o^{(m)}\\) ved hjælp af feedforward-udtrykkene:\n\\[\n\\begin{aligned}\ny^{(m)} &= \\sigma (r_0 + r_1 \\cdot x_1^{(m)} + r_2 \\cdot x_2^{(m)} + \\cdots + r_n \\cdot x_n^{(m)})  \\\\\nz^{(m)} &= \\sigma (v_0 + v_1 \\cdot y^{(m)})  \\\\\no^{(m)} &= \\sigma(w_0 + w_1 \\cdot z^{(m)})\n\\end{aligned}\n\\]\nUdregn følgende:\n\\[\n\\begin{aligned}\n\\delta_w^{(m)} &= (t^{(m)}-o^{(m)} ) \\cdot o^{(m)}  \\cdot (1-o^{(m)})  \\\\\n\\delta_v^{(m)} &= \\delta_w^{(m)}\\cdot w_1 \\cdot z^{(m)} \\cdot (1-z^{(m)}) \\\\\n\\delta_r^{(m)} &= \\delta_v^{(m)} \\cdot v_1 \\cdot y^{(m)} \\cdot (1-y^{(m)})\n\\end{aligned}\n\\] Bemærk her, at vi kender \\(y^{(m)}\\), \\(z^{(m)}\\) og \\(o^{(m)}\\) på grund af feedforward, mens \\(w_1\\) og \\(v_1\\) er de nuværende værdier af vægtene (inden opdatering). Bemærk også, at for at beregne \\(\\delta_v^{(m)}\\) må vi først have beregnet \\(\\delta_w^{(m)}\\) (som hører til det sidste lag). Tilsvarende for at beregne \\(\\delta_r^{(m)}\\) må vi først have beregnet \\(\\delta_v^{(m)}\\) (som hører til det næstsidste lag). Det er derfor, at algoritmen hedder backpropagation.\nVægtene opdatereres:\n\\(w\\)-vægtene: \\[\n\\begin{aligned}\nw_0^{\\textrm{ny}} &\\leftarrow w_0 + \\eta \\cdot \\sum_{m=1}^{M} \\delta_w^{(m)} \\cdot 1\\\\\nw_1^{\\textrm{ny}} &\\leftarrow w_1 + \\eta \\cdot \\sum_{m=1}^{M} \\delta_w^{(m)} \\cdot z^{(m)}\\\\\n\\end{aligned}\n\\] \\(v\\)-vægtene: \\[\n\\begin{aligned}\nv_0^{\\textrm{ny}} &\\leftarrow v_0 + \\eta \\cdot \\sum_{m=1}^{M} \\delta_v^{(m)}\\cdot 1\\\\\nv_1^{\\textrm{ny}} &\\leftarrow v_1 + \\eta \\cdot \\sum_{m=1}^{M} \\delta_v^{(m)}\\cdot y^{(m)}\\\\\n\\end{aligned}\n\\] \\(r\\)-vægtene: \\[\n\\begin{aligned}\nr_0^{\\textrm{ny}} &\\leftarrow r_0 + \\eta \\cdot \\sum_{m=1}^M \\delta_r^{(m)} \\cdot 1 \\\\\nr_1^{\\textrm{ny}} &\\leftarrow r_1 + \\eta \\cdot \\sum_{m=1}^M \\delta_r^{(m)} \\cdot x_1^{(m)} \\\\\n& \\quad \\vdots \\\\\nr_n^{\\textrm{ny}} &\\leftarrow r_n + \\eta \\cdot \\sum_{m=1}^M \\delta_r^{(m)} \\cdot x_n^{(m)}\n\\end{aligned}\n\\]\n\nAlle vægtene er nu opdateret, og vi kan gentage punkt 2 til 4, hvor feedforward i 2 hver gang er baseret på de netop opdaterede vægte fra det foregående gennemløb. Opdateringen af vægtene fortsætter indtil værdien af tabsfunktionen næsten ikke ændrer sig. Håbet er nu, at vi har fundet et minimum (eventuelt kun lokalt) for tabsfunktionen."
  },
  {
    "objectID": "materialer/simple_neurale_net/simple_neurale_net.html#og-hvor-blev-den-vejrudsigt-så-af",
    "href": "materialer/simple_neurale_net/simple_neurale_net.html#og-hvor-blev-den-vejrudsigt-så-af",
    "title": "Simple kunstige neurale netværk",
    "section": "Og hvor blev den vejrudsigt så af?",
    "text": "Og hvor blev den vejrudsigt så af?\nVi tog jo egentlig udgangspunkt i et eksempel om at forudsige vejret, men hvis du har læst med så langt, er du sikkert ikke en gang klar over, om solen skinner, eller det regner lige nu! Så lad os lige prøve at zoome ud og komme tilbage til den vejrudsigt.\nVi havde de fire inputvariable:\n\\[\n\\begin{aligned}\n&x_1: \\textrm{Er det regnvejr i dag? Hvis 'ja' er } x_1=1 \\textrm{ og } 0 \\textrm{ ellers.} \\\\\n&x_2: \\textrm{Luftfugtigheden i dag.} \\\\\n&x_3: \\textrm{Temperaturen i dag.} \\\\\n&x_4: \\textrm{Lufttrykket i dag.} \\\\\n\\end{aligned}\n\\]\nVi forestiller os, at vi har samlet et stort træningsdatasæt, som beskrevet i afsnittet Træningsdata og tabsfunktion. Herefter bruger vi træningsdata og backpropagation, som gennemgået ovenfor, til at bestemme værdier af vægtene \\(w_0, w_1, v_0, v_1, r_0, r_1, \\dots, r_n\\), så tabsfunktionen minimeres.\nSå står vi her i dag og vil gerne forudsige vejret i morgen. Kig lige ud af vinduet. Regner det eller ej? Mål luftfugtigheden, temperaturen og lufttrykket. Du har nu fire konkret værdier af \\(x_1\\), \\(x_2\\), \\(x_3\\) og \\(x_4\\). Nu bruger du feedforward-udtrykkene i (3), (4) og (5) til at beregne outputværdien \\(o\\).\n\n\nEr \\(o \\geq 0.5\\)? Find paraplyen frem – din højteknologiske og banebrydende vejrudsigt forudsiger, at det bliver regnvejr i morgen.\nEr \\(o&lt;0.5\\)? No worries – i morgen bliver det ikke regnvejr. Så lad bare paraplyen stå.\n\nDet var faktisk \"bare\" det. Sådan kan man altså bruge kunstig intelligens til at forudsige vejret (og så kan du nok godt forestille dig, at i virkelighedens verden, er det hele lidt mere kompliceret)."
  },
  {
    "objectID": "materialer/simple_neurale_net/simple_neurale_net.html#relaterede-forløb",
    "href": "materialer/simple_neurale_net/simple_neurale_net.html#relaterede-forløb",
    "title": "Simple kunstige neurale netværk",
    "section": "Relaterede forløb",
    "text": "Relaterede forløb\n\n\n\n\n\nForløb\n\n\nKort beskrivelse\n\n\n\n\n\n\nAktiveringsfunktioner\n\n\nI opbygningen af kunstige neurale netværk er aktiveringsfunktioner helt centrale. Og aktiveringsfunktioner skal differentieres – det handler dette forløb om.\n\n\n\n\nScreeningsprogrammer\n\n\nKan man lave screeningsprogrammer for sygdomme baseret på genetiske markører med brug af AI? Det undersøger vi i dette forløb, som med fordel kan foregå i et samarbejde med bioteknologi.\n\n\n\n\nOpklar et mord!\n\n\nDer er blevet begået et mord på skolen i nat. Det er jeres opgave at opklare det!\n\n\n\n\nOpdatering af vægte i et simpelt neuralt netværk med to skjulte lag\n\n\nEn øvelse i at opdatere vægtene i et simpelt neuralt netværk med to skjulte lag.\n\n\n\n\nOpdatering af vægte i et simpelt neuralt netværk med ét skjult lag (men med cross-entropy som tabsfunktion)\n\n\nEn øvelse i at opdatere vægtene i et neuralt netværk med ét skjult lag med cross-entropy som tabsfunktion.\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "materialer/kmeans/kmeans.html",
    "href": "materialer/kmeans/kmeans.html",
    "title": "Clustering med K-means",
    "section": "",
    "text": "K-means\nNår \\(K\\)-means metoden bruges, er målet at inddele nogle observationer i grupper, så observationerne i hver gruppe minder meget om hinanden.\n\n\n\n\n\n\nFigur 1: Til venstre ses en række observationer, som ønskes inddelt i \\(3\\) grupper. Til højre ses et bud på en sådan inddeling.\n\n\n\nPå figur 1 til venstre ses en række punkter, hvor vi ønsker at inddele punkterne i 3 grupper. Man kan nok godt få en idé om, hvordan grupperne kan laves alene ved at se på billedet til venstre. På figur 1 til højre ses et bud på en løsning, som ser fornuftig ud, men ved nogle punkter tænker man nok alligevel lidt, om de nu skulle have været i den orange eller blå gruppe. Når vi arbejder med \\(K\\)-means, så er idéen, at vi ikke på forhånd har nogle observationer, hvor vi ved hvilken gruppe, de tilhører. Med andre ord har vi altså ikke et træningsdatasæt at gå ud fra her. Derfor taler man også om unsupervised learning. Det eneste, vi ved om vores punkter i figur 1, er deres \\(x\\)- og \\(y\\)-koordinat og ud fra det, skal vi så prøve at danne nogle grupper. Antallet af grupper ved man faktisk heller ikke nødvendigvis noget om – så her er det et valg, at vi har besluttet at prøve at inddele data i 3 grupper. Det kunne i princippet lige så godt have været 2 eller 4 grupper eller noget helt andet!\nObservationerne vil vi her kalde for \\(\\vec{x_1}, \\vec{x_2},....,\\vec{x_n}\\), så der i alt er \\(n\\) observationer. Hver observation er et punkt med \\(d\\) koordinater (som dog behandles, som var det vektorer/stedvektorer), og som udgangspunkt benyttes euklidisk afstand til at bestemme afstand mellem punkter. I eksemplet i figur 1 er \\(d=2\\), fordi alle punkter i planen har 2 koordinater.\nGivet et heltal \\(k\\), så ønsker vi at opdele de \\(n\\) observationer \\(\\vec{x_1}, \\vec{x_2},....,\\vec{x_n}\\) i \\(k\\) grupper, som vi kalder for \\(S_1,S_2,....,S_k\\). Antallet af observationer i gruppen1 \\(S_i\\) betegnes med \\(|S_i|\\).\n1 En gruppe \\(S_i\\) er egentlig en mængde, og \\(|S_i|\\) er kardinaliteten af denne mængde – altså antallet af elementer i mængden.Hele idéen i \\(K\\)-means metoden er, at det skal være sådan, at observationerne i samme gruppe ligger tæt på hinanden. Det er også sådan, at vi har farvet punkterne til højre i figur 1.\nHvis man skal oversætte det til matematik, så betyder det, at vi ønsker at minimere følgende sum (som vi kalder for \\(SUMPAR\\))\n\\[SUMPAR=\\sum_{i=1}^{k}\\frac{1}{|S_i|}\\sum_{\\vec p\\in S_i}\\sum_{\\vec q\\in S_i}\\|\\vec p-\\vec q\\|^2\\] Det ser måske lidt voldsomt ud, men lad os prøve at nedbryde ovenstående lidt. Vi forestiller os, at vi har de \\(k\\) grupper \\(S_1, S_2, \\dots , S_k\\). Vi ser først på et punkt \\(\\vec p \\in S_i\\). Den kvadrerede afstand til et andet punkt \\(\\vec q\\) i samme gruppe er givet ved udtrykket\n\\[\n\\|\\vec p- \\vec q\\|^2\n\\]\nDet vil sige, den euklidiske afstand mellem \\(\\vec p\\) og \\(\\vec q\\) opløftet i anden. Den gennemsnitlige kvadrerede afstand til alle punkter i samme gruppe \\(S_i\\) vil derfor være\n\\[\\frac{1}{|S_i|} \\sum_{\\vec q \\in S_i} \\|\\vec p- \\vec q\\|^2 \\]\nDet er altså den gennemsnitlige kvadrerede afstand fra ét punkt \\(\\vec p\\) til alle andre punkter i samme gruppe – inklusiv punktet selv. Vi vil nu lægge alle disse gennemsnitlige kvadrerede afstande sammen for alle punkter i \\(S_i\\). Gør vi det, får vi:\n\\[ \\sum_{\\vec p\\in S_i}\\frac{1}{|S_i|}\\sum_{\\vec q\\in S_i}\\|\\vec p-\\vec q\\|^2 \\]\nDa størrelsen \\(\\frac{1}{|S_i|}\\) indgår i alle led i den yderste sum, kan vi sætte \\(\\frac{1}{|S_i|}\\) uden for det yderste sumtegn2. Derfor kan vi omskrive ovenstående til\n2 Det svarer bare til at sætte uden for en parentes.\\[\n\\frac{1}{|S_i|}\\sum_{\\vec p\\in S_i}\\sum_{\\vec q\\in S_i}\\|\\vec p-\\vec q\\|^2\n\\]\nDet her vil vi gerne gøre for alle grupper, og derfor ender vi samlet set med\n\\[\nSUMPAR=\\sum_{i=1}^{k}\\frac{1}{|S_i|}\\sum_{\\vec p\\in S_i}\\sum_{\\vec q\\in S_i}\\|\\vec p-\\vec q\\|^2\n\\tag{1}\\]\nAlt i alt får vi altså, at \\(SUMPAR\\) giver summen af hvert punkts gennemsnitlige kvadrerede afstand til alle punkter i samme gruppe som sig selv (inklusiv sig selv).\nIdéen er så nu, at vi vil prøve at bestemme grupperne \\(S_1, S_2, \\dots, S_k\\) sådan, at denne sum bliver så lille så muligt. Det vil nemlig svare til, at de punkter, der ligger tæt på hinanden, kommer i samme gruppe, og punkter, som ligger langt væk fra hinanden, kommer i forskellige grupper.\nDet er desværre ikke lige til at finde den optimale løsning på dette problem, men her angives en metode/algoritme, som forhåbentlig finder en god løsning.\n\n\nAlgoritme\nVi vil nu se på en metode til at finde en god løsning til \\(K\\)-means problemet. Vi får her brug for “midterpunktet” for hver gruppe, som vi vil kalde for \\(\\vec{\\mu_1},\\vec{\\mu_2},...,\\vec{\\mu_k}\\). Ved midterpunktet vil vi simpelthen bare forstå gennemsnittet af alle punkter i den pågældende gruppe.\nI algoritmen vil vi prøve at minimere følgende sum\n\\[\nSUMMIDT=\\sum_{i=1}^{k}\\sum_{\\vec p\\in S_i}\\|\\vec p-\\vec{\\mu_i}\\|^2\n\\tag{2}\\]\nHer summeres altså den kvadrerede afstand fra hvert punkt til midterpunktet for gruppen, som punktet er i. Og det gør man så for alle grupper og lægger alle de kvadredede afstande sammen. Senere vil vi se på sammenhængen mellem summen \\(SUMPAR\\) og summen \\(SUMMIDT\\).\nSpørgsmålet er nu, hvordan man kommer igang med at fastlægge grupper og midterpunkter, for vi kender ikke mængderne \\(S_1,S_2,....,S_k\\) og dermed heller ikke midterpunkterne \\(\\vec{\\mu_1},\\vec{\\mu_2},...,\\vec{\\mu_k}\\).\nFor at løse det problem vil vi bruge følgende fremgangsmåde/algoritme:\n\nStart med at tage hver eneste observation og tilføj den til en tilfældig gruppe (der skal mindst være én observation i hver gruppe).\nMidterpunkterne bestemmes ved at lade\n\n\\[\n\\vec{\\mu_i}=\\frac{1}{|S_i|}\\sum_{\\vec p\\in S_i}\\vec p\n\\]\n\nFor hver af de \\(n\\) observationer findes det midterpunkt, der har den mindste afstand til punktet. Hvis det for en observation \\(\\vec{x_i}\\) er midterpunktet \\(\\vec{\\mu_a}\\), der er nærmest, skal \\(\\vec{x_i}\\) være i mængden \\(S_a\\).\nGentag trin 2 og 3 indtil vi kommer til et tidspunkt, hvor ingen punkter kommer til at skifte til en anden gruppe.\n\nDet virker jo meget rimeligt. Så er spørgsmålet bare, om denne fremgangsmåde virkelig fungerer! Det vil vi se nærmere på i afsnittet om sammenhængen mellem SUMPAR og SUMMIDT. Men lad os starte med at se på et par eksempler.\n\n\nEksempel på beregning af midterpunkter\nFørst kunne det måske være rart at få en fornemmelse af, hvorfor \\(\\vec{\\mu_1},\\vec{\\mu_2},...,\\vec{\\mu_k}\\) betegnes som midterpunkter.\n\nEksempel 1 Vi forestiller os, at vi har to grupper med følgende punkter:\n\nGruppe 1 med punkterne \\((3,9)\\) og \\((7,11)\\).\nGruppe 2 med punkterne \\((10,30)\\), \\((17,34)\\), \\((12,27)\\) og \\((11,32)\\).\n\nSom nævnt tidligere kan vi tænke på hvert punkt som stedvektoren til punktet.3 Vi kan nu finde midterpunktet for den første gruppe:\n3 Husk at et punkt og stedvektoren til punktet har samme koordinater.\\[\\vec{\\mu_1}=\\frac{1}{|S_1|}\\sum_{\\vec p\\in S_1}\\vec p = \\frac{\\begin{pmatrix}\n3 \\\\ 9\\end{pmatrix} + \\begin{pmatrix}\n7 \\\\ 11\\end{pmatrix}}{2}= \\frac{\\begin{pmatrix}\n10 \\\\ 20\\end{pmatrix} }{2} = \\begin{pmatrix}\n5 \\\\ 10\\end{pmatrix}\\]\nMidterpunktet for den første gruppe har altså koordinatsæt \\((5,10)\\).\nMidterpunktet for den anden gruppe bliver tilsvarende\n\\[\\vec{\\mu_2}=\\frac{1}{|S_2|}\\sum_{\\vec p\\in S_2}\\vec p = \\frac{\\begin{pmatrix}\n10 \\\\ 30\\end{pmatrix} + \\begin{pmatrix}\n17 \\\\ 34\\end{pmatrix} + \\begin{pmatrix}\n12 \\\\ 27\\end{pmatrix} + \\begin{pmatrix}\n11 \\\\ 32\\end{pmatrix}}{4}= \\frac{\\begin{pmatrix}\n50 \\\\ 123 \\end{pmatrix} }{4} = \\begin{pmatrix}\n12.5 \\\\ 30.75 \\end{pmatrix}\\]\nMidterpunktet for den anden gruppe har så koordinatsæt \\((12.5, 30.75)\\).\nDette er illustreret i figur 2.\n\n\n\n\n\n\nFigur 2: To grupper af punkter (orange og blå) sammen med de tilhørende midterpunkter \\(\\vec{\\mu_1}\\) og \\(\\vec{\\mu_2}\\).\n\n\n\nPå figur 2 bliver det tydeligt, hvorfor det er fornuftigt at vælge midterpunkterne, som det sker i trin 2 i algoritmen – midterpunkterne ligger simpelthen i “midten” af hver gruppe.\n\n\n\nEksempel på algoritmen\nLad os nu prøve at bruge algoritmen på punkterne fra eksempel 1. I figur 3 ses punkterne indtegnet, men uden angivelse af hvilken gruppe hvert enkelt punkt tilhører.\n\n\n\n\n\n\n\n\nFigur 3: Illustration af punkter som ønskes inddelt i 2 grupper.\n\n\n\n\n\nI trin 1 skal vi tilføje hver observation i en tilfældig gruppe. Et sådant valg ses i figur 4.\n\n\n\n\n\n\n\n\nFigur 4: Tilfældig inddeling af punkterne i 2 grupper.\n\n\n\n\n\nVi skal nu have beregnet midtpunkterne i hver af de to grupper. Gør man det fås:\n\\[\n\\vec{\\mu_1} = \\begin{pmatrix} 8.33 \\\\ 22.0 \\end{pmatrix} \\quad \\textrm{og} \\quad \\vec{\\mu_2} = \\begin{pmatrix} 11.7 \\\\ 25.7 \\end{pmatrix}\n\\] Disse to midtpunkter er indtegnet i figur 5 og markeret med et plus.\n\n\n\n\n\n\n\n\nFigur 5: Tilfældig inddeling af punkterne i 2 grupper og med tilhørende midtpunkter, som her er markeret med et plus.\n\n\n\n\n\nI trin 3 skal vi have beregnet afstand fra hver af de 6 punkter til hver af de to midtpunkter. For eksempel bliver afstanden \\(d\\) fra punktet \\((3,9)\\) til punktet med stedvektor \\(\\vec{\\mu_1}\\) være:\n\\[\nd=\\sqrt{(3-8.33)^2+(9-22.0)^2}=14.05\n\\] Resultatet af at beregne alle afstande på denne måde ses i tabel 1.\n\n\n\n\n\n\n\n\n\n\n\n\nAfstand til \\(\\vec{\\mu_1}\\)\nAfstand til \\(\\vec{\\mu_2}\\)\n\n\n\n\n14.05\n18.79\n\n\n11.08\n15.39\n\n\n8.172\n4.643\n\n\n14.8\n9.894\n\n\n6.2\n1.374\n\n\n10.35\n6.368\n\n\n\n\n\n\nTabel 1: Afstanden fra de 6 datapunkter til hvert af midtpunkterne \\(\\vec{\\mu_1}\\) og \\(\\vec{\\mu_2}\\).\n\n\n\n\nVi skal nu afgøre hvilken gruppe, de enkelte punkter skal tilhøre, ved at se på hvilket midtpunkt som hvert enkelt punkt ligger tættest på. For eksempel kan vi i tabel 1 se, at det første punkt \\((3,9)\\) ligger tættest på \\(\\vec{\\mu_1}\\), og det punkt skal derfor (fortsat) hører til gruppe 1.\nI tabel 2 ses den oprindelige gruppe samt den nye gruppe for hvert punkt.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfstand til \\(\\vec{\\mu_1}\\)\nAfstand til \\(\\vec{\\mu_2}\\)\nOpr. gruppe\nNy gruppe\n\n\n\n\n14.05\n18.79\n1\n1\n\n\n11.08\n15.39\n2\n1\n\n\n8.172\n4.643\n1\n2\n\n\n14.8\n9.894\n2\n2\n\n\n6.2\n1.374\n1\n2\n\n\n10.35\n6.368\n2\n2\n\n\n\n\n\n\nTabel 2: Afstanden fra de 6 datapunkter til hvert af midtpunkterne \\(\\vec{\\mu_1}\\) og \\(\\vec{\\mu_2}\\) samt en angivelse af, hvilken gruppe punktet oprindeligt tilhørte, og hvilken gruppe punktet tilhører efter trin 3.\n\n\n\n\nI figur 6 ses punkterne indtegnet med en angivelse af den nye inddeling (men stadig med de først beregnede midterpunkter).\n\n\n\n\n\n\n\n\nFigur 6: Inddeling af punkterne i 2 grupper efter første gennemløb af algoritmen.\n\n\n\n\n\nVi skal nu i gang med det næste gennemløb af algoritmen, og vi bestemmer derfor først de nye midtpunkter. Gør man det fås:\n\\[\n\\vec{\\mu_1} = \\begin{pmatrix} 5.00 \\\\ 10.0 \\end{pmatrix} \\quad \\textrm{og} \\quad \\vec{\\mu_2} = \\begin{pmatrix} 12.5 \\\\ 30.8 \\end{pmatrix}\n\\]\nDe to nye midtpunkter ses indtegnet i figur 7 – igen markeret med et plus.\n\n\n\n\n\n\n\n\nFigur 7: Inddeling af punkterne i 2 grupper efter første gennemløb af algoritmen og med de nye tilhørende midtpunkter indtegnet.\n\n\n\n\n\nVi kan nu igen udregne afstande fra alle punkter til de to nye midtpunkter og finde ud af om nogle af punkterne eventuelt skal skifte gruppe. Resultatet ses i tabel 3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfstand til \\(\\vec{\\mu_1}\\)\nAfstand til \\(\\vec{\\mu_2}\\)\nOpr. gruppe\nNy gruppe\n\n\n\n\n2.236\n23.73\n1\n1\n\n\n2.236\n20.5\n1\n1\n\n\n20.62\n2.61\n2\n2\n\n\n26.83\n5.551\n2\n2\n\n\n18.38\n3.783\n2\n2\n\n\n22.8\n1.953\n2\n2\n\n\n\n\n\n\nTabel 3: Afstanden fra de 6 datapunkter til hvert af de nye midtpunkterne \\(\\vec{\\mu_1}\\) og \\(\\vec{\\mu_2}\\) samt en angivelse af, hvilken gruppe punktet oprindeligt tilhørte, og hvilken gruppe punktet tilhører efter trin 3 (andet gennemløb af algoritmen).\n\n\n\n\nVi kan nu se, at ingen af punkterne har skiftet gruppe, og algoritmen stopper derfor. Den endelige inddeling i grupper bliver derfor som vist i figur 7, hvilket nok også er den inddelingen, som vi ville have valgt bare ved at kigge på punkterne med det blotte øje.\n\n\nFornuftigt valg af midterpunkter og grupper\nVi vil nu argumentere for, hvorfor algoritmen virker. Vi starter med at se på, hvorfor det er fornuftigt at vælge midterpunkterne, som vi gør i trin 2 i algoritmen.\nDa vi med algoritmen ønsker, at summen i (2) kaldet \\(SUMMIDT\\) skal minimeres, vil vi se, at valget af \\(\\vec{\\mu_1},\\vec{\\mu_2},...,\\vec{\\mu_k}\\) netop minimerer denne sum, når vi tænker, at grupperne er fastlagt.\nVed summen \\(SUMMIDT\\) har \\(\\vec{\\mu_i}\\) kun en effekt på delen hørende til gruppen \\(S_i\\), altså \\[\\sum_{\\vec p\\in S_i}\\|\\vec p-\\vec{\\mu_i}\\|^2\\]\nFor en vektor \\(\\vec v\\), har vi følgende sammenhæng mellem længde og skalarprodukt/prikprodukt:\n\\[\\|\\vec v\\|^2=\\vec v\\cdot \\vec v \\tag{3}\\]\nDette gør, at vi kan omskrive vores sum for gruppen \\(S_i\\) til\n\\[\\sum_{\\vec p\\in S_i}{(\\vec  p-\\vec{\\mu_i})\\cdot (\\vec p-\\vec{\\mu_i})}\\] Skalarproduktet udregnes ved at tage summen af produktet af tilsvarende koordinater for vektorerne. Hvis vi lader \\(p_m\\) og \\(\\mu_{i,m}\\) betegne det \\(m\\)’te koordinat af henholdsvis \\(\\vec p\\) og \\(\\vec{\\mu_i}\\), så kan ovenstående sum skrives som\n\\[\\sum_{\\vec p\\in S_{i}}\\sum_{m=1}^{d}{(p_m-\\mu_{i,m})\\cdot (p_m-\\mu_{i,m})} = \\sum_{m=1}^{d} \\sum_{\\vec p\\in S_{i}} {(p_m-\\mu_{i,m})\\cdot (p_m-\\mu_{i,m})}\\] Her vil valget af \\(\\mu_{i,m}\\) kun have effekt på \\[\\sum_{\\vec  p\\in S_{i}}{(p_m-\\mu_{i,m})\\cdot (p_m-\\mu_{i,m})}\\] I denne sum har vi ikke længere vektorer, og vi kan derfor benytte anden kvadratsætning til at få\n\\[\\sum_{\\vec p\\in S_i}{(p_m^2-2\\cdot p_m\\cdot \\mu_{i,m}+\\mu_{i,m}^2)}\\] For at finde ud af hvordan \\(\\mu_{i,m}\\) skal vælges for at lave summen mindst mulig, differentieres ovenstående udtryk med hensyn til \\(\\mu_{i,m}\\) og udtrykket sættes lig med \\(0\\):\n\\[\\begin{align}\n\\frac{\\partial}{\\partial \\mu_{i,m}} \\sum_{\\vec p\\in S_i}{(p_m^2-2\\cdot p_m\\cdot \\mu_{i,m}+\\mu_{i,m}^2)}\n&= \\sum_{\\vec p\\in S_i} \\frac{\\partial}{\\partial \\mu_{i,m}} {(p_m^2-2\\cdot p_m\\cdot \\mu_{i,m}+\\mu_{i,m}^2)}\\\\\n&= \\sum_{\\vec p\\in S_i}{(-2\\cdot p_m+2\\cdot \\mu_{i,m})}=0\n\\end{align}\\]\nDen sidste ligning kan omskrives til \\[ \\sum_{\\vec p\\in S_i}{2\\cdot \\mu_{i,m}} = \\sum_{\\vec p\\in S_i}{2\\cdot p_m}\\] Ved division med \\(2\\) fås \\[ \\sum_{\\vec p\\in S_i}{\\mu_{i,m}} = \\sum_{\\vec p\\in S_i}{p_m}\\]\nVi kan nu udnytte at hvert led i den første sum slet ikke afhænger af \\(\\vec p\\), og da summen består af\\(|S_i|\\) led fås \\[|S_i| \\cdot  \\mu_{i,m}= \\sum_{\\vec p\\in S_i}{p_m}\\]\nAltså er \\[\\mu_{i,m}=\\frac{1}{|S_i|} \\sum_{\\vec p\\in S_i}p_m\\] Hvis dette valg tages for alle koordinater for \\(\\vec{\\mu_i}\\) svarer det til \\[\\vec{\\mu_{i}}=\\frac{1}{|S_i|} \\sum_{\\vec p\\in S_i} \\vec p\\] som netop er den måde \\(\\vec{\\mu_i}\\) vælges på ved trin \\(2\\) i algoritmen.\nHer glemte vi at argumentere for, at valget af \\(\\mu_{i,m}\\) rent faktisk gav et lokalt minimum, men lidt løst kan man sige, at hvis \\(\\mu_{i,m}\\) enten vælges alt for lille eller stor, vil afstanden og dermed også den kvadrerede afstand til punkterne i gruppen \\(S_i\\) blive store. Det kan selvfølgelig også bevises helt formelt.\nLad os nu se på valget af grupper ved trin \\(3\\) i algoritmen. For en punkt \\(\\vec p\\) vælges den gruppe \\(S_i\\), hvor midtpunktet \\(\\vec{\\mu_i}\\) er tættest på \\(\\vec p\\). Derved er det oplagt, at denne proces minimerer summen \\(SUMMIDT\\) i (2), når vi har fastholdt midterpunkterne \\(\\vec{\\mu_1},\\vec{\\mu_2},...,\\vec{\\mu_k}\\).\nNår et punkt skifter gruppe vil \\(SUMMIDT\\) ikke længere være optimal i forhold til \\(\\vec{\\mu_1},\\vec{\\mu_2},...,\\vec{\\mu_k}\\) før de bliver opdateret igen. I algoritmen bliver disse to trin netop gentaget, indtil ingen punkter skifter gruppe, hvorved \\(SUMMIDT\\) har ramt et lokalt minimum i forhold til valg af gruppe for det enkelt punkt og valg af midterpunkt for hver gruppe.\n\n\nSammenhængen mellem SUMPAR og SUMMIDT\nNu vil vi endelig se på sammenhængen mellem de to summer \\(SUMMIDT\\) i (2) og \\(SUMPAR\\) i (1). Vi vil vise, at \\[SUMPAR=2\\cdot SUMMIDT\\] når midterpunkterne er valgt på denne måde\n\\[\n\\vec{\\mu_{i}}=\\frac{1}{|S_i|} \\sum_{\\vec p\\in S_i}\\vec p \\quad \\quad \\textrm{og derved} \\quad \\quad |S_i|\\cdot \\vec{\\mu_{i}}=\\sum_{\\vec p\\in S_i} \\vec p\n\\tag{4}\\]\nDet betyder, at hvis vi minimerer summen \\(SUMMIDT\\), så har vi også minimeret summen \\(SUMPAR\\), som var det vi oprindeligt ønskede.\nVi starter med at se på summen \\(SUMPAR\\) i (1) dog kun for en af grupperne \\(S_a\\) og uden faktoren \\(\\frac{1}{|S_i|}\\). Altså ser vi på summen \\[\n\\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\|\\vec p-\\vec q\\|^2\n\\tag{5}\\]\nVed at bruge sammenhængen mellem længde af vektor og skalarprodukt får vi\n\\[\n\\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}(\\vec p-\\vec q)\\cdot(\\vec p-\\vec q)\n\\]\nHer bruger vi nu, hvad der svarer til anden kvadratsætning for vektorer og vi omskriver tilbage til længder ved at bruge (3)\n\\[\n\\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}(\\|\\vec p\\|^2+\\|\\vec q\\|^2-2\\cdot \\vec p\\cdot \\vec q)\n\\]\nDenne dobbeltsum opdeles nu i tre dobbeltsummer og \\(-2\\) kan trækkes ud af den ene\n\\[\n\\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\|\\vec p\\|^2+\\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\|\\vec q\\|^2-2\\cdot \\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a} \\vec p\\cdot \\vec q\n\\]\nDe to første dobbeltsummer er faktisk ens og derfor får vi\n\\[\n2\\cdot \\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\|\\vec p\\|^2-2\\cdot \\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\vec p\\cdot \\vec q\n\\tag{6}\\]\nFor at komme videre med ovenstående vælger vi at se på dobbeltsummen\n\\[\n\\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\vec p\\cdot \\vec q\n\\] Den inderste sum afhænger ikke af \\(\\vec p\\) og derfor kan \\(\\vec p\\) sættes uden for sumtegnet4:\n4 Husk på at den distributive regel også gælder for vektorer: \\(\\vec a \\cdot \\vec b + \\vec a \\cdot \\vec c = \\vec a \\cdot \\left (\\vec b + \\vec c \\right)\\)\\[\n\\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\vec p\\cdot \\vec q = \\sum_{\\vec p\\in S_a}\\vec p\\cdot \\left (\\sum_{\\vec q\\in S_a} \\vec q \\right )\n\\]\nFra valget af \\(\\vec{\\mu_a}\\) ved vi fra (4), at \\(|S_a|\\cdot \\vec{\\mu_{a}}=\\sum_{\\vec q \\in S_a} \\vec q\\). Bruger vi det får vi\n\\[\n\\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\vec p\\cdot \\vec q = \\sum_{\\vec p\\in S_a}\\vec p\\cdot |S_a|\\cdot \\vec{\\mu_{a}}\n\\] Sætter vi \\(|S_a|\\cdot \\vec{\\mu_{a}}\\) uden for summmen5 og udnytter ovenstående én gang til, får vi:\n5 Bemærk, at vi igen her benytter den distributive regel for vektorer.\\[\\begin{align}\n\\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a} \\vec p\\cdot \\vec q &= |S_a|\\cdot \\vec{\\mu_{a}} \\cdot \\left ( \\sum_{\\vec p\\in S_a}\\vec p \\right ) \\\\\n&= \\left ( |S_a|\\cdot \\vec{\\mu_{a}} \\right ) \\cdot \\left ( |S_a|\\cdot \\vec{\\mu_{a}} \\right )\n\\end{align}\\]\nVi har nu et prikprodukt mellem to vektorer, som hver især er ganget med en skalar (her \\(|S_a|\\)). Bruger vi den kommutative lov6 for at gange med en skalar, får vi\n6 Den kommutative lov siger, at \\(k \\cdot (\\vec a \\cdot \\vec b) =  (k \\cdot\\vec a) \\cdot (\\vec b) =  (\\vec a ) \\cdot (k \\cdot\\vec b)\\)\\[\n\\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a} \\vec p\\cdot \\vec q = |S_a|^2 \\cdot \\| \\vec{\\mu_{a}} \\|^2\n\\]\nDet må derfor betyde, at \\[\n|S_a|^2\\cdot \\|\\vec{\\mu_a}\\|^2-\\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\vec p\\cdot \\vec q=0 \\quad \\Leftrightarrow  \\quad\n2 \\cdot |S_a|^2\\cdot \\|\\vec{\\mu_a}\\|^2-2\\cdot\\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\vec p\\cdot \\vec q=0\n\\]\nDa dette giver \\(0\\), kan det tilføjes til udtrykket i (6):\n\\[\\begin{align}\n2\\cdot \\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\|\\vec p\\|^2&-2\\cdot \\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\vec p\\cdot \\vec q = \\\\\n2\\cdot \\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\|\\vec p\\|^2-2\\cdot \\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\vec p\\cdot \\vec q &+\n2 \\cdot |S_a|^2\\cdot \\|\\vec{\\mu_a}\\|^2-2\\cdot\\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\vec p\\cdot \\vec q = \\\\\n2\\cdot \\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\|\\vec p\\|^2 +\n2 \\cdot |S_a|^2 &\\cdot \\|\\vec{\\mu_a}\\|^2-4\\cdot\\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\vec p\\cdot \\vec q\n\\end{align}\\]\nI den sidste dobbeltsum kan \\(\\vec p\\) igen tages ud af den inderste sum og vi kan igen udnytte at \\(|S_a|\\cdot \\vec{\\mu_{a}}=\\sum_{\\vec q \\in S_a} \\vec q\\). Derved får vi\n\\[\n2\\cdot \\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\|\\vec p\\|^2 +\n2 \\cdot |S_a|^2\\cdot \\|\\vec{\\mu_a}\\|^2-4\\cdot\\sum_{\\vec p\\in S_a}\\vec p\\cdot |S_a|\\cdot \\vec{\\mu_{a}}\n\\]\nVed den første dobbeltsum ses det, at leddene ikke afhænger af \\(\\vec q\\) og derfor er \\(\\sum_{\\vec q\\in S_a}\\|\\vec p\\|^2 = |S_a| \\cdot \\|\\vec p\\|^2\\) (fordi der er \\(|S_a|\\) led i summen). Det vil sige, at vi kan omskrive til\n\\[\n2\\cdot \\sum_{\\vec p\\in S_a}|S_a| \\cdot \\|\\vec p\\|^2 +\n2 \\cdot |S_a|^2\\cdot \\|\\vec{\\mu_a}\\|^2-4\\cdot\\sum_{\\vec p\\in S_a}\\vec p\\cdot |S_a|\\cdot \\vec{\\mu_{a}}\n\\]\nVi kan nu se, at \\(2 \\cdot |S_a|\\) indgår i alle led og vi kan derfor skrive:\n\\[\n2\\cdot |S_a| \\cdot \\left ( \\sum_{\\vec p\\in S_a} \\|\\vec p\\|^2  +\n|S_a|\\cdot \\|\\vec{\\mu_a}\\|^2-2\\cdot\\sum_{\\vec p\\in S_a}\\vec p\\cdot \\vec{\\mu_{a}} \\right )\n\\]\nHer kan \\(|S_a|\\cdot \\|\\mu_a\\|^2\\) laves om til en sum, hvor alle led er \\(\\|\\mu_a\\|^2\\). Det vil sige\n\\[\n2\\cdot |S_a| \\cdot \\left ( \\sum_{\\vec p\\in S_a} \\|\\vec p\\|^2  +\n\\sum_{\\vec p\\in S_a} \\|\\vec{\\mu_a}\\|^2-2\\cdot\\sum_{\\vec p\\in S_a}\\vec p\\cdot \\vec{\\mu_{a}} \\right )\n\\]\nHele udtrykket kan nu samles i én sum:\n\\[\n2\\cdot |S_a| \\sum_{\\vec p\\in S_a} \\left (  \\|\\vec p\\|^2  +\n\\|\\vec{\\mu_a}\\|^2-2\\cdot\\vec p\\cdot \\vec{\\mu_{a}} \\right )\n\\] Ved brug af anden kvadratsætning for vektorer kan dette omskrives til\n\\[\n2\\cdot |S_a| \\sum_{\\vec p\\in S_a}   (\\vec p - \\vec{\\mu_a}) \\cdot (\\vec p - \\vec{\\mu_a}) = 2\\cdot |S_a| \\sum_{\\vec p\\in S_a} \\| \\vec p - \\vec{\\mu_a} \\|^2\n\\] Nu kan man jo godt have glemt, hvad det overhovedet var, vi var igang med at regne på! Men vi minder om, at det var udtrykket i (5). Det vil sige, at vi er kommet frem til, at\n\\[\n\\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\|\\vec p-\\vec q\\|^2 = 2\\cdot |S_a| \\sum_{\\vec p\\in S_a} \\| \\vec p - \\vec{\\mu_a} \\|^2\n\\] Eller skrevet på en anden måde:\n\\[\n\\frac{1}{|S_i|}\\sum_{\\vec p\\in S_i}\\sum_{\\vec q\\in S_i}\\|\\vec p-\\vec q\\|^2 = 2 \\sum_{\\vec p\\in S_i} \\| \\vec p - \\vec{\\mu_i} \\|^2\n\\] Summerer vi over alle \\(k\\) grupper får vi: \\[\n\\sum_{i=1}^k \\frac{1}{|S_i|}\\sum_{\\vec p\\in S_i}\\sum_{\\vec q\\in S_i}\\|\\vec p-\\vec q\\|^2 = 2 \\sum_{i=1}^k \\sum_{\\vec p\\in S_i} \\| \\vec p - \\vec{\\mu_i} \\|^2\n\\] Sammenligner vi med (1) og (2) har vi netop vist, at\n\\[\nSUMPAR = 2 \\cdot SUMMIDT\n\\]\nDet vil altså sige, at hvis vi minimerer summen \\(SUMMIDT\\), så har vi også minimeret summen \\(SUMPAR\\), hvilket præcis var, hvad vi oprindeligt ønskede.\n\n\nOpsummering/optimal løsning\nNu har vi set på selve algoritmen og fundet ud af, at den finder et lokalt minimum for summen \\(SUMPAR\\), som man ønsker minimeret. Der er dog ingen garanti for, at man opnår et globalt minimum, eller hvor lang tid algoritmen er om at finde en løsning.\nDet er egentlig heller ikke noget problem at få lavet en algoritme, der finder en optimal løsning, problemet er blot, at den vil køre alt for langsomt. En sådan optimal algoritme kan laves ved blot at undersøge hver mulig inddeling i grupper og så finde den inddeling, der giver den mindste værdi af \\(SUMPAR\\). Dog vil det være sådan, at selv ved blot \\(2\\) grupper og \\(100\\) punkter vil der være \\(2^{99}\\) muligheder7, der skal tjekkes. At undersøge så mange muligheder er ikke praktisk muligt – selv ikke på en computer!\n7 Fordi for hvert punkt kan punktet enten være i den ene eller den anden gruppe. Det giver i første omgang \\(2^{100}\\) grupper. Nu vil en inddeling hvor for eksempel punktet \\(A\\) og \\(B\\) er i gruppe \\(1\\), mens \\(C\\) er i gruppe \\(2\\) være den samme inddeling, som hvis \\(C\\) er i gruppe \\(1\\) og \\(A\\) og \\(B\\) er i gruppe \\(2\\). På grund af denne symmetri ender vi derfor samlet set med \\(2^{100}/2=2^{99}\\) grupper.\n\nK-means ikke blot med punkter\nIndtil videre har vi udelukkende set på data som værende punkter, hvor vi kan anvende euklidisk afstand for at måle afstanden mellem punkterne. Det kunne dog være langt mere interessant f.eks. at arbejde med mennesker og information om dem (f.eks. alder, køn, forbrug og så videre) og stadigvæk med et ønske om at inddele disse mennesker i et bestemt antal grupper, hvor der er stor ligmed mellem dem indenfor samme gruppe. Her skal man selvfølgelig have tænkt lidt over, hvordan man kommer fra mennesker til punkter og efterfølgende får noget, der svarer til euklidisk afstand. Det kan man læse meget mere om under feature-skalering."
  },
  {
    "objectID": "materialer/kunstige_neuroner/smartere_end_adaline.html",
    "href": "materialer/kunstige_neuroner/smartere_end_adaline.html",
    "title": "AI MAT - matematikken bag magien",
    "section": "",
    "text": "I noten om perceptroner beskrev vi perceptron learning algoritmen, som altid konvergerer, hvis data er lineært separabel. Men verden er sjældent lineært separabel, og derfor introducerede vi ADALINE algoritmen, som også virker, selvom data ikke er lineært separabel. I noten om kunstige neuroner beskrev vi en helt tredje metode.\nVi vil her med et enkelt lille eksempel afsløre, at ADALINE ikke altid er så smart, som man kunne tro. Dernæst vil vi forklare hvordan kunstige neuroner, kan være en løsning på det skitserede problem.\nVi vil se på data i nedenstående tabel\n\n\n\n\\(x_1\\)\n\\(x_2\\)\nTargetværdi\n\n\n\n\n\\(-0.5\\)\n\\(0.5\\)\n\\(1\\)\n\n\n\\(-0.3\\)\n\\(0.3\\)\n\\(1\\)\n\n\n\\(-0.1\\)\n\\(0.7\\)\n\\(1\\)\n\n\n\\(0.1\\)\n\\(0.4\\)\n\\(-1\\)\n\n\n\\(-0.1\\)\n\\(0.2\\)\n\\(-1\\)\n\n\n\\(0.1\\)\n\\(-0.1\\)\n\\(-1\\)\n\n\n\nBemærk, at i ADALINE er targetværdien \\(t \\in \\{-1,1\\}\\).\nI figur 1 har vi indtegnet punkterne \\((x_1,x_2)\\) og farvet punkterne med en targetværdi på \\(1\\) blå og dem med en targetværdi på \\(-1\\) røde.\n\n\n\n\n\n\nFigur 1: Punkter med en targetværdi på \\(1\\) er blå og dem med en targetværdi på \\(-1\\) er røde.\n\n\n\nDet er tydeligt, at punkterne er lineært separable og den indtegnede linje er også den som ADALINE giver1. Du kan selv prøve ADALINE her. De estimerede vægte er \\(w_0=-0.9346, w_1=-2.838\\) og \\(w_2=1.668\\).Det vil sige, at den indtegnede linje har ligning\n1 Her er alle startvægte sat til \\(0\\), learning rate er på \\(0.1\\), stop-kriterie er på \\(0.000001\\) og maksimalt antal iterationer er sat til \\(50000\\).\\[\n-0.9346-2.838 x_1 + 1.668x_2=0\n\\]\nDet er alt sammen meget fint, men lad os nu prøve at indtegne et nyt rødt punkt:\n\n\n\n\\(x_1\\)\n\\(x_2\\)\nTargetværdi\n\n\n\n\n\\(1\\)\n\\(-1\\)\n\\(-1\\)\n\n\n\nDet nye punkt er indtegnet i figur 2 sammen med de øvrige seks punkter. Det er tydeligt, at data stadig er lineært separabel.\n\n\n\n\n\n\nFigur 2: Et nyt rødt punkt er indtegnet og data er stadig lineært separabel.\n\n\n\nHvis vi prøver at køre ADALINE algoritmen fås linjen, som er indtegnet i figur 3. Vi kan allerede se nu, at det er helt skørt. Data er lineært separabel, men alligevel er der et rødt punkt, som bliver klassificeret forkert – faktisk var den oprindelige linje fra figur 1 bedre.\n\n\n\n\n\n\nFigur 3: Et nyt rødt punkt er indtegnet og den linje, som ADALINE finder.\n\n\n\nDet er jo ikke ligefrem super overbevisende. Data er lineært separabel og alligevel kan ADALINE ikke finde ud af at finde en ret linje, som kan adskille de røde punkter fra de blå!\nHvis vi skal forstå, hvad der sker, må vi se lidt nærmere på den tabsfunktion, som ADALINE forsøger at mininere. Fra afsnittet om ADALINE ved vi, at tabsfunktionen2 er\n2 Bemærk her, at det ikke er afgørende, at der er ganget med \\(1/2\\) – det viser sig bare smartere senere.\\[\n\\begin{aligned}\nE(w_0, w_1, &\\dots, w_n)\\\\ &= \\frac{1}{2} \\sum_{m=1}^{M} \\left (t^{(m)}-\n(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)}) \\right)^2\n\\end{aligned}\n\\tag{1}\\]\nhvor det \\(m\\)’te træningseksempel er \\[(x_1^{(m)}, x_2^{(m)}, \\dots, x_n^{(m)}, t^{(m)})\\]\nDet vil sige, at det \\(m\\)’te træningseksempel giver et bidrag til tabsfunktionen på\n\\[\n\\left ( t^{(m)}- (w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)}) \\right)^2\n\\]\nFor et blåt punkt med \\(t^{(m)}=1\\) vil det sige, at bidraget til tabsfunktionen er præcis \\(0,\\) hvis \\[\n1- \\left (w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)} \\right) =0\n\\] og for et rødt punkt med \\(t^{(m)}=-1\\) er bidraget til tabsfunktionen præcis \\(0,\\) hvis \\[\n-1- \\left (w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)} \\right)=0\n\\] Nu er \\(1- (w_0 + w_1 \\cdot x_1 + \\cdots + w_n \\cdot x_n)=0\\) og \\(-1- (w_0 + w_1 \\cdot x_1 + \\cdots + w_n \\cdot x_n)=0\\) jo bare ligninger for rette linjer3. Disse linjer ses indtegnet på figur 4 (som henholdsvis en blå og rød stiplet linje) sammen med de oprindelige seks punkter og den linje, som ADALINE fandt baseret på disse seks punkter. Samtidig er det for hvert punkt markeret, hvor meget dette punkt bidrager til tabsfunktionen.\n3 Det er i hvert tilfælde \"bare linjer\", når \\(n=2\\). Hvis \\(n=3\\), er der tale om ligningen for en plan, og hvis \\(n&gt;3\\), kalder man det for ligningen for en \"hyperplan\". Men sidstnævnte er visuelt svære at forestille sig, fordi koordinatsystemet, disse hyperplaner skal tegnes i, har en dimension større end \\(3\\). Og de er ikke så nemme at tegne!\n\n\n\n\n\nFigur 4: Punkter med en targetværdi på \\(1\\) er blå og dem med en targetværdi på \\(-1\\) er røde. Den sorte linje med ligning \\(w_0+w_1 x_1 + w_2 x_2=0\\) svarer til den ADALINE fandt. Den blå stiplede linje har ligning \\(1-(w_0+w_1 x_1 + w_2 x_2)=0\\), mens den røde stiplede linje har ligning \\(-1-(w_0+w_1 x_1 + w_2 x_2)=0\\).\n\n\n\nDet ses nu på figur 4, at blå punkter, som ligger tæt på den blå stiplede linje, bidrager mindst til tabsfunktionen, mens røde punkter, som ligger tæt på den røde stiplede linje, ligeledes bidrager mindst til tabsfunktionen. Den samlede værdi af tabsfunktionen4 er her \\(0.75\\).\n4 Værdien udregnes ved at lægge alle bidragene sammen og gange med \\(\\frac{1}{2}\\). Jævnfør udtrykket for tabsfunktionen i (1).Laver vi nu samme øvelse med det ekstra punkt fås resultat i figur 5.\n\n\n\n\n\n\nFigur 5: I alt syv punkter sammen med den sorte linje med ligning \\(w_0+w_1 x_1 + w_2 x_2=0\\) svarer til den ADALINE finder. Punkter med en targetværdi på \\(1\\) er blå og dem med en targetværdi på \\(-1\\) er røde. Den blå stiplede linje har ligning \\(1-(w_0+w_1 x_1 + w_2 x_2)=0\\), mens den røde stiplede linje har ligning \\(-1-(w_0+w_1 x_1 + w_2 x_2)=0\\). Den samlede værdi af tabsfunktionen er her \\(2.00\\).\n\n\n\nIgen ser vi, at blå punkter tæt på den blå stiplede linje bidrager mindst til tabsfunktionen og tilsvarende for de røde punkter, som ligger tæt på den røde stiplede linje. Det nye punkts bidrag til tabsfunktionen bliver derfor her det mindste bidrag blandt alle de røde punkter. Den samlede værdi af tabsfunktionen er her \\(2.00\\).\nHvis vi i stedet prøver at bruge vores egen oprindelige linje (baseret på de seks første punkter), som rent faktisk kunne adskille de blå punkter fra de røde, så fås det resultat, som ses i figur 6.\n\n\n\n\n\n\nFigur 6: I alt syv punkter sammen med den sorte linje, som ADALINE giver baseret på de oprindelige seks punkter. Punkter med en targetværdi på \\(1\\) er blå og dem med en targetværdi på \\(-1\\) er røde. Den blå stiplede linje har ligning \\(1-(w_0+w_1 x_1 + w_2 x_2)=0\\), mens den røde stiplede linje har ligning \\(-1-(w_0+w_1 x_1 + w_2 x_2)=0\\). Den samlede værdi af tabsfunktionen er her \\(10.60\\).\n\n\n\nDet er nu tydeligt, at det nye røde punkter ligger så langt væk fra den stiplede røde linje, at det bidrager betydeligt til tabsfunktionen. Derfor er den samlede værdi af tabsfunktionen \\(10.60\\) – og derfor vælger ADALINE linjen i figur 5 til at adskille punkterne. Ikke fordi, det er den linje, som giver den laveste andel af korrekt klassificerede, men fordi det er den linje, som minimerer tabsfunktionen! Det kan jo godt virke lidt skørt, når vi selv kan indtegne en linje, som kan separere alle punkterne."
  },
  {
    "objectID": "materialer/kunstige_neuroner/smartere_end_adaline.html#hvorfor-er-kunstige-neuroner-smartere-end-adaline",
    "href": "materialer/kunstige_neuroner/smartere_end_adaline.html#hvorfor-er-kunstige-neuroner-smartere-end-adaline",
    "title": "AI MAT - matematikken bag magien",
    "section": "",
    "text": "I noten om perceptroner beskrev vi perceptron learning algoritmen, som altid konvergerer, hvis data er lineært separabel. Men verden er sjældent lineært separabel, og derfor introducerede vi ADALINE algoritmen, som også virker, selvom data ikke er lineært separabel. I noten om kunstige neuroner beskrev vi en helt tredje metode.\nVi vil her med et enkelt lille eksempel afsløre, at ADALINE ikke altid er så smart, som man kunne tro. Dernæst vil vi forklare hvordan kunstige neuroner, kan være en løsning på det skitserede problem.\nVi vil se på data i nedenstående tabel\n\n\n\n\\(x_1\\)\n\\(x_2\\)\nTargetværdi\n\n\n\n\n\\(-0.5\\)\n\\(0.5\\)\n\\(1\\)\n\n\n\\(-0.3\\)\n\\(0.3\\)\n\\(1\\)\n\n\n\\(-0.1\\)\n\\(0.7\\)\n\\(1\\)\n\n\n\\(0.1\\)\n\\(0.4\\)\n\\(-1\\)\n\n\n\\(-0.1\\)\n\\(0.2\\)\n\\(-1\\)\n\n\n\\(0.1\\)\n\\(-0.1\\)\n\\(-1\\)\n\n\n\nBemærk, at i ADALINE er targetværdien \\(t \\in \\{-1,1\\}\\).\nI figur 1 har vi indtegnet punkterne \\((x_1,x_2)\\) og farvet punkterne med en targetværdi på \\(1\\) blå og dem med en targetværdi på \\(-1\\) røde.\n\n\n\n\n\n\nFigur 1: Punkter med en targetværdi på \\(1\\) er blå og dem med en targetværdi på \\(-1\\) er røde.\n\n\n\nDet er tydeligt, at punkterne er lineært separable og den indtegnede linje er også den som ADALINE giver1. Du kan selv prøve ADALINE her. De estimerede vægte er \\(w_0=-0.9346, w_1=-2.838\\) og \\(w_2=1.668\\).Det vil sige, at den indtegnede linje har ligning\n1 Her er alle startvægte sat til \\(0\\), learning rate er på \\(0.1\\), stop-kriterie er på \\(0.000001\\) og maksimalt antal iterationer er sat til \\(50000\\).\\[\n-0.9346-2.838 x_1 + 1.668x_2=0\n\\]\nDet er alt sammen meget fint, men lad os nu prøve at indtegne et nyt rødt punkt:\n\n\n\n\\(x_1\\)\n\\(x_2\\)\nTargetværdi\n\n\n\n\n\\(1\\)\n\\(-1\\)\n\\(-1\\)\n\n\n\nDet nye punkt er indtegnet i figur 2 sammen med de øvrige seks punkter. Det er tydeligt, at data stadig er lineært separabel.\n\n\n\n\n\n\nFigur 2: Et nyt rødt punkt er indtegnet og data er stadig lineært separabel.\n\n\n\nHvis vi prøver at køre ADALINE algoritmen fås linjen, som er indtegnet i figur 3. Vi kan allerede se nu, at det er helt skørt. Data er lineært separabel, men alligevel er der et rødt punkt, som bliver klassificeret forkert – faktisk var den oprindelige linje fra figur 1 bedre.\n\n\n\n\n\n\nFigur 3: Et nyt rødt punkt er indtegnet og den linje, som ADALINE finder.\n\n\n\nDet er jo ikke ligefrem super overbevisende. Data er lineært separabel og alligevel kan ADALINE ikke finde ud af at finde en ret linje, som kan adskille de røde punkter fra de blå!\nHvis vi skal forstå, hvad der sker, må vi se lidt nærmere på den tabsfunktion, som ADALINE forsøger at mininere. Fra afsnittet om ADALINE ved vi, at tabsfunktionen2 er\n2 Bemærk her, at det ikke er afgørende, at der er ganget med \\(1/2\\) – det viser sig bare smartere senere.\\[\n\\begin{aligned}\nE(w_0, w_1, &\\dots, w_n)\\\\ &= \\frac{1}{2} \\sum_{m=1}^{M} \\left (t^{(m)}-\n(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)}) \\right)^2\n\\end{aligned}\n\\tag{1}\\]\nhvor det \\(m\\)’te træningseksempel er \\[(x_1^{(m)}, x_2^{(m)}, \\dots, x_n^{(m)}, t^{(m)})\\]\nDet vil sige, at det \\(m\\)’te træningseksempel giver et bidrag til tabsfunktionen på\n\\[\n\\left ( t^{(m)}- (w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)}) \\right)^2\n\\]\nFor et blåt punkt med \\(t^{(m)}=1\\) vil det sige, at bidraget til tabsfunktionen er præcis \\(0,\\) hvis \\[\n1- \\left (w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)} \\right) =0\n\\] og for et rødt punkt med \\(t^{(m)}=-1\\) er bidraget til tabsfunktionen præcis \\(0,\\) hvis \\[\n-1- \\left (w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)} \\right)=0\n\\] Nu er \\(1- (w_0 + w_1 \\cdot x_1 + \\cdots + w_n \\cdot x_n)=0\\) og \\(-1- (w_0 + w_1 \\cdot x_1 + \\cdots + w_n \\cdot x_n)=0\\) jo bare ligninger for rette linjer3. Disse linjer ses indtegnet på figur 4 (som henholdsvis en blå og rød stiplet linje) sammen med de oprindelige seks punkter og den linje, som ADALINE fandt baseret på disse seks punkter. Samtidig er det for hvert punkt markeret, hvor meget dette punkt bidrager til tabsfunktionen.\n3 Det er i hvert tilfælde \"bare linjer\", når \\(n=2\\). Hvis \\(n=3\\), er der tale om ligningen for en plan, og hvis \\(n&gt;3\\), kalder man det for ligningen for en \"hyperplan\". Men sidstnævnte er visuelt svære at forestille sig, fordi koordinatsystemet, disse hyperplaner skal tegnes i, har en dimension større end \\(3\\). Og de er ikke så nemme at tegne!\n\n\n\n\n\nFigur 4: Punkter med en targetværdi på \\(1\\) er blå og dem med en targetværdi på \\(-1\\) er røde. Den sorte linje med ligning \\(w_0+w_1 x_1 + w_2 x_2=0\\) svarer til den ADALINE fandt. Den blå stiplede linje har ligning \\(1-(w_0+w_1 x_1 + w_2 x_2)=0\\), mens den røde stiplede linje har ligning \\(-1-(w_0+w_1 x_1 + w_2 x_2)=0\\).\n\n\n\nDet ses nu på figur 4, at blå punkter, som ligger tæt på den blå stiplede linje, bidrager mindst til tabsfunktionen, mens røde punkter, som ligger tæt på den røde stiplede linje, ligeledes bidrager mindst til tabsfunktionen. Den samlede værdi af tabsfunktionen4 er her \\(0.75\\).\n4 Værdien udregnes ved at lægge alle bidragene sammen og gange med \\(\\frac{1}{2}\\). Jævnfør udtrykket for tabsfunktionen i (1).Laver vi nu samme øvelse med det ekstra punkt fås resultat i figur 5.\n\n\n\n\n\n\nFigur 5: I alt syv punkter sammen med den sorte linje med ligning \\(w_0+w_1 x_1 + w_2 x_2=0\\) svarer til den ADALINE finder. Punkter med en targetværdi på \\(1\\) er blå og dem med en targetværdi på \\(-1\\) er røde. Den blå stiplede linje har ligning \\(1-(w_0+w_1 x_1 + w_2 x_2)=0\\), mens den røde stiplede linje har ligning \\(-1-(w_0+w_1 x_1 + w_2 x_2)=0\\). Den samlede værdi af tabsfunktionen er her \\(2.00\\).\n\n\n\nIgen ser vi, at blå punkter tæt på den blå stiplede linje bidrager mindst til tabsfunktionen og tilsvarende for de røde punkter, som ligger tæt på den røde stiplede linje. Det nye punkts bidrag til tabsfunktionen bliver derfor her det mindste bidrag blandt alle de røde punkter. Den samlede værdi af tabsfunktionen er her \\(2.00\\).\nHvis vi i stedet prøver at bruge vores egen oprindelige linje (baseret på de seks første punkter), som rent faktisk kunne adskille de blå punkter fra de røde, så fås det resultat, som ses i figur 6.\n\n\n\n\n\n\nFigur 6: I alt syv punkter sammen med den sorte linje, som ADALINE giver baseret på de oprindelige seks punkter. Punkter med en targetværdi på \\(1\\) er blå og dem med en targetværdi på \\(-1\\) er røde. Den blå stiplede linje har ligning \\(1-(w_0+w_1 x_1 + w_2 x_2)=0\\), mens den røde stiplede linje har ligning \\(-1-(w_0+w_1 x_1 + w_2 x_2)=0\\). Den samlede værdi af tabsfunktionen er her \\(10.60\\).\n\n\n\nDet er nu tydeligt, at det nye røde punkter ligger så langt væk fra den stiplede røde linje, at det bidrager betydeligt til tabsfunktionen. Derfor er den samlede værdi af tabsfunktionen \\(10.60\\) – og derfor vælger ADALINE linjen i figur 5 til at adskille punkterne. Ikke fordi, det er den linje, som giver den laveste andel af korrekt klassificerede, men fordi det er den linje, som minimerer tabsfunktionen! Det kan jo godt virke lidt skørt, når vi selv kan indtegne en linje, som kan separere alle punkterne."
  },
  {
    "objectID": "materialer/kunstige_neuroner/smartere_end_adaline.html#kunstige-neuroner-og-aktiveringsfunktioner",
    "href": "materialer/kunstige_neuroner/smartere_end_adaline.html#kunstige-neuroner-og-aktiveringsfunktioner",
    "title": "AI MAT - matematikken bag magien",
    "section": "Kunstige neuroner og aktiveringsfunktioner",
    "text": "Kunstige neuroner og aktiveringsfunktioner\nProblemet med ADALINE, som vi har set i eksemplet ovenfor, opstår fordi, et ekstremt punkt får lov til at \"trække\" uforholdsmæssigt meget i den linje, som ADALINE finder, for at dette punkts bidrag til tabsfunktionen ikke skal blive alt for stort.\nVi så det i figur 5 og figur 6. I figur 5 brugte vi den linje, som ADALINE gav, og her var det ekstreme punkts bidrag til tabsfunktionen på \\(0.32\\). I figur 6 valgte vi en linje, som oplagt er bedre til at adskille de blå punkter fra de røde, men her er det ekstreme punkts bidrag til tabsfunktionen helt oppe på \\(19.72\\).\nFor at forstå det lidt bedre skal vi måske lige repetere, hvordan man finder afstanden fra et punkt \\(P(x_1,y_1)\\) til en linje \\(l\\) med ligning \\(ax+by+c=0\\):\n\\[\n\\textrm{dist}(P,l)=\\frac{|a x_1 + b y_1 +c|}{\\sqrt{a^2+b^2}}\n\\]\nDenne afstandsformel kan generaliseres, så afstanden fra et punkt \\(P(x_1^{(m)}, x_2^{(m)}, \\dots, x_n^{(m)})\\) (i et \\(n\\)-dimensionalt rum!) til planen \\(\\alpha\\) med ligning \\(w_0+w_1 x_1 + w_2 x_2 + \\cdots + w_n x_n=0\\) er:\n\\[\n\\textrm{dist}(P,\\alpha)=\\frac{\\left | w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)} \\right |}{\\sqrt{w_1^2 + w_2^2 + \\cdots + w_n^2}}\n\\]\nDet vil sige, at udtrykket i tælleren \\(|w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)}|\\) bliver et mål for hvor langt væk punktet \\(P(x_1^{(m)}, x_2^{(m)}, \\dots, x_n^{(m)})\\) ligger fra planen. Det forklarer, hvordan et ekstremt punkt kan give et meget stort bidrag til tabsfunktionen:\n\\[\n\\left ( t^{(m)}- (w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)}) \\right)^2\n\\tag{2}\\]\nHvis punktet ligger langt væk fra den plan, som måske umiddelbart ser fornuftig ud, så vil punktet give et stort bidrag til tabsfunktionen, fordi værdien af \\(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)}\\) bliver stor, og dermed vil bidraget til tabsfunktionen i (2) også blive stort!\nAlt det her leder os frem til, at valget af tabsfunktion måske i virkeligheden ikke er super smart. Problemet opstår grundlæggende, fordi targetværdien \\(t\\) og udtrykket i den inderste parentes i (2) er på to helt vidt forskellige skalaer. Targetværdien er enten \\(-1\\) eller \\(1\\), mens udtrykket \\(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)}\\) kan antage en hvilken som helst reel værdi – en værdi som kan blive vældig stor, hvis punktet \\(P(x_1^{(m)}, x_2^{(m)}, \\dots, x_n^{(m)})\\) ligger langt væk fra planen. Derfor bliver ADALINE nødt til at tvinge planen med ligningen\n\\[\nw_0 + w_1 \\cdot x_{1} + \\cdots + w_n \\cdot x_{n}=0\n\\]\nover mod et ekstremt punkt, sådan at dette punkts bidrag til tabsfunktionen ikke bliver alt for stort.\nProblemet kan løses ved at bruge en kunstig neuron.\nHelt grundlæggende handler problemet om, at targetværdi \\(t,\\) og det udtryk, som vi beregner på baggrund af punktet \\(P(x_1^{(m)}, x_2^{(m)}, \\dots, x_n^{(m)})\\), skal være på samme skala. I den kunstige neuron brugte vi sigmoid-funktionen \\(\\sigma\\), som aktiveringsfunktion. Forskriften for sigmoid-funktionen er:\n\\[\n\\sigma(x)=\\frac{1}{1+e^{-x}}\n\\tag{3}\\]\nog grafen ses i figur 7.\n\n\n\n\n\n\nFigur 7: Grafen for sigmoid-funktionen med forskrift \\(\\sigma(x)=\\frac{1}{1+e^{-x}}\\).\n\n\n\nDet centrale her er værdimængden for sigmoid-funktion:\n\\[\nVm(\\sigma)=(0,1).\n\\]\nDet vil vi udnytte og nu omdefinere targetværdien \\(t\\) på denne måde:\n\\[\nt=\n\\begin{cases}\n1 & \\textrm{hvis punktet er blåt} \\\\\n0 & \\textrm{hvis punktet er rødt} \\\\\n\\end{cases}\n\\]\nSå targetværdierne er nu \\(0\\) eller \\(1\\) i stedet for \\(-1\\) og \\(1\\). Vi husker nu, hvordan vi definerede tabsfunktionen for de kunstige neuroner:\n\\[\n\\begin{aligned}\nE(w_0, w_1, &\\dots, w_n) \\\\ &= \\frac{1}{2} \\sum_{m=1}^{M} \\left (t^{(m)}-\n\\sigma(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)}) \\right)^2\n\\end{aligned}\n\\tag{4}\\]\nBemærk, at problemet med de to skalaer nu er løst. Targetværdien er enten \\(0\\) eller \\(1\\) samtidig med, at \\(\\sigma(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)})\\) også ligger mellem \\(0\\) og \\(1\\). Vi sammenligner altså ikke længere pærer med bananer! Den \"perceptron\", som minimerer tabsfunktionen i (4), er netop det, vi kalder for en kunstig neuron.\nI noten om kunstige neuroner beskrev vi, hvordan vi kan tænke på outputværdien\n\\[\no = \\sigma(w_0 + w_1 \\cdot x_1 + \\cdots + w_n \\cdot x_n)\n\\]\nsom en sandsynlighed for at punktet \\(P(x_1, x_2, \\dots, x_n)\\) er blåt. Det gjorde vi på denne måde:\n\\[\n\\textrm{Nyt punkt }=\n\\begin{cases}\n\\textrm{blåt} & \\textrm{hvis } o \\geq 0.5\\\\\n\\textrm{rødt} & \\textrm{hvis } o &lt; 0.5\\\\\n\\end{cases}\n\\tag{5}\\]\nhvor\n\\[\no = \\sigma(w_0 + w_1 \\cdot x_1 + \\cdots + w_n \\cdot x_n).\n\\]\nVi argumenterede også for, at skillelinjen, for hvornår et punkt \\((x_1, x_2, \\dots, x_n)\\) er blåt eller rødt, kan beskrives ved ligningen\n\\[\nw_0 + w_1 \\cdot x_{1} + \\cdots + w_n \\cdot x_{n} = 0\n\\]\nTabsfunktionen for kunstige neuroner giver os altså stadigvæk en plan, som kan bruges til at adskille de røde punkter fra de blå.\nLad os prøve først at illustrere det med datasættet bestående af de seks punkter i figur 1. Resultat af at bruge ADALINE (fuldt optrukket linje) og en kunstig neuron (stiplet linje) ses i figur 8. Det er her tydeligt, at begge metoder kan bruges til at finde en linje, som adskiller de blå punkter fra de røde, og der er i det hele taget ikke den store forskel på de to metoder.\n\n\n\n\n\n\nFigur 8: Fuldt optrukket linje svarer til ADALINE – stiplet linje svarer til en kunstig neuron.\n\n\n\nBruger vi nu ADALINE og en kunstig neuron på data fra figur 2 fås resultatet i figur 9. Igen svarer ADALINE til fuldt optrukket linje og sigmoid til stiplet linje. Vi kan nu se, at den kunstige neuron præcis gør det, som vi havde håbet på: Den adskiller de blå punkter fra de røde også selvom ét af punkterne er ekstremt.\n\n\n\n\n\n\nFigur 9: Fuldt optrukket linje svarer til ADALINE – stiplet linje svarer til en kunstig neuron.\n\n\n\nVægtene fra den kunstige neuron i det sidste eksempel er \\(w_0=-6.046\\), \\(w_1=-16.69\\) og \\(w_2=10.94\\) svarende til linjen med ligning \\[\n-6.046 - 16.69x_1+10.94x_2=0\n\\] Udregner vi \\[\no = \\sigma(-6.046 - 16.69x_1+10.94x_2)\n\\] får vi altså sandsynligheden for at et punkt er blåt. Gør vi det fås resultatet i nedenstående tabel:\n\n\n\n\\(x_1\\)\n\\(x_2\\)\nTargetværdi\nSandsynlighed\n\n\n\n\n\\(-0.5\\)\n\\(0.5\\)\n\\(1\\)\n\\(1.00\\)\n\n\n\\(-0.3\\)\n\\(0.3\\)\n\\(1\\)\n\\(0.90\\)\n\n\n\\(-0.1\\)\n\\(0.7\\)\n\\(1\\)\n\\(0.96\\)\n\n\n\\(0.1\\)\n\\(0.4\\)\n\\(0\\)\n\\(0.03\\)\n\n\n\\(-0.1\\)\n\\(0.2\\)\n\\(0\\)\n\\(0.10\\)\n\n\n\\(0.1\\)\n\\(-0.1\\)\n\\(0\\)\n\\(0.00\\)\n\n\n\\(1\\)\n\\(-1\\)\n\\(0\\)\n\\(0.00\\)\n\n\n\nDer er her fin overensstemmelse mellem targetværdien og den beregnede sandsynlighed (outputværdien \\(o\\)). Læg også mærke til at det ekstreme punkt har en beregnet sandsynlighed på \\(0.00\\) og dermed bliver prædikteret til klart at være et ikke blåt – det vil sige et rødt – punkt."
  },
  {
    "objectID": "materialer/funktioner_af_flere_variable/tangentplaner.html",
    "href": "materialer/funktioner_af_flere_variable/tangentplaner.html",
    "title": "Tangentplaner",
    "section": "",
    "text": "Vi vil her forklare, hvordan man bestemmer ligningen for en tangentplan til grafen for en funktion af to variable. Som eksempel vil vi igen bruge:\n\\[\nf(x,y)= 2x^2-y^2+3xy+1.\n\\]\nPå figuren herunder ses grafen for funktionen \\(f\\) sammen med grafen for snitfunktionen \\(g(x)=f(x,y_0)\\), hvor \\(y_0=-2\\). Derudover er tangenten til grafen for \\(g\\) i punktet \\(P(x_0, y_0, f(x_0,y_0))=P(1,-2,-7)\\) indtegnet (stiplet linje).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVi har tidligere beregnet, at denne tangent har en hældning på \\(-2\\), men helt generelt vil hældningen være \\(f_x(x_0,y_0)\\). Det betyder grafisk, at hvis vi står i punktet \\(P\\) og gerne vil bevæge os langs tangenten, så skal vi: Bevæge os \\(1\\) enheden i \\(x\\)-aksens retning, \\(0\\) enheder i \\(y\\)-aksens retning (husk på at snitkurven forløber i planen med ligning \\(y=y_0\\), hvor \\(y\\) er fastholdt, og dermed ikke ændrer sig) og \\(f_x(x_0,y_0)\\) enheder i \\(z\\)-aksens retning. Dermed vil en retningsvektor for denne tangent være\n\\[\n\\vec{r_1} =\n\\begin{pmatrix}\n1 \\\\ 0 \\\\ f_x(x_0,y_0)\n\\end{pmatrix}.\n\\]\nPå helt tilsvarende vis vil grafen for snitfunktionen \\(h(y)=f(x_0,y)\\) have en tangent i punktet \\(P(x_0, y_0, f(x_0,y_0))\\) med hældning \\(f_y(x_0,y_0)\\). Dette er illustreret med eksemplet fra før herunder.\n\n\n\n\nI det konkrete eksempel er hældningen af denne tangent \\(7\\). Generelt vil en retningsvektor for tangenten være\n\\[\n\\vec{r_2} =\n\\begin{pmatrix}\n0 \\\\ 1 \\\\ f_y(x_0,y_0)\n\\end{pmatrix}.\n\\]\nSom bekendt udspænder to vektorer en plan og den plan, som disse to retningsvektorer udspænder kaldes for tangentplanen1 til grafen for \\(f\\) i punktet \\(P(x_0, y_0, f(x_0,y_0))\\). Man kan igen tænke på grafen for \\(f\\) som en bakke. Hvis vi står i punktet \\(P\\) og placerer en bordplade i punktet, så vil denne bordplade svare til tangentplanen (eller rettere en del af den).\n1 Mere formelt er det faktisk sådan, at hvis alle tangentvektorer til alle snitkurver i et punkt \\(P\\) ligger i en plan, så kaldes denne plan for tangentplanen. Men her er det fint bare at tænke på, at de to retningsvektorer \\(\\vec{r_1}\\) og \\(\\vec{r_2}\\) udspænder en plan – og så vil det som regel være sådan for de \"pæne\" funktioner, vi beskæftiger os med, at denne plan også indeholder alle andre tangentvektorer og dermed formelt set vil være tangentplanen.Vi vil nu finde en ligning for tangentplanen. Vi minder om, at en plan gennem punktet \\((x_0,y_0,z_0)\\) med normalvektor\n\\[\n\\vec{n} = \\begin{pmatrix}\na \\\\ b \\\\ c\n\\end{pmatrix}\n\\]\nhar ligning\n\\[\na(x-x_0) + b(y-y_0) + c(z-z_0)=0.\n\\tag{1}\\]\nVi husker også på, at en normalvektor til en plan, kan fås ved at krydse to retningsvektorer til planen. Derfor vil en normalvektor til tangentplanen være:\n\\[\n\\vec{n} =\n\\begin{pmatrix}\n1 \\\\ 0 \\\\ f_x(x_0,y_0)\n\\end{pmatrix}\n\\times\n\\begin{pmatrix}\n0 \\\\ 1 \\\\ f_y(x_0,y_0)\n\\end{pmatrix}\n\\]\nDet giver\n\\[\n\\begin{aligned}\n\\vec{n}&=\n\\begin{pmatrix}\n0 \\cdot f_y(x_0,y_0) - f_x(x_0,y_0) \\cdot 1\n\\\\\nf_x(x_0,y_0) \\cdot 0 - 1 \\cdot f_y(x_0,y_0)\n\\\\\n1 \\cdot 1 - 0 \\cdot 0\n\\end{pmatrix} =\n\\begin{pmatrix}\n- f_x(x_0,y_0)\n\\\\\n-f_y(x_0,y_0)\n\\\\\n1\n\\end{pmatrix}\n\\end{aligned}\n\\] Indsættes dette i planens ligning i (1) fås\n\\[\n- f_x(x_0,y_0)(x-x_0)-f_y(x_0,y_0)(y-y_0)+ (z-f(x_0,y_0))=0.\n\\] Hvilket efter lidt omrokeringer giver \\[\nz=f_x(x_0,y_0)(x-x_0)+f_y(x_0,y_0)(y-y_0)+f(x_0,y_0).\n\\tag{2}\\]\nDette er den generelle ligning for tangentplanen til grafen for \\(f\\) i punktet \\(P(x_0,y_0,f(x_0,y_0))\\).\nI eksemplet er\n\\[\nx_0=1, \\quad y_0=-2, \\quad f(1,-2)=-7, \\quad f_x(1,-2)=-2, \\quad \\textrm{og} \\quad f_y(1,-2)=7\n\\] Indsættes dette i (2) fås\n\\[\n\\begin{aligned}\nz &= -2(x-1)+7(y+2)-7 \\quad \\Leftrightarrow \\\\\nz &= -2x+7y+9\n\\end{aligned}\n\\] Denne tangentplan ses tegnet sammen med grafen for \\(f\\) herunder."
  },
  {
    "objectID": "materialer/gradientnedstigning/kontinuitet.html",
    "href": "materialer/gradientnedstigning/kontinuitet.html",
    "title": "Kontinuitet for funktioner af to variable",
    "section": "",
    "text": "Vi har lige påstået, at en funktion \\(f\\) af to variable siges at være kontinuert i \\((x_0,y_0)\\), hvis følgende gælder\n\\[\n\\lim_{(x,y) \\rightarrow (x_{0},y_{0})}{f\\left( x,y \\right) = f(x_{0},y_{0})}\n\\]\nMen der er faktisk grund til at dvæle lidt ved denne definition, for hvad vil det overhovedet sige, at \\((x,y) \\rightarrow (x_{0},y_{0})\\)? Forestil dig at du har været i byen, og at \\((x_0,y_0)\\) er dit hjem. Så kan man jo gå hjem på rigtig mange måder. Det kan være, at man går langs en ret linje, det kan være, at man går i zig-zag hjem eller noget helt tredje. Ovenstående definition på kontinuitet giver kun mening, hvis \\(f(x,y)\\) nærmer sig \\(f(x_0,y_0)\\) uanset på hvilken måde \\((x,y)\\) nærmer sig \\((x_0,y_0)\\).\nVi skal nu se på et eksempel, hvor en funktion \\(f\\) ikke er kontinuert i \\((0,0)\\), fordi man kan “gå hjem” på nogle måder, så \\(f(x,y)\\) ikke altid nærmer sig \\(f(0,0)\\)! Det kan godt være lidt svært at forestille sig, men her kommer eksemplet."
  },
  {
    "objectID": "materialer/gradientnedstigning/kontinuitet.html#skiferien",
    "href": "materialer/gradientnedstigning/kontinuitet.html#skiferien",
    "title": "Kontinuitet for funktioner af to variable",
    "section": "Skiferien",
    "text": "Skiferien\nVi forestiller os, at grafen for funktionen \\(f(x,y)\\) beskriver et landskab. Står vi på en flad mark er \\(f(x,y)\\) bare \\(0\\) for alle værdier af \\((x,y)\\), og det er jo ærlig talt lidt kedeligt. Men nu er din klasse taget på skiferie i et spændende land, hvor skibakkerne kan beskrives som grafen for funktionen \\(f\\) med følgende forskrift:\n\\[\nf(x,y)=\n\\begin{cases}\n\\frac{y \\cdot x^2}{y^2+x^4} \\quad \\textrm{hvis } (x,y) \\neq (0,0) \\\\\n0 \\quad \\textrm{hvis } (x,y) = (0,0)\n\\end{cases}\n\\] Jeres hotel ligger i origo – det vil sige i punktet \\((0,0,0)\\). I kan se skibakken i app’en herunder.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI skal nu i gang med at undersøge, om denne funktion er kontinuert i \\((0,0)\\). I gør det ved at stille jer forskellige steder på skibakken og gå af forskellige ruter hjem. De fleste af jer går langs rette linjer (i \\(xy\\)-planen) og rapporterer, at funktionen er kontinuert (og faktisk også differentiabel) i \\((0,0)\\). I kan se nogle af de forskellige ruter herunder:\n\n\n\nNu er der et par elever, der rapporterer, at de kom vandrende ind mod origo på grafen og hele tiden var i højde \\(1/2\\) lige indtil, de faldt i et hul, da de nåede origo. Hvis det er rigtigt betyder det, at funktionen ikke er kontinuert i origo. De elever, der faldt i et hul, er kendt for ikke at gå den lige vej hjem. Denne gang afslører de, at de gik på grafen, mens de i \\(xy\\)-planen fulgte parablen med ligning \\(y=x^2\\). Du kan se disse elevers rute i app’en herunder.\n\n\n\nMen kan alle eleverne mon have ret? Vi prøver at regne på det.\n\n\n\n\n\n\nOpgave 1: Gå langs \\(y=x\\)\n\n\n\n\n\n\nFind forskriften for snitfunktionen langs linjen med ligning \\(y=x\\). Det vil sige bestem \\(f(x,x)\\).\nHvilken værdi går denne snitfunktion imod, når \\(x\\) går mod \\(0\\)?\n\n\n\n\n\n\n\n\n\n\nOpgave 2: Gå langs \\(y=ax\\)\n\n\n\n\n\n\nFind forskriften for snitfunktionen langs linjen med ligning \\(y=ax\\). Det vil sige bestem \\(f(x,ax)\\).\nHvilken værdi går denne snitfunktion imod, når \\(x\\) går mod \\(0\\)?\n\n\n\n\n\n\n\n\n\n\nOpgave 3: Gå langs \\(y\\)-aksen\n\n\n\n\n\n\nFind forskriften for snitfunktionen langs \\(y\\)-aksen.\nHvilken værdi går denne snitfunktion imod, når \\(x\\) går mod \\(0\\)?\n\n\n\n\nI de tre foregående opgaver skulle du gerne komme frem til at \\(f(x,y) \\rightarrow f(0,0)=0\\), når \\((x,y) \\rightarrow (0,0)\\), så længe vi går langs rette linjer. Vi skal nu undersøge, hvad der sker, hvis vi går langs parabler.\n\n\n\n\n\n\nOpgave 4: Gå langs parablen med ligning \\(y=x^2\\)\n\n\n\n\n\n\nFind forskriften for snitfunktionen langs parablen med ligning \\(y=x^2\\). Det vil sige bestem \\(f(x,x^2)\\).\nHvilken værdi går denne snitfunktion imod, når \\(x\\) går mod \\(0\\)?\n\n\n\n\nHvis du har regnet rigtigt i ovenstående opgave, så har du fået, at\n\\[\n\\lim_{(x,y) \\rightarrow (0,0)}{f\\left( x,y \\right)} = 1/2\n\\]\nnår \\((x,y) \\rightarrow (0,0)\\) langs parablen med ligning \\(y=x^2\\). Da \\(f(0,0)=0\\) har vi altså fundet en måde at nærme os \\((0,0)\\) så\n\\[\n\\lim_{(x,y) \\rightarrow (0,0)}{f\\left( x,y \\right) \\neq f(0,0)}\n\\]\nog derfor er \\(f\\) ikke kontinuert i \\((0,0)\\), selvom det i første omgang så sådan ud (da vi gik langs rette linjer)!\nFor sjov skyld kan vi jo prøve at undersøge, om det gælder langs alle parabler.\n\n\n\n\n\n\nOpgave 5: Gå langs parablen med ligning \\(y=ax^2\\)\n\n\n\n\n\n\nFind forskriften for snitfunktionen langs parablen med ligning \\(y=ax^2\\), hvor \\(a \\neq 0\\). Det vil sige bestem \\(f(x,ax^2)\\).\nHvilken værdi går denne snitfunktion imod, når \\(x\\) går mod \\(0\\)?\n\n\n\n\nHvis du har regnes rigtig i ovenstående, har du fået, at \\[\n\\lim_{(x,y) \\rightarrow (0,0)}{f\\left( x,y \\right)} = \\frac{a}{a^2+1} \\neq 0\n\\] når \\(a \\neq 0\\). Igen har vi altså set, at\\(f\\) ikke kontinuert i \\((0,0)\\)."
  },
  {
    "objectID": "materialer/gradientnedstigning/gradientnedstigning.html",
    "href": "materialer/gradientnedstigning/gradientnedstigning.html",
    "title": "Gradientnedstigning",
    "section": "",
    "text": "I denne note vil vi forklare hvad gradientnedstigning går ud på, og hvordan gradientnedstigning kan bruges i forbindelse med at bestemme minimum eller maksimum for en funktion.\nVi vil her nøjes med at se på en funktion \\(f(x,y)\\) af to variable. I noten om funktioner af flere variable har vi skrevet, at gradientvektoren\n\\[\n\\nabla f\\left( x_{0},y_{0} \\right) = \\begin{pmatrix}\nf_x\\left( x_{0},y_{0} \\right) \\\\\nf_y\\left( x_{0},y_{0} \\right) \\\\\n\\end{pmatrix}\n\\]\nangiver den retning, man skal bevæge sig væk fra punktet \\((x_{0},y_{0})\\), for at funktionsværdierne \\(f(x,y)\\) vokser mest muligt. Det er denne egenskab, som vi vil bevise her og forklare, hvordan den kan bruges til at bestemme maksimum eller minimum for en funktion. For at gøre det må vi starte med at definere de såkaldte retningsafledede.\n\nRetningsafledede\nNår vi står i et punkt \\((x_{0},y_{0})\\) og gerne vil undersøge i hvilken retning funktionsværdien vokser mest, så kunne vi jo starte med at udregne de to partielle afledede\n\\[\nf_x( x_{0},y_{0}) \\quad \\textrm{og} \\quad f_y( x_{0},y_{0}).\n\\]\nDisse to størrelser angiver væksthastigheden i henholdsvis \\(x\\)- og \\(y\\)-aksens retning. Men der er ingen, som siger, at det lige præcis er i en af de to retninger, at funktionsværdien vokser mest. Det kunne lige så godt være i en hvilken som helst anden retning.\nVi vil her angive den retning i \\(xy\\)-planen, som vi nu vil bevæge os i med en enhedsvektor – det vil sige en vektor med længde 1:\n\\[\n\\vec{u} = \\begin{pmatrix}\nu_{1} \\\\\nu_{2} \\\\\n\\end{pmatrix}\n\\] hvor altså \\(\\lvert \\vec u \\rvert = 1\\).\nVi definerer nu den retningsafledede af \\(f\\) i punktet \\((x_{0},y_{0})\\) i retningen \\(\\vec{u}\\) ved\n\\[\nD_{\\vec{u}}f\\left( x_{0},y_{0} \\right) = \\lim_{h \\rightarrow 0}\\frac{f\\left( x_{0} + hu_{1},y_{0} + hu_{2} \\right) - f(x_{0},y_{0})}{h}\n\\tag{1}\\]\nhvis ellers grænsen eksisterer.\nBemærk, at hvis \\(\\vec{u}\\) peger i \\(x\\)-aksens retning, så bliver den retningsafledede til \\(f_x(x_{0},y_{0})\\), og hvis den peger i \\(y\\)-aksens retning, bliver den til \\(f_y(x_{0},y_{0})\\).\nAf definitionen kan man se, at man udregner en sekanthældning ved at tage et skridt \\(h\\) i \\(\\vec{u}\\)’s retning og dividere den fundne funktionstilvækst med \\(h\\). Derefter lader man \\(h\\) gå mod 0. Det giver hældningen af grafen for \\(f\\) i punktet \\((x_{0},y_{0})\\) i retningen \\(\\vec{u}\\). Og dermed altså væksthastigheden for \\(f\\) i retningen \\(\\vec{u}\\).\nIdéen med den retningsafledede er illustreret i figuren nedenfor. Til venstre ses en repræsentant for \\(\\vec u\\) i \\(xy\\)-planen. Man kan ændre på den retning, som \\(\\vec u\\) peger i, ved at trække i skyderen. Til højre ses grafen for en funktion \\(f\\) af to variable, hvor et punkt \\(P(x_0,y_0,f(x_0,y_0))\\) på grafen er indtegnet. Samtidig vises den snitkurve som fås, hvis man på grafen i punktet \\(P\\) bevæger sig langs en linje i retningen \\(\\vec u\\). Denne snitkurve har i punktet \\(P\\) en tangent, som også er indtegnet, og denne tangents hældning vil netop svarer til størrelsen af den retningsafledede \\(D_{\\vec{u}}f\\left( x_{0},y_{0} \\right)\\). Hvis man ændrer på den retning, som \\(\\vec u\\) peger i, kan man se, hvordan størrelsen af den retningsafledede ændrer sig.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDet viser sig, at man kan udregne de retningsafledede med et prikprodukt:\n\\[\nD_{\\vec{u}}f\\left( x_{0},y_{0} \\right) = \\nabla f(x_{0},y_{0}) \\cdot \\vec{u}.\n\\]\nVi vil nedenfor argumentere for formlen, men lad os først se på konsekvenserne af den. Vi ved fra almindelig vektorregning, at\n\\[\n\\vec{a} \\cdot \\vec{b} = \\lvert \\vec{a} \\rvert \\cdot \\lvert \\vec{b} \\rvert \\cdot \\cos(v)\n\\]\nhvor \\(v\\) er vinklen mellem de to vektorer. Da \\(\\lvert \\vec{u} \\rvert = 1\\) betyder det, at\n\\[\nD_{\\vec{u}}f\\left( x_{0},y_{0} \\right) = \\lvert \\nabla f(x_{0},y_{0}) \\rvert \\cdot \\cos(v)\n\\]\nhvor \\(v\\) er vinklen mellem gradientvektoren \\(\\nabla f\\left( x_{0},y_{0} \\right)\\) og den valgte retning \\(\\vec{u}\\).\nVi ved, at \\(-1 \\leq \\cos(v) \\leq 1\\) samt at \\(\\cos(0^{{^\\circ}})=1\\) og \\(\\cos(180^{{^\\circ}})=-1\\). Det følger derfor, at den retningsafledede er størst (og dermed at \\(f\\) vokser mest), når \\(\\vec{u}\\) peger i \\(\\nabla f(x_{0},y_{0})\\)’s retning. Og tilsvarende at den retningsafledede er mindst (og dermed at \\(f\\) aftager mest), når \\(\\vec{u}\\) peger i \\(-\\nabla f(x_{0},y_{0})\\)’s retning. Det vil sige, at den retningsaflededes størsteværdi er\n\\[\nD_{\\vec{u}}f\\left( x_{0},y_{0} \\right) = \\ \\ \\ \\lvert \\nabla f(x_{0},y_{0}) \\rvert\n\\]\nnår \\(v = 0^{{^\\circ}}\\) og retningsaflededes mindsteværdi er\n\\[\nD_{\\vec{u}}f\\left( x_{0},y_{0} \\right) = - \\lvert \\nabla f(x_{0},y_{0}) \\rvert\n\\]\nnår \\(v = 180^{{^\\circ}}\\). Det var netop, hvad vi gerne ville vise.\nPrincippet er illustreret i figuren herunder. Gradientvektoren \\(\\nabla f(x_{0},y_{0})\\) er indtegnet (med blå) og man kan se, at den retningsafledede antager den største værdi, netop når \\(\\vec u\\) peger i gradientens retning (prøv at trække i skyderen). Og omvendt antager den retningsafledede den mindste værdi, når \\(\\vec u\\) peger i minus gradientens retning.\n\n\n\nFor at vise, at man kan udregne de retningsafledede med et prikprodukt:\n\\[\nD_{\\vec{u}}f\\left( x_{0},y_{0} \\right) = \\nabla f(x_{0},y_{0}) \\cdot \\vec{u}\n\\]\nkan du vælge enten at læse et bevis, som baserer sig på geometriske argumenter eller et bevis som er baseret på middelværdisætningen.\n\n\nOptimering ved hjælp af gradientnedstigning\nVi vil nu se på, hvordan gradienten kan bruges til at bestemme maksimum eller minimum for en funktion.\nBetragt en funktion \\(f\\) givet ved forskriften \\[\nf\\left( x,y \\right) = \\left( \\left( x - 5 \\right)^{2} + 3 \\right) \\cdot \\left( 5 + \\left( y - 10 \\right)^{2} \\right) + 30\n\\]\nHvis man ser lidt på forskriften, kan man måske overbevise sig selv om, at funktionen har et minimum på 45, som fås, når \\(\\left( x,y \\right) = (5,10)\\).\nGrafen ses herunder.\n\n\n\nMan kan lave en iterativ metode til at finde minimumspunktet ved at udnytte egenskaben ved gradientvektoren:\n\nVælg et startpunkt \\((x_0,y_0)\\) som et første gæt på et minimumspunkt.\n\nVi udnytter nu, at \\(- \\nabla f(x_0,y_0)\\) angiver den retning, hvor funktionsværdien falder mest i punktet \\((x_0,y_0,f(x_0,y_0))\\).\n\nGå derfor et lille skridt i retningen \\(- \\nabla f(x_0,y_0)\\). Det giver så det næste punkt \\((x_1,y_1)\\), som forhåbentlig er et bedre bud på et minimumspunkt.\nProcessen foregår i definitionsmængden, men på grafen svarer det til at gå et lille stykke den stejleste vej ned ad bakken.\nProcessen itereres så gentagne gange indtil man forhåbentlig når minimumspunktet.\n\nVælger vi med den konkrete funktion et startpunkt på\n\\[\n(x_0,y_0) = ( - 3,4)\n\\]\nog vælger vi i hvert skridt at lægge -0,001 gange den negative gradientvektor i punktet til, så kan nogle af de følgende \\((x,y)\\)-punkter ses til venstre i figur 1. Læg her mærke til hvordan vi nærmer os det globale minimumssted i \\((5,10)\\). Til højre i figur 1 ses det også hvordan vi ved hjælp af gradientnedstigning, nærmer os den globale minimumsværdi på \\(f(5,10)=45\\).\n\n\n\n\n\n\nFigur 1: Til venstre ses et udvalg af nogle af de \\((x,y)\\)-punkter, som genereres i forbindelse med gradientnedstigning. Til højre ses et udvalg af nogle af de funktionsværdier, som genereres i forbindelse med gradientnedstigning.\n\n\n\nVi ser, at den iterative gradientnedstigning faktisk nærmer sig det globale minimumspunkt. Så om ikke andet så virker metoden i hvert fald i dette konkrete tilfælde.\n\n\nTræning af neurale netværk\nAt lede efter et globalt minimumspunkt eller i det mindste et brugbart lokalt minimumspunkt for en funktion af rigtig mange variable er et problem, man står overfor, når man skal træne et neuralt netværk og have fastlagt en masse vægte i netværket.\nDet kan ikke gøres analytisk, så derfor bruger man netop en iterativ proces baseret på gradientnedstigning som metode til at finde frem til minimumspunktet. Eksemplet ovenfor illustrerer derfor idéen bag en central del af træningen af et neuralt netværk.\nLæs mere om hvordan gradientnedstigning konkret bruges her: Perceptroner og Kunstige neurale netværk."
  },
  {
    "objectID": "materialer/tabsfunktioner/tabsfunktioner.html",
    "href": "materialer/tabsfunktioner/tabsfunktioner.html",
    "title": "Tabsfunktioner",
    "section": "",
    "text": "I langt de fleste tilfælde sker træning af AI modeller ved at minimere en tabsfunktion. Lidt løst sagt kan man sige, at en tabsfunktion måler, hvor god en AI model er til at forudsige det, vi gerne vil have den til at sige noget om. I denne note lærer du lidt om, hvordan tabsfunktioner kan se ud, og hvad træningsdata er for en størrelse."
  },
  {
    "objectID": "materialer/tabsfunktioner/tabsfunktioner.html#træningsdata-og-targetværdier",
    "href": "materialer/tabsfunktioner/tabsfunktioner.html#træningsdata-og-targetværdier",
    "title": "Tabsfunktioner",
    "section": "Træningsdata og targetværdier",
    "text": "Træningsdata og targetværdier\nDu har sikkert hørt vendingen, at man \"træner en AI\". Du kan nok også godt regne ud, at det ikke er en klassisk fodboldtræner, som står for den træning. Men gad vide hvordan det så foregår?\nNår man træner en AI model, har man brug for noget, som kaldes for træningsdata. I træningsdata har man givet en række inputværdier\n\\[\nx_1, x_2, \\dots, x_n\n\\]\npå baggrund af hvilke, man ønsker at forudsige en såkaldt targetværdi \\(t\\), som også er en del af træningsdata. Det betyder, at et enkelt træningsdatasæt kan skrives sådan her:\n\\[\n(x_1, x_2, \\dots, x_n, t).\n\\] Altså inputværdierne sammen med den tilhørende targetværdi.\nLad os tage et eksempel fra den virkelige verden, så bliver det lidt nemmere at forstå: Vi forestiller os, at vi på baggrund af en blodprøve gerne vil kunne prædiktere, om en patient har kræft eller ej. Her kan inputværdierne \\(x_1, x_2, \\dots, x_n\\) være forskellige biomarkører, man måler i blodet (spørg en biologilærer om, hvad det kunne være). Targetværdien \\(t\\) kan antage to værdier:\n\\[\nt=\n\\begin{cases}\n1 & \\textrm{hvis patienten har kræft} \\\\\n0 & \\textrm{hvis patienten ikke har kræft} \\\\\n\\end{cases}\n\\] Man kunne også have valgt: \\[\nt=\n\\begin{cases}\n1 & \\textrm{hvis patienten har kræft} \\\\\n-1 & \\textrm{hvis patienten ikke har kræft} \\\\\n\\end{cases}\n\\] Eller noget helt tredje! Lad os for nu sige, at vi vælger den første mulighed, hvor \\(t \\in \\{0,1\\}\\).\nAt bestemme om patienten har kræft eller ej – det vil sige, om targetværdien er \\(0\\) eller \\(1\\) – beror på faglig ekspertise indenfor det genstandsfelt, hvor AI modellen skal anvendes. I eksemplet med kræft vil det for eksempel være baseret på forskellige diagnostiske tests, som en læge kan bruge til at vurdere, om patienten har kræft1.\n1 Måske er disse tests først taget et stykke tid efter blodprøven, fordi det ikke er muligt at stille diagnose på tidspunktet for blodprøven. I så fald kan man måske være heldig at få udviklet en AI model, som kan prædiktere kræft tidligere end med gængse metoder.Targetværdien \\(t\\) er altså en slags facitliste for, hvad det rigtige svar er. AI-modellen skal så trænes til at forudsige (eller prædiktere), hvad det korrekte svar er.\nI figur 1 ses et eksempel på et fiktivt datasæt, hvor en biomarkør er målt på en skala fra 0 til 50 (\\(x\\)-aksen) samtidig med, at det ved hjælp af targetværdien er angivet, om patienten har kræft eller ej (\\(y\\)-aksen). Det ser her ud som om, at en lav værdi af biomarkøren (cirka under 25) indikerer, at patienten ikke har kræft, men en bestemt skæringsværdi findes ikke.\n\n\n\n\n\n\n\n\nFigur 1: Her ses et plot af data med biomarkør på \\(x\\)-aksen og sygdomsstatus på \\(y\\)-aksen.\n\n\n\n\n\nIdéen er nu, at man \"fodrer\" sin AI algoritme med en hel masse inputværdier (her værdien af biomarkøreren) med tilhørende targetværdier og finder den AI model, som på en eller anden måde er god til at forudsige targetværdien baseret på inputværdierne. Det med om en model er god eller ej, måler man typisk ved at se på, hvor stor en fejl AI modellen begår, og man ønsker så at finde den model, som samlet set laver så små fejl som muligt. Funktioner, som kan måle sådanne fejl, kaldes på engelsk for error functions, mens de på dansk typisk kaldes for tabsfunktioner.\nOverordnet set skal en tabsfunktion \\(E\\) have følgende egenskaber:\n\n\n\n\n\n\nEgenskaber ved en tabsfunktion \\(E\\)\n\n\n\n\n\n\nTabsfunktionen skal være positiv eller \\(0\\): \\(E \\geq 0\\) (vi vil ikke operere med negative fejl).\nHvis AI modellen er god til at prædiktere, skal \\(E\\) være tæt på \\(0\\), mens hvis AI modellen er dårlig til at prædiktere, skal \\(E\\) være langt væk fra \\(0\\).\n\n\n\n\nOverordnet set vil vi altså gerne have en AI model med så lille et samlet tab eller så lille en samlet fejl som muligt. Derfor skal tabsfunktionen minimeres.\nI AI modellen vil det typisk være sådan, at de forskellige inputværdier vægtes med en række vægte \\(w_0, w_1, \\dots, w_n\\) på denne måde:\n\\[\nw_0 + w_1 \\cdot x_1 + \\cdots +w_n \\cdot x_n.\n\\] Tænk på det på den måde, at hvis inputværdien \\(x_i\\) er vigtig, så er vægten \\(w_i\\) stor (som i langt væk fra \\(0\\)), mens hvis \\(x_i\\) ikke er vigtig, så er \\(w_i\\) tæt på \\(0\\).\nNår AI modellen trænes, er det dybest set bare disse vægte, man \"skruer\" på, sådan at modellen bliver så god som mulig til at prædiktere det, den er trænet på. For store kunstige neurale netværk – for eksempel de store sprogmodeller – taler vi om milliarder af vægte!"
  },
  {
    "objectID": "materialer/tabsfunktioner/tabsfunktioner.html#prædiktion",
    "href": "materialer/tabsfunktioner/tabsfunktioner.html#prædiktion",
    "title": "Tabsfunktioner",
    "section": "Prædiktion",
    "text": "Prædiktion\nMan kan tænke på en AI model som en funktion \\(f\\), der afhænger af vægtene \\(w_0, w_1, \\dots, w_n \\!:\\)\n\\[\nf(w_0, w_1, \\dots, w_n).\n\\] Funktionen afhænger selvfølgelig også af hele træningsdatasættet, men eftersom det er vægtene, man skal justere, alt imens træningsdata er fastlagt, vil vi blot tænke på \\(f\\) som en funktion af vægtene.\nFunktionen \\(f\\) kaldes for øvrigt i mange AI modeller for en aktiveringsfunktion. Ofte vil værdimængden for \\(f\\) være \\((0,1)\\). Det gælder for eksempel, hvis \\(f\\) er sigmoid-funktionen \\(\\sigma\\) med forskrift:\n\\[\n\\sigma (x) = \\frac{1}{1+e^{-x}}.\n\\] Med inputværdier \\((x_1, \\dots, x_n)\\) og vægte \\(w_0, w_1, \\dots, w_n\\) bruges sigmoid-funktionen, som aktiveringsfunktion sådan her:\n\\[\nf(w_0, w_1, \\dots, w_n) = \\frac{1}{1+e^{-(w_0 + w_1 \\cdot x_1 + \\cdots + w_n \\cdot x_n)}}.\n\\]\nHvis der bare er tale om en enkelt inputværdi \\(x_1\\), kan det simpliciferes til:\n\\[\nf(w_0, w_1) = \\frac{1}{1+e^{-(w_0 + w_1 \\cdot x_1)}}.\n\\]\nSå er det ikke helt så slemt at se på!\nGrafen for sigmoid-funktionen kan ses i figur 2.\n\n\n\n\n\n\nFigur 2: Grafen for sigmoid-funktionen.\n\n\n\nDa funktionsværdien ligger mellem \\(0\\) og \\(1\\), betyder det, at vi kan tolke værdien af \\(f\\) som en sandsynlighed. Vi forestiller os, at vi får et nyt sæt af inputværdier – for eksempel målingerne fra en ny blodprøve, og vi vil gerne finde ud af, om patienten har kræft eller ej. Disse værdier \"sendes\" nu ind i funktionen \\(f\\) og ud kommer en outputværdi, som vi vil kalde for \\(o\\). Værdien af \\(o\\) betragtes nu som sandsynligheden for, at den rigtige targetværdi er \\(1\\). Det kunne for eksempel være sådan her:\n\\[\n\\textrm{prædiktion}=\n\\begin{cases}\n\\textrm{patienten har kræft} & \\textrm{hvis } o \\geq 0.5 \\\\\n\\textrm{patienten har ikke kræft} & \\textrm{hvis } o &lt; 0.5 \\\\\n\\end{cases}\n\\]\nI vores eksempel med kræft, vil det nok typisk være sådan, at det er meget vigtigt, at alle patienter, hvor der er den mindste mistanke om kræft, sendes til videre udredning. Og derfor kunne man for eksempel også have valgt følgende prædiktion:\n\\[\n\\textrm{prædiktion}=\n\\begin{cases}\n\\textrm{patienten har kræft} & \\textrm{hvis } o \\geq 0.05 \\\\\n\\textrm{patienten har ikke kræft} & \\textrm{hvis } o &lt; 0.05 \\\\\n\\end{cases}\n\\]\nDet afhænger altså af den konkrete anvendelse, hvordan man vil forholde sig til den beregnede outputværdi.\nMen uanset hvad, så vil det kun give mening, hvis vi har fundet de værdier af vægtene, som gør, at denne prædiktion rent faktisk bliver god.\nVi har hele tiden sagt, at det gør vi ved at minimere tabsfunktionen, men det kræver jo, at vi har en tabsfunktion. Inden vi dykker længere ned i forskellige typer af tabsfunktioner, skal vi lige have skrevet vores træningsdata lidt mere formelt op.\nVi antager, at vi har \\(M\\) forskellige træningseksempler bestående af inputværdier med tilhørende targetværdi. Det kan opskrives sådan her:\n\\[\n\\begin{aligned}\n&\\text{Træningseksempel 1:} \\quad (x_1^{(1)}, x_2^{(1)}, \\dots, x_n^{(1)}, t^{(1)}) \\\\\n&  \\quad \\quad \\quad \\quad \\vdots \\\\\n&\\text{Træningseksempel m:} \\quad (x_1^{(m)}, x_2^{(m)}, \\dots, x_n^{(m)}, t^{(m)}) \\\\\n&  \\quad \\quad \\quad \\quad \\vdots \\\\\n&\\text{Træningseksempel M:} \\quad (x_1^{(M)}, x_2^{(M)}, \\dots, x_n^{(M)}, t^{(M)}) \\\\\n\\end{aligned}\n\\]\nFor det \\(m\\)’te træningseksempel beregnes outputværdien \\(o^{(m)}\\) ofte som\n\\[\no^{(m)} = f(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)})\n\\]\nog med sigmoid-funktionen som aktiveringsfunktion bliver det\n\\[\n\\begin{aligned}\no^{(m)} &= \\sigma(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)}) \\\\\n&= \\frac{1}{1+e^{-(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)})}}.\n\\end{aligned}\n\\tag{1}\\]\nFor perceptroner og kunstige neuroner svarer \\(x_1, x_2, \\dots, x_n\\) direkte til inputværdierne, som AI modellen i sidste ende skal virke på. I et kunstig neuralt netværk er det mere kompliceret, men ovenstående er korrekt, hvis man tænker på \\(x_1, x_2, \\dots, x_n\\), som de værdier neuronerne i det sidste skjulte lag sender videre til outputlaget.\nHele idéen omkring træningsdata, outputværdi og tabsfunktion er illustreret i figur 3 herunder.\n\n\n\n\n\n\nFigur 3: Idéen med træningsdata, outputværdi og tabsfunktion kort fortalt."
  },
  {
    "objectID": "materialer/tabsfunktioner/tabsfunktioner.html#gradientnedstigning",
    "href": "materialer/tabsfunktioner/tabsfunktioner.html#gradientnedstigning",
    "title": "Tabsfunktioner",
    "section": "Gradientnedstigning",
    "text": "Gradientnedstigning\nEn AI model trænes som sagt ved at finde minimum for tabsfunktionen. Et sådant minimum bestemmes ofte ved hjælp af en numerisk metode, som kaldes for gradientnedstigning. Her kommer gradientnedstigning kort fortalt. Tabsfunktionen\n\\[\nE(w_0,w_1,\\dots, w_n)\n\\] er en funktion af flere variable. Her viser det sig, at gradienten (bestående af alle de partielle afledede) \\[\n\\nabla E(w_0,w_1,\\dots, w_n) =\n\\begin{pmatrix}\n\\frac{\\partial E}{ \\partial w_0} \\\\\n\\frac{\\partial E}{ \\partial w_1} \\\\\n\\vdots \\\\\n\\frac{\\partial E}{ \\partial w_n} \\\\\n\\end{pmatrix}\n\\]\nvil pege i den retning, hvor funktionværdien for \\(E\\) i et givent punkt vokser mest. Derfor vil den negative gradient \\(-\\nabla E(w_0,w_1,\\dots, w_n)\\) pege i den retning, hvor funktionværdien for \\(E\\) i et givent punkt aftager mest.\nDenne viden udnyttes i gradientnedstigning: Stil dig i et tilfældig punkt \\((w_0, w_1, \\dots, w_n)\\) og gå et lille stykke i den negative gradients retning. Så kommer du – hvis ikke du tager et alt for stort skridt – en lille smule tættere på minimum. Det betyder, at alle vægte bliver opdateret på denne måde:\n\n\n\n\n\n\nOpdateringsregler baseret på gradientnedstigning\n\n\n\n\n\n\\[\nw_i^{(\\textrm{ny})} \\leftarrow w_i - \\eta\\cdot \\frac{\\partial E}{\\partial w_i}\n\\tag{2}\\]\n\n\n\nI ovenstående opdateringsregel svarer \\(\\eta\\) til skridtlængden (den kaldes også i AI verdenen for en learning rate), mens pilen til venstre betyder, at vægten \\(w_i\\) skal opdateres ved at tage den nuværende værdi af \\(w_i\\) og trække \\(\\eta\\cdot \\frac{\\partial E}{\\partial w_i}\\) fra.\nOg så er vi endelig klar til at kaste os over forskellige tabsfunktioner!"
  },
  {
    "objectID": "materialer/tabsfunktioner/tabsfunktioner.html#squared-error-tabsfunktionen",
    "href": "materialer/tabsfunktioner/tabsfunktioner.html#squared-error-tabsfunktionen",
    "title": "Tabsfunktioner",
    "section": "Squared error tabsfunktionen",
    "text": "Squared error tabsfunktionen\nEn ofte anvendt tabsfunktion er squared error, som måler de kvadrerede fejl:\n\\[\nE = \\frac{1}{2} \\sum \\left (t-o \\right)^2,\n\\tag{3}\\]\nhvor der summeres over alle træningsdata. Det vil sige, at hvis vi skal skrive det lidt mere korrekt op, bliver det \\[\n\\begin{aligned}\nE(w_0, w_1, &\\dots, w_n) = \\frac{1}{2} \\sum_{m=1}^{M} \\left (t^{(m)}-\no^{(m)} \\right)^2,\n\\end{aligned}\n\\tag{4}\\]\nhvor \\(o^{(m)}\\) er den beregnede outputværdi hørende til det \\(m\\)’te træningseksempel. Faktisk vil man måske i virkeligheden oftere støde på mean squared error tabsfunktionen: \\[\n\\begin{aligned}\nE(w_0, w_1, &\\dots, w_n) = \\frac{1}{M} \\sum_{m=1}^{M} \\left (t^{(m)}-\no^{(m)} \\right)^2,\n\\end{aligned}\n\\] hvor man ser på den gennemsnitlige kvadrede fejl. Men eftersom vi kun er interesseret i at finde minimum for tabsfunktionen, så gør det ingen forskel, om vi ser på squared error eller mean squared error. Vi vil derfor her på siden nøjes med at se på squared error.\nLad os starte med at indse, at \\(E\\) opfylder de to betingelser for en tabsfunktion. For det første kan vi se, at \\(E \\geq 0\\), fordi der er tale om en kvadreret sum. For det andet kan vi se, at hvis AI modellen er god, så vil den beregnede sandsynlighed \\(o\\), for at patienten har kræft være tæt på \\(1\\), når \\(t=1\\), og \\(o\\) vil være tæt på \\(0\\), når \\(t=0\\). Det betyder, at de kvadrerede forskelle \\((t-o)^2\\) i det tilfælde vil være små, og dermed vil tabsfunktionen også være lille. Altså lever \\(E\\) op til de krav, vi stiller til en tabsfunktion.\nDifferentierer vi tabsfunktionen i (3) med hensyn til den \\(i\\)’te vægt \\(w_i\\) får vi: \\[\n\\begin{aligned}\n\\frac{\\partial E}{\\partial w_i} &= \\frac{\\partial}{\\partial w_i}\\left ( \\frac{1}{2} \\sum_{m=1}^M \\left (t^{(m)}-o^{(m)} \\right)^2 \\right ) \\\\\n&=\\frac{1}{2} \\sum_{m=1}^M 2 \\cdot \\left (t^{(m)}-o^{(m)} \\right) \\frac{\\partial}{\\partial w_i} (t^{(m)}-o^{(m)}) \\\\\n&= \\sum_{m=1}^M \\left (t^{(m)}-o^{(m)} \\right) (-1) \\frac{\\partial o^{(m)}}{\\partial w_i} \\\\\n&= - \\sum_{m=1}^M \\left (t^{(m)}-o^{(m)} \\right) \\frac{\\partial o^{(m)}}{\\partial w_i}\n\\end{aligned}\n\\tag{5}\\]\nBruger vi sigmoid-funktionen til at beregne outputværdien \\(o^{(m)}\\) så får vi \\[\n\\begin{aligned}\n\\frac{\\partial o^{(m)}}{\\partial w_i} &= \\frac{\\partial }{\\partial w_i} \\left ( \\sigma (w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_i \\cdot x_i^{(m)} + \\cdots + w_n \\cdot x_n^{(m)}) \\right ) \\\\\n& = \\sigma'(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)}) \\cdot x_i^{(m)}\n\\end{aligned}\n\\]\nBemærk, at vi her ganger med \\(x_i^{(m)}\\), fordi vi skal differentiere summen:\n\\[\nw_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_i \\cdot x_i^{(m)} + \\cdots + w_n \\cdot x_n^{(m)}\n\\]\nmed hensyn til \\(w_i\\) og det eneste led, der afhænger af \\(w_i\\) er \\(w_i \\cdot x_i^{(m)}\\).\nSigmoid-funktionen har den særlige egenskab, at\n\\[\n\\sigma'(x) = \\sigma(x) \\cdot (1-\\sigma(x))\n\\] Og da aktiveringsfunktionen netop beregner outputværdien \\(o^{(m)}\\), så vil\n\\[\n\\frac{\\partial o^{(m)}}{\\partial w_i}  = o^{(m)} \\cdot (1-o^{(m)}) \\cdot x_i^{(m)}\n\\tag{6}\\]\nIndsættes dette i (5), kan den partielle afledede af tabfunktionen med hensyn til \\(w_i\\) skrives som\n\\[\n\\begin{aligned}\n\\frac{\\partial E}{\\partial w_i} &= -\\sum_{m=1}^M \\left (t^{(m)}-o^{(m)} \\right) \\cdot o^{(m)} \\cdot (1-o^{(m)}) \\cdot x_i^{(m)}.\n\\end{aligned}\n\\] Bruger vi den generelle opdateringsregel i (2), får vi\n\\[\nw_i^{(\\textrm{ny})} \\leftarrow w_i - \\eta \\cdot \\left ( -\\sum_{m=1}^M \\left (t^{(m)}-o^{(m)} \\right) \\cdot o^{(m)} \\cdot (1-o^{(m)}) \\cdot x_i^{(m)}\\right).\n\\]\nSom kan omskrives til:\n\n\n\n\n\n\nOpdateringsregler: Squared error tabsfunktion (med sigmoid som aktiveringsfunktion)\n\n\n\n\n\n\\[\nw_i^{(\\textrm{ny})} \\leftarrow w_i + \\eta \\cdot \\sum_{m=1}^M \\left (t^{(m)}-o^{(m)} \\right) \\cdot o^{(m)} \\cdot (1-o^{(m)}) \\cdot x_i^{(m)}.\n\\tag{7}\\]\n\n\n\nLad os se på et eksempel.\n\nEksempel 1 Vi vil i vores fiktive eksempel med biomarkør og prædiktion af kræft bruge squared error tabsfunktionen sammen med sigmoid som aktiveringsfunktion.\nEn delmængde af træningsdatasættet er (ud af i alt 50):\n\n\n\nBiomarkør\nTarget \\(t\\)\n\n\n\n\n\\(19.58\\)\n\\(0\\)\n\n\n\\(18.83\\)\n\\(0\\)\n\n\n\\(8.97\\)\n\\(0\\)\n\n\n\\(36.41\\)\n\\(1\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\\(10.60\\)\n\\(0\\)\n\n\n\nVi kan på den baggrund opskrive squared error tabsfunktionen:\n\\[\n\\begin{aligned}\nE(w_0,w_1) = \\frac{1}{2} (\n& (0-\\sigma(w_0+w_1 \\cdot 19.58))^2 + \\\\\n& (0-\\sigma(w_0+w_1 \\cdot 18.83))^2 + \\\\\n& (0-\\sigma(w_0+w_1 \\cdot 8.97))^2 + \\\\\n& (1-\\sigma(w_0+w_1 \\cdot 36.41))^2 + \\\\\n& \\qquad \\qquad \\qquad\\vdots \\\\\n& (0-\\sigma(w_0+w_1 \\cdot 10.60))^2)\n\\end{aligned}\n\\]\nVi søger nu de værdier af \\(w_0\\) og \\(w_1\\), som minimerer tabsfunktionen. Bruges gradientnedstigning (du kan selv prøve ved at bruge app’en) her fås2:\n2 For at være sikker på, at man finder et lokalt minimum for tabsfunktionen, er \"Maksimalt antal iterationer før algoritmen stopper\" her sat op til 10000. Husk også at vælge \"squared error\" som tabsfunktion og \"sigmoid\" som aktiveringsfunktion.\\[\nw_0 = -7.455 \\quad \\quad \\textrm{og} \\quad \\quad w_1= 0.2539\n\\]\nGrafen for \\[\n\\sigma(-7.455+0.2539 \\cdot x) = \\frac{1}{1+e^{-(-7.455+0.2539 \\cdot x)}}\n\\] ses indtegnet sammen med datapunkterne i figur 4:\n\n\n\n\n\n\n\n\nFigur 4: Her ses et plot af data med biomarkør på \\(x\\)-aksen og sygdomsstatus på \\(y\\)-aksen sammen med grafen for den fundne sigmoid-funktion baseret på at minimere squared error tabsfunktionen. De to mørkeblå punkter illustrerer to nye, fiktive patienter.\n\n\n\n\n\nVi kan nu bruge de fundne vægte til at prædiktere om en fremtidig patient har kræft eller ej. Lad os se på to forskellige værdier af biomarkøren og udregne outputværdi:\n\\[\n\\begin{aligned}\n\\textrm{Patient 1} \\quad \\quad & x = 20: \\quad \\quad o = \\sigma(-7.455+0.2539 \\cdot 20)= 0.085 \\\\\n\\textrm{Patient 2} \\quad \\quad & x = 35: \\quad \\quad o = \\sigma(-7.455+0.2539 \\cdot 35)= 0.807\\\\\n\\end{aligned}\n\\]\nDet vil sige, at hvis patient 1 har en målt biomarkør på 20, så vil vi prædiktere, at der er 8.5% risiko for, at patienten har kræft. Og tilsvarende hvis patient 2 har en målt biomarkør på 35, så vil vi prædiktere, at risikoen for kræft er steget til 80.7%. Disse to patienter ses også indtegnet på figur 4."
  },
  {
    "objectID": "materialer/tabsfunktioner/tabsfunktioner.html#cross-entropy-tabsfunktionen",
    "href": "materialer/tabsfunktioner/tabsfunktioner.html#cross-entropy-tabsfunktionen",
    "title": "Tabsfunktioner",
    "section": "Cross-entropy tabsfunktionen",
    "text": "Cross-entropy tabsfunktionen\nEn anden tabsfunktion, som meget ofte anvendes, men som nok er lidt sværere umiddelbart at forstå, er cross-entropy tabsfunktionen. Den er defineret sådan her:\n\\[\n\\begin{aligned}\nE(w_0, w_1, \\dots, & w_n) = \\\\ &- \\sum_{m=1}^{M} \\left (t^{(m)} \\cdot \\ln(o^{(m)}) + (1-t^{(m)}) \\cdot \\ln(1-o^{(m)})  \\right)\n\\end{aligned}\n\\tag{8}\\]\nher skal outputværdien \\(o^{(m)}\\) ligger mellem \\(0\\) og \\(1\\). Vi bruger derfor igen sigmoid-funktionen3:\n3 Hvis du har læst om logistisk regression, så kan du i afsnittet om likelihood funktionen se, at cross-entropy tabsfunktionen faktisk svarer til minus log-likelihood funktionen. Det vil sige, at finde minimum for cross-entropy svarer til at finde maksimum for log-likelihood funktionen, når man laver logistisk regression.\\[\n\\begin{aligned}\no^{(m)} &= \\sigma (w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)}) \\\\\n&=\\frac{1}{1+e^{-(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)})}}\n\\end{aligned}\n\\]\nDet er ikke oplagt, at cross-entropy overhovedet er en tabsfunktion. Lad os starte med at argumentere for, at \\(E \\geq 0\\).\nHvis vi ser på hvert led i summen i (8), så er der to muligheder alt efter, om \\(t^{(m)}=0\\) eller \\(t^{(m)}=1\\):\n\\[\n\\begin{aligned}\nt^{(m)}=0: & \\quad  t^{(m)} \\cdot \\ln(o^{(m)}) + (1-t^{(m)}) \\cdot \\ln(1-o^{(m)}) = \\ln(1-o^{(m)}) \\\\\nt^{(m)}=1: & \\quad t^{(m)} \\cdot \\ln(o^{(m)}) + (1-t^{(m)}) \\cdot \\ln(1-o^{(m)}) = \\ln(o^{(m)})\n\\end{aligned}\n\\tag{9}\\]\nNu ved vi, at \\(0&lt;o^{(m)}&lt;1\\), og derfor er også \\(0&lt;1-o^{(m)}&lt;1\\). På figur 5 ses grafen for den naturlige logaritme. Her ses det tydeligt, at hvis \\(x\\) ligger mellem \\(0\\) og \\(1\\), så er \\(\\ln(x)\\) negativ.\n\n\n\n\n\n\nFigur 5: Grafen for den naturlige logaritmefunktion.\n\n\n\nDet vil sige, at alle led i summen i (8) er negative, og da der står et minustegn foran hele summen, bliver cross-entropy tabsfunktionen altså positiv.\nVi mangler nu at se, at hvis AI modellen er god, så vil tabsfunktionen være tæt på 0. Her er der igen to muligheder. En god model vil have det sådan, at hvis targetværdien \\(t^{(m)}=1\\), så vil den tilhørende outputværdi \\(o^{(m)}\\) også være tæt på \\(1\\) og omvendt, hvis \\(t^{(m)}=0\\). Vi ser igen på hvert led i summen i (8), som vi gjorde det ovenfor:\n\\[\nt^{(m)}=0: \\quad  t^{(m)} \\cdot \\ln(o^{(m)}) + (1-t^{(m)}) \\cdot \\ln(1-o^{(m)}) = \\ln(1-o^{(m)}) \\\\\n\\] og hvis også \\(o^{(m)}\\) er tæt på \\(0\\), så vil \\[\n\\ln(1-o^{(m)}) \\approx \\ln(1)=0\n\\]\nTilsvarende hvis: \\[\nt^{(m)}=1: \\quad t^{(m)} \\cdot \\ln(o^{(m)}) + (1-t^{(m)}) \\cdot \\ln(1-o^{(m)}) = \\ln(o^{(m)})\n\\] og hvis \\(o^{(m)}\\) er tæt på \\(1\\), så får vi også i det tilfælde, at \\[\n\\ln(o^{(m)}) \\approx \\ln(1)=0.\n\\] Det betyder altså samlet set, at hvis modellen er god, så vil alle led i tabsfunktionen i (8) være tæt på \\(0\\), og den samlede tabsfunktion vil dermed også være tæt på \\(0\\).\nVi vil nu differentiere cross-entropy tabsfunktionen i (8) med hensyn til \\(w_i\\). Husk på at selvom det ikke umiddelbart ser ud som om, at tabsfunktionen afhænger af nogle vægte, så gør den det alligevel via outputværdien \\(o^{(m)}\\):\n\\[\no^{(m)} = f(w_0 + w_1 \\cdot x_1^{(m)} + \\cdots + w_n \\cdot x_n^{(m)})\n\\] Differentierer vi tabsfunktionen ledvist får vi:\n\\[\n\\begin{aligned}\n\\frac{\\partial E}{\\partial w_i} &= - \\sum_{m=1}^{M} \\left ( \\frac{\\partial }{\\partial w_i} \\left (t^{(m)} \\cdot \\ln(o^{(m)}) \\right) + \\frac{\\partial }{\\partial w_i}\\left ((1-t^{(m)}) \\cdot \\ln(1-o^{(m)}) \\right ) \\right) \\\\\n&= - \\sum_{m=1}^{M} \\left ( t^{(m)} \\cdot \\frac{1}{o^{(m)}} \\cdot \\frac{\\partial o^{(m)}}{\\partial w_i} + (1-t^{(m)}) \\cdot \\frac{-1}{1-o^{(m)}} \\cdot \\frac{\\partial o^{(m)}}{\\partial w_i} \\right) \\\\\n\\end{aligned}\n\\] Vi ser nu, at \\(\\frac{\\partial o^{(m)}}{\\partial w_i}\\) indgår som en fællesfaktor i hvert led i summen, og vi kan derfor sætte denne størrelse uden for parentesen:\n\\[\n\\begin{aligned}\n\\frac{\\partial E}{\\partial w_i} &= - \\sum_{m=1}^{M} \\left ( \\frac{t^{(m)}}{o^{(m)}}  - \\frac{(1-t^{(m)})}{1-o^{(m)}}  \\right)\\cdot \\frac{\\partial o^{(m)}}{\\partial w_i} \\\\\n\\end{aligned}\n\\]\nDe to brøker har \\(o^{(m)} \\cdot (1-o^{(m)})\\) som fællesnævner og vi kan derfor sætte på fælles brøkstreg:\n\\[\n\\begin{aligned}\n\\frac{\\partial E}{\\partial w_i} &= - \\sum_{m=1}^{M} \\frac{t^{(m)} \\cdot (1-o^{(m)}) - o^{(m)} \\cdot (1-t^{(m)})}{o^{(m)} \\cdot (1-o^{(m)})} \\cdot \\frac{\\partial o^{(m)}}{\\partial w_i} \\\\\n&= - \\sum_{m=1}^{M}  \\frac{t^{(m)}-t^{(m)} \\cdot o^{(m)} - o^{(m)} +o^{(m)} \\cdot t^{(m)})}{o^{(m)} \\cdot (1-o^{(m)})} \\cdot \\frac{\\partial o^{(m)}}{\\partial w_i} \\\\\n&= - \\sum_{m=1}^{M} \\frac{t^{(m)}- o^{(m)}}{o^{(m)} \\cdot (1-o^{(m)})}\\cdot \\frac{\\partial o^{(m)}}{\\partial w_i} \\\\\n\\end{aligned}\n\\]\nDa vi bruger sigmoid som aktiveringsfunktion, ved vi fra (6), at\n\\[\n\\frac{\\partial o^{(m)}}{\\partial w_i} = o^{(m)} \\cdot (1-o^{(m)}) \\cdot x_i^{(m)}\n\\] og derfor får vi \\[\n\\begin{aligned}\n\\frac{\\partial E}{\\partial w_i} &= - \\sum_{m=1}^{M} \\frac{t^{(m)}- o^{(m)}}{o^{(m)} \\cdot (1-o^{(m)})}\\cdot o^{(m)} \\cdot (1-o^{(m)}) \\cdot x_i^{(m)} \\\\\n&= - \\sum_{m=1}^{M} (t^{(m)}- o^{(m)})\\cdot x_i^{(m)}\n\\end{aligned}\n\\] Bemærk her, at \\(o^{(m)} \\cdot (1-o^{(m)})\\) forkorter ud.\nOpdateringsreglen i (2) bliver derfor med cross-entropy tabsfunktionen: \\[\nw_i^{(\\textrm{ny})} \\leftarrow w_i - \\eta \\cdot \\left (  - \\sum_{m=1}^{M} (t^{(m)}- o^{(m)})\\cdot x_i^{(m)} \\right)\n\\] som kan omskrives til\n\n\n\n\n\n\nOpdateringsregler: Cross-entropy tabsfunktion (med sigmoid som aktiveringsfunktion)\n\n\n\n\n\n\\[\nw_i^{(\\textrm{ny})} \\leftarrow w_i + \\eta \\cdot \\sum_{m=1}^{M} (t^{(m)}- o^{(m)})\\cdot x_i^{(m)}.\n\\tag{10}\\]\n\n\n\nDer er en interessant sammenhæng mellem denne opdateringsregel og Perceptron Learning algoritmen, som du kan læse mere om i boksen herunder.\n\n\n\n\n\n\nCross-entropy versus Perceptron Learning algoritmen\n\n\n\n\n\nI perceptron learning algoritmen er både target- og outputværdien enten \\(-1\\) eller \\(1\\) og her opdateres vægtene ét træningseksempel ad gangen på denne måde:\n\\[\nw_i^{(\\textrm{ny})} \\leftarrow w_i + \\eta \\cdot (t-o) \\cdot x_i\n\\] hvor \\(t-o\\) enten kan være \\(-2, 0\\) eller \\(2\\). I opdateringsreglen i (10) er \\(t-o\\) enten \\(-1, 0\\) eller \\(1\\), men eftersom vi bare kan vælge en skridtlængde \\(\\eta\\), som er dobbelt så stor, så gør det ingen reel forskel.\nDet betyder, at den eneste forskel på perceptron learning algoritmen og cross-entropy tabsfunktionen sammen med sigmoid som aktiveringsfunktion er, at alle træningsdata bruges i opdateringsreglen i sidstnævnte.\n\n\n\nLad os igen se på et eksempel.\n\nEksempel 2 Vi vil i vores fiktive eksempel med biomarkør og prædiktion af kræft nu bruge cross-entropy tabsfunktionen sammen med sigmoid som aktiveringsfunktion. Vi skal igen datasættet fra eksempel 1 og indsætte i cross-entropy tabsfunktionen i (8). Her bruger vi de to udtryk vi fandt i (9) alt efter om \\(t^{(m)}=0\\) eller \\(t^{(m)}=1\\):\n\\[\n\\begin{aligned}\nE(w_0,w_1) = - (\n&\\ln(1-\\sigma(w_0+w_1 \\cdot 19.58)) + \\\\\n& \\ln(1-\\sigma(w_0+w_1 \\cdot 18.83)+ \\\\\n& \\ln(1-\\sigma(w_0+w_1 \\cdot 8.97) + \\\\\n& \\ln(\\sigma(w_0+w_1 \\cdot 36.41) + \\\\\n& \\qquad \\qquad \\qquad\\vdots \\\\\n& \\ln(1-\\sigma(w_0+w_1 \\cdot 10.60))\n\\end{aligned}\n\\]\nVi søger nu igen de værdier af \\(w_0\\) og \\(w_1\\), som minimerer tabsfunktionen. Bruges gradientnedstigning (du kan selv prøve ved at bruge app’en) her fås4:\n4 For at være sikker på, at man finder et lokalt minimum for tabsfunktionen, er \"Maksimalt antal iterationer før algoritmen stopper\" igen sat op til 10000. Husk også at vælge \"cross-entropy\" som tabsfunktion og \"sigmoid\" som aktiveringsfunktion.\\[\nw_0 = -9.413  \\quad \\quad \\textrm{og} \\quad \\quad w_1=0.3218\n\\]\nGrafen for \\[\n\\sigma(-9.413+0.3218 \\cdot x) = \\frac{1}{1+e^{-(-9.413+0.3218 \\cdot x)}}\n\\] ses indtegnet sammen med datapunkterne i figur 6:\n\n\n\n\n\n\n\n\nFigur 6: Her ses et plot af data med biomarkør på \\(x\\)-aksen og sygdomsstatus på \\(y\\)-aksen sammen med grafen for den fundne sigmoid-funktion baseret på at minimere cross-entropy tabsfunktionen. De to lyseblå punkter illustrerer to nye, fiktive patienter.\n\n\n\n\n\nVi kan nu igen bruge de fundne vægte til at prædiktere om en fremtidig patient har kræft eller ej. Lad os se på to forskellige værdier af biomarkøren og udregne outputværdi:\n\\[\n\\begin{aligned}\n\\textrm{Patient 1} \\quad \\quad & x = 20: \\quad \\quad o = \\sigma(-9.413+0.3218 \\cdot 20)= 0.048 \\\\\n\\textrm{Patient 2} \\quad \\quad & x = 35: \\quad \\quad o = \\sigma(-9.413+0.3218 \\cdot 35)= 0.864\\\\\n\\end{aligned}\n\\]\nDet vil sige, at hvis patient 1 har en målt biomarkør på 20, så vil vi nu prædiktere, at der er 4.8% risiko for, at patienten har kræft. Og tilsvarende hvis patient 2 har en målt biomarkør på 35, så er vores bud på risikoen for kræft nu helt oppe på 86.4%. Disse to patienter ses også indtegnet på figur 6.\n\nUmiddelbart kan man jo tænke, at det er hip som hap, om vi vælger den ene eller den anden tabsfunktion. I det næste afsnit skal vi se, at cross-entropy tabsfunktionen faktisk passer bedre sammen med sigmoid-funktionen som aktiveringsfunktion end squared error tabsfunktionen gør. Men lad os for nu sammenligne de to sigmoid-funktioner, som vi fandt i eksempel 1 og eksempel 2.\n\n\n\n\n\n\n\n\nFigur 7: Her ses et plot af data med biomarkør på \\(x\\)-aksen og sygdomsstatus på \\(y\\)-aksen sammen med graferne for de to fundne sigmoid-funktioner baseret på at minimere henholdsvis squared error (mørkeblå) og cross-entropy (lyseblå) tabsfunktionen. De to punkter på hver graf illustrerer to nye, fiktive patienter.\n\n\n\n\n\nI figur 7 har vi tegnet de to grafer for de to forskellige sigmoid-funktioner ind i samme koordinatsystem. Her kan man se, at de to grafer, som er baseret på at minimere henholdsvis cross-entropy tabsfunktionen (lyseblå) og squared error tabsfunktionen (mørkeblå), ikke er sammenfaldende. Det fremgår også af de sandsynligheder, som vi beregnede i eksempel 1 og eksempel 2, og som er opsummeret herunder.\n\nPrædikteret sandsynlighed for at patienten har kræft\n\n\n\nPatient 1 (\\(x=20\\))\nPatient 2 (\\(x=35\\))\n\n\n\n\nSquared error\n\\(0.085\\)\n\\(0.807\\)\n\n\nCross-entropy\n\\(0.048\\)\n\\(0.864\\)\n\n\n\nOm den ene model til forudsigelse af kræft er bedre end den anden, kan man ikke udtalelse sig om alene på baggrund af graferne i figur 7. Det vil i stedet kræve, at man for eksempel bruger nogle af de metoder til modeludvælgelse, som er beskrevet i noten om krydsvalidering."
  },
  {
    "objectID": "materialer/tabsfunktioner/tabsfunktioner.html#slow-learning",
    "href": "materialer/tabsfunktioner/tabsfunktioner.html#slow-learning",
    "title": "Tabsfunktioner",
    "section": "Slow learning",
    "text": "Slow learning\nSom vi lige har set, er resultatet forskelligt, alt efter hvilken tabsfunktion man bruger. Vi skal i dette afsnit se, at cross-entropy sammen med aktiveringsfunktionen sigmoid løser et problem, som squared error (også sammen med sigmoid) har. Dermed kan der være algoritmiske fordele ved at bruge cross-entropy tabsfunktionen.\nVi starter med at huske, at de to tabsfunktioner giver følgende to opdateringsregler:\n\\[\n\\begin{aligned}\n&\\textrm{Squared error:} \\quad \\quad  w_i^{(\\textrm{ny})} \\leftarrow w_i + \\eta \\cdot \\sum_{m=1}^M \\left (t^{(m)}-o^{(m)} \\right) \\cdot o^{(m)} \\cdot (1-o^{(m)}) \\cdot x_i^{(m)} \\\\\n&\\textrm{Cross-entropy:} \\quad \\quad w_i^{(\\textrm{ny})} \\leftarrow w_i + \\eta \\cdot \\sum_{m=1}^{M} (t^{(m)}- o^{(m)})\\cdot x_i^{(m)}.\n\\end{aligned}\n\\]\nProblemet opstår, fordi man i forbindelse med gradientnedstigning starter i et tilfældigt punkt \\((w_0, w_1, \\dots, w_n)\\). Hvis dette punkt svarer til vægte, som resulterer i forkerte prædiktioner, så for eksempel \\(o^{(m)} \\approx 0\\), men \\(t^{(m)} = 1\\), så vil faktoren \\(o^{(m)} \\cdot (1-o^{(m)})\\) være tæt på \\(0\\). Det betyder, at vægtene næsten ikke bliver opdateret, når vi bruger squared error, fordi opdateringsleddene alle er tæt på \\(0\\). Noget tilsvarende gør sig gældende, hvis \\(o^{(m)} \\approx 1\\) og \\(t^{(m)} = 0\\). Dette fænomen kalder man for slow learning.\nI figur 8 ses grafen for squared error tabsfunktionen fra eksemplet om biomarkører og prædiktion af kræft. Her er det ret tydeligt, at der findes værdier af vægtene \\(w_0\\) og \\(w_1\\), hvor grafen flader helt ud. Hvis man får startet sin gradientnedstigning her, så kan der gå lang tid inden, man ender i minimum.\n\n\n\n\n\n\n\n\nFigur 8: Graf for squared error tabsfunktionen fra eksemplet om biomarkører og prædiktion af kræft.\n\n\n\n\nNoget tilsvarende opstår ikke med cross-entropy, da faktoren \\(o^{(m)} \\cdot (1-o^{(m)})\\) ikke indgår i opdateringsleddet i for cross-entropy: \\[\nw_i^{(\\textrm{ny})} \\leftarrow w_i + \\eta \\cdot \\sum_{m=1}^{M} (t^{(m)}- o^{(m)})\\cdot x_i^{(m)}\n\\] Det ses også på grafen for cross-entropy tabsfunktionen i figur 9. Her er der ingen steder, hvor grafen flader ud. Det vil sige, at man ikke på samme måde kan komme til at starte et uheldigt sted på grafen. Derimod vil man ret hurtigt \"lande\" i minimum uanset, hvor man starter.\n\n\n\n\n\n\n\n\nFigur 9: Graf for cross-entropy tabsfunktionen fra eksemplet om biomarkører og prædiktion af kræft."
  },
  {
    "objectID": "materialer/tabsfunktioner/tabsfunktioner.html#relaterede-forløb",
    "href": "materialer/tabsfunktioner/tabsfunktioner.html#relaterede-forløb",
    "title": "Tabsfunktioner",
    "section": "Relaterede forløb",
    "text": "Relaterede forløb\n\n\n\n\n\nForløb\n\n\nKort beskrivelse\n\n\n\n\n\n\nAktiveringsfunktioner\n\n\nI opbygningen af kunstige neurale netværk er aktiveringsfunktioner helt centrale. Og aktiveringsfunktioner skal differentieres – det handler dette forløb om.\n\n\n\n\nOpdatering af vægte i en kunstig neuron\n\n\nEn øvelse i at opdatere vægtene i en kunstig neuron.\n\n\n\n\nOpdatering af vægte i et simpelt neuralt netværk med to skjulte lag\n\n\nEn øvelse i at opdatere vægtene i et simpelt neuralt netværk med to skjulte lag.\n\n\n\n\nOpdatering af vægte i et simpelt neuralt netværk med ét skjult lag (men med cross-entropy som tabsfunktion)\n\n\nEn øvelse i at opdatere vægtene i et neuralt netværk med ét skjult lag med cross-entropy som tabsfunktion.\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "materialer/logistisk/max_likelihood.html",
    "href": "materialer/logistisk/max_likelihood.html",
    "title": "Maksimering af log-likelihoodfunktionen ved brug af partielt afledte",
    "section": "",
    "text": "Når \\(l(a,b)\\) skal maksimeres, kan det gøres ved hjælp af partielt afledede. Husk på, at i et maksimumspunkt, vil begge de partielt afledte være lig 0, dvs. \\[\\begin{align*}\n\\frac{\\partial l(a,b)}{\\partial a} &=0 \\\\\n\\frac{\\partial l(a,b)}{\\partial b} &=0.\n\\end{align*}\\] Vi finder derfor først et mere eksplicit udtryk for \\(l(a,b)\\) som funktion af \\(a\\) og \\(b\\).\n\nEksplicit udtryk for \\(l(a,b)\\)\nVi ved, at log-likelihoodfunktionen er givet ved \\[\n\\begin{aligned}\nl(a,b) &=\\sum_{i=1}^n \\ln(p_i(a,b)) \\\\  \n&= \\sum_{i=1}^n\\big( {y_i}\\cdot \\ln(p(x_i))+(1-y_i)\\cdot \\ln(1-p(x_i)) \\big).\n\\end{aligned}\n\\tag{1}\\]\nVed at ophæve parentesen \\((1-y_i)\\) i (1) fås \\[ l(a,b)=\\sum_{i=1}^n \\big({y_i}\\cdot \\ln(p(x_i))+\\ln(1-p(x_i))- y_i\\cdot \\ln(1-p(x_i))\\big).\\] I to af leddene inden for sumtegnet har vi \\(y_i\\) som en faktor. Vi kan derfor sætte \\(y_i\\) uden for parentes \\[ l(a,b)=\\sum_{i=1}^n \\big(\\ln(1-p(x_i))+{y_i}\\cdot (\\ln(p(x_i))-\\ln(1-p(x_i)))\\big).\\] Ved hjælp af logaritmeregnereglen \\(ln(a/b)=ln(a)-ln(b)\\) får vi \\[ l(a,b)=\\sum_{i=1}^n \\left(\\ln(1-p(x_i))+y_i\\cdot \\ln\\left(\\frac{p(x_i)}{1-p(x_i)}\\right)\\right).\\] Her opsplitter vi til to summer, hvor den ene ikke afhænger af \\(y_i\\). \\[ l(a,b)=\\sum_{i=1}^n \\ln(1-p(x_i))+\\sum_{i=1}^n y_i\\cdot \\ln\\left(\\frac{p(x_i)}{1-p(x_i)}\\right). \\tag{2}\\] Nu har vi fået styr på udtrykket for \\(l(a,b)\\), som dog afhænger af \\(p(x_i)\\). Vi udnytter nu, at vi havde udtrykket \\[p(x_i) = \\frac{1}{1+e^{-(a\\cdot x_i+b)}}\\] og \\[\\ln\\left(\\frac{p(x_i)}{1-p(x_i)}\\right)=ax_i + b.\\] Indsættes dette i (2), får vi \\[l(a,b)=\\sum_{i=1}^n \\ln\\left(1-\\frac{1}{1+e^{-(a\\cdot x_i+b)}}\\right)+\\sum_{i=1}^n y_i\\cdot (ax_i+b).\\] Udtrykket i logaritmen sættes på fælles brøkstreg, og brøken forlænges med \\(e^{a\\cdot x_i+b}\\)\n\\[\n\\begin{aligned}\nl(a,b)&=\\sum_{i=1}^n \\ln\\left(\\frac{e^{-(a\\cdot x_i+b)}}{1+e^{-(a\\cdot x_i+b)}}\\right)+\\sum_{i=1}^n y_i\\cdot (ax_i+b) \\\\ &=\\sum_{i=1}^n \\ln\\left(\\frac{1}{1+e^{a\\cdot x_i+b}}\\right)+\\sum_{i=1}^n y_i\\cdot (ax_i+b)\n\\end{aligned}\n\\] Her benytter vi igen regnereglen \\(\\ln(a/b)=\\ln(a)-\\ln(b)\\). \\[ l(a,b)=\\sum_{i=1}^n\\big(\\ln(1)-\\ln(1+e^{a\\cdot x_i+b})\\big)+\\sum_{i=1}^n y_i\\cdot (ax_i+b).\\] Da \\(\\ln(1)=0\\), har vi endelig \\[\nl(a,b)=\\sum_{i=1}^n \\big(-\\ln(1+e^{a\\cdot x_i+b})\\big)+\\sum_{i=1}^n y_i\\cdot (ax_i+b).\n\\tag{3}\\]\n\n\nPartielt afledede\nVi finder nu de partielt afledte af \\(l(a,b)\\) ved at differentiere (3). Lad os først se på \\(\\frac{\\partial l(a,b)}{\\partial b}\\). I den første sum i (3) skal vi se hvert led som en sammensat funktion, hvor den indre funktion har et led, som også er en sammensat funktion. Så får vi \\[\\frac{\\partial l(a,b)}{\\partial b}= \\sum_{i=1}^n -\\frac{1}{1+e^{a\\cdot x_i+b}}\\cdot (0+e^{a\\cdot x_i+b})\\cdot(0+1) +\\sum_{i=1}^n y_i\\cdot (0+1).\\] Ved at reducere fås \\[\\frac{\\partial l(a,b)}{\\partial b}= \\sum_{i=1}^n -\\frac{e^{a\\cdot x_i+b}}{1+e^{a\\cdot x_i+b}} +\\sum_{i=1}^n y_i\\] Ved at bruge at \\[\np(x) = \\frac{1}{1+e^{-(ax+b)}}= \\frac{e^{(ax+b)}}{1+e^{(ax+b)}}\n\\tag{4}\\] i forbindelse med den første sum og efterfølgende samle leddene i en sum, fås \\[\\frac{\\partial l(a,b)}{\\partial b}= \\sum_{i=1}^n -p(x_i) +\\sum_{i=1}^n y_i=\\sum_{i=1}^n (y_i-p(x_i)).\\]\nNu ser vi på \\(\\frac{\\partial l(a,b)}{\\partial a}\\) på tilsvarende måde. \\[\\frac{\\partial l(a,b)}{\\partial a}= \\sum_{i=1}^n -\\frac{1}{1+e^{a\\cdot x_i+b}}\\cdot (0+e^{a\\cdot x_i+b})\\cdot(1\\cdot x_i+0) +\\sum_{i=1}^n y_i\\cdot (1\\cdot x_i+0)\\] Der reduceres \\[\\frac{\\partial l(a,b)}{\\partial a}= \\sum_{i=1}^n -\\frac{e^{a\\cdot x_i+b}}{1+e^{a\\cdot x_i+b}}\\cdot x_i +\\sum_{i=1}^n y_i\\cdot x_i.\\] Igen bruges (4) til at få \\[\\frac{\\partial l(a,b)}{\\partial a}= \\sum_{i=1}^n -p(x_i)\\cdot x_i +\\sum_{i=1}^n y_i\\cdot x_i=\\sum_{i=1}^n (y_i\\cdot x_i-p(x_i)\\cdot x_i).\\]\nEndelig kan \\(x_i\\) sættes udenfor parentes, hvorved vi har \\[\\frac{\\partial l(a,b)}{\\partial a}=\\sum_{i=1}^n (y_i-p(x_i))\\cdot x_i.\\]\nFor at lave optimering og finde maksimum, skal vi undersøger, hvornår de partielt afledte er nul. Vi skal således løse følgende to ligninger med to ubekendte \\[\\begin{align*}\n0=\\frac{\\partial l(a,b)}{\\partial a}=\\sum_{i=0}^n (y_i-p(x_i))\\cdot x_i \\quad \\text{og} \\quad 0=\\frac{\\partial l(a,b)}{\\partial b}=\\sum_{i=1}^n (y_i-p(x_i)) .\n\\end{align*}\\] Dette ligningssystem er dog ikke bare lige til at løse, så her bliver man nødt til at benytte sig af numeriske metoder til løsning af ligningssytemer."
  },
  {
    "objectID": "materialer/sprogmodeller.html",
    "href": "materialer/sprogmodeller.html",
    "title": "Materialer om sprogmodeller",
    "section": "",
    "text": "Materialer om sprogmodeller\nPå denne side finder du forskellige noter om sprogmodeller. Noterne varierer i sværhedsgrad og i matematisk fokus.\nNoterne er skrevet til elever i gymnasiet og bør læses i den rækkefølge, som de er beskrevet nedenfor. Det er dog ikke nødvendigt at læse alle noterne for at få en forståelse for de store sprogmodeller.\nSværhedsgraden af noterne er klassificeret fra \"forholdvis nem\" (*) til \"svær\" (****).\n\n\n\nIntroduktion til sprogmodeller\n\nNoten giver en en kort og letlæselig introduktion til sprogmodeller, som handler om, hvordan sprogmodeller i virkeligheden bare prøver at forudsige det næste ord i en sætning. Vi anbefaler, at man starter med at læse denne note.\nSværhedsgrad: *\n\n\n\n\n\n\nSimple sprogmodeller\n\nI noten om simple sprogmodeller giver vi en \"blød\" introduktion til idéen bag sprogmodeller, men denne note er ikke en forudsætning for de efterfølgende noter, så man kan vælge at springe den over.\nSværhedsgrad: **\n\n\n\n\n\n\nWord2Vec\n\nDenne note handler om, hvordan ord kan repræsenteres som vektorer, hvor den semantiske betydning af ordet indgår i vektorrepræsentationen. Det gøres ved, at ord, som har nogenlunde samme betydning, bliver repræsenteret ved vektorer, som peger i nogenlunde samme retning. Denne note er central for at forstå de store sprogmodeller.\nSværhedsgrad: ****"
  },
  {
    "objectID": "materialer/neurale_net/neurale_net_helt_generelt.html",
    "href": "materialer/neurale_net/neurale_net_helt_generelt.html",
    "title": "Kunstige neurale netværk helt generelt",
    "section": "",
    "text": "I denne note vil vi se på, hvordan man kan udvide det neurale netværk, vi så på i noten om neurale netværk til et netværk med et vilkårligt antal skjulte lag."
  },
  {
    "objectID": "materialer/neurale_net/neurale_net_helt_generelt.html#sec-feedforward_indekser",
    "href": "materialer/neurale_net/neurale_net_helt_generelt.html#sec-feedforward_indekser",
    "title": "Kunstige neurale netværk helt generelt",
    "section": "Feedforward med indekser",
    "text": "Feedforward med indekser\nVi vil nu se på, hvordan de forskellige \\(a_j^{(k)}\\)-værdier beregnes. Det vil sige, at vi altså skal se på, hvordan de forskellige feedforward-ligninger ser ud med vores nye notation.\n\n\n\n\n\n\nFigur 3: Udregning af \\(a_1^{(2)}\\).\n\n\n\nLad os se på et konkret eksempel, så bliver det lidt nemmere at forholde sig til. Vi starter med at udregne outputværdien \\(a_1^{(2)}\\) for den første neuron i det andet lag. Denne neuron får input fra alle neuroner i det foregående lag (som her er inputlaget). Bruger vi den notation for vægtene, som vi lige har indført, så starter vi med at beregne: \\[\nz_1^{(2)} = w_{11}^{(2)} \\cdot x_1 + w_{12}^{(2)} \\cdot x_2 + w_{13}^{(2)} \\cdot x_3 + w_{14}^{(2)} \\cdot x_4 + b_1^{(2)}\n\\] Der er to ting at bemærke her: 1) Vi vælger, at kalde udtrykket på højreside for \\(z_1^{(2)}\\) og, 2) vi har kaldt biasen for \\(b_1^{(2)}\\).\nBruger vi nu de mere generelle udtryk for inputværdierne \\(a_1^{(1)}, a_2^{(1)}, \\dots, a_4^{(1)}\\) kan vi skrive: \\[\\begin{align}\nz_1^{(2)} &= w_{11}^{(2)} \\cdot a_1^{(1)} + w_{12}^{(2)} \\cdot a_2^{(1)} + w_{13}^{(2)} \\cdot a_3^{(1)} + w_{14}^{(2)} \\cdot a_4^{(1)} + b_1^{(2)} \\\\\n&= \\sum_{i=1}^{4} w_{1i}^{(2)} a_i^{(1)} +  b_1^{(2)}\n\\end{align}\\] Og endelig finder vi outputværdien \\(a_1^{(2)}\\) for den første neuron i det andet lag ved som tidligere at anvende sigmoid-funktionen på ovenstående udtryk: \\[\\begin{align}\na_1^{(2)} &= \\sigma(z_1^{(2)}) \\\\\n&= \\sigma \\left( \\sum_{i=1}^{4} w_{1i}^{(2)} a_i^{(1)} +  b_1^{(2)} \\right)\n\\end{align}\\] Det her er faktisk notationsmæssigt selve idéen. Folder vi det ud til hele det andet lag får vi derfor:\n\n\n\n\n\n\nFeedforwardligninger til lag 2\n\n\n\n\n\nBeregn først: \\[\\begin{align}\nz_1^{(2)} &= \\sum_{i=1}^{4} w_{1i}^{(2)} a_i^{(1)} +  b_1^{(2)} \\\\\n& \\\\\nz_2^{(2)} &=\\sum_{i=1}^{4} w_{2i}^{(2)} a_i^{(1)} +  b_2^{(2)} \\\\\n& \\\\\nz_3^{(2)} &= \\sum_{i=1}^{4} w_{3i}^{(2)} a_i^{(1)} +  b_3^{(2)} \\\\\n\\end{align}\\] Outputværdierne for neuroner i det andet lag udregnes dernæst på denne måde: \\[\\begin{align}\na_1^{(2)} &= \\sigma(z_1^{(2)}) \\\\\n& \\\\\na_2^{(2)} &= \\sigma(z_2^{(2)}) \\\\\n&\\\\\na_3^{(2)} &= \\sigma(z_3^{(2)}) \\\\\n\\end{align}\\]\n\n\n\nOg vover vi pelsen, kan vi helt generelt skrive:\n\n\n\n\n\n\nFeedforward-ligninger til lag 2\n\n\n\n\n\nBeregn først: \\[\\begin{align}\nz_j^{(2)} = \\sum_{i=1}^{4} w_{ji}^{(2)} a_i^{(1)} +  b_j^{(2)}\n\\end{align}\\] Outputværdierne for neuroner i det andet lag udregnes dernæst på denne måde: \\[\\begin{align}\na_j^{(2)} &= \\sigma(z_j^{(2)})\n\\end{align}\\] for \\(j \\in \\{1, 2, 3 \\}\\).\n\n\n\nFordelen ved denne notation er, at det nu er utrolig nemt at opskrive feedforward-ligningerne for lag 3 og 4 - det er blot nogle indekser, som skal ændres lidt. I det tredje lag er der to neuroner, hvis outputværdier beregnes på denne måde:\n\n\n\n\n\n\nFeedforward-ligninger til lag 3\n\n\n\n\n\nBeregn først: \\[\nz_j^{(3)} = \\sum_{i=1}^{3} w_{ji}^{(3)} a_i^{(2)} +  b_j^{(3)}\n\\tag{1}\\] Outputværdierne for neuroner i det tredje lag udregnes dernæst på denne måde: \\[\\begin{align}\na_j^{(3)} &= \\sigma(z_j^{(3)})\n\\end{align}\\] for \\(j \\in \\{1, 2 \\}\\).\n\n\n\nOg endelig beregnes outputtet fra hele netværket i det fjerde lag:\n\n\n\n\n\n\nFeedforward-ligninger til lag 4\n\n\n\n\n\nUdregn først: \\[\nz_j^{(4)} = \\sum_{i=1}^{2} w_{ji}^{(4)} a_i^{(3)} +  b_j^{(4)}\n\\tag{2}\\] Outputværdierne for neuroner i det tredje lag udregnes dernæst på denne måde: \\[\\begin{align}\ny_j = a_j^{(4)} &= \\sigma(z_j^{(4)})\n\\end{align}\\] for \\(j \\in \\{1, 2, 3 \\}\\).\n\n\n\nDet fremgår nu tydeligt, at feedforward-ligningerne er på fuldstændig samme form, og vi vil derfor helt generelt kunne skrive:\n\n\n\n\n\n\nFeedforward-ligninger generelt\n\n\n\n\n\nBeregn først: \\[\\begin{align}\nz_j^{(k)} = \\sum_{i} w_{ji}^{(k)} a_i^{(k-1)} +  b_j^{(k)}\n\\end{align}\\] Outputværdierne for neuroner i det \\(k\\)’te lag udregnes dernæst på denne måde: \\[\\begin{align}\na_j^{(k)} &= \\sigma(z_j^{(k)})\n\\end{align}\\] for \\(k \\in \\{2, 3, 4 \\}\\).\n\n\n\nNår man bruger feedforward, starter man altså med at udregne outputværdierne for det første skjulte lag, dernæst for det andet skjulte lag og så videre, indtil man når til outputværdierne for selve netværket (deraf navnet: feedforward ). Bemærk her, at det ikke giver mening at udregne \\(a_j^{(1)}\\), fordi det svarer til inputværdierne til netværket."
  },
  {
    "objectID": "materialer/neurale_net/neurale_net_helt_generelt.html#sec-backpropagation_indekser",
    "href": "materialer/neurale_net/neurale_net_helt_generelt.html#sec-backpropagation_indekser",
    "title": "Kunstige neurale netværk helt generelt",
    "section": "Backpropagation med indekser",
    "text": "Backpropagation med indekser\nLad os nu se på hvordan backpropagation fungerer. Vi skal altså have opskrevet vores opdateringsregler med den nye notation, og vi vil gribe det an, ligesom vi gjorde det i afsnittet Hvordan træner man et kunstigt neuralt netværk?. Nemlig ved at starte i det sidste lag (her lag \\(4\\)) og finde opdateringsreglerne for de vægte og bias, som har direkte indflydelse på outputværdierne fra lag \\(4\\).\n\nOpdateringsregler for lag \\(4\\)\nVi er altså i første omgang på jagt efter \\[\n\\frac{\\partial E}{\\partial w_{ji}^{(4)}} \\quad \\text{og} \\quad \\frac{\\partial E}{\\partial b_j^{(4)}},\n\\] for \\(j \\in \\{1, 2, 3\\}\\), \\(i \\in \\{1, 2\\}\\). Tabsfunktionen \\(E\\), som hører til netværket i figur 1, bliver her: \\[\nE=\\frac{1}{2} \\sum_{j=1}^3 \\left( t_j-y_j \\right)^2 = \\frac{1}{2} \\sum_{j=1}^3 \\left( t_j-a_j^{(4)} \\right)^2\n\\tag{3}\\] hvor igen \\(t_j\\) er den ønskede target-værdi for den \\(j\\)’te outputneuron.\nLad os starte med at bestemme \\(\\frac{\\partial E}{\\partial w_{ji}^{(4)}}\\). Vi må derfor først se på, hvordan \\(w_{ji}^{(4)}\\) påvirker tabsfunktionen \\(E\\). Da \\(w_{ji}^{(4)}\\) kun indgår i udtrykket for beregningen af \\(z_j^{(4)}\\), som igen bruges til beregningen af \\(a_j^{(4)}\\), som dernæst direkte påvirker tabsfunktionen, kan vi skrive: \\[\nw_{ji}^{(4)} \\rightarrow z_j^{(4)} \\rightarrow a_j^{(4)} \\rightarrow E\n\\] Bruger vi først kædereglen én gang, får vi derfor \\[\n\\frac{\\partial E}{\\partial w_{ji}^{(4)}} = \\frac{\\partial E}{\\partial z_j^{(4)}} \\cdot \\frac{\\partial z_j^{(4)}}{\\partial w_{ji}^{(4)}}\n\\tag{4}\\] og bruges kædereglen igen, kan første faktor udfoldes yderligere \\[\n\\frac{\\partial E}{\\partial z_j^{(4)}} = \\frac{\\partial E}{\\partial a_j^{(4)}} \\cdot  \\frac{\\partial a_j^{(4)}}{\\partial z_j^{(4)}}\n\\] Lad os starte med at udregne \\(\\frac{\\partial E}{\\partial z_j^{(4)}}\\) ved at udregne hver faktor på højresiden i ovenstående udtryk for sig. Fra (3) får vi, at \\[\nE=\\frac{1}{2} \\sum_{j=1}^3 \\left( t_j-a_j^{(4)} \\right)^2 = \\frac{1}{2} \\left( \\left( t_1-a_1^{(4)} \\right)^2 + \\left( t_2-a_2^{(4)} \\right)^2+ \\left( t_3-a_3^{(4)}\\right)^2 \\right)\n\\] Hvis vi f.eks. skal differentiere ovenstående med hensyn til \\(a_2^{(4)}\\), kan vi se at alle de led, som ikke indeholder \\(a_2^{(4)}\\), vil være at betragte som konstanter, når vi differentierer - og når vi differentierer konstanter, får vi som bekendt \\(0\\). Derfor får vi, at \\[\n\\frac{\\partial E}{\\partial a_2^{(4)}} = \\frac{1}{2}\\cdot 2 \\cdot (t_2-a_2^{(4)})\\cdot (-1) = -(t_2-a_2^{(4)})\n\\] På tilsvarende vis har vi derfor generelt, at \\[\n\\frac{\\partial E}{\\partial a_j^{(4)}} = -(t_j-a_j^{(4)})\n\\tag{5}\\] Vi ved også, at \\[\na_j^{(4)} = \\sigma(z_j^{(4)})\n\\] Og bruger vi endnu en gang, at sigmoid-funktionen differentieret er \\(\\sigma'(x)=\\sigma(x)(1-\\sigma(x))\\), får vi, at \\[\n\\frac{\\partial a_j^{(4)}}{\\partial z_j^{(4)}}  = \\sigma'(z_j^{(4)})= \\sigma(z_j^{(4)}) \\cdot (1-\\sigma(z_j^{(4)}))= a_j^{(4)}\\cdot (1-a_j^{(4)})\n\\tag{6}\\] Indtil videre har vi altså, at \\[\\begin{align}\n\\frac{\\partial E}{\\partial z_j^{(4)}} &= \\frac{\\partial E}{\\partial a_j^{(4)}} \\cdot  \\frac{\\partial a_j^{(4)}}{\\partial z_j^{(4)}} \\\\\n&=-(t_j-a_j^{(4)}) \\cdot  a_j^{(4)}\\cdot (1-a_j^{(4)})\n\\end{align}\\] I forhold til det videre arbejde viser det sig hensigtsmæssigt, at lave en samlet betegnelse for \\[\\begin{align}\n\\frac{\\partial E}{\\partial z_j^{(4)}}  \n&=-(t_j-a_j^{(4)}) \\cdot  a_j^{(4)}\\cdot (1-a_j^{(4)})\n\\end{align}\\] Vi sætter derfor \\[\n\\delta_j^{(4)} = \\frac{\\partial E}{\\partial z_j^{(4)}}  = -(t_j-a_j^{(4)}) \\cdot a_j^{(4)} \\cdot (1-a_j^{(4)})\n\\] Udtrykket \\(\\delta_j^{(4)}\\) kalder man også for fejlleddet for det fjerde lag, men det kommer vi tilbage til senere.\nVi har nu fundet den første faktor i (4), og mangler derfor kun at bestemme \\(\\frac{\\partial z_j^{(4)}}{\\partial w_{ji}^{(4)}}\\). Bruger vi (2) ser vi, at \\[\nz_j^{(4)} =  \\sum_{i=1}^{2} w_{ji}^{(4)} a_i^{(3)} +  b_j^{(4)}  =\nw_{j1}^{(4)} a_1^{(3)}+ w_{j2}^{(4)} a_2^{(3)} +  b_j^{(4)}\n\\] Skal vi f.eks. differentiere dette udtryk med hensyn til \\(w_{j1}^{(4)}\\), får vi (fordi de fleste led i ovenstående, vil være at betragte som konstanter) \\[\n\\frac{\\partial z_j^{(4)}}{\\partial w_{j1}^{(4)}} =  a_1^{(3)}\n\\] Og helt tilsvarende hvis vi differentierer med hensyn til \\(w_{j2}^{(4)}\\), får vi \\[\n\\frac{\\partial z_j^{(4)}}{\\partial w_{j2}^{(4)}} =  a_2^{(3)}\n\\] Generelt har vi derfor, at \\[\n\\frac{\\partial z_j^{(4)}}{\\partial w_{ji}^{(4)}} = a_i^{(3)}\n\\tag{7}\\]\nSamler vi nu de tre udtryk, som vi netop har udledt og indsætter i (4) får vi \\[\n\\frac{\\partial E}{\\partial w_{ji}^{(4)}} =  -(t_j-a_j^{(4)}) \\cdot a_j^{(4)} \\cdot (1-a_j^{(4)}) \\cdot a_i^{(3)}\n\\] og med den lidt kortere notation, som vi indførte ovenfor, kan vi nu skrive \\[\n\\frac{\\partial E}{\\partial w_{ji}^{(4)}} =  \\delta_j^{(4)} \\cdot a_i^{(3)}\n\\] For at finde opdateringsreglerne for biasene, må vi først bestemme de partielle afledede af \\(E\\) med hensyn til \\(b_j^{(4)}\\). På helt tilsvarende vis får vi, at \\[\n\\frac{\\partial E}{\\partial b_j^{(4)}} = \\frac{\\partial E}{\\partial z_j^{(4)}} \\cdot \\frac{\\partial z_j^{(4)}}{\\partial b_j^{(4)}}\n\\] Vi ved allerede, at \\[\\begin{align}\n\\frac{\\partial E}{\\partial z_j^{(4)}}  = \\delta_j^{(4)}\n\\end{align}\\] og ser man på ligningen i (2), ses det nemt, at \\[\n\\frac{\\partial z_j^{(4)}}{\\partial b_j^{(4)}} = 1\n\\] og derfor har vi, at \\[\n\\frac{\\partial E}{\\partial b_j^{(4)}}  =\\delta_j^{(4)}\n\\] Opdateringsreglerne for de vægte og bias, som hører til outputlaget (lag \\(4\\)) er derfor \\[\nw_{ji}^{(4)} \\leftarrow w_{ji}^{(4)} - \\eta \\cdot \\frac{\\partial E}{\\partial w_{ji}^{(4)}} = w_{ji}^{(4)} - \\eta \\cdot \\delta_j^{(4)} \\cdot a_i^{(3)}\n\\] og \\[\nb_j^{(4)} \\leftarrow b_j^{(4)} - \\eta \\cdot \\frac{\\partial E}{\\partial b_j^{(4)}}  = b_j^{(4)} - \\eta \\cdot \\delta_j^{(4)}\n\\] Vi kan altså opsummere:\n\n\n\n\n\n\nOpdateringsregler til vægte og bias i outputlaget (lag 4)\n\n\n\n\n\nVægtene i outputlaget opdateres på denne måde: \\[\nw_{ji}^{(4)} \\leftarrow w_{ji}^{(4)} - \\eta \\cdot \\delta_j^{(4)} \\cdot a_i^{(3)}\n\\] Biasene i outputlaget opdateres på denne måde: \\[\nb_j^{(4)} \\leftarrow b_j^{(4)} - \\eta \\cdot \\delta_j^{(4)}\n\\] hvor \\[\n\\delta_j^{(4)} = \\frac{\\partial E}{\\partial z_j^{(4)}}= -(t_j-a_j^{(4)}) \\cdot a_j^{(4)} \\cdot (1-a_j^{(4)})\n\\tag{8}\\]\n\n\n\nUdtrykket \\(\\delta_j^{(4)}\\) kalder man, som nævnt tidligere, også for fejlleddet i den \\(j\\)’te række i det fjerde lag, og man kan se på ovenstående opdateringsregler, at dette fejlled netop indgår i opdateringen af både vægtene og biasene. Faktisk kan vi, præcis som vi gjorde det tidligere, tillægge dette fejlled en intuitiv god mening. Det kommer vi tilbage til igen senere!\nBemærk, at hvis vi i vores netværk starter med at vælge mere eller mindre tilfældige vægte, så kan vi på baggrund af dem bruge feedforwardligningerne til at udregne, \\(a_j^{(4)}\\)- og \\(a_i^{(3)}\\)- værdierne. Samtidig kender vi target-værdierne \\(t_j\\), og vi kan derfor også udregne fejlleddene \\(\\delta_j^{(4)}\\). Vi har altså alt, hvad vi skal bruge for at benytte ovenstående opdateringsregler.\n\n\nOpdateringsregler for lag \\(3\\)\nVi bevæger os nu et trin længere bagud i netværket og udleder opdateringsreglerne for det næstsidste lag - lag \\(3\\). Altså skal vi have bestemt \\[\n\\frac{\\partial E}{\\partial w_{ji}^{(3)}} \\quad \\text{og} \\quad \\frac{\\partial E}{\\partial b_j^{(3)}},\n\\] for \\(j \\in \\{1, 2\\}\\), \\(i \\in \\{1, 2, 3\\}\\). Vi må igen se på, hvordan \\(w_{ji}^{(3)}\\) påvirker tabsfunktionen \\(E\\). Ser vi på figur figur 1, kan vi se, at \\(w_{ji}^{(3)}\\) direkte påvirker \\(z_j^{(3)}\\), som igen direkte påvirker \\(a_j^{(3)}\\). Nu vil den \\(j\\)’te neuron i det tredje lag fyre værdien \\(a_j^{(3)}\\) til alle neuroner i det fjerde lag. Altså vil \\(a_j^{(3)}\\) påvirke \\(z_1^{(4)}, z_2^{(4)}\\) og \\(z_3^{(4)}\\), som bruges til beregning af \\(a_1^{(4)}, a_2^{(4)}\\) og \\(a_3^{(4)}\\), som så igen vil påvirke tabsfunktionen \\(E\\). Det kan illustreres på denne måde \\[\n\\begin{matrix}\n& & & & z_1^{(4)} \\rightarrow a_1^{(4)} & & \\\\\n& & & \\nearrow  & &  \\searrow & \\\\\nw_{ji}^{(3)} & \\rightarrow & z_j^{(3)} \\rightarrow a_j^{(3)} & \\rightarrow &\nz_2^{(4)} \\rightarrow a_2^{(4)} & \\rightarrow & E \\\\\n& & & \\searrow & &  \\nearrow &  \\\\\n& & & & z_3^{(4)} \\rightarrow a_3^{(4)} & & \\\\\n\\end{matrix}\n\\] I første omgang kan vi skrive \\[\n\\frac{\\partial E}{\\partial w_{ji}^{(3)}} = \\frac{\\partial E}{\\partial z_j^{(3)}} \\cdot \\frac{\\partial z_j^{(3)}}{\\partial w_{ji}^{(3)}}\n\\tag{9}\\] og så gentagne gange bruge kædereglen til at udfolde dette udtryk.\nLad os starte med det nemmeste, nemlig \\(\\frac{\\partial z_j^{(3)}}{\\partial w_{ji}^{(3)}}\\). Ser vi på definitionen af \\(z_j^{(3)}\\) i (1), kan vi argumentere helt tilsvarende, som da vi ovenfor udledte udtrykket i (7) og får \\[\n\\frac{\\partial z_j^{(3)}}{\\partial w_{ji}^{(3)}} = a_i^{(2)}\n\\]\nLad os nu kaste os over den første faktor i (9). Vi kan starte med at udnytte denne lidt overordnede måde, som \\(z_j^{(3)}\\) påvirker \\(E\\) på \\[\nz_j^{(3)} \\rightarrow a_j^{(3)} \\rightarrow E\n\\] Kædereglen giver os derfor i første omgang \\[\n\\frac{\\partial E}{\\partial z_j^{(3)}} = \\frac{\\partial E}{\\partial a_j^{(3)}} \\cdot\n\\frac{\\partial a_j^{(3)}}{\\partial z_j^{(3)}}\n\\tag{10}\\] Igen er sidste faktor nem nok, idet \\[\na_j^{(3)} = \\sigma (z_j^{(3)})\n\\] og derfor er \\[\n\\frac{\\partial a_j^{(3)}}{\\partial z_j^{(3)}} = \\sigma' (z_j^{(3)})=\\sigma(z_j^{(3)})\\cdot (1-\\sigma(z_j^{(3)}))= a_j^{(3)} \\cdot (1-a_j^{(3)}),\n\\] hvor vi endnu en gang har benyttet, at \\(\\sigma'(x)=\\sigma(x)(1-\\sigma(x))\\).\nNår vi skal bestemme \\(\\frac{\\partial E}{\\partial a_j^{(3)}}\\) kommer vi ikke udenom kædereglen for funktioner af flere variable. Det bliver tydeligt, når vi zoomer ind på hvordan \\(a_j^{(3)}\\) påvirker \\(E\\): \\[\n\\begin{matrix}\n  & & z_1^{(4)} \\rightarrow a_1^{(4)} & & \\\\\n  & \\nearrow  & &  \\searrow & \\\\\n  a_j^{(3)} & \\rightarrow &\nz_2^{(4)} \\rightarrow a_2^{(4)} & \\rightarrow & E \\\\\n& \\searrow & &  \\nearrow &  \\\\\n& & z_3^{(4)} \\rightarrow a_3^{(4)} & & \\\\\n\\end{matrix}\n\\] For at vi senere kan udnytte nogle af de ligninger, som vi udledte i lag \\(4\\), vil vi faktisk bare nøjes med at se på det, på denne måde: \\[\n\\begin{matrix}\n  & & z_1^{(4)} & & \\\\\n  & \\nearrow  & &  \\searrow & \\\\\n  a_j^{(3)} & \\rightarrow &\nz_2^{(4)} & \\rightarrow & E \\\\\n& \\searrow & &  \\nearrow &  \\\\\n& & z_3^{(4)}  & & \\\\\n\\end{matrix}\n\\] Nu er vi endelig klar til at bruge kædereglen for funktioner af flere variable: \\[\\begin{align}\n\\frac{\\partial E}{\\partial a_j^{(3)}} &=  \\frac{\\partial E}{\\partial z_1^{(4)}} \\cdot \\frac{\\partial z_1^{(4)}}{\\partial a_j^{(3)}}  + \\frac{\\partial E}{\\partial z_2^{(4)}} \\cdot \\frac{\\partial z_2^{(4)}}{\\partial a_j^{(3)}} + \\frac{\\partial E}{\\partial z_3^{(4)}} \\cdot \\frac{\\partial z_3^{(4)}}{\\partial a_j^{(3)}} \\\\\n&= \\sum_{k=1}^{3}\\frac{\\partial E}{\\partial z_k^{(4)}} \\cdot \\frac{\\partial z_k^{(4)}}{\\partial a_j^{(3)}}  \n\\end{align}\\] Se nu dukker der noget op, som vi har set før! Nemlig det fejlled, som vi definerede i (8), og som vi allerede har regnet ud, da vi opdaterede vægtene og biasene i lag \\(4\\). Tænk lige over det - det er faktisk ret fedt! Dvs. at vi kan skrive: \\[\n\\begin{aligned}\n\\frac{\\partial E}{\\partial a_j^{(3)}} &= \\sum_{k=1}^{3} \\delta_k^{(4)} \\cdot \\frac{\\partial z_k^{(4)}}{\\partial a_j^{(3)}}  \n\\end{aligned}\n\\tag{11}\\] Så mangler vi kun lige at finde \\(\\frac{\\partial z_k^{(4)}}{\\partial a_j^{(3)}}\\)! Fra (2) har vi, at \\[\nz_k^{(4)} = \\sum_i w_{ki}^{(4)} a_i^{(3)}+b_k^{(4)}\n\\] så \\[\n\\frac{\\partial z_k^{(4)}}{\\partial a_j^{(3)}} = \\frac{\\partial}{\\partial a_j^{(3)}} \\left(\\sum_i w_{ki}^{(4)} a_i^{(3)}+b_k^{(4)} \\right)\n\\] Når vi skal differentierer summen i ovenstående udtryk, får vi kun et led med, når \\(i=j\\), fordi i alle andre tilfælde, vil vi med hensyn til \\(a_j^{(3)}\\) skulle differentiere en konstant. Og da \\[\n\\frac{\\partial}{\\partial a_j^{(3)}}\\left ( w_{kj}^{(4)} a_j^{(3)} \\right) = w_{kj}^{(4)}\n\\] har vi altså, at \\[\n\\frac{\\partial z_k^{(4)}}{\\partial a_j^{(3)}} = w_{kj}^{(4)}\n\\] Indsætter vi dette i (11), har vi nu \\[\\begin{align}\n\\frac{\\partial E}{\\partial a_j^{(3)}} = \\sum_{k=1}^{3} \\delta_k^{(4)} \\cdot \\frac{\\partial z_k^{(4)}}{\\partial a_j^{(3)}}  = \\sum_{k=1}^{3} \\delta_k^{(4)} \\cdot w_{kj}^{(4)}\n\\end{align}\\]\nNu skal vi i første omgang tilbage til (10) og indsætte det vi netop er kommet frem til: \\[\\begin{align}\n\\frac{\\partial E}{\\partial z_j^{(3)}}=\\underbrace{\\left ( \\sum_{k=1}^{3} \\delta_k^{(4)} \\cdot w_{kj}^{(4)}\\right )}_{\\frac{\\partial E}{\\partial a_j^{(3)}}}\n\\cdot \\underbrace{a_j^{(3)} \\cdot (1-a_j^{(3)})}_{\\frac{\\partial a_j^{(3)}}{\\partial z_j^{(3)}}}\n\\end{align}\\] Som vi gjorde i afsnit 1.2.1, vil vi også give dette lidt lange udtryk en særlig betegnelse, nemlig \\[\\begin{align}\n\\delta_j^{(3)} = \\frac{\\partial E}{\\partial z_j^{(3)}}=\\left ( \\sum_{k=1}^{3} \\delta_k^{(4)} \\cdot w_{kj}^{(4)}\\right )\n\\cdot a_j^{(3)} \\cdot (1-a_j^{(3)})\n\\end{align}\\] Det kan vist godt være lidt svært at bevare overblikket her, men nu er vi faktisk i mål! Vi indsætter i (9) \\[\\begin{align}\n\\frac{\\partial E}{\\partial w_{ji}^{(3)}} &= \\frac{\\partial E}{\\partial z_j^{(3)}} \\cdot \\frac{\\partial z_j^{(3)}}{\\partial w_{ji}^{(3)}} \\\\\n&= \\delta_j^{(3)} \\cdot a_i^{(2)}\n\\end{align}\\]\nDet er nu en smal sag at bestemme \\(\\frac{\\partial E}{\\partial b_j^{(3)}}\\), da \\[\\begin{align}\n\\frac{\\partial E}{\\partial b_j^{(3)}} &= \\frac{\\partial E}{\\partial z_j^{(3)}} \\cdot \\frac{\\partial z_j^{(3)}}{\\partial b_j^{(3)}} \\\\ &= \\delta_j^{(3)}\\cdot \\frac{\\partial z_j^{(3)}}{\\partial b_j^{(3)}}\n\\end{align}\\] Fra (1) har vi, at \\[\nz_j^{(3)} = \\sum_{i=1}^3 w_{ji}^{(3)} a_i^{(2)} + b_j^{(3)}\n\\] og derfor er \\[\n\\frac{\\partial z_j^{(3)}}{\\partial b_j^{(3)}} = 1\n\\] Altså får vi \\[\\begin{align}\n\\frac{\\partial E}{\\partial b_j^{(3)}} = \\delta_j^{(3)}\n\\end{align}\\] Glæden er stor, da vi nu har alle ingredienser til at opskrive opdateringsreglerne for det tredje lag!\n\n\n\n\n\n\nOpdateringsregler til vægte og bias i lag 3\n\n\n\n\n\nVægtene i outputlaget opdateres på denne måde: \\[\nw_{ji}^{(3)} \\leftarrow w_{ji}^{(3)} - \\eta \\cdot \\delta_j^{(3)} \\cdot a_i^{(2)}\n\\] Biasene i outputlaget opdateres på denne måde: \\[\nb_j^{(3)} \\leftarrow b_j^{(3)} - \\eta \\cdot \\delta_j^{(3)}\n\\] hvor \\[\n\\delta_j^{(3)} = \\frac{\\partial E}{\\partial z_j^{(3)}}=\\left( \\sum_{k=1}^{3}\\delta_k^{(4)} \\cdot w_{kj}^{(4)}   \\right) \\cdot a_j^{(3)} \\cdot (1-a_j^{(3)})\n\\tag{12}\\]\n\n\n\nBemærk, at udgangspunktet for ovenstående er, at vi først har lavet et feedforward i netværket, så vi har alle \\(a_i^{(2)}\\)- og \\(a_j^{(3)}\\)-værdier. Derudover har vi allerede opdateret vægtene og biasene i lag \\(4\\). Derfor kender vi også fejleddene \\(\\delta_k^{(4)}\\) fra lag \\(4\\), som indgår i beregningen af \\(\\delta_j^{(3)}\\) i (12). Altså er det muligt at foretage de beregninger, som opdateringsreglerne i lag \\(3\\) kræver.\n\n\nOpdateringsregler for lag \\(2\\)\nVi er nu fremme ved det sidste lag, hvor vi skal have opdateret vægte og bias (husk på at \\(a_i^{(1)}\\)-værdierne jo ikke skal beregnes, men er inputværdierne til netværket). Den gode nyhed her er, at der absolut intet nyt er under solen! Vi vil derfor heller ikke gå i drabelige deltaljer med alle udregninger her, men blot skitsere idéen.\nVi er nu på jagt efter \\[\n\\frac{\\partial E}{\\partial w_{ji}^{(2)}} \\quad \\text{og} \\quad \\frac{\\partial E}{\\partial b_j^{(2)}}\n\\] og kigger vi på vores netværk i figur 1 kan vi se følgende afhængigheder: \\[\n\\begin{matrix}\n& & & & z_1^{(3)}  & & \\\\\n& & & \\nearrow  & &  \\searrow & \\\\\nw_{ji}^{(2)} & \\rightarrow & z_j^{(2)} \\rightarrow a_j^{(2)} &  &  &  & E \\\\\n& & & \\searrow & &  \\nearrow &  \\\\\n& & & & z_2^{(3)} & & \\\\\n\\end{matrix}\n\\] Vi kan nu igen skrive \\[\n\\frac{\\partial E}{\\partial w_{ji}^{(2)}} = \\frac{\\partial E}{\\partial z_j^{(2)}} \\cdot \\frac{\\partial z_j^{(2)}}{\\partial w_{ji}^{(2)}}\n\\tag{13}\\] Helt analogt til tidligere ses det nemt, at \\[\n\\frac{\\partial z_j^{(2)}}{\\partial w_{ji}^{(2)}} = a_i^{(1)}\n\\] og kædreglen giver igen, at \\[\n\\frac{\\partial E}{\\partial z_j^{(2)}}= \\frac{\\partial E}{\\partial a_j^{(2)}} \\cdot\n\\frac{\\partial a_j^{(2)}}{\\partial z_j^{(2)}}\n\\tag{14}\\] Her fås også uden problemer, at den sidste faktor kan skrives som \\[\n\\frac{\\partial a_j^{(2)}}{\\partial z_j^{(2)}} = a_j^{(2)} \\cdot (1-a_j^{(2)})\n\\] og bruger man kædereglen for funktioner af flere variable, kommer man frem til, at \\[\\begin{align}\n\\frac{\\partial E}{\\partial a_j^{(2)}} &= \\sum_{k=1}^2 \\frac{\\partial E}{\\partial z_k^{(3)}}\n\\cdot \\frac{\\partial  z_k^{(3)}}{\\partial a_j^{(2)}} \\\\\n&= \\sum_{k=1}^2  \\delta_k^{(3)} w_{kj}^{(3)},\n\\end{align}\\] hvor vi allerede har udregnet \\(\\delta_k^{(3)}\\), da vi opdaterede vægtene og biasene i lag \\(3\\).\nIndsætter vi i (14) og samtidig definerer fejlleddet \\(\\delta_j^{(2)}\\) for det andet lag, får vi \\[\n\\delta_j^{(2)} = \\frac{\\partial E}{\\partial z_j^{(2)}} = \\left ( \\sum_{k=1}^2  \\delta_k^{(3)} w_{kj}^{(3)} \\right ) \\cdot a_j^{(2)} \\cdot (1-a_j^{(2)})\n\\] Alt i alt ender vi med \\[\\begin{align}\n\\frac{\\partial E}{\\partial w_{ji}^{(2)}} &= \\delta_j^{(2)} \\cdot a_i^{(1)} \\\\\n&= \\delta_j^{(2)} \\cdot x_i\n\\end{align}\\] fordi alle \\(a_i^{(1)}\\)-værdierne svarer til selve inputværdierne \\(x_i\\) til netværket.\nDet er nu ikke svært at se, at \\[\n\\frac{\\partial E}{\\partial b_j^{(2)}} = \\delta_j^{(2)}\n\\] og vi får derfor følgende opdateringsregler for lag 2:\n\n\n\n\n\n\nOpdateringsregler til vægte og bias i lag 2\n\n\n\n\n\nVægtene i outputlaget opdateres på denne måde: \\[\\begin{align}\nw_{ji}^{(2)} \\leftarrow w_{ji}^{(2)} - \\eta \\cdot \\delta_j^{(2)} \\cdot a_i^{(1)}\n\\end{align}\\] Biasene i outputlaget opdateres på denne måde: \\[\\begin{align}\nb_j^{(2)} \\leftarrow b_j^{(2)} - \\eta \\cdot \\delta_j^{(2)}\n\\end{align}\\] hvor \\[\n\\delta_j^{(2)} = \\frac{\\partial E}{\\partial z_j^{(2)}}= \\left ( \\sum_{k=1}^2  \\delta_k^{(3)} w_{kj}^{(3)} \\right ) \\cdot a_j^{(2)} \\cdot (1-a_j^{(2)})\n\\tag{15}\\]"
  },
  {
    "objectID": "materialer/neurale_net/neurale_net_helt_generelt.html#var-det-så-egentlig-smart-med-alle-de-indekser",
    "href": "materialer/neurale_net/neurale_net_helt_generelt.html#var-det-så-egentlig-smart-med-alle-de-indekser",
    "title": "Kunstige neurale netværk helt generelt",
    "section": "Var det så egentlig smart med alle de indekser?",
    "text": "Var det så egentlig smart med alle de indekser?\nHvis man er nået hertil, kan man godt følge sig en lille smule forpustet. Der har godt nok været mange indekser at holde styr på! Både nogle der var sænkede, og nogle der var hævede og sat i parenteser! Alligevel kan man måske godt se fidusen nu.\nHvis vi ser på de opdateringsregler, som vi lige har udledt, så kan man se, at selve opdateringsreglerne af vægte og bias følger præcis samme form. Faktisk kan man, hvis man sammenligner opdateringsreglerne for de tre lag se, at opdateringsreglerne er på denne form:\n\n\n\n\n\n\nGenerelle opdateringsregler til vægte og bias\n\n\n\n\n\nVægtene opdateres generelt på denne måde: \\[\\begin{align}\nw_{ji}^{(\\text{lag})} \\leftarrow w_{ji}^{(\\text{lag})} - \\eta \\cdot \\delta_j^{(\\text{lag})} \\cdot a_i^{(\\text{lag-1})}\n\\end{align}\\] Biasene i outputlaget opdateres på denne måde: \\[\\begin{align}\nb_j^{(\\text{lag})} \\leftarrow b_j^{(\\text{lag})} - \\eta \\cdot \\delta_j^{(\\text{lag})}\n\\end{align}\\]\n\n\n\nBemærk her, at da vi allerede har lavet en feedforward i netværket, så kender vi outputværdierne \\(a_i^{(\\text{lag})}\\) i alle lag. Det vil sige, at vi kan opdatere vægtene og biasene, når blot vi kan beregne fejlleddene.\nDen eneste reelle forskel på opdateringsreglerne er, at fejlleddene udregnes lidt forskelligt, alt efter om der er tale om outputlaget eller et skjult lag:\n\n\n\n\n\n\nBeregning af fejlleddene\n\n\n\n\n\nFejlleddene i outputlaget beregnes på denne måde: \\[\\begin{align}\n\\delta_j^{(\\text{outputlag})} = -(t_j-y_j) \\cdot y_j \\cdot (1-y_j),\n\\end{align}\\] idet outputværdierne fra netværket netop er \\(y_1, y_2, \\dots\\).\nFejlleddene i et skjult lag beregnes på denne måde: \\[\\begin{align}\n\\delta_j^{(\\text{lag})} = \\left ( \\sum_{k}  \\delta_k^{(\\text{lag+1})} w_{kj}^{(\\text{lag+1})} \\right ) \\cdot a_j^{(\\text{lag})} \\cdot (1-a_j^{(\\text{lag})})\n\\end{align}\\]\n\n\n\nBemærk her, at fejlleddene fra outputlaget uden videre kan beregnes, da vi kender target-værdierne \\(t_j\\) og outputværdierne \\(y_j\\) fra netværket (fordi vi allerede har lavet en feedforward). Vi kan også beregne fejlleddene i alle skjulte lag, idet vi hele tiden arbejder bagud i netværket (backpropagation). Det vil sige, at vi hele tiden har adgang til fejlleddene i laget længere fremme (lag+1), hvor (lag+1) første gang vil svare til outputlaget. Desuden kender vi pga. feedforward alle outputværdier \\(a_j^{(\\text{(lag)})}\\) og alle vægte \\(w_{kj}^{(\\text{(lag+1)})}\\). Derfor kan vi også beregne fejlleddene i alle de skjulte lag.\nDenne indsigt og den generelle overordnede struktur på opdateringsreglerne, var meget svær at indse med fremgangsmåde i afsnittet Hvordan træner man et kunstigt neuralt netværk?. Her druknede alt bare i et sandt bogstavshelvede!\nDer er et par andre interessante ting at sige om beregningen af fejlleddene. Lad os først se på outputlaget: \\[\n\\delta_j^{(\\text{outputlag})} = -(t_j-y_j) \\cdot y_j \\cdot (1-y_j)\n\\] Hvis der er stor forskel på target-værdien \\(t_j\\) og outputværdien \\(y_j\\), så bliver forskellen \\(t_j-y_j\\) numerisk stor. Altså vil en stor forskel på det, vi ønsker, og det vi får ud af netværket betyde, at fejlleddet bliver større og i sidste ende, at de vægte, som direkte påvirker outputtet, også vil blive opdateret meget. Endelig ser vi igen, at hvis outputneuronen er mættet (dvs. at \\(y_j\\) enten er tæt på \\(0\\) eller \\(1\\)), så vil fejlleddet ikke blive opdateret i samme grad, som hvis outputneuronen ikke havde været mættet (fordi hvis \\(y_j\\) enten er tæt på \\(0\\) eller \\(1\\), så vil \\(y_j \\cdot (1-y_j)\\) være tæt på \\(0\\)).\nVi ser altså, at fejlleddet fra det sidste lag direkte afhænger af hvor stor forskellen er på target-værdi og outputværdi.\nSer vi så på fejlleddene fra de skjulte lag: \\[\n\\delta_j^{(\\text{lag})} = \\left ( \\sum_{k}  \\delta_k^{(\\text{lag+1})} w_{kj}^{(\\text{lag+1})} \\right ) \\cdot a_j^{(\\text{lag})} \\cdot (1-a_j^{(\\text{lag})})\n\\] Så kan vi igen se, at hvis den tilhørende outputneuron, som fyrer værdien \\(a_j^{(\\text{lag})}\\), er mættet, så vil fejlleddet være tættere på \\(0\\), end hvis neuronen ikke havde været mættet. Samtidig kan vi også se, at der i fejlleddet indgår en vægtet sum af alle fejlleddene fra laget længere fremme: \\[\n\\sum_{k}  \\delta_k^{(\\text{lag+1})} w_{kj}^{(\\text{lag+1})}\n\\] På den måde vil store fejl i laget længere fremme også få indflydelse på fejlleddet i det nuværende lag."
  },
  {
    "objectID": "materialer/neurale_net/neurale_net_helt_generelt.html#backpropagation---generelt",
    "href": "materialer/neurale_net/neurale_net_helt_generelt.html#backpropagation---generelt",
    "title": "Kunstige neurale netværk helt generelt",
    "section": "Backpropagation - generelt",
    "text": "Backpropagation - generelt\nLad os så se på backpropagation. Vi ved fra det foregående, at der reelt set kun er to ting, vi skal gøre:\n\nFinde opdateringsreglerne for vægte og bias i outputlaget.\nFinde opdateringsreglerne for vægte og bias i et vilkårligt skjult lag.\n\n\nOpdateringsregler i outputlaget\nVores tabsfunktion er stadig \\[\nE= \\frac{1}{2} \\sum_{i=1}^{n_K} \\left ( t_i - a_i^{(K)} \\right )^2,\n\\] hvor \\(t_i\\) igen er targetværdierne. Vi skal bestemme \\[\n\\frac{\\partial E}{\\partial w_{ji}^{(K)}} \\quad \\text{og} \\quad \\frac{\\partial E}{\\partial b_j^{(K)}}\n\\] Vi gør præcis som i afsnit 1.2.1. Vi indser først, at vi har denne direkte afhængighed fra \\(w_{ji}^{(K)}\\) til \\(E\\): \\[\nw_{ji}^{(K)} \\rightarrow z_j^{(K)} \\rightarrow a_j^{(K)} \\rightarrow E\n\\] Derfor får vi \\[\n\\frac{\\partial E}{\\partial w_{ji}^{(K)}} = \\frac{\\partial E}{\\partial z_j^{(K)}} \\cdot \\frac{\\partial z_j^{(K)}}{\\partial w_{ji}^{(K)}}\n\\tag{18}\\] På grund af feedforwardligningen i (16) får vi for det første, at \\[\n\\frac{\\partial z_j^{(K)}}{\\partial w_{ji}^{(K)}} = a_i^{(K-1)}\n\\tag{19}\\] Nu bruger vi kædereglen til at bestemme \\[\n\\frac{\\partial E}{\\partial z_j^{(K)}} = \\frac{\\partial E}{\\partial a_j^{(K)}} \\cdot  \\frac{\\partial a_j^{(K)}}{\\partial z_j^{(K)}}\n\\tag{20}\\] På grund af feedforwardligningen i (17) og egenskaben ved differentialkvotienten af sigmoid-funktionen får vi sidste faktor til \\[\n\\frac{\\partial a_j^{(K)}}{\\partial z_j^{(K)}}  =  a_j^{(K)}\\cdot (1-a_j^{(K)})\n\\] Endelig får vi, ved at differentiere tabsfunktionen med hensyn til \\(a_j^{(K)}\\) \\[\n\\frac{\\partial E}{\\partial a_j^{(K)}} = -(t_j-a_j^{(K)})\n\\] Vi definerer nu igen fejlleddet for outputlaget \\(\\delta_j^{(K)}\\), som tidligere \\[\n\\delta_j^{(K)} = \\frac{\\partial E}{\\partial z_j^{(K)}}\n\\] og indsætter vi det, vi netop har udledt, i (20) får vi \\[\n\\delta_j^{(K)} =  -(t_j-a_j^{(K)}) \\cdot a_j^{(K)} \\cdot (1-a_j^{(K)})\n\\] Indsætter vi nu det hele i (18), har vi altså: \\[\n\\frac{\\partial E}{\\partial w_{ji}^{(K)}} = \\delta_j^{(K)}  \\cdot a_i^{(K-1)}\n\\] Det er ikke svært at overbevise sig selv om, at \\[\n\\frac{\\partial E}{\\partial b_j^{(K)}} = \\delta_j^{(K)}\n\\] og derfor har vi:\n\n\n\n\n\n\nGenerelle opdateringsregler til vægte og bias i outputlaget (lag \\(K\\))\n\n\n\n\n\nVægtene i outputlaget opdateres på denne måde: \\[\\begin{align}\nw_{ji}^{(K)} \\leftarrow w_{ji}^{(K)} - \\eta \\cdot \\delta_j^{(K)} \\cdot a_i^{(K-1)}\n\\end{align}\\] Biasene i outputlaget opdateres på denne måde: \\[\\begin{align}\nb_j^{(K)} \\leftarrow b_j^{(K)} - \\eta \\cdot \\delta_j^{(K)}\n\\end{align}\\] hvor \\[\\begin{align}\n\\delta_j^{(K)} = \\frac{\\partial E}{\\partial z_j^{(K)}}= -(t_j-a_j^{(K)}) \\cdot a_j^{(K)} \\cdot (1-a_j^{(K)})\n\\end{align}\\]\n\n\n\n\n\nOpdateringsregler i et vilkårligt skjult lag\nVi ser nu på et vilkårligt skjult lag \\(k\\), som hverken er inputlaget eller outputlaget. Det vil sige, at \\(k \\in \\{2, 3, \\dots, K-1 \\}\\). Vi antager, at vi har kørt backpropagation på alle lag, der ligger længere fremme i netværket, og specielt har vi altså beregnet fejlleddene i lag \\(k+1:\\) \\[\n\\delta_j^{(k+1)} = \\frac{\\partial E}{\\partial z_j^{(k+1)}}\n\\] Vi indser først, at vi har denne afhængighed fra \\(w_{ji}^{(k)}\\) til tabsfunktionen \\(E\\): \\[\n\\begin{matrix}\n& & & & z_1^{(k+1)}  & & \\\\\n& & & \\nearrow  & \\vdots &  \\searrow & \\\\\nw_{ji}^{(k)} & \\rightarrow & z_j^{(k)} \\rightarrow a_j^{(k)} & \\rightarrow  &  z_j^{(k+1)} & \\rightarrow  & E \\\\\n& & & \\searrow & \\vdots &  \\nearrow &  \\\\\n& & & & z_{n_{k+1}}^{(k+1)} & & \\\\\n\\end{matrix}\n\\tag{21}\\] Vi starter som tidligere med at bruge kædereglen én gang: \\[\n\\frac{\\partial E}{\\partial w_{ji}^{(k)}} = \\frac{\\partial E}{\\partial z_j^{(k)}} \\cdot \\frac{\\partial z_j^{(k)}}{\\partial w_{ji}^{(k)}}\n\\tag{22}\\] Fra feedforwardligningen i (16) får vi for det første, at \\[\n\\frac{\\partial z_j^{(k)}}{\\partial w_{ji}^{(k)}} = a_i^{(k-1)}\n\\] Endnu en anvendelse af kædereglen, og hvor vi også i samme hug definerer fejlleddet \\(\\delta_j^{(k)}\\) for det \\(k\\)’te skjulte lag, giver: \\[\n\\delta_j^{(k)} = \\frac{\\partial E}{\\partial z_j^{(k)}}= \\frac{\\partial E}{\\partial a_j^{(k)}} \\cdot\n\\frac{\\partial a_j^{(k)}}{\\partial z_j^{(k)}}\n\\tag{23}\\] Den sidste partielle afledede kan vi udlede fra feedforwardligningen (17) og egenskaben ved differentialkvotienten af sigmoid-funktionen: \\[\n\\frac{\\partial a_j^{(k)}}{\\partial z_j^{(k)}} = a_j^{(k)} \\cdot (1-a_j^{(k)})\n\\] For at beregne \\(\\frac{\\partial E}{\\partial a_j^{(k)}}\\) må vi have fat i kædereglen for funktioner af flere variable (se illustrationen i (21): \\[\\begin{align}\n\\frac{\\partial E}{\\partial a_j^{(k)}} = \\sum_{i=1}^{n_{k+1}} \\frac{\\partial E}{\\partial z_i^{(k+1)}}\n\\cdot \\frac{\\partial  z_i^{(k+1)}}{\\partial a_j^{(k)}}\n\\end{align}\\] Vi udnytter nu, at vi allerede kender fejlleddene fra lag \\(k+1\\) og kan derfor omskrive til\n\\[\n\\frac{\\partial E}{\\partial a_j^{(k)}} = \\sum_{i=1}^{n_{k+1}} \\delta_i^{(k+1)}\n\\cdot \\frac{\\partial  z_i^{(k+1)}}{\\partial a_j^{(k)}}\n\\tag{24}\\]\nFra feedforwardligningen i (16) får vi, at \\(z_i^{(k+1)}\\) kan skrives som \\[\nz_i^{(k+1)} = \\sum_{j} w_{ij}^{(k+1)} a_j^{(k)} +  b_i^{(k+1)}\n\\] og derfor er \\[\\begin{align}\n\\frac{\\partial  z_i^{(k+1)}}{\\partial a_j^{(k)}} = w_{ij}^{(k+1)}\n\\end{align}\\] Indsætter vi i (24) fås \\[\\begin{align}\n\\frac{\\partial E}{\\partial a_j^{(k)}} = \\sum_{i=1}^{n_{k+1}} \\delta_i^{(k+1)}\n\\cdot w_{ij}^{(k+1)}\n\\end{align}\\] og ved indsættelse i (23) får vi nu fejlleddet i det \\(k\\)’te lag \\[\n\\delta_j^{(k)} = \\frac{\\partial E}{\\partial z_j^{(k)}}=  \\left ( \\sum_{i=1}^{n_{k+1}} \\delta_i^{(k+1)} \\cdot w_{ij}^{(k+1)} \\right) \\cdot a_j^{(k)} \\cdot (1-a_j^{(k)})\n\\] Vi bruger nu udtrykket for \\(\\frac{\\partial E}{\\partial w_{ji}^{(k)}}\\) i (22) og ender med \\[\\begin{align}\n\\frac{\\partial E}{\\partial w_{ji}^{(k)}} = \\delta_j^{(k)} \\cdot a_i^{(k-1)}\n\\end{align}\\] og tilsvarende får vi også, at \\[\n\\frac{\\partial E}{\\partial b_j^{(k)}} = \\delta_j^{(k)}\n\\] Opdateringsreglerne for et vilkårligt skjult lag bliver så:\n\n\n\n\n\n\nOpdateringsregler til vægte og bias i et vilkårligt skjult lag \\(k\\)\n\n\n\n\n\nVægtene i outputlaget opdateres på denne måde: \\[\\begin{align}\nw_{ji}^{(k)} \\leftarrow w_{ji}^{(k)} - \\eta \\cdot \\delta_j^{(k)} \\cdot a_i^{(k-1)}\n\\end{align}\\] Biasene i outputlaget opdateres på denne måde: \\[\\begin{align}\nb_j^{(k)} \\leftarrow b_j^{(k)} - \\eta \\cdot \\delta_j^{(k)}\n\\end{align}\\] hvor \\[\\begin{align}\n\\delta_j^{(k)} = \\frac{\\partial E}{\\partial z_j^{(k)}}=  \\left ( \\sum_{i=1}^{n_{k+1}} \\delta_i^{(k+1)} \\cdot w_{ij}^{(k+1)} \\right) \\cdot a_j^{(k)} \\cdot (1-a_j^{(k)})\n\\end{align}\\]"
  },
  {
    "objectID": "materialer/neurale_net/neurale_net_helt_generelt.html#stokastisk-gradientnedstigning",
    "href": "materialer/neurale_net/neurale_net_helt_generelt.html#stokastisk-gradientnedstigning",
    "title": "Kunstige neurale netværk helt generelt",
    "section": "Stokastisk gradientnedstigning",
    "text": "Stokastisk gradientnedstigning\nVi har faktisk snydt lidt… Okay – indrømmet – det er lidt træls at komme at sige nu! Men i alt hvad vi har lavet indtil nu, har vi kun kigget på ét træningseksempel. Vi har ladet inputværdierne for det ene træningseksempel \"kører igennem\" netværket (feedforward), beregnet tabsfunktionen og brugt resultatet herfra til at opdatere alle vægtene (backpropagation). Men vi har jo ikke kun ét træningseksempel. Vi har faktisk rigtig mange! Måske ligefrem tusindvis af træningsdata. Men hvad gør man så?\nLad os lige genopfriske den tabsfunktion, som vi endte med i det helt generelle tilfælde: \\[\nE= \\frac{1}{2} \\sum_{i=1}^{n_K} \\left ( t_i - a_i^{(K)} \\right )^2.\n\\tag{25}\\] Her er \\(t_i\\) target-værdien for den \\(i\\)’te outputneuron for lige præcis det træningseksempel vi står med. Husk på at et givet træningseksempel består af inputværdierne \\[\nx_1, x_2, \\dots, x_{n_1}\n\\] og de ønskede target-værdier \\[\nt_1, t_2, \\dots, t_{n_K}.\n\\] Når vi kører disse inputværdier igennem netværket, får de selvfølgelig i sidste ende direkte betydning for outputværdierne i det sidste lag (\\(K\\)): \\[\na_1^{(K)}, a_2^{(K)}, \\cdots, a_{n_K}^{(K)}.\n\\] Det vil sige, at i vores tabsfunktion i (25), så afhænger både \\(t_i\\)’erne og \\(a_i^{(K)}\\)’erne af træningseksemplet. Hvis vi sådan lidt generelt benævner vores træningseksempel med \\(x\\), så vil det kunne udtrykkes sådan her: \\[\nE_x= \\frac{1}{2} \\sum_{i=1}^{n_K} \\left ( t_{x,i} - a_{x,i}^{(K)} \\right )^2,\n\\] hvor så \\(t_{x,i}\\) er target-værdien for den \\(i\\)’te outputneuron fra træningsdata \\(x\\) og \\(a_{x,i}^{(K)}\\) er outputværdien for den \\(i\\)’te outputneuron, som er beregnet på baggrund af inputværdierne fra træningsdata \\(x\\).\nDen samlede tabsfunktion, som er den, vi i virkeligheden ønsker at minimere, bliver så gennemsnittet af tabsfunktionerne hørende til de enkelte træningsdata: \\[\nE = \\frac{1}{n} \\sum_x E_x= \\frac{1}{n} \\sum_x \\left ( \\frac{1}{2} \\sum_{i=1}^{n_K} \\left ( t_{x,i} - a_{x,i}^{(K)} \\right )^2 \\right ).\n\\tag{26}\\] Husk på at vi er ude efter \\[\n\\frac{\\partial E}{\\partial w_{ji}^{(k)}} \\quad \\text{og} \\quad \\frac{\\partial E}{\\partial b_j^{(k)}}\n\\] for \\(k \\in \\{2, 3, \\dots, K\\}\\) og hvor \\(E\\) nu er summen i (26). Heldigvis kan vi differentiere ledvis, og der gælder derfor \\[\n\\frac{\\partial E}{\\partial w_{ji}^{(k)}} = \\frac{1}{n} \\sum_x \\frac{\\partial E_x}{\\partial w_{ji}^{(k)}}\n\\] og tilsvarende \\[\n\\frac{\\partial E}{\\partial b_j^{(k)}} = \\frac{1}{n} \\sum_x \\frac{\\partial E_x}{\\partial b_j^{(k)}}\n\\] Det kommer så til at betyde, at opdateringsreglerne nu generelt bliver på formen \\[\nw_{ji}^{(k)} \\leftarrow w_{ji}^{(k)}-\\eta \\cdot \\frac{\\partial E}{\\partial w_{ji}^{(k)}}  =\nw_{ji}^{(k)}-\\eta \\cdot \\frac{1}{n} \\sum_x \\frac{\\partial E_x}{\\partial w_{ji}^{(k)}}\n\\tag{27}\\] og tilsvarende for biasene \\[\nb_j^{(k)} \\leftarrow b_j^{(k)} -\\eta \\cdot \\frac{\\partial E}{\\partial b_j^{(k)}}  =\nb_j^{(k)}-\\eta \\cdot \\frac{1}{n} \\sum_x \\frac{\\partial E_x}{\\partial b_j^{(k)}}\n\\tag{28}\\] Alle leddene \\(\\frac{\\partial E_x}{\\partial w_{ji}^{(k)}}\\) og \\(\\frac{\\partial E_x}{\\partial b_j^{(k)}}\\), som indgår i opdateringsreglerne, svarer netop til hvad vi har udledt i de foregående afsnit, fordi vi jo netop her kun så på ét træningseksempel ad gangen. Hvis vi overfører dette til opdateringsreglerne i outputlaget, så vil vi f.eks. få\n\n\n\n\n\n\nGenerelle opdateringsregler til vægte og bias i outputlaget (lag \\(K\\)) med brug af alle træningsdata\n\n\n\n\n\nVægtene i outputlaget opdateres på denne måde: \\[\\begin{align}\nw_{ji}^{(K)} \\leftarrow w_{ji}^{(K)} - \\eta \\cdot \\frac{1}{n} \\sum_x \\left ( \\delta_{x,j}^{(K)} \\cdot a_{x,i}^{(K-1)} \\right )\n\\end{align}\\] Biasene i outputlaget opdateres på denne måde: \\[\\begin{align}\nb_j^{(K)} \\leftarrow b_j^{(K)} - \\eta \\cdot \\frac{1}{n} \\sum_x \\left ( \\delta_{x,j}^{(K)} \\right )\n\\end{align}\\] hvor \\[\\begin{align}\n\\delta_{x,j}^{(K)} = \\frac{\\partial E_x}{\\partial z_j^{(K)}}= -(t_{x,j}-a_{x,j}^{(K)}) \\cdot a_{x,j}^{(K)} \\cdot (1-a_{x,j}^{(K)})\n\\end{align}\\]\n\n\n\nOg helt tilsvarende vil det se ud for opdateringsreglerne i de skjulte lag.\nLad os lige dvæle lidt ved, hvad det her, det egentlig betyder. Lad os sige at vi har \\(1000\\) træningsdata. Så skal vi lade de \\(1000\\) træningsdata kører igennem netværket, så vi kan beregne de \\(1000\\) led, som indgår i de ovenstående summer. Herefter kan vi opdatere alle vægte og bias én gang. Det vil blot være ét lille skridt på vej ned i dalen mod det lokale minimum, som vi er på jagt efter. Dette lille skridt skal gentages rigtig mange gange, indtil værdien af tabsfunktionen ser ud til at begynde at konvergere – svarende til at vi har ramt det lokale minimum.\nSå selvom gradientnedstigning kan bruges til at finde et lokalt minimum for tabsfunktionen \\(E\\), så er det faktisk også en beregningsmæssig stor og tung opgave! Derfor er der forsket meget videre i at gøre det endnu bedre og endnu hurtigere. I algoritmer som disse er der ofte et trade-off: Man kan gøre noget hurtigere ved at bruge mere hukommelse – eller bruge mindre hukommelse ved at gøre det en smule langsommere. En af de teknikker, der er kommet ud af den forskning, er, at man kan bruge mindre hukommelse ved i hvert opdateringsskridt kun at bruge en tilfældigt udvalgt del af træningsdata – det kunne f.eks. være \\(10\\%\\) af alle træningsdata. Så vil man i hvert skridt stadig bruge opdateringsreglerne i (27) og (28), men hvor der nu kun summeres over de \\(10 \\%\\) af træningsdatene. Hver gang man laver et nyt opdateringsskridt, vil man tage en ny tilfældigt udvalgt del af træningsdata. Denne teknik kalder man stokastisk gradientnedstigning (stochastic gradient descent). Og der er endnu flere af sådanne små ændringer, der enten gør algoritmen hurtigere eller, at den bruger mindre hukommelse. Det vil komme an på den enkelte anvendelse, hvad der er vigtigst her."
  },
  {
    "objectID": "materialer/sprogmodeller/simple.html",
    "href": "materialer/sprogmodeller/simple.html",
    "title": "Simple sprogmodeller",
    "section": "",
    "text": "I denne note vil vi beskrive et helt simpelt – og naivt – bud på en sprogmodel. Selvom modellen, som præsenteres her, er for simpel, giver den alligevel en god forståelse for den grundlæggende idé bag de store sprogmodeller."
  },
  {
    "objectID": "materialer/sprogmodeller/simple.html#sandsynligheden-for-næste-ord",
    "href": "materialer/sprogmodeller/simple.html#sandsynligheden-for-næste-ord",
    "title": "Simple sprogmodeller",
    "section": "Sandsynligheden for næste ord",
    "text": "Sandsynligheden for næste ord\nVi tager udgangspunkt i en sprogmodel, der skal kunne gætte næste ord i en sætning. Hvis vi for eksempel ved, at en sætning starter med \\[\n\\textrm{\"Jeg går en tur i ---\"}\n\\] så skal sprogmodellen prøve at gætte det næste ord. Den skulle gerne vælge et af de mest sandsynlige næste ord. Vi skriver sandsynligheden for at næste ord er \"skoven\", når sætningen starter med \"Jeg går en tur i\", som \\[\nP(\\textrm{skoven} \\mid \\textrm{Jeg går en tur i}).\n\\]\nDenne sandsynlighed kaldes for en betinget sandsynlighed, som du kan læse mere om i boksen herunder.\n\n\n\n\n\n\nBetingede sandsynligheder\n\n\n\n\n\nOvenfor har vi brugt notationen for betingede sandsynligheder. Hvis \\(A\\) og \\(B\\) er to hændelser og \\(P(B)&gt;0\\), så betegner \\(P(A\\mid B)\\) den betingede sandsynlighed for \\(A\\) givet \\(B\\), som er givet ved formlen \\[\n\\label{eq:betinget}\nP(A\\mid B) = \\frac{P(A\\cap B)}{P(B)}\n\\tag{1}\\]\nHer er \\(A\\cap B\\) fælleshændelsen, det vil sige hændelsen, at \\(A\\) og \\(B\\) forekommer samtidig. Vi fortolker \\(P(A\\mid B)\\) som sandsynligheden for, at hændelsen \\(A\\) indtræffer, hvis vi ved, at hændelsen \\(B\\) er indtruffet. Dette giver mening i forhold til (1), idet brøken angiver, hvor stor en andel af sandsynligheden for \\(B\\), der udgøres af sandsynligheden for, at \\(A\\) indtræffer samtidig med \\(B\\).\nI vores eksempel ovenfor, er \\(B\\) hændelsen, at sætningen starter med \"Jeg går en tur i\", mens \\(A\\) er hændelsen, at næste ord er \"skoven\". Den betingede sandsynlighed \\(P(A\\mid B)\\) er så sandsynligheden for at næste ord er \"skoven\", når vi ved, at sætningen starter med \"Jeg går en tur i\". Den er givet ved \\[\n\\begin{aligned}\nP(A\\mid B) &= P(\\textrm{skoven} \\mid \\textrm{Jeg går en tur i}) \\\\\n&= \\frac{P(\\textrm{Jeg går en tur i skoven})}{P(\\textrm{Jeg går en tur i})}\n\\end{aligned}\n\\]\n\n\n\nHvordan kan vi så finde denne sandsynlighed? Jo, her får vi brug for vores korpus af tilgængelig tekst. Vi tæller, hvor mange gange ordkombinationerne \"Jeg går en tur i\" og \"Jeg går en tur i skoven\" optræder i teksten. Vi har så, at andelen af gange, \"Jeg går en tur i\" efterfølges af \"skoven\", er givet ved\n\\[\n\\begin{multline}\nP(\\textrm{skoven} \\mid \\textrm{Jeg går en tur i})= \\\\ \\frac{\\textrm{Antal gange \"Jeg går en tur i skoven\" optræder}}{\\textrm{Antal gange \"Jeg går en tur i\" optræder}}\n\\end{multline}\n\\] Her opstår et problem: det er slet ikke sikkert, at kombinationen \"jeg går en tur i\" findes i vores tekstkorpus1.Man er derfor nødt til at gøre noget smartere. Det kan gøres på mange måder, og vi ser først på en naiv tilgang kaldet \\(N\\)-gram sprogmodeller.\n1 Selv hvis den gør, er det ikke sikkert, at alle relevante fortsættelser (\"byen\", \"parken\", \"haven\", ...) er repræsentereret."
  },
  {
    "objectID": "materialer/sprogmodeller/simple.html#n-gram-sprogmodeller",
    "href": "materialer/sprogmodeller/simple.html#n-gram-sprogmodeller",
    "title": "Simple sprogmodeller",
    "section": "\\(N\\)-gram sprogmodeller",
    "text": "\\(N\\)-gram sprogmodeller\nI \\(N\\)-gram sprogmodeller forsøger man også at bestemme sandsynligheden for næste ord, men nu baserer man sig kun på de \\(N-1\\) foregående ord. Hvis vi skal gætte næste ord efter \"Jeg går en tur i\", ville en \\(4\\)-gram sprogmodel basere sig på sandsynligheder på formen \\[\nP(\\textrm{skoven} \\mid \\textrm{en tur i})=\\frac{\\textrm{Antal gange \"en tur i skoven\" optræder}}{\\textrm{Antal gange \"en tur i\" optræder}}\n\\] Vi tager altså ikke starten på sætningen \"Jeg går\" i betragtning, fordi en 4-gram sprogmodel udelukkende kigger på de sidste tre ord \"en tur i\".\nSom et eksempel på, hvordan \\(N\\)-gram sprogmodeller fungerer, ser vi på et meget lille tekstkorpus bestående af fire sætninger med seks forskellige ord: \\[\n\\begin{aligned}\n&\\textrm{\"En hund løber efter en kat.}\\\\\n&\\textrm{Løber en hund efter en kat?}\\\\\n&\\textrm{En kat løber ikke efter en hund.}\\\\\n&\\textrm{Efter en kat løber en hund.\"}\n\\end{aligned}\n\\] Der er 25 ord i teksten, men kun 6 forskellige: en (8), hund (4), løber (4), efter (4), kat (4), ikke (1), hvor tallet i parentes angiver antal gange, ordet optræder i vores tekst. Vi ignorerer tegnsætning og skelner ikke mellem små og store bogstaver.\nEt bigram er et par af ord, der forekommer efter hinanden i teksten. I tabel 1 nedenfor er der lavet en hyppighedstabel over alle bigram i vores tekst. Vi lader som om, teksten starter forfra, så det sidste \"hund\" efterfølges af \"En\".\n\n\n\n\n\n\n\nen\nhund\nløber\nefter\nkat\nikke\n\n\n\n\nen\n0\n4\n0\n0\n4\n0\n\n\nhund\n1\n0\n1\n2\n0\n0\n\n\nløber\n2\n0\n0\n1\n0\n1\n\n\nefter\n4\n0\n0\n0\n0\n0\n\n\nkat\n1\n0\n3\n0\n0\n0\n\n\nikke\n0\n0\n0\n1\n0\n0\n\n\n\n\n\nTabel 1: Hyppighed af bigram.\n\n\n\nTabellen viser hyppigheden af forskellige bigram i vores tekst. Ordet i venstre søjle er første ord i bigrammet, og ordet i første række er andet ord i bigrammet. For eksempel betyder de to 4-taller i anden række, at \"en hund\" og \"en kat\" hver optræder 4 gange. Der forekommer 12 forskellige bigram i teksten. Det er dem, hvor der ikke står 0 i tabellen. Hvis der står 0, svarer det til et bigram, der ikke forekommer.\nHvis det sidste ord i vores sætning er \"ord\\(_1\\)\", kan vi beregne sandsynligheden for, at næste ord vil være \"ord\\(_2\\)\". Det skriver vi som \\[\nP(\\textrm{ord}_2\\mid \\textrm{ord}_1) = \\frac{\\textrm{Antal gange bigrammet \"ord$_1$ ord$_2$\" optræder}}{\\textrm{Antal gange \"ord$_1$\"  optræder}}\n\\] Hvis for eksempel det seneste ord i vores sætning er \"løber\", så er sandsynligheden for at næste ord er \"efter\" \\[\nP(\\textrm{efter} \\mid \\textrm{løber})=\\frac{1}{4},\n\\] idet \"løber\" forekommer 4 gange, og 1 af gangene er \"efter\" det næste ord.\nLad os illustrere, hvordan man kan bruge bigram til at danne nye sætninger.\n\nVælg et begyndelsesord - lad os sige \"En\".\nFra tabel 1 kan vi se, at der i vores tekst er to muligheder for næste ord, nemlig \"hund\" og \"kat\". De er lige sandsynlige - de optræder begge 4 gange ud af 8. Vi slår plat og krone for at finde næste ord. Det blev \"kat\".\nVi har nu \"En kat\" og kigger i tabel 1 efter et ord, der står efter \"kat\". Der er to muligheder: \"løber\" (3 gange) og \"en\" (1 gang). Vi vælger nu \"løber\" med sandsynlighed 3/4 og \"en\" med sandsynlighed 1/4. Det blev \"løber\".\nNu har vi \"En kat løber\". Hvad kommer efter \"løber\"? Det gør \"en\" (2 gange), \"efter\" (1 gang) og \"ikke\" (1 gang). Vi vælger et af ordene \"en\", \"efter\" og \"ikke\" med sandsynlighed hhv 2/4, 1/4 og 1/4. Vi får \"en\".\nVi har \"En kat løber en\". Næste mulige ord er \"hund\" og \"kat\", som er lige sandsynlige. Vi får \"kat\".\nVi slutter her og ender med sætningen \"En kat løber en kat\". Det giver ikke så meget mening.\n\nDet startede meget godt med at danne vores sætning, men på et tidspunkt holdt den op med at give mening. Problemet er, at man ikke får ret meget af sammenhængen med, når man kun bruger det sidste ord til at gætte det næste udfra. Derfor får man let genereret nogle ret underlige sætninger. Man kan forbedre det ved at kigge på trigram. Et trigram er en sekvens på tre ord efter hinanden. I tabel 2 nedenfor er vist hyppigheden af trigram i vores lille tekst.\n\n\n\n\n\n\n\nen\nhund\nløber\nefter\nkat\nikke\n\n\n\n\nen hund\n1\n0\n1\n2\n0\n0\n\n\nen kat\n1\n0\n3\n0\n0\n0\n\n\nhund en\n0\n1\n0\n0\n0\n0\n\n\nhund løber\n0\n0\n0\n1\n0\n0\n\n\nhund efter\n2\n0\n0\n0\n0\n0\n\n\nløber en\n0\n2\n0\n0\n0\n0\n\n\nløber efter\n1\n0\n0\n0\n0\n0\n\n\nløber ikke\n0\n0\n0\n1\n0\n0\n\n\nefter en\n0\n2\n0\n0\n2\n0\n\n\nkat en\n0\n0\n0\n0\n1\n0\n\n\nkat løber\n2\n0\n0\n0\n0\n1\n\n\nikke efter\n1\n0\n0\n0\n0\n0\n\n\n\n\n\nTabel 2: Hyppighed af trigram.\n\n\n\nSøjlen til venstre i tabel 2 er de første to ord i trigrammet, mens første række angiver tredje ord. Bemærk, at kun bigram, der faktisk forekommer i vores tekstkorpus er vist i første søjle. Anden række viser således, at bigrammet \"en hund\" optræder med \"en\", \"løber\" og \"efter\" som næste ord. Trigrammet \"en hund efter\" optræder 2 gange i vores tekstkorpus.\nMan kan nu finde sandsynlighederne for trigrammet \"ord\\(_1\\) ord\\(_2\\) ord\\(_3\\)\", når vi ved, at de to første ord er \"ord\\(_1\\) ord\\(_2\\)\". Dette skriver vi igen som en betinget sandsynlighed\n\\[\n\\begin{multline}\nP(\\textrm{ord}_3\\mid \\textrm{ord}_1\\textrm{ ord}_2) = \\\\ \\frac{\\textrm{Antal gange trigrammet \"ord$_1$ ord$_2$ ord$_3$\" optræder}}{\\textrm{Antal gange bigrammet \"ord$_1$ ord$_2$\" optræder}}\n\\end{multline}\n\\]\nBruger man informationen i trigram til at generere ny tekst, er det mere restriktivt, hvad man kan skrive. Man kan ikke skrive \"En hund en kat en hund\", fordi \"hund en kat\" ikke er et trigram i vores tekstkorpus. Man kunne derimod godt skrive \"En hund en hund en hund\", da både \"hund en hund\" og \"en hund en\" er trigram i vores tekstkorpus.\n\nLad os begynde som i bigram-eksemplets trin 2, hvor vi har \"En kat\". Der er igen to muligheder: \"en kat løber\" og \"en kat en\". Lad os sige, vores tilfældige valg giver \"en kat løber\"\nNu skal vi finde en mulighed til \"kat løber ...\" og der kan vi vælge \"en\" eller \"ikke\". Vi kan ikke vælge \"efter\", som vi kunne i bigram-modellen. Vi rammer måske \"En kat løber ikke\"\nVi skal finde et ord til \"løber ikke ...\" og der er nu kun \"efter\" at vælge.\nVi har \"en kat løber ikke efter\" og har kun muligheden \"ikke efter en\"\nFra \"en kat løber ikke efter en\", kan vi vælge \"hund\" eller \"kat\". Vælger vi \"hund\", får vi \"en kat løber ikke efter en hund\".\n\nDet er et meget lille tekstkorpus, vi har, og det giver naturligvis problemer. Man kan ikke generere fornuftige sætninger som \"Løber en kat efter en hund?\" (\"kat efter\" er end ikke et bigram i vores lille tekstkorpus). Et andet problem opstår, hvis vi ønsker at starte en sætning med \"Efter kat\". Dette bigram forekommer ikke i vores tekstkorpus, så vi kan slet ikke komme videre.\nSelv hvis vi havde store mængder tekst i vores tekstkorpus, er to ord ikke meget at gætte næste ord ud fra, da meningen med teksten nemt går tabt, når man kun betragter de sidste to ord. For at få et bedre indtryk af meningen med sætningen kan man bruge \\(N\\)-gram, som består af \\(N\\) på hinanden følgende ord. Man prøver så at gætte det \\(N\\)te ord ud fra de \\(N-1\\) foregående. Her er der igen et problem med, at mange \\((N-1)\\)-gram slet ikke findes i vores tekstkorpus. Starter vi med sådan et \\((N-1)\\)-gram, kan vi ikke komme til at gætte videre. Jo større \\(N\\) er, desto større bliver problemet med manglende \\(N\\)-gram."
  },
  {
    "objectID": "materialer/sprogmodeller/simple.html#mere-avancerede-sprogmodeller",
    "href": "materialer/sprogmodeller/simple.html#mere-avancerede-sprogmodeller",
    "title": "Simple sprogmodeller",
    "section": "Mere avancerede sprogmodeller",
    "text": "Mere avancerede sprogmodeller\nFor at kunne gætte næste ord med en \\(N\\)-gram sprogmodel, har vi brug for et stort \\(N\\) for at få meningen med. Det giver rigtig mange mulige kombinationer af de \\(N-1\\) ord, som vi prædikterer næste ord ud fra. Mange af dem vil ikke være repræsenteret i vores tekstkorpus, og vi kan derfor ikke benytte \\(N\\)-gram modellen. Men hvad nu, hvis vores tekstkorpus indeholder en ordsekvens, hvis betydning minder om? Måske ønsker vi at prædiktere næste ord i sætningen \\[\n\\textrm{\"Min hund har en blød ---\"}\n\\] Og måske står denne kombination af ord ikke noget sted i vores tekstkorpus. Til gengæld er der måske et sted, hvor der står \\[\n\\textrm{\"Min kat har en blød pels\"}\n\\] Hvis vi nu ved, at ordene \"hund\" og \"kat\" tit indgår i sammenhænge, der ligner hinanden, så kan vi måske erstatte sætningen \"Min hund har en blød\" med \"Min kat har en blød\" og bruge det til at gætte, at næste ord skal være \"pels\". For at udføre denne idé i praksis, får vi brug for en stor sprogmodel, som en model for sprogets betydning. Et eksempel på, hvordan det kan gøres, er den algoritme, som kaldes for Word2Vec. Kort fortalt er idéen at repræsentere hvert ord med en vektor, hvor ord, hvis betydning minder om hinanden, svarer til vektorer, med nogenlunde samme retning og længde. Et konkret eksempel på det ses i figur 1.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigur 1: Eksempel på hvordan fire ord hver bliver repræsenteret som en vektor. Vektorerne, som repræsenterer dyrerne, peger i nogenlunde samme retning sammenlignet med vektoreren, som repræsenterer ordet \"kælk\". Samtidig kan det også ses, at vektorerne, som repræsenterer ordene \"kat\" og \"mis\" ligner hinanden mere end vektoren, som repræsenterer ordet \"hund\".\n\n\n\nNår vi har lavet vektorrepræsentationer af alle ord i sproget, skal vi bruge dem til at lave prædiktioner af næste ord ud fra de foregående. Til det kan man benytte en form for neuralt netværk til tekstgenerering. I praksis bruges dog en transformer, som er endnu mere avanceret, og som i praksis er den sprogmodel, der virker bedst til tekstgenerering."
  },
  {
    "objectID": "materialer/sprogmodeller/intro.html",
    "href": "materialer/sprogmodeller/intro.html",
    "title": "Introduktion til sprogmodeller",
    "section": "",
    "text": "Mange former for kunstig intelligens skal kunne håndtere sprog. Det gælder selvfølgelig ChatGPT, franske Le Chat og andre chat-bots og generative AI-programmer. Men I kender det også fra for eksempel oversættelsesprogrammer, tekstbehandlingsprogrammer, der retter grammatik, mobiltelefonens forslag til næste ord i en besked og mailprogrammer, der klassificerer emails som spam ud fra indholdet.\nSprog er komplekst. Der er flere hundrede tusinde ord i det danske sprog, afhængigt af hvordan man tæller. Disse ord kan sættes sammen til sætninger på et utal af måder. Men et sprog har samtidig struktur. Det har en syntaks, som er regler for, hvilke ord man må bruge, og hvordan sætninger er sat sammen. Noget vanskeligere så har det også en semantik, der handler om betydningen af sætninger. Mens syntaksen langt hen ad vejen følger regler, som man ville kunne programmere en computer til at kende, så er semantikken meget mindre regelret. Hvordan kan en computer for eksempel vide, om \"en god kost\" refererer til mad eller en fejekost? Vi mennesker afgør det normalt ud fra sammenhængen. Vi skal se, at man kan lære en computer at gøre det samme ved hjælp af en sprogmodel. Eftersom denne model skal indgå i et computerprogram, er der naturligvis tale om en matematisk model."
  },
  {
    "objectID": "materialer/sprogmodeller/intro.html#prædiktion-af-næste-ord",
    "href": "materialer/sprogmodeller/intro.html#prædiktion-af-næste-ord",
    "title": "Introduktion til sprogmodeller",
    "section": "Prædiktion af næste ord",
    "text": "Prædiktion af næste ord\nFælles for mange sprogmodeller er, at de virker ved at gætte (prædiktere) det næste ord i en sætning ud fra de foregående. Generativ AI virker for eksempel ved at bygge sætninger op et ord ad gangen, hvor hvert ord vælges på baggrund af de foregående ord. Hvis en sætning starter med \\[\n\\textrm{\"Jeg går en tur i ---\"}\n\\] så skal sprogmodellen kunne komme med et gæt på det næste ord. Det kunne være ordet \"skoven\".\nHvordan kommer sprogmodellen så med et godt gæt? Jo, først skal modellen trænes på store mængder af tilgængelig tekst, et tekstkorpus. På baggrund af dette tekstkorpus skal sprogmodellen så lære, hvilket ord, der sandsynligvis kommer efter \"Jeg går en tur i\". Det gør den konkret ved at bygge en funktion, der som input tager starten på en sætning og som output giver næste ord. Mere præcist giver funktionen for hvert ord i dens ordforråd sandsynligheden for, at netop dette ord er det næste. Sprogmodellen gætter så på et af de mest sandsynlige ord som det næste. Et eksempel kan ses i tabel 1. Her kan man se, at \"skoven\" og \"byen\" er gode bud på det næste ord i sætningen \"Jeg går en tur i\".\n\n\n\n\n\n\nNæste ord\nSandsynlighed\n\n\n\n\nskoven\n\\(0.385\\)\n\n\nbyen\n\\(0.326\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\nguitar\n\\(0.001\\)\n\n\n\n\n\nTabel 1: Sandsynligheden for det næste ord i sætningen \"Jeg går en tur i\".\n\n\n\nI noten om \"Simple sprogmodeller\" link ser vi på, hvordan man lidt naivt kunne gøre det ved at tælle, hvor hyppigt forskellige ordkombinationer forekommer, og hvorfor det ikke er en god idé."
  },
  {
    "objectID": "materialer/sprogmodeller/intro.html#store-sprogmodeller",
    "href": "materialer/sprogmodeller/intro.html#store-sprogmodeller",
    "title": "Introduktion til sprogmodeller",
    "section": "Store sprogmodeller",
    "text": "Store sprogmodeller\nI stedet må man have fat i en mere avanceret sprogmodel, en såkaldt stor sprogmodel (large language model, LLM). Enhver sprogmodel bygger på viden og hypoteser om, hvordan sprog fungerer. En helt grundlæggende hypotese er, at betydningen af ord kan forstås ved at se på, hvilke sammenhænge, også kaldet kontekst, et ord optræder i. Det er en idé, der blandt andet skyldes den danske sprogforsker Louis Hjelmslev (1899-1965). Vi vil gerne have en model, som har indbygget information om, at\n\nordet \"mus\" kan være et lille pattedyr eller en computermus alt efter sammenhængen,\nordene \"søvn\", \"sove\", \"seng\", \"senge\" er relaterede, fordi de ofte indgår i de samme sammenhænge,\n\"op\" og \"ned\" er relaterede ord, selvom de er hinandens modsætninger.\n\nI noten Word2Vec ser vi på en matematisk model for sproget, hvor alle ord bliver repræsenteret som vektorer, der inkorporerer netop denne slags information. Fordelen ved disse vektorer er, at en computer kan regne med dem, samtidig med at de indeholder information om betydning af ordene.\nFor at kunne bruge disse vektorer til at gætte næste ord, skal der stadig bygges en funktion, der tager vektorerne som input og giver sandsynligheder for næste ord som output. Da det kræver en meget kompliceret funktion, benyttes der, som i så mange andre avancerede AI-algoritmer, et neuralt netværk. Det er emnet i noten om Tekstgenerering med neurale netværk.\nDen form for neuralt netværk, som benyttes i Chat-GPT og andre generative AI-programmer kaldes transformeren. Transformeren kombinerer idéerne fra Word2Vec og neurale netværk. Du kan læse om de væsentligste principper bag transformeren i denne note."
  },
  {
    "objectID": "srp.html",
    "href": "srp.html",
    "title": "SRP",
    "section": "",
    "text": "I arbejdet med studieretningsprojektet kan matematik og AI indgå i et samarbejde med en lang række andre fag. Idéer til sådanne samarbejder findes herunder. Under nogle af emnerne er der også indsat konkrete forslag til problemformuleringer.\nHvis man ønsker, at inddrage kunstige neurale netværk kan noten om simple neurale netværk eller kunstige neurale netværk benyttes. En mulig fremgangsmåde i forbindelse med de generelle kunstige neurale netværk er at bede eleven udlede opdateringsreglerne for et konkret, lille netværk med f.eks. ét skjult lag.\nEn anden mulighed er at bruge noten om perceptroner - eventuelt kombineret med noten om gradientnedstigning."
  },
  {
    "objectID": "srp.html#samfundsfag-og-matematik",
    "href": "srp.html#samfundsfag-og-matematik",
    "title": "SRP",
    "section": "Samfundsfag og matematik",
    "text": "Samfundsfag og matematik\n\n\n\n\n\n\nKandidattest\n\n\n\n\n\nUdarbejdelse af kandidattest i forbindelse med valg. [samfundsfag A]\n\nMaterialer\nNoten om perceptroner.\nNoten om simple neurale netværk.\n\n\n\n\n\n\n\n\n\n\nOvervågning\n\n\n\n\n\nBrugen af kunstig intelligens i forbindelse med ansigtsgenkendelse. Herunder kan emner som persondataloven, retssikkerhed og/eller partiernes holdning til overvågning behandles. [samfundsfag A]\n\nMaterialer\nNoten om simple neurale netværk.\nNoten om kunstige neurale netværk."
  },
  {
    "objectID": "srp.html#dansk-og-matematik",
    "href": "srp.html#dansk-og-matematik",
    "title": "SRP",
    "section": "Dansk og matematik",
    "text": "Dansk og matematik\n\n\n\n\n\n\nAI og anvendelser\n\n\n\n\n\nFormidlingsopgave hvor AI metoder behandles og derefter formidles f.eks. som en populærvidenskabelig artikel. Eleverne skal skrive en danskfaglig meta-del, hvor de redegør for deres overvejelser og valg med hensyn til målgruppe, virkemidler med videre.\n\nMaterialer\nNoten om kunstige neurale netværk.\nNoten om simple neurale netværk.\nNoten om perceptroner.\nNoten om naiv Bayes klassifier."
  },
  {
    "objectID": "srp.html#engelsk-og-matematik",
    "href": "srp.html#engelsk-og-matematik",
    "title": "SRP",
    "section": "Engelsk og matematik",
    "text": "Engelsk og matematik\n\n\n\n\n\n\nMachines like me\n\n\n\n\n\nRedegørelse for hvad et kunstigt neuralt netværk er. I engelsk perspektiveres der til Ian McEwans bog “Machines like me”. [engelsk A]"
  },
  {
    "objectID": "srp.html#idræt-og-matematik",
    "href": "srp.html#idræt-og-matematik",
    "title": "SRP",
    "section": "Idræt og matematik",
    "text": "Idræt og matematik\n\n\n\n\n\n\nBaseball og machine learning\n\n\n\n\n\nImplementering af et kunstig neuralt netværk, som kan forudsige baseball tegn (app til implementering af netværk er under udarbejdelse). [idræt C, evt. innovativ]\n\nMaterialer\nStealing Baseball Signs with a Phone (Machine Learning)."
  },
  {
    "objectID": "srp.html#biologi-og-matematik",
    "href": "srp.html#biologi-og-matematik",
    "title": "SRP",
    "section": "Biologi og matematik",
    "text": "Biologi og matematik\n\n\n\n\n\n\nDiagnosticering af sygdomme\n\n\n\n\n\nRedegørelse for hvordan et kunstigt neuralt netværk kan trænes, så det kan anvendes i forbindelse med diagnosticering af sygdomme - herunder kan opdateringsreglerne for et lille, simpelt netværk udledes. [biologi A]\n\nMaterialer\nMeet the computer diagnosing cancer.\n\n\n\n\n\n\n\n\n\n\nDiabetes type II og logistisk regression\n\n\n\n\n\nI biologi arbejdes der med diabetes type II og oral glukosetolerancetest (OGTT) som screeningstest. [biologi C]\nI matematik redegøres der for logistisk regression – herunder hvordan denne metode kan benyttes til at prædiktere sygdom ved en person ud fra information fra et større datasæt. Desuden forklares idéen bag maksimum likelihood, og hvordan parametrene i modellen estimeres.\nDer kan eventuelt konstrueres et OGTT-datasæt, hvorpå der udføres logistisk regression – herunder kan der redegøres for betydningen af odds, og der kan foretages en prædiktion for diabetes på en fiktiv person, der er testet.\n\nMaterialer\nDansk studie: 3 dages motion om ugen booster diabetes-patienters behandling.\nNoten om logistisk regression."
  },
  {
    "objectID": "srp.html#informatik-og-matematik",
    "href": "srp.html#informatik-og-matematik",
    "title": "SRP",
    "section": "Informatik og matematik",
    "text": "Informatik og matematik\n\n\n\n\n\n\nGenkendelse af håndskrevne tal\n\n\n\n\n\nImplementering af et kunstig neuralt netværk med ét skjult lag, som kan kende forskel på f.eks. håndskrevne 2- og 9-taller. [informatik B, innovativ opgave]\n\nProblemformulering\nUdarbejd et løsningsforslag til hvordan man oversætter håndskrevne tal, så de kan genkendes af en computer. I den forbindelse skal du:\n\nRedegør for hvad der forstås ved et kunstigt neuralt netværk, hvor du tager udgangspunkt i et netværk med ét skjult lag. Kom herunder ind på feedforward og backpropagation.\nImplementer et kunstig neuralt netværk med ét skjult lag, som kan bruges til at kende forskel på 2- og 9-taller (brug en passende delmængde af MNIST train-datasættet).\nVurder dit løsningsforslag i forhold til styrker og svagheder samt graden af innovation. Inddrag i den forbindelse en passende delmængde af MNIST test-datasættet.\n\n\n\nMaterialer\nNetværket kan trænes på en passende delmængde af MNIST datasættet.\n\n\n\n\n\n\n\n\n\n\nKunstig intelligens - muligheder og begrænsninger\n\n\n\n\n\nRedegørelse for hvordan et kunstigt neuralt netværk trænes. Diskussion af de etiske problemstillinger, som kan opstå i forbindelse med anvendelsen af kunstig intelligens og/eller diskussion af de muligheder og begrænsninger, der er ved brugen kunstig intelligens. [informatik C]\n\nProblemformulering 1\n\nRedegør kort for begrebet ”kunstig intelligens” - herunder ”deep learning”.\nForklar hvordan et kunstig neuralt netværk virker. Herunder ønskes en redegørelse for hvordan et kunstigt neuralt netværk lærer vha. backpropagation og hvordan kædereglen benyttes i den forbindelse.\nDiskuter de etiske problemstillinger som kan opstå i anvendelsen af kunstig intelligens.\n\n\n\nProblemformulering 2\n\nRedegør for udviklingen inden for kunstig intelligens. Inddrag begreberne machine learning, deep learning samt supervised og unsupervised learning.\nRedegør for teorien bag kunstige neurale netværk herunder hvordan kunstige neurale netværk lærer vha. backpropagation og costfunktionen. Forklar også hvordan kædereglen benyttes i den forbindelse.\nDiskuter hvilke muligheder og begrænsninger der er ved brugen af machine learning. Inddrag bilag 1.\n\nBilag 1"
  },
  {
    "objectID": "srp.html#psykologi-og-matematik",
    "href": "srp.html#psykologi-og-matematik",
    "title": "SRP",
    "section": "Psykologi og matematik",
    "text": "Psykologi og matematik\n\n\n\n\n\n\nPrædiktion af psykisk sygdom ved hjælp af deep learning\n\n\n\n\n\nForklare hvordan kunstige neurale netværk kan bruges til at prædiktere psykisk sygdom baseret på register og genetiske data.\n\nMaterialer\nNoten om simple neurale netværk.\nNoten om kunstige neurale netværk.\nDeep Learning for Cross-Diagnostic Prediction of Mental Disorder Diagnosis and Prognosis Using Danish Nationwide Register and Genetic Data."
  },
  {
    "objectID": "teacher.html",
    "href": "teacher.html",
    "title": "For lærerne",
    "section": "",
    "text": "Her kommer information om hvordan materialerne kan bruges i forskellige typer forløb i gymnasiet.\nVi har på nuværende tidspunkt erfaring med SRO i matematik og samfundsfag samt forskellige typer af SRP. Kontakt Ege Rubak for nærmere information."
  },
  {
    "objectID": "materialer_test.html",
    "href": "materialer_test.html",
    "title": "Materialer",
    "section": "",
    "text": "Vi har inddelt vores AI materialer i følgende fire grupper:\n\n\n\n\n\n\n\n\n\n\nMaterialer om kunstige neurale netværk\n\n\nForskellige noter – med forskelligt fokus og sværhedsgrad – om kunstige neurale netværk.\n\n\n\n\n\n\n\n\n\n\n\n\n\nMaterialer om sprogmodeller\n\n\nForskellige noter – med forskelligt fokus og sværhedsgrad – om sprogmodeller.\n\n\n\n\n\n\n\n\n\n\n\n\n\nØvrige AI materialer\n\n\nForskellige noter – med forskelligt fokus og sværhedsgrad – om forskellige andre AI materialer (end neurale net og sprogmodeller).\n\n\n\n\n\n\n\n\n\n\n\n\n\nBaggrundsmateriale\n\n\nForskellige noter om noget af det baggrundsstof, som de forskellige AI metoder bygger på.\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "sro.html",
    "href": "sro.html",
    "title": "SRO",
    "section": "",
    "text": "I arbejdet med studieretningsopgaven kan matematik og AI indgå i et samarbejde med en lang række andre fag. Konkrete forløb er beskrevet herunder."
  },
  {
    "objectID": "sro.html#samfundsfag-og-matematik",
    "href": "sro.html#samfundsfag-og-matematik",
    "title": "SRO",
    "section": "Samfundsfag og matematik",
    "text": "Samfundsfag og matematik\n\n\n\n\n\n\nUlighed\n\n\n\n\n\nDer tages afsæt i følgende holdninger til ulighed uden at sætte partier på:\n\n”Blå blok”: Øget ulighed er en drivkraft for øget vækst, som giver øget velstand for alle.\n”Rød blok”: Større lighed er et kendetegn ved de bedst fungerende demokratier og lykkeligste samfund. Det giver samtidig de bedste muligheder for alle og samlet set de bedste rammevilkår for virksomheder.\n\n\nProblemformulering\nHvad er ulighed, og er det et problem i Danmark?\n\nRedegør kort for begrebet ulighed - herunder holdninger til ulighed.\nForklar hvordan kunstig intelligens kan bruges ved kandidattests i forbindelse med valg og lav en simpel kandidattest ud fra nogle få velvalgte spørgsmål om aspekter af ulighed, som skal give en anbefaling om at stemme på enten rød eller blå blok.\nKom desuden ind på forskellige matematiske mål for ulighed herunder Gini-koefficienten.\nDiskussionsspørgsmålet er op til jer (Måske kan uligheden begrænses? Skal den begrænses? Hvordan kan den begrænses? Fordele og ulemper ved ulighed og så videre).\n\n\n\nMaterialer\nNoten om perceptroner.\nPerceptron app - under udarbejdelse.\nJensby, Jakob & Brøndum, Peter (2020): Ulighedens mange ansigter."
  }
]