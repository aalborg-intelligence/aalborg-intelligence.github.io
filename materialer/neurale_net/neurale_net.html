<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="Denne note giver en grundig gennemgang af matematikken bag kunstige neurale netværk.">

<title>Kunstige neurale netværk</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../logo/SVG/Bomaerke_05_AIMAT_2024.svg" rel="icon" type="image/svg+xml">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../logo/PNG/Logo_multi_AIMAT_RGB_2024.png" alt="" class="navbar-logo">
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../undervisningsforlob.html"> 
<span class="menu-text">Undervisningsforløb</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../materialer.html"> 
<span class="menu-text">Materialer</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../sro.html"> 
<span class="menu-text">SRO</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../srp.html"> 
<span class="menu-text">SRP</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../apps.html"> 
<span class="menu-text">Apps</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../referencer.html"> 
<span class="menu-text">Referencer</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">Om os</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Indhold</h2>
   
  <ul>
  <li><a href="#hvad-er-kunstig-intelligens-og-hvad-skal-vi-med-det" id="toc-hvad-er-kunstig-intelligens-og-hvad-skal-vi-med-det" class="nav-link active" data-scroll-target="#hvad-er-kunstig-intelligens-og-hvad-skal-vi-med-det">Hvad er kunstig intelligens og hvad skal vi med det?</a></li>
  <li><a href="#sec-hvordanFunktion" id="toc-sec-hvordanFunktion" class="nav-link" data-scroll-target="#sec-hvordanFunktion">Hvordan laver man en funktion, som kan finde "ting" på billeder?</a>
  <ul class="collapse">
  <li><a href="#video-kunstige-neurale-netværk-1" id="toc-video-kunstige-neurale-netværk-1" class="nav-link" data-scroll-target="#video-kunstige-neurale-netværk-1">VIDEO: Kunstige neurale netværk 1</a></li>
  </ul></li>
  <li><a href="#sec-feedforward" id="toc-sec-feedforward" class="nav-link" data-scroll-target="#sec-feedforward">Hvordan virker et kunstigt neuralt netværk?</a>
  <ul class="collapse">
  <li><a href="#video-kunstige-neurale-netværk-2" id="toc-video-kunstige-neurale-netværk-2" class="nav-link" data-scroll-target="#video-kunstige-neurale-netværk-2">VIDEO: Kunstige neurale netværk 2</a></li>
  </ul></li>
  <li><a href="#sec-backpropagation_bogstaver" id="toc-sec-backpropagation_bogstaver" class="nav-link" data-scroll-target="#sec-backpropagation_bogstaver">Hvordan træner man et kunstigt neuralt netværk?</a>
  <ul class="collapse">
  <li><a href="#video-kunstige-neurale-netværk-3" id="toc-video-kunstige-neurale-netværk-3" class="nav-link" data-scroll-target="#video-kunstige-neurale-netværk-3">VIDEO: Kunstige neurale netværk 3</a></li>
  <li><a href="#video-kunstige-neurale-netværk-4" id="toc-video-kunstige-neurale-netværk-4" class="nav-link" data-scroll-target="#video-kunstige-neurale-netværk-4">VIDEO: Kunstige neurale netværk 4</a></li>
  <li><a href="#sec-opdatering_w" id="toc-sec-opdatering_w" class="nav-link" data-scroll-target="#sec-opdatering_w">Opdatering af <span class="math inline">\(w\)</span>-vægtene</a></li>
  <li><a href="#video-kunstige-neurale-netværk-5" id="toc-video-kunstige-neurale-netværk-5" class="nav-link" data-scroll-target="#video-kunstige-neurale-netværk-5">VIDEO: Kunstige neurale netværk 5</a></li>
  <li><a href="#sec-opdatering_uv" id="toc-sec-opdatering_uv" class="nav-link" data-scroll-target="#sec-opdatering_uv">Opdatering af <span class="math inline">\(u\)</span>- og <span class="math inline">\(v\)</span>-vægtene</a></li>
  <li><a href="#video-kunstige-neurale-netværk-6" id="toc-video-kunstige-neurale-netværk-6" class="nav-link" data-scroll-target="#video-kunstige-neurale-netværk-6">VIDEO: Kunstige neurale netværk 6</a></li>
  <li><a href="#sec-opdatering_rs" id="toc-sec-opdatering_rs" class="nav-link" data-scroll-target="#sec-opdatering_rs">Opdatering af <span class="math inline">\(r\)</span>- og <span class="math inline">\(s\)</span>-vægtene</a></li>
  <li><a href="#video-kunstige-neurale-netværk-7" id="toc-video-kunstige-neurale-netværk-7" class="nav-link" data-scroll-target="#video-kunstige-neurale-netværk-7">VIDEO: Kunstige neurale netværk 7</a></li>
  </ul></li>
  <li><a href="#sec-bogstaver_til_indekser" id="toc-sec-bogstaver_til_indekser" class="nav-link" data-scroll-target="#sec-bogstaver_til_indekser">Fra bogstaver til indekser</a>
  <ul class="collapse">
  <li><a href="#sec-feedforward_indekser" id="toc-sec-feedforward_indekser" class="nav-link" data-scroll-target="#sec-feedforward_indekser">Feedforward med indekser</a></li>
  <li><a href="#sec-backpropagation_indekser" id="toc-sec-backpropagation_indekser" class="nav-link" data-scroll-target="#sec-backpropagation_indekser">Backpropagation med indekser</a>
  <ul class="collapse">
  <li><a href="#sec-opdatering_lag4" id="toc-sec-opdatering_lag4" class="nav-link" data-scroll-target="#sec-opdatering_lag4">Opdateringsregler for lag <span class="math inline">\(4\)</span></a></li>
  <li><a href="#sec-opdatering_lag3" id="toc-sec-opdatering_lag3" class="nav-link" data-scroll-target="#sec-opdatering_lag3">Opdateringsregler for lag <span class="math inline">\(3\)</span></a></li>
  <li><a href="#sec-opdatering_lag2" id="toc-sec-opdatering_lag2" class="nav-link" data-scroll-target="#sec-opdatering_lag2">Opdateringsregler for lag <span class="math inline">\(2\)</span></a></li>
  </ul></li>
  <li><a href="#var-det-så-egentlig-smart-med-alle-de-indekser" id="toc-var-det-så-egentlig-smart-med-alle-de-indekser" class="nav-link" data-scroll-target="#var-det-så-egentlig-smart-med-alle-de-indekser">Var det så egentlig smart med alle de indekser?</a></li>
  </ul></li>
  <li><a href="#sec-NN_generelt" id="toc-sec-NN_generelt" class="nav-link" data-scroll-target="#sec-NN_generelt">Kunstige neurale netværk helt generelt</a>
  <ul class="collapse">
  <li><a href="#backpropagation---generelt" id="toc-backpropagation---generelt" class="nav-link" data-scroll-target="#backpropagation---generelt">Backpropagation - generelt</a>
  <ul class="collapse">
  <li><a href="#opdateringsregler-i-outputlaget" id="toc-opdateringsregler-i-outputlaget" class="nav-link" data-scroll-target="#opdateringsregler-i-outputlaget">Opdateringsregler i outputlaget</a></li>
  <li><a href="#opdateringsregler-i-et-vilkårligt-skjult-lag" id="toc-opdateringsregler-i-et-vilkårligt-skjult-lag" class="nav-link" data-scroll-target="#opdateringsregler-i-et-vilkårligt-skjult-lag">Opdateringsregler i et vilkårligt skjult lag</a></li>
  </ul></li>
  <li><a href="#stokastisk-gradientnedstigning" id="toc-stokastisk-gradientnedstigning" class="nav-link" data-scroll-target="#stokastisk-gradientnedstigning">Stokastisk gradientnedstigning</a></li>
  </ul></li>
  <li><a href="#valg-af-tabsfunktion" id="toc-valg-af-tabsfunktion" class="nav-link" data-scroll-target="#valg-af-tabsfunktion">Valg af tabsfunktion</a></li>
  <li><a href="#billedgenkendelse-og-kunstige-neurale-netværk" id="toc-billedgenkendelse-og-kunstige-neurale-netværk" class="nav-link" data-scroll-target="#billedgenkendelse-og-kunstige-neurale-netværk">Billedgenkendelse og kunstige neurale netværk</a></li>
  <li><a href="#videre-læsning" id="toc-videre-læsning" class="nav-link" data-scroll-target="#videre-læsning">Videre læsning</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Kunstige neurale netværk</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Denne note giver en grundig gennemgang af matematikken bag kunstige neurale netværk.</p>
<section id="hvad-er-kunstig-intelligens-og-hvad-skal-vi-med-det" class="level1 page-columns page-full">
<h1>Hvad er kunstig intelligens og hvad skal vi med det?</h1>
<p>Forestil dig at du gerne vil have en funktion <span class="math inline">\(f\)</span>, som tager et billede som input og som output fortæller dig, om der er en hund på billedet eller ej. Det kan illustreres sådan her:</p>
<div id="fig-funktion" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-funktion-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/funktion.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-funktion-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figur&nbsp;1: Funktion, der tager et billede som input, og som returnerer "ja" eller "nej" som output.
</figcaption>
</figure>
</div>
<p>Okay, det er måske ikke så tit, at man har brug for en funktion, som kan detektere, om der er en hund på et billede, men hvad så hvis funktionen i stedet kan afgøre, om der er en kræftknude på et røntgenbillede? Eller hvis den kan genkende håndskrevet tekst? Sidstnævnte bliver f.eks. flittigt brugt til sortering af breve. Vi ønsker os i virkeligheden at være i stand til at programmere en funktion, som kan "tænke" som et menneske. Når jeg ser et billede, kan jeg på ingen tid afgøre, om der er en hund på billedet eller ej. Står jeg med et brev i hånden, kan jeg som regel også læse navn og adresse. En læge vil også kunne kigge på et røntgenbillede og afgøre, om der er en kræftknude eller ej. Det er i bund og grund, det vi forstår ved kunstig intelligens. At få computeren til at "tænke" som et menneske. Nu kunne man måske godt indvende "hvad skal det til for?". Der er vel ingen grund til at få en computer til at finde kræftknuder på et røntgenbillede, hvis vi allerede kan få en læge til det? Men hvad nu, hvis computeren faktisk kan opdage kræftknuder tidligere end lægen? Eller hvad hvis man har så mange røntgenbilleder, at det vil være smart, at få en computer til at kigge dem igennem først?</p>
</section>
<section id="sec-hvordanFunktion" class="level1 page-columns page-full">
<h1>Hvordan laver man en funktion, som kan finde "ting" på billeder?</h1>
<p>Lad os sige, at vi nu kan se fidusen med den der lidt mærkelige funktion, som kan tage et billede som input, og som output kan fortælle et eller andet om billedet. Men det er jo ikke ligefrem den slags input og output, som vi plejer at arbejde med. Vi er f.eks. vant til at se på en eksponentialfunktion, der som input kan tage et hvilket som helst reelt tal og som output giver et positivt reelt tal. Vi plejer at sige, at funktionens defintionsmængde <span class="math inline">\(Dm(f)=\mathbb{R}\)</span> og at funktionens værdimængde <span class="math inline">\(Vm(f)=\mathbb{R}_+\)</span>. Det kan også skrives sådan her: <span class="math display">\[f: \mathbb{R} \rightarrow \mathbb{R}_+\]</span> Men hvordan giver man så et billede som input? Digitale billeder består af en masse "pixels". En pixel svarer til et lille kvadratisk udsnit af billedet, som lidt forenklet er vist på <a href="#fig-pixel" class="quarto-xref">figur&nbsp;2</a>.</p>
<div id="fig-pixel" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-pixel-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/pixel.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-pixel-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figur&nbsp;2: Et digitalt billede består af pixels.
</figcaption>
</figure>
</div>
<p>Du har sikkert prøvet at zoome rigtig langt ind på et digitalt billede og set, at det ender med at bestå af små "kasser". Hvis billedet er sort-hvid, så kan farven på hver enkelt pixel repræsenteres ved et tal mellem <span class="math inline">\(0\)</span> og <span class="math inline">\(255\)</span>. Hvis værdien er <span class="math inline">\(0\)</span>, er pixlen sort, hvis værdien er <span class="math inline">\(255\)</span> er pixlen hvid og alt imellem <span class="math inline">\(0\)</span> og <span class="math inline">\(255\)</span> repræsenterer gråtoner. Hvis billedet er med farver, bruger man tre værdier mellem <span class="math inline">\(0\)</span> og <span class="math inline">\(255\)</span> til at repræsentere farven (RGB-farver: rød, grøn og blå), men lad os bare for enkelthedens skyld antage, at vi kun betragter sort-hvid billeder. Hvis mit billede er et <span class="math inline">\(8 \times 8\)</span> pixels som på <a href="#fig-pixel" class="quarto-xref">figur&nbsp;2</a>, så kan jeg altså repræsentere billedet vha. en vektor med <span class="math inline">\(64\)</span> dimensioner! Det vil sige, at min funktions definitionsmængden i virkeligheden er en delmængde af: <span class="math display">\[Dm(f) = \mathbb{R}^{64}  \quad\text{eller rettere}\quad Dm(f) = \{0, 1, \dots, 255\}^{64}\]</span> Lad os sige, at vi gerne vil have vores funktion til at finde en hund eller en kræftknude på billedet. Så kunne funktionens værdimængde såmænd bare være: <span class="math display">\[Vm(f) = [0,1]\]</span> Her vil tolkningen så f.eks. kunne være, at hvis outputværdien <span class="math inline">\(o \geq 0,5\)</span>, så er svaret "ja" (det er en hund) og hvis <span class="math inline">\(o&lt;0.5\)</span>, så er svaret "nej". Vi kunne altså bruge outputværdien til at lave følgende forudsigelse/prædiktion: <span id="eq-prediktion"><span class="math display">\[
\textrm{prædiktion}=
\begin{cases}
\textrm{ja} &amp; \textrm{hvis } o \geq 0,5 \\
\textrm{nej} &amp; \textrm{hvis } o &lt; 0,5 \\
\end{cases}
\tag{1}\]</span></span> Så i et lidt forenklet setup leder vi altså efter en funktion, som tager en <span class="math inline">\(64\)</span>-dimensional vektor som input, og som output leverer et tal i intervallet <span class="math inline">\([0,1]\)</span>: <span class="math display">\[
f: \mathbb{R}^{64} \rightarrow [0,1]
\]</span> Så langt så godt. Men hvad gør vi så nu? Skal vi sige, at hvis der findes nogle forholdsvis mørke pixels i midten og nogle mørke pixels, som stikker op fra de andre mørke pixels (halen), så er det en hund...? Det virker ikke umiddelbart specielt anvendeligt. Og hvad nu hvis hunden sidder på sin hale eller man kun kan se dens hoved? Inden for den tidligere klassiske kunstig intelligens ville man netop forsøge sig med denne fremgangsmåde, men AI-forskerne løb efterhånden panden mod en mur, ligesom vi noget forenklet har skitseret det her. Det virker simpelthen som en helt uoverskuelig opgave at skulle programmere en computer på den klassiske måde (a la "gør dit og dut og dat og hvis A så B ellers C... osv.") <span class="citation" data-cites="videnskabsteori">(<a href="#ref-videnskabsteori" role="doc-biblioref">Sørensen and Johansen 2020</a>)</span>. Problemet er blandt andet, at vi jo faktisk ikke en gang selv fuldstændigt og i detaljer kan forklare, hvordan vi selv genkender en hund på et billede. Det er "bare" noget vores hjerne gør (fordi den i virkeligheden har øvet sig på rigtig mange "hundebilleder"). Det var netop denne erkendelse, som førte til udviklingen af kunstige neurale netværk: Hvis vi ikke selv præcist og detaljeret kan forklare, hvad vores hjerne gør, så skulle vi måske i stedet prøve at programmere vores computer, så den efterligner den måde den menneskelige hjerne fungerer på. Man vendte sig derfor mod biologien <span class="citation" data-cites="baktoft">(<a href="#ref-baktoft" role="doc-biblioref">Baktoft 2014</a>)</span> og blev inspireret af den måde millionvis af neuroner i hjernen kommunikerer med hinanden på (men det må du hellere spørge en biologilærer om). Man kan derfor tænke på kunstige neurale netværk, som en forsimplet model af den menneskelige hjerne. Det får også den konsekvens, at vores funktion ender med at blive lidt magi. Vi kan ikke nødvendigvis forklare, hvorfor den præcis ser ud som den gør, men vi kan blot i sidste ende forhåbentlig konstatere, at det virker! Det er faktisk lidt grænseoverskridende. Vi er jo f.eks. vant til at kunne fortolke på de konstanter, som indgår i en lineær funktion, der er anvendt i en given sammenhæng. Men her må du glemme alt om at tillægge de konstanter, vi nu er på jagt efter, nogen som helst betydning!</p>
<section id="video-kunstige-neurale-netværk-1" class="level2">
<h2 class="anchored" data-anchor-id="video-kunstige-neurale-netværk-1">VIDEO: Kunstige neurale netværk 1</h2>
<p>I denne video forklarer vi lidt om, hvad et kunstigt neuralt netværk er samt hvilke input- og outputværdier, man kan bruge.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/09LTr2eVOWg" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</section>
</section>
<section id="sec-feedforward" class="level1 page-columns page-full">
<h1>Hvordan virker et kunstigt neuralt netværk?</h1>
<p>Kunstige neurale netværk som bruges i den virkelige verden består som regel af millionvis af de såkaldte neuroner. For at holde tingene simple vil vi her begrænse os til nogle få. Forståelsesmæssigt mister man ingenting, notationen bliver blot lidt simplere. På <a href="#fig-simple_NN_noweights" class="quarto-xref">figur&nbsp;3</a> ser du et sådant simpelt kunstigt neuralt netværk, hvor alle cirklerne repræsenterer disse neuroner. I første omgang ser det måske lidt uoverskueligt ud, men vi tager det et skridt ad gangen.</p>
<div id="fig-simple_NN_noweights" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-simple_NN_noweights-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/simple_NN_noweights.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-simple_NN_noweights-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figur&nbsp;3: Simpelt kunstigt neuralt netværk.
</figcaption>
</figure>
</div>
<p>Det første man kan se er, at et kunstigt neuralt netværk består af et inputlag (repræsenteret ved de fire lilla cirkler) og et outputlag (repræsenteret ved den blå cirkel). De fire værdier <span class="math inline">\(x_1, x_2, x_3\)</span> og <span class="math inline">\(x_4\)</span> svarer til de inputværdier, vi tidligere har talt om. Det kunne f.eks. være værdier, som repræsenterer gråskalaværdier på et <span class="math inline">\(2 \times 2\)</span> pixels billede (det er selvfølgelig et lidt kedeligt billede, men tænk på at principperne her kan skaleres op). Vi har været vant til at se på vektorer i planen. Inputværdierne her svarer faktisk til en vektor i det firedimensionale rum: <span class="math display">\[
\vec{x}=
\begin{pmatrix}
x_1 \\ x_2 \\ x_3 \\ x_4
\end{pmatrix}
\]</span> Outputværdien <span class="math inline">\(o\)</span> kunne være et tal mellem <span class="math inline">\(0\)</span> og <span class="math inline">\(1\)</span> og man kan f.eks. prædiktere vha. udtrykket i (<a href="#eq-prediktion" class="quarto-xref">1</a>).</p>
<p>Derudover indgår der to skjulte lag, som er vist ved de lysegrønne og mørkegrønne cirkler. Det er dem, som udgør selve "maskinrummet" i det kunstige neurale netværk. Lad os starte med at se på cirklen, hvor der står <span class="math inline">\(y_1\)</span>. Pilene op til neuronen, hvor der står <span class="math inline">\(y_1\)</span>, viser, at den modtager alle fire inputværdier <span class="math inline">\(x_1, x_2, x_3\)</span> og <span class="math inline">\(x_4\)</span>. Disse fire værdier bruges til at beregne <span class="math inline">\(y_1\)</span>. Vi starter med at udregne: <span id="eq-linkom"><span class="math display">\[
r_1 \cdot x_1 + r_2 \cdot x_2 + r_3 \cdot x_3 + r_4 \cdot x_4 + r_0
\tag{2}\]</span></span></p>
<p>Værdierne <span class="math inline">\(r_1, r_2, r_3\)</span> og <span class="math inline">\(r_4\)</span> kalder man for vægte. Hvis f.eks. <span class="math inline">\(r_1\)</span> er stor og <span class="math inline">\(r_2, r_3\)</span> og <span class="math inline">\(r_4\)</span> er tæt på <span class="math inline">\(0\)</span>, så vil <span class="math inline">\(r_1 \cdot x_1\)</span> også blive stor (med mindre <span class="math inline">\(x_1\)</span> er meget tæt på <span class="math inline">\(0\)</span>) og <span class="math inline">\(r_2 \cdot x_2+r_3 \cdot x_3+r_4 \cdot x_4\)</span> vil være tæt på <span class="math inline">\(0\)</span>. På den måde vil inputværdien <span class="math inline">\(x_1\)</span> altså få stor indflydelse på udtrykket i (<a href="#eq-linkom" class="quarto-xref">2</a>) - man siger, at <span class="math inline">\(x_1\)</span> kommer til at vægte højt.</p>
<p>Værdien <span class="math inline">\(r_0\)</span> kaldes for en "bias" og det er altså en konstant størrelse, som bliver lagt til uafhængig af inputværdierne. Du skal tænke på ovenstående udtryk, som du tænker på en lineær funktion <span class="math inline">\(y=a \cdot x + b\)</span>. Her er der bare lige lidt flere <span class="math inline">\(x\)</span>-værdier og <span class="math inline">\(a\)</span> og <span class="math inline">\(b\)</span> er skiftet ud med <span class="math inline">\(r\)</span>’er.</p>
<div id="fig-simple_NN_weights" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-simple_NN_weights-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/simple_NN_weights.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-simple_NN_weights-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figur&nbsp;4: Simpelt kunstigt neuralt netværk med navngivning af vægte.
</figcaption>
</figure>
</div>
<p>Værdien af udtrykket i (<a href="#eq-linkom" class="quarto-xref">2</a>) kan være et hvilket som helst reelt tal. Ofte vil man være interesseret i, at den værdi der "kommer ud af" neuronen er et tal mellem <span class="math inline">\(0\)</span> og <span class="math inline">\(1\)</span>. Til det bruges ofte den såkaldte "sigmoid"-funktion, som er defineret sådan her: <span id="eq-sigmoid"><span class="math display">\[
\sigma(x)=\frac{1}{1+e^{-x}}
\tag{3}\]</span></span> Grafen for sigmoid-funktionen ses i <a href="#fig-sigmoid_graf" class="quarto-xref">figur&nbsp;5</a>. Her kan man se, hvordan ethvert reelt tal bliver afbildet over i et tal mellem <span class="math inline">\(0\)</span> og <span class="math inline">\(1\)</span>.</p>
<div class="cell page-columns page-full">
<div class="cell-output-display page-columns page-full">
<div id="fig-sigmoid_graf" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-sigmoid_graf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="neurale_net_files/figure-html/fig-sigmoid_graf-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-sigmoid_graf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figur&nbsp;5: Grafen for sigmoid-funktionen.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Sigmoid-funktionens differentialkvotient har en bestemt egenskab, som det fremgår af denne sætning:</p>
<blockquote class="blockquote">
<div id="thm-sigmoid_diff" class="theorem">
<p><span class="theorem-title"><strong>Sætning 1</strong></span> Om sigmoid-funktionens differentialkvotient gælder <span class="math display">\[
\sigma'(x) = \sigma(x) \cdot (1 - \sigma(x)).
\]</span> Det vil sige, hvis <span class="math inline">\(y=\sigma(x)\)</span> så er <span class="math display">\[
y' = y \cdot (1 - y).
\]</span></p>
</div>
</blockquote>
<p>Beviset er ikke så svært og overlades til læseren.</p>
<p>Det er netop sigmoid-funktionen, som bruges til at udregne <span class="math inline">\(y_1\)</span>: <span id="eq-y_1_1"><span class="math display">\[
y_1=\sigma(r_1 \cdot x_1 + r_2 \cdot x_2+r_3 \cdot x_3+r_4 \cdot x_4+r_0)
\tag{4}\]</span></span> Det vil sige, at <span id="eq-y_1_2"><span class="math display">\[
y_1=\frac{1}{1+e^{-(r_1 \cdot x_1 + r_2 \cdot x_2+r_3 \cdot x_3+r_4 \cdot x_4+r_0)}}
\tag{5}\]</span></span></p>
<p>Nu beregnes <span class="math inline">\(y_2\)</span> helt tilsvarende, men med andre vægte. Før kaldte vi vægtene for <span class="math inline">\(r_1, r_2\)</span> osv. De nye vægte vælger vi nu at kalde for <span class="math inline">\(s_1, s_2, \dots\)</span>, som det også er vist på <a href="#fig-simple_NN_weights" class="quarto-xref">figur&nbsp;4</a>. Vi definerer altså <span id="eq-y_2_1"><span class="math display">\[
y_2=\sigma(s_1 \cdot x_1 + s_2 \cdot x_2+s_3 \cdot x_3+s_4 \cdot x_4+s_0)
\tag{6}\]</span></span> Det vil sige, at <span id="eq-y_2_2"><span class="math display">\[
y_2=\frac{1}{1+e^{-(s_1 \cdot x_1 + s_2 \cdot x_2+s_3 \cdot x_3+s_4 \cdot x_4+s_0)}}
\tag{7}\]</span></span></p>
<p>Nu sker der det, at (de lysegrønne) neuroner i det andet lag "fyrer" deres <span class="math inline">\(y\)</span>-værdier frem til alle neuronerne i det tredje lag. Disse værdier bliver nu brugt som inputs til beregning af de nye <span class="math inline">\(z\)</span>-værdier (se igen <a href="#fig-simple_NN_weights" class="quarto-xref">figur&nbsp;4</a>. Vi kan nu, som vi har gjort ovenfor definere de nye <span class="math inline">\(z\)</span>-værdier i det tredje lag, idet vi nu kalder vægtene for <span class="math inline">\(v_1, v_2, u_1\)</span> og <span class="math inline">\(u_2\)</span>, som det er vist på <a href="#fig-simple_NN_weights" class="quarto-xref">figur&nbsp;4</a>. Den eneste forskel fra tidligere er, at disse neuroner i vores eksempel kun modtager to og ikke fire inputværdier: <span id="eq-z_1"><span class="math display">\[
z_1=\sigma(v_1 \cdot y_1 + v_2 \cdot y_2 + v_0)
\tag{8}\]</span></span> og <span id="eq-z_2"><span class="math display">\[
z_2=\sigma(u_1 \cdot y_1 + u_2 \cdot y_2 + u_0)
\tag{9}\]</span></span></p>
<p>Nu fyrer neuroner i det tredje lag deres <span class="math inline">\(z\)</span>-værdier til det sidste outputlag, hvor der i dette simple eksempel kun er en enkelt neuron. Hvis vi ønsker, at outputtet <span class="math inline">\(o\)</span> bliver et tal mellem <span class="math inline">\(0\)</span> og <span class="math inline">\(1\)</span> sætter vi <span id="eq-o"><span class="math display">\[
o=\sigma(w_1 \cdot z_1 + w_2 \cdot z_2 + w_0)
\tag{10}\]</span></span> Vi kan nu foretage den ønskede prædiktion ved f.eks. at bruge udtrykket i (<a href="#eq-prediktion" class="quarto-xref">1</a>).</p>
<p>Det vi her har beskrevet kaldes for <strong>feedforward</strong>, fordi man sender input-værdierne fremad i netværket igennem alle lagene, indtil man har beregnet outputværdien (eller outputværdierne). Hvis man har et kunstigt neuralt netværk, som er "indstillet" korrekt - det vil sige, at alle vægte og bias har de "rigtige" værdier - så kan netværket bruges til at prædiktere med. Men hvordan i alverden sørger man for at vælge de "rigtige" værdier for alle vægte og bias? Husk på i virkelighedens verden taler vi om millioner af værdier! I vores simple eksempel havde vi kun 19 vægte: <span class="math display">\[
\begin{pmatrix}r_0\\r_1\\r_2\\r_3\\r_4\end{pmatrix}\quad
  \begin{pmatrix}s_0\\s_1\\s_2\\s_3\\s_4\end{pmatrix}\quad
  \begin{pmatrix}v_0\\v_1\\v_2\end{pmatrix}\quad
  \begin{pmatrix}u_0\\u_1\\u_2\end{pmatrix}\quad
  \begin{pmatrix}w_0\\w_1\\w_2\end{pmatrix}
  \]</span></p>
<p>Det gøres ved hjælp af en fiks teknik, som kaldes for <strong>backpropagation</strong>, som vi nu skal se nærmere på.</p>
<section id="video-kunstige-neurale-netværk-2" class="level2">
<h2 class="anchored" data-anchor-id="video-kunstige-neurale-netværk-2">VIDEO: Kunstige neurale netværk 2</h2>
<p>I denne video giver vi et eksempel på et simpelt kunstig neuralt netværk og forklarer <strong>feedforward</strong>.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/hUlyeMJGvXM" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</section>
</section>
<section id="sec-backpropagation_bogstaver" class="level1 page-columns page-full">
<h1>Hvordan træner man et kunstigt neuralt netværk?</h1>
<p>Vi har altså nu set på, hvordan et kunstigt neuralt netværk virker, hvis vi kender værdierne for alle vægte og bias. Det store spørgsmål er nu, hvordan man får bestemt disse vægte, så netværket bliver så godt så muligt til at finde hundebilleder, eller hvad vi nu er på jagt efter.</p>
<p>Det første vi må gøre, er at opstille et mål for hvor godt et givet netværk er. Så lad os sige, at vi allerede har nogle vægte (i starten vælger man bare nogle mere eller mindre tilfældige vægte). Og lad os se på eksemplet hvor vi har fire inputværdier: <span class="math display">\[\vec{x}=
\begin{pmatrix}
x_1 \\ x_2 \\ x_3 \\ x_4
\end{pmatrix}\]</span> som vi kan tænke på som pixelværdier på et billede af en hund (det er helt håbløst, at tro at et billede af en hund kan repræsenteres ved fire pixelværdier, men lige nu er det principperne, der er det vigtigste). For at træne et netværk er man også nødt til at fortælle netværket, hvad der så rent faktisk er på billedet. Ellers får vi aldrig netværket til at forstå noget som helst, hvis ikke vi sammen med inputværdierne også kender den ønskede prediktion. Tænk på da du som lille barn lærte at genkende hundebilleder i en billedbog. Det lærte du kun, fordi der i timevis inden havde siddet en voksen og fortalt dig hvilke billeder, der forestillede en hund og hvilke der ikke gjorde. Den samme information må vi også give netværket. Så sammen med input værdien <span class="math inline">\(\vec{x}\)</span>, giver vi også en såkaldt <em>target</em>-værdi <span class="math inline">\(t\)</span>. Her sætter vi: <span id="eq-target"><span class="math display">\[
t=
\begin{cases}
1 &amp; \textrm{hvis billedet er af en hund} \\
0 &amp; \textrm{ellers} \\
\end{cases}
\tag{11}\]</span></span> Sender vi inputværdierne repræsenteret ved vektoren <span class="math inline">\(\vec{x}\)</span> ind i netværket, så vil netværket returnere en outputværdi <span class="math inline">\(o\)</span> mellem <span class="math inline">\(0\)</span> og <span class="math inline">\(1\)</span>. Som tidligere vil vi tolke det på den måde, at netværket mener, at vi står med et billede af en hund hvis <span class="math inline">\(o\geq 0.5\)</span>, og hvis <span class="math inline">\(o&lt;0.5\)</span> så vil netværket sige, at det ikke er en hund. Et netværk, som er god til at genkende hundebilleder, vil opføre sig sådant, at hvis inputværdien <span class="math inline">\(\vec{x}\)</span> svarer til et hundebillede (dvs. <span class="math inline">\(t=1\)</span>), så vil <span class="math inline">\(o\)</span> være tæt på <span class="math inline">\(1\)</span>. Og omvendt hvis inputværdien <span class="math inline">\(\vec{x}\)</span> ikke svarer til et hundebillede (dvs. <span class="math inline">\(t=0\)</span>), så vil <span class="math inline">\(o\)</span> være tæt på <span class="math inline">\(0\)</span>. Det vil sige, at et godt netværk har den egenskab at <span class="math display">\[t-o \approx 0\]</span> Læg mærke til at forskellen her både kan være positiv og negativ, vi vil bare gerne have, at den er tæt på <span class="math inline">\(0\)</span>.</p>
<p>Det kan vi nu bruge til at definere det, man kalder for en <em>error-</em> eller tabsfunktion <span class="math inline">\(E\)</span>. For et givet input <span class="math inline">\(\vec{x}\)</span> med target-værdi <span class="math inline">\(t\)</span> og hvor netværket giver outputværdien <span class="math inline">\(o\)</span> definerer vi tabsfunktionen <span class="math inline">\(E\)</span> på denne måde: <span id="eq-error_func"><span class="math display">\[
E = \frac{1}{2}(t-o)^2
\tag{12}\]</span></span> Bemærk, at hvis der er stor forskel på <span class="math inline">\(t\)</span> og <span class="math inline">\(o\)</span> (hvilket vi jo ikke er interesseret i), så vil fejlen også være stor. Og omvendt hvis der er lille forskel på <span class="math inline">\(t\)</span> og <span class="math inline">\(o\)</span>, så vil fejlen være lille. Desuden vil fortegnet på fejlen forsvinde, fordi vi opløfter i anden. At vi ganger med <span class="math inline">\(1/2\)</span> viser sig bekvemt senere, men det er i princippet underordnet.</p>
<p>I virkeligheden vil man have rigtige mange træningsdata med tilhørende target- og outputværdier. Forestil dig at vi nummerer alle disse target- og outputværdier på følgende måde: <span class="math display">\[(t_1, o_1), (t_2, o_2), (t_3, o_3), \dots, (t_n, o_n)\]</span> Og da vil man definere tabsfunktionen ved at lægge alle de kvadrerede fejl sammen: <span class="math display">\[\begin{align*}
E &amp;= \frac{1}{2} ((t_1-o_1)^2+(t_2-o_2)^2+\cdots+(t_n-o_n)^2) \\ &amp;= \frac{1}{2} \sum_{i=1}^n (t_i-o_i)^2
\end{align*}\]</span> Vi vil dog se på det tilfælde, hvor vi hele tiden ser på et træningseksempel ad gangen og på den baggrund opdaterer vægtene. Derfor vil vi begrænse os til at se på fejlfunktionen i (<a href="#eq-error_func" class="quarto-xref">12</a>).</p>
<p>Ønsket er nu, at bestemme biasene og vægtene (lad os bare samlet set kalde dem for vægtene fremover): <span class="math display">\[
r_0, r_1, r_2, r_3, r_4, s_0, s_1, s_2, s_3, s_4, v_0, v_1, v_2, u_0, u_1, u_2, w_0, w_1, w_2
\]</span> sådan at tabsfunktionen <span class="math inline">\(E\)</span> bliver så lille som mulig. Det giver jo god mening! Find de vægte som gør, at netværket begår så lille en fejl, som overhovedet mulig. Ja da - det er det, vi gør! Vi betragter nu tabsfunktionen, som en funktion af alle vægtene: <span class="math display">\[\begin{align*}
E(r_0, r_1, r_2, r_3, r_4, s_0, s_1, s_2, s_3, s_4, &amp;v_0, v_1, v_2, u_0, u_1, u_2, w_0, w_1, w_2) \\ &amp;=\frac{1}{2} (t-o)^2
\end{align*}\]</span> Det ser umiddelbart lidt mærkeligt ud, for vægtene ser jo ikke ud til at indgå på højreside i ovenstående udtryk, men husk på at outputværdien <span class="math inline">\(o\)</span> jo netop bliver beregnet vha. feedforward, som er baseret på alle vægtene.</p>
<p>Vi vil altså gerne finde minimum for tabsfunktionen <span class="math inline">\(E\)</span>, og vi ved jo godt, hvordan man finder minimum for en funktion af to variable: Sæt de partielle afledede lig med <span class="math inline">\(0\)</span>, løs de to ligninger og tjek op på at det rent faktisk er et minimum, du har fundet (og ikke f.eks. et lokalt maksimum eller et saddelpunkt).</p>
<p>I princippet kunne vi gøre noget tilsvarende her: <span class="math inline">\(E\)</span> er en funktion af <span class="math inline">\(19\)</span> variable (de <span class="math inline">\(19\)</span> vægte). Sæt alle de <span class="math inline">\(19\)</span> partielle afledede lig med <span class="math inline">\(0\)</span>, løs ligningerne og find ud af, at det er et (evt. lokalt) minimum, du har fundet. Problemet bliver bare, at I virkelighedens verden har vi ikke kun <span class="math inline">\(19\)</span> vægte, men millionvis af vægte. Så det er en megastor opgave at finde funktionsudtryk for alle de partielle afledte og selvom vi forestiller os, vi kunne finde dem, eller de faldt ned fra månen, er der stadig et problem: At løse alle de millionvis af ligninger, som vi får, når vi sætter de partielle afledede lig med <span class="math inline">\(0\)</span>, viser sig simpelthen at blive alt for beregningsmæssigt tungt. Læs: Det tager for lang tid og/eller fylder for meget i hukommelsen - selv for en stor computer!</p>
<div id="fig-EksE" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-EksE-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/minMaxFunc.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-EksE-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figur&nbsp;6: Eksempel på grafen for en tabsfunktion, som kun afhænger af to variable.
</figcaption>
</figure>
</div>
<p>Derfor er man nødt til at gøre noget andet. Forestil dig at tabsfunktionen kun afhænger af to variable <span class="math inline">\(E(v,w)\)</span><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> og at grafen for den ser ud, som vist i <a href="#fig-EksE" class="quarto-xref">figur&nbsp;6</a>. Her kan du se, at tabsfunktionen har to lokale minima og ét globalt minimum. Vi vil allerhelst finde vægtene sådan, at vi ender i det globale minimum, men kan vi kun finde et lokalt minimum, så kan det også gå (selvom det selvfølgelig ikke er det optimale). Forestil dig at grafen er et landskab. At finde grafens minimum svarer til, at du gerne vil ned i den dybeste dal. Din placering i landskabet svarer til, at du står i et eller andet punkt i planen <span class="math inline">\((v_0,w_0)\)</span> og din højde i vertikal retning er <span class="math inline">\(E(v_0,w_0)\)</span>. Som du måske husker, så gælder der, at hvis du i dette punkt gerne vil bevæge dig i den retning, som er <em>allerstejlest</em>, så skal du gå i retningen givet ved gradienten: <span class="math display">\[
\nabla E(v_0,w_0) = \begin{pmatrix} \frac{\partial E }{\partial v}(v_0,w_0) \\ \\ \frac{\partial E }{\partial w}(v_0,w_0) \end{pmatrix}
\]</span> Det betyder også, at hvis du gerne vil gå <em>allermest ned ad bakke</em>, så skal du gå i den stik modsatte retning - altså minus gradienten: <span class="math display">\[
- \nabla E(v_0,w_0) = \begin{pmatrix} - \frac{\partial E }{\partial v}(v_0,w_0) \\ \\ - \frac{\partial E }{\partial w}(v_0,w_0) \end{pmatrix}
\]</span> Dét trick skal vi bruge! Vi starter altså med at vælge nogle mere eller mindre tilfældige vægte. Det svarer til, at du står et mere eller mindre tilfældigt sted i landskabet på <a href="#fig-EksE" class="quarto-xref">figur&nbsp;6</a>. Så vælger vi at gå et lille stykke i den retning, hvor det går allermest ned ad bakke, ved at følge retningen angivet ved den negative gradient. Når vi står der, beregner vi gradienten i det punkt<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>, og går igen et lille stykke i den retning, som den negative gradient angiver. Sådan fortsætter vi, og hvis vi sørger for ikke at tage alt for store skridt ad gangen, så vil vi til sidst ende i et lokalt minimum (der er desværre ingen garanti for, at vi vil ende i et globalt minimum<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>).</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;Du kan med god ret spørge: "Hvorfor nu det?". I virkeligheden afhænger den jo af millionvis af variable. Svaret er, at hvis vi skal forestille os grafen for tabsfunktionen, så er vores forestillingsevne begrænset til 3 dimensioner. Derfor må vi lige for en stund antage, at tabsfunktionen kun afhænger af to variable!</p></div><div id="fn2"><p><sup>2</sup>&nbsp;Hov! Vi kan jo ikke finde funktionsudtryk for alle de partielle afledte, så hvad foregår der her? Jo, vi vil se, at vi ved backpropagation kan udregne de partielle afledte <em>i et punkt</em> uden at finde et funktionsudtryk.</p></div><div id="fn3"><p><sup>3</sup>&nbsp;Hvis netværket ikke ender med at opføre sig tilfredsstillende, kan man jo prøve at starte et nyt tilfældigt sted i landskabet og gentage proceduren. Hvis man er heldig, lander man i et andet lokalt eller globalt minimum, hvor minimumsværdien er mindre end den tidligere.</p></div></div><p>Idéen er altså, at vi vælger en værdi for hver af de <span class="math inline">\(19\)</span> vægte. Lad os bare som eksempel så på vægten <span class="math inline">\(s_1\)</span>. Så beregner vi den partielle afledede <span class="math display">\[
\frac{\partial E}{\partial s_1}
\]</span> og så ændrer vi værdien af <span class="math inline">\(s_1\)</span> en lille smule i retning af den negative partielle afledede. Vi viser, at vi ændrer værdien af <span class="math inline">\(s_1\)</span> til en ny værdi, ved at bruge en pil: <span id="eq-opdatering_s1"><span class="math display">\[
s_1 \leftarrow s_1 - \eta  \frac{\partial E}{\partial s_1}
\tag{13}\]</span></span> Lad os lige bruge lidt tid på at forstå, hvad der står her! Venstresiden er den nye værdi af vægten <span class="math inline">\(s_1\)</span>. Denne værdi beregnes ved hjælp af udtrykket på højreside. Her angiver <span class="math inline">\(s_1\)</span> den gamle/oprindelige værdi af <span class="math inline">\(s_1\)</span>. Symbolet <span class="math inline">\(\eta\)</span> (udtales "eta") er her et lille, positivt tal (f.eks. <span class="math inline">\(0.05\)</span>) som angiver, at vi bare gerne vil ændre <span class="math inline">\(s_1\)</span> en lille smule. Derfor må <span class="math inline">\(\eta\)</span> ikke være al for stor. Man kalder også <span class="math inline">\(\eta\)</span> for læringsraten eller på engelsk: <em>learning rate</em>. Endelig viser <span class="math inline">\(-\frac{\partial E}{\partial s_1}\)</span>, at vi ønsker, at ændre alle vægte i retning af den negative gradient. Det vil nu sige, at alle <span class="math inline">\(19\)</span> vægte opdateres vha. formler, som den i (<a href="#eq-opdatering_s1" class="quarto-xref">13</a>). Altså skal vi nu bare have fundet et udtryk for alle de <span class="math inline">\(19\)</span> partielle afledede, og vi er i mål! Dette er netop, hvad <strong>backpropagation algoritmen</strong> gør, som vi gennemgår i det følgende.</p>
<section id="video-kunstige-neurale-netværk-3" class="level2">
<h2 class="anchored" data-anchor-id="video-kunstige-neurale-netværk-3">VIDEO: Kunstige neurale netværk 3</h2>
<p>I videoen her forklarer vi, hvad targetværdier er, og hvordan tabsfunktionen defineres.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/v2Jv5RTlZMw" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</section>
<section id="video-kunstige-neurale-netværk-4" class="level2">
<h2 class="anchored" data-anchor-id="video-kunstige-neurale-netværk-4">VIDEO: Kunstige neurale netværk 4</h2>
<p>I denne video bliver gradientnedstigning forklaret.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/ll3OO6Q2TuA" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</section>
<section id="sec-opdatering_w" class="level2">
<h2 class="anchored" data-anchor-id="sec-opdatering_w">Opdatering af <span class="math inline">\(w\)</span>-vægtene</h2>
<p>Når man bruger backpropagation, starter man med at finde de partielle afledede for de vægte, som direkte påvirker outputværdien <span class="math inline">\(o\)</span>. På <a href="#fig-simple_NN_weights" class="quarto-xref">figur&nbsp;4</a> fremgår det, at det er vægtene <span class="math inline">\(w_0, w_1\)</span> og <span class="math inline">\(w_2\)</span> (husk at vi kalder vores bias for <span class="math inline">\(w_0\)</span>). Lad os starte med at finde den partielle afledede for <span class="math inline">\(w_1\)</span>. Ved at bruge kædereglen får vi: <span class="math display">\[
\frac{\partial E}{\partial w_1} = \frac{d E}{d o} \cdot \frac{\partial o}{\partial w_1}
\]</span> Vi ved fra (<a href="#eq-error_func" class="quarto-xref">12</a>), at <span class="math inline">\(E=\frac{1}{2}(t-o)^2\)</span> og derfor er: <span id="eq-dEdo"><span class="math display">\[
\frac{d E}{d o} = \frac{1}{2} \cdot 2 \cdot (t-o) \cdot (-1) = -(t-o)
\tag{14}\]</span></span> Fra (<a href="#eq-o" class="quarto-xref">10</a>) har vi, at <span class="math inline">\(o=\sigma(w_1 \cdot z_1 + w_2 \cdot z_2 + w_0)\)</span> og derfor får vi <span class="math display">\[
\frac{\partial o}{\partial w_1} =\sigma'(w_1 \cdot z_1 + w_2 \cdot z_2 + w_0) \cdot z_1
\]</span> Vi har tidligere vist, at <span class="math inline">\(\sigma'(z)=\sigma(z)(1-\sigma(z))\)</span> og derfor har vi <span class="math display">\[
\frac{\partial o}{\partial w_1} =\sigma(w_1 \cdot z_1 + w_2 \cdot z_2 + w_0)(1-\sigma(w_1 \cdot z_1 + w_2 \cdot z_2 + w_0)) \cdot z_1
\]</span> Bruger vi nu, at <span class="math inline">\(o=\sigma(w_1 \cdot z_1 + w_2 \cdot z_2 + w_0)\)</span> kan vi skrive ovenstående lidt mere kompakt: <span class="math display">\[
\frac{\partial o}{\partial w_1} =o(1-o) \cdot z_1
\]</span> Alt i alt får vi altså, at <span id="eq-dEdw_1"><span class="math display">\[
\frac{\partial E}{\partial w_1} = \frac{d E}{d o} \cdot \frac{\partial o}{\partial w_1}
= -(t-o) \cdot o \cdot (1-o) \cdot z_1
\tag{15}\]</span></span> Vi kan nu udlede den første opdateringsregel for vægten <span class="math inline">\(w_1\)</span> ved at bruge idéen fra (<a href="#eq-opdatering_s1" class="quarto-xref">13</a>): <span class="math display">\[
w_1 \leftarrow w_1 - \eta  \cdot \frac{\partial E}{\partial w_1}
\]</span> Indsættes udtrykket fra (<a href="#eq-dEdw_1" class="quarto-xref">15</a>), får vi <span class="math display">\[
w_1 \leftarrow w_1 - \eta  \cdot (-(t-o) \cdot o \cdot (1-o) \cdot z_1)
\]</span> Det vil sige, at <span class="math display">\[
w_1 \leftarrow w_1 + \eta  \cdot (t-o) \cdot o \cdot (1-o) \cdot z_1
\]</span> Det er værd at dvæle lidt ved opdateringsleddet <span class="math inline">\(\eta  \cdot (t-o) \cdot o \cdot (1-o) \cdot z_1\)</span> på højresiden, fordi det faktisk giver intuitiv god mening. For det første er <span class="math inline">\(\eta\)</span>, det vi som sagt kalder for vores <em>learning rate</em> - et lille positivt tal, som sørger for, at vi ikke tager for store skridt på vores vej ned i dalen (til det lokale minimum). Faktoren <span class="math inline">\(t-o\)</span> er jo netop fejlen. Nemlig forskellen mellem det vi ønsker <span class="math inline">\(t\)</span> (target), og det som netværket giver <span class="math inline">\(o\)</span> (output). Jo større fejl/forskel, desto mere må vi justere vægten. Ser vi på faktoren <span class="math inline">\(o\cdot(1-o)\)</span>, så vil det være sådan, at hvis outputværdien <span class="math inline">\(o\)</span> er tæt på enten <span class="math inline">\(0\)</span> eller <span class="math inline">\(1\)</span> (man siger at neuronen er "mættet"), så vil <span class="math inline">\(o\cdot(1-o)\)</span> være tæt på <span class="math inline">\(0\)</span>. Det vil sige, at hvis outputværdien er tæt på <span class="math inline">\(0\)</span> eller <span class="math inline">\(1\)</span>, så ændrer vi heller ikke så meget på vægten. Endelig er der faktoren <span class="math inline">\(z_1\)</span>, som er inputtet fra det foregående lag (se <a href="#fig-simple_NN_weights" class="quarto-xref">figur&nbsp;4</a>). Hvis værdien af denne er (numerisk) stor, så får det også stor betydning for opdateringsleddet (eller tænk på det omvendt: hvis <span class="math inline">\(z_1\)</span> er tæt på <span class="math inline">\(0\)</span>, så har <span class="math inline">\(z_1\)</span> alligevel ikke så stor indflydelse på outputværdien, og så giver det heller ikke mening at justere så meget på den tilhørende vægt <span class="math inline">\(w_1\)</span>).</p>
<p>Det viser sig faktisk, at faktoren <span class="math inline">\((t-o) \cdot o \cdot (1-o)\)</span> kommer til at gå igen rigtige mange gange i det følgende. Det bliver i længden lidt tungt at slæbe rundt på. Derfor vælger vi at definere <span id="eq-delta"><span class="math display">\[
\delta = (t-o) \cdot o \cdot (1-o)
\tag{16}\]</span></span> og derfor kan opdateringsreglen for <span class="math inline">\(w_1\)</span> nu også skrives: <span id="eq-opdatering_w1"><span class="math display">\[
w_1 \leftarrow w_1 + \eta  \cdot \delta \cdot z_1
\tag{17}\]</span></span></p>
<p>Helt analogt med ovenstående kan man udlede opdateringsregler for <span class="math inline">\(w_2\)</span> og <span class="math inline">\(w_0\)</span>. Resultatet er samlet her.</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Opdateringsregler for <span class="math inline">\(w\)</span>-vægtene
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><span class="math display">\[\begin{align*}
w_0 &amp;\leftarrow w_0 + \eta  \cdot \delta  \\
w_1 &amp;\leftarrow w_1 + \eta  \cdot \delta \cdot z_1 \\
w_2 &amp;\leftarrow w_2 + \eta  \cdot \delta \cdot z_2 \\
\end{align*}\]</span> hvor <span class="math display">\[\delta = (t-o) \cdot o \cdot (1-o)\]</span></p>
</div>
</div>
</div>
<p>Men hvordan foregår det der med de opdateringsregler så egentligt? Jo altså vi starter med at sætte vægtene mere eller mindre tilfældigt. Så laver vi ved hjælp af vores træningseksempel <span class="math inline">\((\vec{x},t)\)</span> et <strong>feedforward</strong> i netværket, som det er beskrevet i <a href="#sec-feedforward" class="quarto-xref">afsnit&nbsp;3</a>. Derfor får vi beregnet outputværdien <span class="math inline">\(o\)</span> samt <span class="math inline">\(z_1\)</span> og <span class="math inline">\(z_2\)</span> (husk at <span class="math inline">\(z_1\)</span> og <span class="math inline">\(z_2\)</span> bruges til at beregne <span class="math inline">\(o\)</span>). Desuden kender vi jo fra vores træningsdata target-værdien <span class="math inline">\(t\)</span>. Og voila! Alt hvad der indgår på højresiderne i ovenstående opdateringsregler har vi nu adgang til, og vi kan derfor beregne de nye <span class="math inline">\(w\)</span> vægte.</p>
<p>Så mangler vi bare at finde opdateringsreglerne for de restende vægte!</p>
</section>
<section id="video-kunstige-neurale-netværk-5" class="level2">
<h2 class="anchored" data-anchor-id="video-kunstige-neurale-netværk-5">VIDEO: Kunstige neurale netværk 5</h2>
<p>I videoen her forklarer vi hvordan <span class="math inline">\(w\)</span>-vægtene opdateres.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/X5g4h3cKSok" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</section>
<section id="sec-opdatering_uv" class="level2">
<h2 class="anchored" data-anchor-id="sec-opdatering_uv">Opdatering af <span class="math inline">\(u\)</span>- og <span class="math inline">\(v\)</span>-vægtene</h2>
<p>Vi går nu et trin længere tilbage i netværket - væk fra outputlaget. Her kan vi se neuronerne, som fyrer værdierne <span class="math inline">\(z_1\)</span> og <span class="math inline">\(z_2\)</span>, som bliver påvirket af <span class="math inline">\(u\)</span>- og <span class="math inline">\(v\)</span>-vægtene. Lad os her starte med at bestemme opdateringsreglerne for <span class="math inline">\(v\)</span>-vægtene. For at gøre det skal vi finde ud af hvordan <span class="math inline">\(v\)</span>-vægtene påvirker neuronerne længere fremme i netværket. Se igen på <a href="#fig-simple_NN_weights" class="quarto-xref">figur&nbsp;4</a>. Her er det tydeligt, at <span class="math inline">\(v\)</span>-vægtene påvirker den mørkegrønne neuron, som fyrer værdien <span class="math inline">\(z_1\)</span>, som igen påvirker outputværdien. Derfor kan vi bruge kædereglen på følgende måde: <span class="math display">\[
\frac{\partial E}{\partial v_1} = \frac{d E}{d o} \cdot \frac{\partial o}{\partial z_1} \cdot \frac{\partial z_1}{\partial v_1}
\]</span> Vi ved allerede fra (<a href="#eq-dEdo" class="quarto-xref">14</a>), at <span class="math display">\[
\frac{d E}{d o} = -(t-o)
\]</span> Den partielle afledede af <span class="math inline">\(o\)</span> med hensyn til <span class="math inline">\(z_1\)</span> finder vi ved at bruge definitionen af outputværiden <span class="math inline">\(o\)</span> i (<a href="#eq-o" class="quarto-xref">10</a>) <span id="eq-dodz_1"><span class="math display">\[
\begin{aligned}
\frac{\partial o}{\partial z_1} &amp;= \sigma'(w_1 \cdot z_1+w_2 \cdot z_2 + w_0) \cdot w_1  \\
&amp;= \sigma(w_1 \cdot z_1+w_2 \cdot z_2 + w_0) \cdot (1-\sigma(w_1 \cdot z_1+w_2 \cdot z_2 + w_0)) \cdot w_1  \\
&amp;= o \cdot (1-o) \cdot w_1
\end{aligned}
\tag{18}\]</span></span> hvor vi igen har brugt <a href="#thm-sigmoid_diff" class="quarto-xref">sætning&nbsp;1</a>. Og endelig ved at udnytte definitionen af <span class="math inline">\(z_1\)</span> i (<a href="#eq-z_1" class="quarto-xref">8</a>) får vi, at <span class="math display">\[\begin{align}
\frac{\partial z_1}{\partial v_1} &amp;= \sigma'(v_1 \cdot y_1+v_2 \cdot y_2 + v_0) \cdot y_1 \\
&amp;= \sigma(v_1 \cdot y_1+v_2 \cdot y_2 + v_0) \cdot (1-\sigma(v_1 \cdot y_1+v_2 \cdot y_2 + v_0)) \cdot y_1 \\
&amp;= z_1 \cdot (1-z_1) \cdot y_1
\end{align}\]</span> Sætter vi det hele sammen får vi, at <span class="math display">\[
\frac{\partial E}{\partial v_1} = \underbrace{-(t-o)}_{\frac{\partial E}{\partial o}}  \cdot \underbrace{o \cdot (1-o) \cdot w_1}_{\frac{\partial o}{\partial z_1}} \cdot \underbrace{z_1 \cdot (1-z_1) \cdot y_1}_{\frac{\partial z_1}{\partial v_1}}
\]</span> og bruger vi definitionen af <span class="math inline">\(\delta\)</span> i (<a href="#eq-delta" class="quarto-xref">16</a>) får vi et lidt mere kompakt udtryk <span class="math display">\[
\frac{\partial E}{\partial v_1} = -\delta \cdot w_1 \cdot z_1 \cdot (1-z_1) \cdot y_1
\]</span> Opdateringsreglen for <span class="math inline">\(v_1\)</span> bliver derfor <span class="math display">\[
v_1 \leftarrow v_1 - \eta \cdot \frac{\partial E}{\partial v_1}
\]</span> og med det netop udledte udtryk for <span class="math inline">\(\frac{\partial E}{\partial v_1}\)</span> får vi <span class="math display">\[
v_1 \leftarrow v_1 - \eta \cdot (-\delta \cdot w_1 \cdot z_1 \cdot (1-z_1)\cdot y_1)
\]</span> Det vil sige, at <span class="math display">\[
v_1 \leftarrow v_1 + \eta \cdot \delta \cdot w_1 \cdot z_1 \cdot (1-z_1) \cdot y_1
\]</span> Læg igen mærke til, at når vi har været igennem et feedforward i netværket, så kender vi alle de størrelser, som indgår i ovenstående udtryk.</p>
<p>På helt tilsvarende vis kan man bestemme opdateringsreglerne for <span class="math inline">\(v_0\)</span> og <span class="math inline">\(v_2\)</span>. De tre opdateringsregler for <span class="math inline">\(v\)</span>-vægtene ses her:</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Opdateringsregler for <span class="math inline">\(v\)</span>-vægtene
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><span class="math display">\[\begin{align}
v_0 &amp;\leftarrow v_0 + \eta  \cdot \delta \cdot w_1 \cdot z_1 \cdot (1-z_1) \\
v_1 &amp;\leftarrow v_1 + \eta  \cdot \delta \cdot w_1 \cdot z_1 \cdot (1-z_1) \cdot y_1 \\
v_2 &amp;\leftarrow v_2 + \eta  \cdot \delta \cdot w_1 \cdot z_1 \cdot (1-z_1) \cdot y_2 \\
\end{align}\]</span> hvor <span class="math display">\[
\delta = (t-o) \cdot o \cdot (1-o)
\]</span></p>
</div>
</div>
</div>
<p>Opdateringsreglerne for <span class="math inline">\(u\)</span>-vægtene findes på præcis samme måde. Her skal man blot se, at <span class="math inline">\(u\)</span>-vægtene har indflydelse på outputtet via <span class="math inline">\(z_2\)</span> (se <a href="#fig-simple_NN_weights" class="quarto-xref">figur&nbsp;4</a>). Derfor skal man f.eks. finde den partielle afledede af <span class="math inline">\(E\)</span> med hensyn til <span class="math inline">\(u_1\)</span> ved at bruge kædereglen på denne måde <span class="math display">\[
\frac{\partial E}{\partial u_1} = \frac{d E}{d o} \cdot \frac{\partial o}{\partial z_2} \cdot \frac{\partial z_2}{\partial u_1}
\]</span> Udregninger svarende til det netop gennemgåede giver os</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Opdateringsregler for <span class="math inline">\(u\)</span>-vægtene
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><span class="math display">\[\begin{align}
u_0 &amp;\leftarrow u_0 + \eta  \cdot \delta \cdot w_2 \cdot z_2 \cdot (1-z_2) \\
u_1 &amp;\leftarrow u_1 + \eta  \cdot \delta \cdot w_2 \cdot z_2 \cdot (1-z_2) \cdot y_1 \\
u_2 &amp;\leftarrow u_2 + \eta  \cdot \delta \cdot w_2 \cdot z_2 \cdot (1-z_2) \cdot y_2 \\
\end{align}\]</span> hvor <span class="math display">\[
\delta = (t-o) \cdot o \cdot (1-o)
\]</span></p>
</div>
</div>
</div>
</section>
<section id="video-kunstige-neurale-netværk-6" class="level2">
<h2 class="anchored" data-anchor-id="video-kunstige-neurale-netværk-6">VIDEO: Kunstige neurale netværk 6</h2>
<p>I videoen her forklarer vi, hvordan <span class="math inline">\(v\)</span>-vægtene opdateres.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/CVG2lh9T6lg" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</section>
<section id="sec-opdatering_rs" class="level2">
<h2 class="anchored" data-anchor-id="sec-opdatering_rs">Opdatering af <span class="math inline">\(r\)</span>- og <span class="math inline">\(s\)</span>-vægtene</h2>
<p>Så er vi endelig fremme ved <span class="math inline">\(r\)</span>- og <span class="math inline">\(s\)</span> vægtene. Start lige med at tage en dyb indånding! Nu bliver det lidt mere kompliceret. Se på <a href="#fig-simple_NN_weights" class="quarto-xref">figur&nbsp;4</a>. Lad os starte med at finde den partielle afledede af <span class="math inline">\(E\)</span> med hensyn til <span class="math inline">\(r_1\)</span>. Når man ser på netværket, kan man se, at <span class="math inline">\(r_1\)</span> i første omgang påvirker <span class="math inline">\(y_1\)</span>, <span class="math inline">\(y_1\)</span> påvirker både <span class="math inline">\(z_1\)</span> og <span class="math inline">\(z_2\)</span>, som så til sidst påvirker outputværdien <span class="math inline">\(o\)</span>. Det kan illustreres sådan her <span class="math display">\[
\begin{matrix}
&amp; &amp; &amp; &amp; z_1 &amp; &amp; &amp; \\
&amp; &amp; &amp; \nearrow &amp; &amp; \searrow &amp; &amp; \\
r_1 &amp; \rightarrow &amp; y_1 &amp; &amp; &amp; &amp; \rightarrow &amp; o \\
&amp; &amp; &amp; \searrow &amp; &amp; \nearrow &amp; &amp; \\
&amp; &amp; &amp; &amp; z_2 &amp; &amp; &amp; \\
\end{matrix}
\]</span></p>
<p>Balladen er, at <span class="math inline">\(y_1\)</span> både påvirker <span class="math inline">\(z_1\)</span> og <span class="math inline">\(z_2\)</span>, og det gør det hele lidt mere kompliceret. Lad os lige starte med at se bort fra det. Ifølge kædereglen får vi så: <span class="math display">\[
\frac{\partial E}{\partial r_1} = \frac{d E}{d o} \cdot \frac{\partial o}{\partial y_1}  \cdot \frac{\partial y_1}{\partial r_1}
\]</span> Men så var det jo, at <span class="math inline">\(o\)</span> i virkeligheden afhænger af <span class="math inline">\(y_1\)</span> både via <span class="math inline">\(z_1\)</span> og <span class="math inline">\(z_2\)</span>. Man kunne skrive det sådan her: <span class="math display">\[
o(z_1(y_1), z_2(y_1))
\]</span> Bemærk, at <span class="math inline">\(z_1\)</span> og <span class="math inline">\(z_2\)</span> jo også afhænger af <span class="math inline">\(y_2\)</span>, men når vi skal differentiere med hensyn til <span class="math inline">\(y_1\)</span>, så er <span class="math inline">\(y_2\)</span> at betragte som en konstant. Og når konstanter bliver differentieret, så giver det som bekendt <span class="math inline">\(0\)</span>.</p>
<p>Derfor: For at finde den partielle afledede af <span class="math inline">\(o\)</span> med hensyn til <span class="math inline">\(y_1\)</span> må vi benytte kædereglen for funktioner af flere variable. Den siger, at <span class="math display">\[
\frac{\partial o}{\partial y_1} = \frac{\partial o}{\partial z_1} \cdot \frac{\partial z_1}{\partial y_1} + \frac{\partial o}{\partial z_2} \cdot \frac{\partial z_2}{\partial y_1}
\]</span> Det samlede udtryk for den partielle afledede af <span class="math inline">\(E\)</span> med hensyn til <span class="math inline">\(r_1\)</span> bliver derfor <span id="eq-samlet_dE_dr1"><span class="math display">\[
\frac{\partial E}{\partial r_1} = \frac{d E}{d o} \cdot
\left(
\frac{\partial o}{\partial z_1} \cdot \frac{\partial z_1}{\partial y_1} + \frac{\partial o}{\partial z_2} \cdot \frac{\partial z_2}{\partial y_1}
\right)
\cdot \frac{\partial y_1}{\partial r_1}
  \tag{19}\]</span></span> Vi finder hver af de afledede, som indgår i ovenstående udtryk én ad gangen. Vi ved allerede fra (<a href="#eq-dEdo" class="quarto-xref">14</a>), at <span class="math display">\[
\frac{d E}{d o} = \frac{1}{2} \cdot 2 \cdot (t-o) \cdot (-1) = -(t-o)
\]</span> Vi ved også fra (<a href="#eq-dodz_1" class="quarto-xref">18</a>), at <span class="math display">\[
\frac{\partial o}{\partial z_1} = o \cdot (1-o) \cdot w_1
\]</span> Differentieres <span class="math inline">\(z_1\)</span> (se (<a href="#eq-z_1" class="quarto-xref">8</a>)) med hensyn til <span class="math inline">\(y_1\)</span> får vi <span class="math display">\[\begin{align}
\frac{\partial z_1}{\partial y_1} &amp;= \sigma'(v_1 \cdot y_1 + v_2 \cdot y_2 + v_0)\cdot v_1 \\
&amp;= z_1 \cdot (1-z_1) \cdot v_1
\end{align}\]</span> hvor vi igen har brugt <a href="#thm-sigmoid_diff" class="quarto-xref">sætning&nbsp;1</a> og definitionen af <span class="math inline">\(z_1\)</span> i (<a href="#eq-z_1" class="quarto-xref">8</a>). Helt tilsvarende kan vi finde <span class="math inline">\(\frac{\partial o}{\partial z_2}\)</span> og <span class="math inline">\(\frac{\partial z_2}{\partial y_1}\)</span> (se (<a href="#eq-z_2" class="quarto-xref">9</a>)) <span class="math display">\[
\frac{\partial o}{\partial z_2} = o \cdot (1-o)\cdot w_2
\]</span> og <span class="math display">\[
\frac{\partial z_2}{\partial y_1} = z_2 \cdot (1-z_2)\cdot u_1
\]</span> Den sidste partielle afledede <span class="math inline">\(\frac{\partial y_1}{\partial r_1}\)</span> finder vi ved at differentiere udtrykket for <span class="math inline">\(y_1\)</span> i (<a href="#eq-y_1_1" class="quarto-xref">4</a>), hvor vi endnu engang udnytter <a href="#thm-sigmoid_diff" class="quarto-xref">sætning&nbsp;1</a>.</p>
<p>Indsætter vi nu alle de udtryk, som vi netop har udledt, i (<a href="#eq-samlet_dE_dr1" class="quarto-xref">19</a>) får vi et temmelig langt udtryk for <span class="math inline">\(\frac{\partial E}{\partial r_1}\)</span>: <span class="math display">\[\begin{align}
\frac{\partial E}{\partial r_1} &amp;= \underbrace{-(t-o)}_{\frac{dE}{do}}\cdot \\ &amp;\Big( \underbrace{o\cdot(1-o)\cdot w_1}_{\frac{\partial o}{\partial z_1}} \cdot \underbrace{z_1\cdot(1-z_1)\cdot v_1}_{\frac{\partial z_1}{\partial y_1}}+\underbrace{o\cdot(1-o)\cdot w_2}_{\frac{\partial o}{\partial z_2}}\cdot \underbrace{z_2\cdot(1-z_2)\cdot u_1}_{\frac{\partial z_2}{\partial y_1}}\Big)\cdot \\ &amp; \qquad \underbrace{y_1\cdot(1-y_1)\cdot x_1}_{\frac{\partial y_1}{\partial r_1}}
\end{align}\]</span> Og sætter vi <span class="math inline">\(o\cdot(1-o)\)</span> uden for parentesen og erstatter <span class="math inline">\((t-o)\cdot o\cdot (1-o)\)</span> med <span class="math inline">\(\delta\)</span> får vi <span class="math display">\[
\frac{\partial E}{\partial r_1}
=-\delta \cdot \Big(w_1 \cdot z_1\cdot (1-z_1)\cdot v_1+w_2 \cdot z_2 \cdot (1-z_2)\cdot  u_1 \Big) \cdot y_1\cdot (1-y_1) \cdot x_1
\]</span> Helt i tråd med tidligere får vi altså følgende opdateringsregel for <span class="math inline">\(r_1\)</span> <span class="math display">\[r_1 \leftarrow r_1 - \eta \cdot \frac{\partial E}{\partial r_1} \]</span> Det vil sige <span class="math display">\[
r_1 \leftarrow r_1 + \eta \cdot \delta \cdot \Big(w_1 \cdot z_1\cdot (1-z_1)\cdot v_1+w_2 \cdot z_2 \cdot (1-z_2)\cdot  u_1 \Big) \cdot y_1\cdot (1-y_1) \cdot x_1
\]</span></p>
<p>Udleder man tilsvarende opdateringsregler for <span class="math inline">\(r_2, r_3, r_4\)</span> og <span class="math inline">\(r_0\)</span> vil man se, at det eneste, som kommer til at ændre sig i ovenstående, er den sidste faktor <span class="math inline">\(x_1\)</span>, som bliver erstattet med henholdsvis <span class="math inline">\(x_2, x_3, x_4\)</span> og <span class="math inline">\(1\)</span>. Derfor får vi samlet set</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Opdateringsregler for <span class="math inline">\(r\)</span>-vægtene
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><span class="math display">\[\begin{align}
r_0 &amp;\leftarrow r_0 +  \eta \cdot \delta \cdot \Big(w_1 \cdot z_1\cdot (1-z_1)\cdot v_1+w_2 \cdot z_2 \cdot (1-z_2)\cdot  u_1 \Big) \cdot y_1\cdot (1-y_1) \\
r_1 &amp;\leftarrow r_1 +  \eta \cdot \delta \cdot \Big(w_1 \cdot z_1\cdot (1-z_1)\cdot v_1+w_2 \cdot z_2 \cdot (1-z_2)\cdot  u_1 \Big) \cdot y_1\cdot (1-y_1) \cdot x_1\\
r_2 &amp;\leftarrow r_2 +  \eta \cdot \delta \cdot \Big(w_1 \cdot z_1\cdot (1-z_1)\cdot v_1+w_2 \cdot z_2 \cdot (1-z_2)\cdot  u_1 \Big) \cdot y_1\cdot (1-y_1) \cdot x_2\\
r_3 &amp;\leftarrow r_3 +  \eta \cdot \delta \cdot \Big(w_1 \cdot z_1\cdot (1-z_1)\cdot v_1+w_2 \cdot z_2 \cdot (1-z_2)\cdot  u_1 \Big) \cdot y_1\cdot (1-y_1) \cdot x_3\\
r_4 &amp;\leftarrow r_4 +  \eta \cdot \delta \cdot \Big(w_1 \cdot z_1\cdot (1-z_1)\cdot v_1+w_2 \cdot z_2 \cdot (1-z_2)\cdot  u_1 \Big) \cdot y_1\cdot (1-y_1) \cdot x_4\\
\end{align}\]</span> hvor <span class="math display">\[
\delta = (t-o) \cdot o \cdot (1-o)
\]</span></p>
</div>
</div>
</div>
<p>Opdateringen af <span class="math inline">\(s\)</span>-vægtene foregår på samme måde. Hvis du ser på <a href="#fig-simple_NN_weights" class="quarto-xref">figur&nbsp;4</a>, kan du se, at alle <span class="math inline">\(s\)</span>-vægtene påvirker <span class="math inline">\(y_2\)</span>, som så påvirker både <span class="math inline">\(z_1\)</span> og <span class="math inline">\(z_2\)</span>, som i sidste ende påvirker outputtet <span class="math inline">\(o\)</span>. Ser vi generelt på vægten <span class="math inline">\(s_i\)</span>, hvor <span class="math inline">\(i=0, 1, 2, 3\)</span> eller <span class="math inline">\(4\)</span>, har vi altså <span class="math display">\[
\begin{matrix}
&amp; &amp; &amp; &amp; z_1 &amp; &amp; &amp; \\
&amp; &amp; &amp; \nearrow &amp; &amp; \searrow &amp; &amp; \\
s_i &amp; \rightarrow &amp; y_2 &amp; &amp; &amp; &amp; \rightarrow &amp; o \\
&amp; &amp; &amp; \searrow &amp; &amp; \nearrow &amp; &amp; \\
&amp; &amp; &amp; &amp; z_2 &amp; &amp; &amp; \\
\end{matrix}
\]</span> Som tidligere kan vi starte med at skrive <span class="math display">\[
\frac{\partial E}{\partial s_i} = \frac{d E}{d o} \cdot \frac{\partial o}{\partial y_2}  \cdot \frac{\partial y_2}{\partial s_i}
\]</span> og bruger vi igen kædreglen for funktioner af flere variable, får vi <span class="math display">\[
\frac{\partial E}{\partial s_i} = \frac{d E}{d o} \cdot
\left(
\frac{\partial o}{\partial z_1} \cdot \frac{\partial z_1}{\partial y_2} + \frac{\partial o}{\partial z_2} \cdot \frac{\partial z_2}{\partial y_2}
\right)
\cdot \frac{\partial y_2}{\partial s_i}
\]</span> I ovenstående udtryk bliver det klart, at opdateringsreglerne vil blive ens bortset fra den sidste faktor.</p>
<p>Nu udledes alle de partielle afledede, fuldstændig som for <span class="math inline">\(r\)</span>-vægtene og vi ender med følgende opdateringsregler for <span class="math inline">\(s\)</span>-vægtene:</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Opdateringsregler for <span class="math inline">\(s\)</span>-vægtene
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><span class="math display">\[\begin{align}
s_0 &amp;\leftarrow s_0 +  \eta \cdot \delta \cdot \Big(w_1 \cdot z_1\cdot (1-z_1)\cdot v_2+w_2 \cdot z_2 \cdot (1-z_2)\cdot  u_2 \Big) \cdot y_2\cdot (1-y_2) \\
s_1 &amp;\leftarrow s_1 + \eta \cdot \delta \cdot \Big(w_1 \cdot z_1\cdot (1-z_1)\cdot v_2+w_2 \cdot z_2 \cdot (1-z_2)\cdot  u_2 \Big) \cdot y_2\cdot (1-y_2) \cdot x_1\\
s_2 &amp;\leftarrow s_2 + \eta \cdot \delta \cdot \Big(w_1 \cdot z_1\cdot (1-z_1)\cdot v_2+w_2 \cdot z_2 \cdot (1-z_2)\cdot  u_2 \Big) \cdot y_2\cdot (1-y_2)  \cdot x_2\\
s_3 &amp;\leftarrow s_3 + \eta \cdot \delta \cdot \Big(w_1 \cdot z_1\cdot (1-z_1)\cdot v_2+w_2 \cdot z_2 \cdot (1-z_2)\cdot  u_2 \Big) \cdot y_2\cdot (1-y_2)  \cdot x_3\\
s_4 &amp;\leftarrow s_4 + \eta \cdot \delta \cdot \Big(w_1 \cdot z_1\cdot (1-z_1)\cdot v_2+w_2 \cdot z_2 \cdot (1-z_2)\cdot  u_2 \Big) \cdot y_2\cdot (1-y_2)  \cdot x_4\\
\end{align}\]</span> hvor <span class="math display">\[
\delta = (t-o) \cdot o \cdot (1-o)
\]</span></p>
</div>
</div>
</div>
<p>Det var faktisk det! Altså det blev jo en værre omgang bogstavgymnastik, men faktum er, at vi er i mål med at udlede backpropagation algoritmen for vores simple netværk i <a href="#fig-simple_NN_weights" class="quarto-xref">figur&nbsp;4</a>. Hurra for det!</p>
</section>
<section id="video-kunstige-neurale-netværk-7" class="level2">
<h2 class="anchored" data-anchor-id="video-kunstige-neurale-netværk-7">VIDEO: Kunstige neurale netværk 7</h2>
<p>I denne video forklares hvordan <span class="math inline">\(r\)</span>-vægtene opdateres.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/fUFH8hVvGMU" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</section>
</section>
<section id="sec-bogstaver_til_indekser" class="level1 page-columns page-full">
<h1>Fra bogstaver til indekser</h1>
<p>Det står på nuværende tidspunkt nok klart for de fleste, at den notation, som vi har anvendt i de foregående afsnit, er en lille smule tung. Der er bare rigtig mange bogstaver, og det kan være svært at huske om et givet bogstav betegner en outputværdi fra en neuron eller, om det er en vægt. Desuden skalerer notationen ufattelig dårligt! Forestil dig, at vi tilføjer <span class="math inline">\(2-3\)</span> ekstra lag til vores netværk - det bliver svært at blive ved med at finde nye bogstaver!</p>
<p>Derfor griber man traditionelt set notationen i forbindelse med kunstige neurale netværk lidt anderledes an, så det skalerer bedre, og så det bliver nemmere at læse (i hvert tilfælde når man lige har vænnet sig til de ekstra indekser, som vi bliver nødt til at indføre).</p>
<p>Lad os se på netværket i <a href="#fig-netvaerk3" class="quarto-xref">figur&nbsp;7</a>. Dette netværk har <span class="math inline">\(3\)</span> outputværdier i stedet for én, og der er ændret på antallet af neuroner i det ene af de skjulte lag i forhold til tidligere.</p>
<div id="fig-netvaerk3" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-netvaerk3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/netvaerk3.jpg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-netvaerk3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figur&nbsp;7: Kunstigt neuralt netværk med flere outputneuroner.
</figcaption>
</figure>
</div>
<p>Hvert lag i netværket er nu nummeret fortløbende fra <span class="math inline">\(1\)</span> til <span class="math inline">\(4\)</span>. Desuden giver vi nu en samlet betegnelse for den værdi, som hver neuron "spytter ud". F.eks. vil den <span class="math inline">\(3.\)</span> neuron i det <span class="math inline">\(2.\)</span> lag "outputte" eller "fyre" værdien <span class="math display">\[
a_3^{(2)}
\]</span> Det vil altså sige, at det tal, som står hævet i parentesen, refererer til laget og det tal, som er sænket, refererer til nummeret på rækken i det givne lag.</p>
<p>Bemærk også at inputværdierne i det første lag nu har to forskellige betegnelser for det samme: <span class="math display">\[
x_i  =a_i^{(1)}
\]</span> og tilsvarende har outputværdierne i det sidste og fjerde lag også to forskellige betegnelser: <span class="math display">\[
y_i  =a_i^{(4)}
\]</span> Lad os nu se på hvordan <strong>feedforward</strong> virker med vores nye notation. For det første er vi nødt til at være lidt smartere end tidligere i forhold til, hvad vi kalder vores vægte og bias. Der er tradition for, at man navngiver vægtene, som det ses på <a href="#fig-w_jik" class="quarto-xref">figur&nbsp;8</a>.</p>
<div id="fig-w_jik" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-w_jik-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/w_jik.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-w_jik-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figur&nbsp;8: Navngivning af vægte.
</figcaption>
</figure>
</div>
<p>Her er tanken, at vi gerne vil beregne outputværdien fra den <span class="math inline">\(j\)</span>’te neuron i det <span class="math inline">\(k\)</span>’te lag. Det gør vi ved at vægte alle outputværdierne fra det foregående lag: (<span class="math inline">\(k-1\)</span>). Den vægt, som vi ganger outputværdien fra den <span class="math inline">\(i\)</span>’te neuron i det <span class="math inline">\((k-1)'te\)</span> lag (<span class="math inline">\(a_i^{(k-1)}\)</span>) med, og som skal bruges for at beregne <span class="math inline">\(a_j^{(k)}\)</span>, vælger vi at kalde for <span class="math display">\[
w_{ji}^{(k)}
\]</span> Hvis man tænker på, at vi skal <em>til</em> række <span class="math inline">\(j\)</span> i <em>lag</em> <span class="math inline">\(k\)</span> <em>fra</em> række <span class="math inline">\(i\)</span>, så kan man måske huske på notationen sådan her: <span class="math display">\[
w_{\textrm{til fra}}^{(\textrm{lag})}
\]</span> Se også hvordan det passer med <a href="#fig-w_jik" class="quarto-xref">figur&nbsp;8</a>.</p>
<section id="sec-feedforward_indekser" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-feedforward_indekser">Feedforward med indekser</h2>
<p>Vi vil nu se på, hvordan de forskellige <span class="math inline">\(a_j^{(k)}\)</span>-værdier beregnes. Det vil sige, at vi altså skal se på, hvordan de forskellige feedforward-ligninger ser ud med vores nye notation.</p>
<div id="fig-udregn_a_1_2" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-udregn_a_1_2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/udregn_a_1-2.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-udregn_a_1_2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figur&nbsp;9: Udregning af <span class="math inline">\(a_1^{(2)}\)</span>.
</figcaption>
</figure>
</div>
<p>Lad os se på et konkret eksempel, så bliver det lidt nemmere at forholde sig til. Vi starter med at udregne outputværdien <span class="math inline">\(a_1^{(2)}\)</span> for den første neuron i det andet lag. Denne neuron får input fra alle neuroner i det foregående lag (som her er inputlaget). Bruger vi den notation for vægtene, som vi lige har indført, så starter vi med at beregne: <span class="math display">\[
z_1^{(2)} = w_{11}^{(2)} \cdot x_1 + w_{12}^{(2)} \cdot x_2 + w_{13}^{(2)} \cdot x_3 + w_{14}^{(2)} \cdot x_4 + b_1^{(2)}
\]</span> Der er to ting at bemærke her: 1) Vi vælger, at kalde udtrykket på højreside for <span class="math inline">\(z_1^{(2)}\)</span> og, 2) vi har kaldt biasen for <span class="math inline">\(b_1^{(2)}\)</span>.</p>
<p>Bruger vi nu de mere generelle udtryk for inputværdierne <span class="math inline">\(a_1^{(1)}, a_2^{(1)}, \dots, a_4^{(1)}\)</span> kan vi skrive: <span class="math display">\[\begin{align}
z_1^{(2)} &amp;= w_{11}^{(2)} \cdot a_1^{(1)} + w_{12}^{(2)} \cdot a_2^{(1)} + w_{13}^{(2)} \cdot a_3^{(1)} + w_{14}^{(2)} \cdot a_4^{(1)} + b_1^{(2)} \\
&amp;= \sum_{i=1}^{4} w_{1i}^{(2)} a_i^{(1)} +  b_1^{(2)}
\end{align}\]</span> Og endelig finder vi outputværdien <span class="math inline">\(a_1^{(2)}\)</span> for den første neuron i det andet lag ved som tidligere at anvende sigmoid-funktionen på ovenstående udtryk: <span class="math display">\[\begin{align}
a_1^{(2)} &amp;= \sigma(z_1^{(2)}) \\
&amp;= \sigma \left( \sum_{i=1}^{4} w_{1i}^{(2)} a_i^{(1)} +  b_1^{(2)} \right)
\end{align}\]</span> Det her er faktisk notationsmæssigt selve idéen. Folder vi det ud til hele det andet lag får vi derfor:</p>
<div class="callout callout-style-simple callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Feedforwardligninger til lag 2
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Beregn først: <span class="math display">\[\begin{align}
z_1^{(2)} &amp;= \sum_{i=1}^{4} w_{1i}^{(2)} a_i^{(1)} +  b_1^{(2)} \\
&amp; \\
z_2^{(2)} &amp;=\sum_{i=1}^{4} w_{2i}^{(2)} a_i^{(1)} +  b_2^{(2)} \\
&amp; \\
z_3^{(2)} &amp;= \sum_{i=1}^{4} w_{3i}^{(2)} a_i^{(1)} +  b_3^{(2)} \\
\end{align}\]</span> Outputværdierne for neuroner i det andet lag udregnes dernæst på denne måde: <span class="math display">\[\begin{align}
a_1^{(2)} &amp;= \sigma(z_1^{(2)}) \\
&amp; \\
a_2^{(2)} &amp;= \sigma(z_2^{(2)}) \\
&amp;\\
a_3^{(2)} &amp;= \sigma(z_3^{(2)}) \\
\end{align}\]</span></p>
</div>
</div>
</div>
<p>Og vover vi pelsen, kan vi helt generelt skrive:</p>
<div class="callout callout-style-simple callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Feedforward-ligninger til lag 2
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Beregn først: <span class="math display">\[\begin{align}
z_j^{(2)} = \sum_{i=1}^{4} w_{ji}^{(2)} a_i^{(1)} +  b_j^{(2)}
\end{align}\]</span> Outputværdierne for neuroner i det andet lag udregnes dernæst på denne måde: <span class="math display">\[\begin{align}
a_j^{(2)} &amp;= \sigma(z_j^{(2)})
\end{align}\]</span> for <span class="math inline">\(j \in \{1, 2, 3 \}\)</span>.</p>
</div>
</div>
</div>
<p>Fordelen ved denne notation er, at det nu er utrolig nemt at opskrive feedforward-ligningerne for lag 3 og 4 - det er blot nogle indekser, som skal ændres lidt. I det tredje lag er der to neuroner, hvis outputværdier beregnes på denne måde:</p>
<div class="callout callout-style-simple callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Feedforward-ligninger til lag 3
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Beregn først: <span id="eq-lag3"><span class="math display">\[
z_j^{(3)} = \sum_{i=1}^{3} w_{ji}^{(3)} a_i^{(2)} +  b_j^{(3)}
\tag{20}\]</span></span> Outputværdierne for neuroner i det tredje lag udregnes dernæst på denne måde: <span class="math display">\[\begin{align}
a_j^{(3)} &amp;= \sigma(z_j^{(3)})
\end{align}\]</span> for <span class="math inline">\(j \in \{1, 2 \}\)</span>.</p>
</div>
</div>
</div>
<p>Og endelig beregnes outputtet fra hele netværket i det fjerde lag:</p>
<div class="callout callout-style-simple callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Feedforward-ligninger til lag 4
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Udregn først: <span id="eq-lag4"><span class="math display">\[
z_j^{(4)} = \sum_{i=1}^{2} w_{ji}^{(4)} a_i^{(3)} +  b_j^{(4)}
\tag{21}\]</span></span> Outputværdierne for neuroner i det tredje lag udregnes dernæst på denne måde: <span class="math display">\[\begin{align}
y_j = a_j^{(4)} &amp;= \sigma(z_j^{(4)})
\end{align}\]</span> for <span class="math inline">\(j \in \{1, 2, 3 \}\)</span>.</p>
</div>
</div>
</div>
<p>Det fremgår nu tydeligt, at feedforward-ligningerne er på fuldstændig samme form, og vi vil derfor helt generelt kunne skrive:</p>
<div class="callout callout-style-simple callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-10-contents" aria-controls="callout-10" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Feedforward-ligninger generelt
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-10-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Beregn først: <span class="math display">\[\begin{align}
z_j^{(k)} = \sum_{i} w_{ji}^{(k)} a_i^{(k-1)} +  b_j^{(k)}
\end{align}\]</span> Outputværdierne for neuroner i det <span class="math inline">\(k\)</span>’te lag udregnes dernæst på denne måde: <span class="math display">\[\begin{align}
a_j^{(k)} &amp;= \sigma(z_j^{(k)})
\end{align}\]</span> for <span class="math inline">\(k \in \{2, 3, 4 \}\)</span>.</p>
</div>
</div>
</div>
<p>Når man bruger feedforward, starter man altså med at udregne outputværdierne for det første skjulte lag, dernæst for det andet skjulte lag og så videre, indtil man når til outputværdierne for selve netværket (deraf navnet: <em>feedforward</em> ). Bemærk her, at det ikke giver mening at udregne <span class="math inline">\(a_j^{(1)}\)</span>, fordi det svarer til inputværdierne til netværket.</p>
</section>
<section id="sec-backpropagation_indekser" class="level2">
<h2 class="anchored" data-anchor-id="sec-backpropagation_indekser">Backpropagation med indekser</h2>
<p>Lad os nu se på hvordan backpropagation fungerer. Vi skal altså have opskrevet vores opdateringsregler med den nye notation, og vi vil gribe det an, ligesom vi gjorde det i <a href="#sec-backpropagation_bogstaver" class="quarto-xref">afsnit&nbsp;4</a>. Nemlig ved at starte i det sidste lag (her lag <span class="math inline">\(4\)</span>) og finde opdateringsreglerne for de vægte og bias, som har direkte indflydelse på outputværdierne fra lag <span class="math inline">\(4\)</span>.</p>
<section id="sec-opdatering_lag4" class="level3">
<h3 class="anchored" data-anchor-id="sec-opdatering_lag4">Opdateringsregler for lag <span class="math inline">\(4\)</span></h3>
<p>Vi er altså i første omgang på jagt efter <span class="math display">\[
\frac{\partial E}{\partial w_{ji}^{(4)}} \quad \text{og} \quad \frac{\partial E}{\partial b_j^{(4)}},
\]</span> for <span class="math inline">\(j \in \{1, 2, 3\}\)</span>, <span class="math inline">\(i \in \{1, 2\}\)</span>. Tabsfunktionen <span class="math inline">\(E\)</span>, som hører til netværket i <a href="#fig-netvaerk3" class="quarto-xref">figur&nbsp;7</a>, bliver her: <span id="eq-E_indekser"><span class="math display">\[
E=\frac{1}{2} \sum_{j=1}^3 \left( t_j-y_j \right)^2 = \frac{1}{2} \sum_{j=1}^3 \left( t_j-a_j^{(4)} \right)^2
\tag{22}\]</span></span> hvor igen <span class="math inline">\(t_j\)</span> er den ønskede target-værdi for den <span class="math inline">\(j\)</span>’te outputneuron.</p>
<p>Lad os starte med at bestemme <span class="math inline">\(\frac{\partial E}{\partial w_{ji}^{(4)}}\)</span>. Vi må derfor først se på, hvordan <span class="math inline">\(w_{ji}^{(4)}\)</span> påvirker tabsfunktionen <span class="math inline">\(E\)</span>. Da <span class="math inline">\(w_{ji}^{(4)}\)</span> kun indgår i udtrykket for beregningen af <span class="math inline">\(z_j^{(4)}\)</span>, som igen bruges til beregningen af <span class="math inline">\(a_j^{(4)}\)</span>, som dernæst direkte påvirker tabsfunktionen, kan vi skrive: <span class="math display">\[
w_{ji}^{(4)} \rightarrow z_j^{(4)} \rightarrow a_j^{(4)} \rightarrow E
\]</span> Bruger vi først kædereglen én gang, får vi derfor <span id="eq-partialE_w_ji_4"><span class="math display">\[
\frac{\partial E}{\partial w_{ji}^{(4)}} = \frac{\partial E}{\partial z_j^{(4)}} \cdot \frac{\partial z_j^{(4)}}{\partial w_{ji}^{(4)}}
\tag{23}\]</span></span> og bruges kædereglen igen, kan første faktor udfoldes yderligere <span class="math display">\[
\frac{\partial E}{\partial z_j^{(4)}} = \frac{\partial E}{\partial a_j^{(4)}} \cdot  \frac{\partial a_j^{(4)}}{\partial z_j^{(4)}}
\]</span> Lad os starte med at udregne <span class="math inline">\(\frac{\partial E}{\partial z_j^{(4)}}\)</span> ved at udregne hver faktor på højresiden i ovenstående udtryk for sig. Fra (<a href="#eq-E_indekser" class="quarto-xref">22</a>) får vi, at <span class="math display">\[
E=\frac{1}{2} \sum_{j=1}^3 \left( t_j-a_j^{(4)} \right)^2 = \frac{1}{2} \left( \left( t_1-a_1^{(4)} \right)^2 + \left( t_2-a_2^{(4)} \right)^2+ \left( t_3-a_3^{(4)}\right)^2 \right)
\]</span> Hvis vi f.eks. skal differentiere ovenstående med hensyn til <span class="math inline">\(a_2^{(4)}\)</span>, kan vi se at alle de led, som ikke indeholder <span class="math inline">\(a_2^{(4)}\)</span>, vil være at betragte som konstanter, når vi differentierer - og når vi differentierer konstanter, får vi som bekendt <span class="math inline">\(0\)</span>. Derfor får vi, at <span class="math display">\[
\frac{\partial E}{\partial a_2^{(4)}} = \frac{1}{2}\cdot 2 \cdot (t_2-a_2^{(4)})\cdot (-1) = -(t_2-a_2^{(4)})
\]</span> På tilsvarende vis har vi derfor generelt, at <span id="eq-partialE_a_j_4"><span class="math display">\[
\frac{\partial E}{\partial a_j^{(4)}} = -(t_j-a_j^{(4)})
\tag{24}\]</span></span> Vi ved også, at <span class="math display">\[
a_j^{(4)} = \sigma(z_j^{(4)})
\]</span> Og bruger vi endnu en gang resultatet fra <a href="#thm-sigmoid_diff" class="quarto-xref">sætning&nbsp;1</a> får vi, at <span id="eq-partial_a_j^(z)_z_j^(4)"><span class="math display">\[
\frac{\partial a_j^{(4)}}{\partial z_j^{(4)}}  = \sigma'(z_j^{(4)})= \sigma(z_j^{(4)}) \cdot (1-\sigma(z_j^{(4)}))= a_j^{(4)}\cdot (1-a_j^{(4)})
\tag{25}\]</span></span> Indtil videre har vi altså, at <span class="math display">\[\begin{align}
\frac{\partial E}{\partial z_j^{(4)}} &amp;= \frac{\partial E}{\partial a_j^{(4)}} \cdot  \frac{\partial a_j^{(4)}}{\partial z_j^{(4)}} \\
&amp;=-(t_j-a_j^{(4)}) \cdot  a_j^{(4)}\cdot (1-a_j^{(4)})
\end{align}\]</span> I forhold til det videre arbejde viser det sig hensigtsmæssigt, at lave en samlet betegnelse for <span class="math display">\[\begin{align}
\frac{\partial E}{\partial z_j^{(4)}}  
&amp;=-(t_j-a_j^{(4)}) \cdot  a_j^{(4)}\cdot (1-a_j^{(4)})
\end{align}\]</span> Vi sætter derfor <span class="math display">\[
\delta_j^{(4)} = \frac{\partial E}{\partial z_j^{(4)}}  = -(t_j-a_j^{(4)}) \cdot a_j^{(4)} \cdot (1-a_j^{(4)})
\]</span> Udtrykket <span class="math inline">\(\delta_j^{(4)}\)</span> kalder man også for fejlleddet for det fjerde lag, men det kommer vi tilbage til senere.</p>
<p>Vi har nu fundet den første faktor i (<a href="#eq-partialE_w_ji_4" class="quarto-xref">23</a>), og mangler derfor kun at bestemme <span class="math inline">\(\frac{\partial z_j^{(4)}}{\partial w_{ji}^{(4)}}\)</span>. Bruger vi (<a href="#eq-lag4" class="quarto-xref">21</a>) ser vi, at <span class="math display">\[
z_j^{(4)} =  \sum_{i=1}^{2} w_{ji}^{(4)} a_i^{(3)} +  b_j^{(4)}  =
w_{j1}^{(4)} a_1^{(3)}+ w_{j2}^{(4)} a_2^{(3)} +  b_j^{(4)}
\]</span> Skal vi f.eks. differentiere dette udtryk med hensyn til <span class="math inline">\(w_{j1}^{(4)}\)</span>, får vi (fordi de fleste led i ovenstående, vil være at betragte som konstanter) <span class="math display">\[
\frac{\partial z_j^{(4)}}{\partial w_{j1}^{(4)}} =  a_1^{(3)}
\]</span> Og helt tilsvarende hvis vi differentierer med hensyn til <span class="math inline">\(w_{j2}^{(4)}\)</span>, får vi <span class="math display">\[
\frac{\partial z_j^{(4)}}{\partial w_{j2}^{(4)}} =  a_2^{(3)}
\]</span> Generelt har vi derfor, at <span id="eq-partial_z_j_4_w_ji_4"><span class="math display">\[
\frac{\partial z_j^{(4)}}{\partial w_{ji}^{(4)}} = a_i^{(3)}
\tag{26}\]</span></span></p>
<p>Samler vi nu de tre udtryk, som vi netop har udledt og indsætter i (<a href="#eq-partialE_w_ji_4" class="quarto-xref">23</a>) får vi <span class="math display">\[
\frac{\partial E}{\partial w_{ji}^{(4)}} =  -(t_j-a_j^{(4)}) \cdot a_j^{(4)} \cdot (1-a_j^{(4)}) \cdot a_i^{(3)}
\]</span> og med den lidt kortere notation, som vi indførte ovenfor, kan vi nu skrive <span class="math display">\[
\frac{\partial E}{\partial w_{ji}^{(4)}} =  \delta_j^{(4)} \cdot a_i^{(3)}
\]</span> For at finde opdateringsreglerne for biasene, må vi først bestemme de partielle afledede af <span class="math inline">\(E\)</span> med hensyn til <span class="math inline">\(b_j^{(4)}\)</span>. På helt tilsvarende vis får vi, at <span class="math display">\[
\frac{\partial E}{\partial b_j^{(4)}} = \frac{\partial E}{\partial z_j^{(4)}} \cdot \frac{\partial z_j^{(4)}}{\partial b_j^{(4)}}
\]</span> Vi ved allerede, at <span class="math display">\[\begin{align}
\frac{\partial E}{\partial z_j^{(4)}}  = \delta_j^{(4)}
\end{align}\]</span> og ser man på ligningen i (<a href="#eq-lag4" class="quarto-xref">21</a>), ses det nemt, at <span class="math display">\[
\frac{\partial z_j^{(4)}}{\partial b_j^{(4)}} = 1
\]</span> og derfor har vi, at <span class="math display">\[
\frac{\partial E}{\partial b_j^{(4)}}  =\delta_j^{(4)}
\]</span> Opdateringsreglerne for de vægte og bias, som hører til outputlaget (lag <span class="math inline">\(4\)</span>) er derfor <span class="math display">\[
w_{ji}^{(4)} \leftarrow w_{ji}^{(4)} - \eta \cdot \frac{\partial E}{\partial w_{ji}^{(4)}} = w_{ji}^{(4)} - \eta \cdot \delta_j^{(4)} \cdot a_i^{(3)}
\]</span> og <span class="math display">\[
b_j^{(4)} \leftarrow b_j^{(4)} - \eta \cdot \frac{\partial E}{\partial b_j^{(4)}}  = b_j^{(4)} - \eta \cdot \delta_j^{(4)}
\]</span> Vi kan altså opsummere:</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-11-contents" aria-controls="callout-11" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Opdateringsregler til vægte og bias i outputlaget (lag 4)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-11" class="callout-11-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Vægtene i outputlaget opdateres på denne måde: <span class="math display">\[
w_{ji}^{(4)} \leftarrow w_{ji}^{(4)} - \eta \cdot \delta_j^{(4)} \cdot a_i^{(3)}
\]</span> Biasene i outputlaget opdateres på denne måde: <span class="math display">\[
b_j^{(4)} \leftarrow b_j^{(4)} - \eta \cdot \delta_j^{(4)}
\]</span> hvor <span id="eq-error_term_j_4"><span class="math display">\[
\delta_j^{(4)} = \frac{\partial E}{\partial z_j^{(4)}}= -(t_j-a_j^{(4)}) \cdot a_j^{(4)} \cdot (1-a_j^{(4)})
\tag{27}\]</span></span></p>
</div>
</div>
</div>
<p>Udtrykket <span class="math inline">\(\delta_j^{(4)}\)</span> kalder man, som nævnt tidligere, også for fejlleddet i den <span class="math inline">\(j\)</span>’te række i det fjerde lag, og man kan se på ovenstående opdateringsregler, at dette fejlled netop indgår i opdateringen af både vægtene og biasene. Faktisk kan vi, præcis som vi gjorde det tidligere, tillægge dette fejlled en intuitiv god mening. Det kommer vi tilbage til igen senere!</p>
<p>Bemærk, at hvis vi i vores netværk starter med at vælge mere eller mindre tilfældige vægte, så kan vi på baggrund af dem bruge feedforwardligningerne til at udregne, <span class="math inline">\(a_j^{(4)}\)</span>- og <span class="math inline">\(a_i^{(3)}\)</span>- værdierne. Samtidig kender vi target-værdierne <span class="math inline">\(t_j\)</span>, og vi kan derfor også udregne fejlleddene <span class="math inline">\(\delta_j^{(4)}\)</span>. Vi har altså alt, hvad vi skal bruge for at benytte ovenstående opdateringsregler.</p>
</section>
<section id="sec-opdatering_lag3" class="level3">
<h3 class="anchored" data-anchor-id="sec-opdatering_lag3">Opdateringsregler for lag <span class="math inline">\(3\)</span></h3>
<p>Vi bevæger os nu et trin længere bagud i netværket og udleder opdateringsreglerne for det næstsidste lag - lag <span class="math inline">\(3\)</span>. Altså skal vi have bestemt <span class="math display">\[
\frac{\partial E}{\partial w_{ji}^{(3)}} \quad \text{og} \quad \frac{\partial E}{\partial b_j^{(3)}},
\]</span> for <span class="math inline">\(j \in \{1, 2\}\)</span>, <span class="math inline">\(i \in \{1, 2, 3\}\)</span>. Vi må igen se på, hvordan <span class="math inline">\(w_{ji}^{(3)}\)</span> påvirker tabsfunktionen <span class="math inline">\(E\)</span>. Ser vi på figur <a href="#fig-netvaerk3" class="quarto-xref">figur&nbsp;7</a>, kan vi se, at <span class="math inline">\(w_{ji}^{(3)}\)</span> direkte påvirker <span class="math inline">\(z_j^{(3)}\)</span>, som igen direkte påvirker <span class="math inline">\(a_j^{(3)}\)</span>. Nu vil den <span class="math inline">\(j\)</span>’te neuron i det tredje lag fyre værdien <span class="math inline">\(a_j^{(3)}\)</span> til alle neuroner i det fjerde lag. Altså vil <span class="math inline">\(a_j^{(3)}\)</span> påvirke <span class="math inline">\(z_1^{(4)}, z_2^{(4)}\)</span> og <span class="math inline">\(z_3^{(4)}\)</span>, som bruges til beregning af <span class="math inline">\(a_1^{(4)}, a_2^{(4)}\)</span> og <span class="math inline">\(a_3^{(4)}\)</span>, som så igen vil påvirke tabsfunktionen <span class="math inline">\(E\)</span>. Det kan illustreres på denne måde <span class="math display">\[
\begin{matrix}
&amp; &amp; &amp; &amp; z_1^{(4)} \rightarrow a_1^{(4)} &amp; &amp; \\
&amp; &amp; &amp; \nearrow  &amp; &amp;  \searrow &amp; \\
w_{ji}^{(3)} &amp; \rightarrow &amp; z_j^{(3)} \rightarrow a_j^{(3)} &amp; \rightarrow &amp;
z_2^{(4)} \rightarrow a_2^{(4)} &amp; \rightarrow &amp; E \\
&amp; &amp; &amp; \searrow &amp; &amp;  \nearrow &amp;  \\
&amp; &amp; &amp; &amp; z_3^{(4)} \rightarrow a_3^{(4)} &amp; &amp; \\
\end{matrix}
\]</span> I første omgang kan vi skrive <span id="eq-partialE_w_ji_3"><span class="math display">\[
\frac{\partial E}{\partial w_{ji}^{(3)}} = \frac{\partial E}{\partial z_j^{(3)}} \cdot \frac{\partial z_j^{(3)}}{\partial w_{ji}^{(3)}}
\tag{28}\]</span></span> og så gentagne gange bruge kædereglen til at udfolde dette udtryk.</p>
<p>Lad os starte med det nemmeste, nemlig <span class="math inline">\(\frac{\partial z_j^{(3)}}{\partial w_{ji}^{(3)}}\)</span>. Ser vi på definitionen af <span class="math inline">\(z_j^{(3)}\)</span> i (<a href="#eq-lag3" class="quarto-xref">20</a>), kan vi argumentere helt tilsvarende, som da vi ovenfor udledte udtrykket i (<a href="#eq-partial_z_j_4_w_ji_4" class="quarto-xref">26</a>) og får <span class="math display">\[
\frac{\partial z_j^{(3)}}{\partial w_{ji}^{(3)}} = a_i^{(2)}
\]</span></p>
<p>Lad os nu kaste os over den første faktor i (<a href="#eq-partialE_w_ji_3" class="quarto-xref">28</a>). Vi kan starte med at udnytte denne lidt overordnede måde, som <span class="math inline">\(z_j^{(3)}\)</span> påvirker <span class="math inline">\(E\)</span> på <span class="math display">\[
z_j^{(3)} \rightarrow a_j^{(3)} \rightarrow E
\]</span> Kædereglen giver os derfor i første omgang <span id="eq-partial_E_z_j_3"><span class="math display">\[
\frac{\partial E}{\partial z_j^{(3)}} = \frac{\partial E}{\partial a_j^{(3)}} \cdot
\frac{\partial a_j^{(3)}}{\partial z_j^{(3)}}
\tag{29}\]</span></span> Igen er sidste faktor nem nok, idet <span class="math display">\[
a_j^{(3)} = \sigma (z_j^{(3)})
\]</span> og derfor er <span class="math display">\[
\frac{\partial a_j^{(3)}}{\partial z_j^{(3)}} = \sigma' (z_j^{(3)})=\sigma(z_j^{(3)})\cdot (1-\sigma(z_j^{(3)}))= a_j^{(3)} \cdot (1-a_j^{(3)}),
\]</span> hvor vi endnu en gang har benyttet <a href="#thm-sigmoid_diff" class="quarto-xref">sætning&nbsp;1</a>.</p>
<p>Når vi skal bestemme <span class="math inline">\(\frac{\partial E}{\partial a_j^{(3)}}\)</span> kommer vi ikke udenom kædereglen for funktioner af flere variable. Det bliver tydeligt, når vi zoomer ind på hvordan <span class="math inline">\(a_j^{(3)}\)</span> påvirker <span class="math inline">\(E\)</span>: <span class="math display">\[
\begin{matrix}
  &amp; &amp; z_1^{(4)} \rightarrow a_1^{(4)} &amp; &amp; \\
  &amp; \nearrow  &amp; &amp;  \searrow &amp; \\
  a_j^{(3)} &amp; \rightarrow &amp;
z_2^{(4)} \rightarrow a_2^{(4)} &amp; \rightarrow &amp; E \\
&amp; \searrow &amp; &amp;  \nearrow &amp;  \\
&amp; &amp; z_3^{(4)} \rightarrow a_3^{(4)} &amp; &amp; \\
\end{matrix}
\]</span> For at vi senere kan udnytte nogle af de ligninger, som vi udledte i lag <span class="math inline">\(4\)</span>, vil vi faktisk bare nøjes med at se på det, på denne måde: <span class="math display">\[
\begin{matrix}
  &amp; &amp; z_1^{(4)} &amp; &amp; \\
  &amp; \nearrow  &amp; &amp;  \searrow &amp; \\
  a_j^{(3)} &amp; \rightarrow &amp;
z_2^{(4)} &amp; \rightarrow &amp; E \\
&amp; \searrow &amp; &amp;  \nearrow &amp;  \\
&amp; &amp; z_3^{(4)}  &amp; &amp; \\
\end{matrix}
\]</span> Nu er vi endelig klar til at bruge kædereglen for funktioner af flere variable: <span class="math display">\[\begin{align}
\frac{\partial E}{\partial a_j^{(3)}} &amp;=  \frac{\partial E}{\partial z_1^{(4)}} \cdot \frac{\partial z_1^{(4)}}{\partial a_j^{(3)}}  + \frac{\partial E}{\partial z_2^{(4)}} \cdot \frac{\partial z_2^{(4)}}{\partial a_j^{(3)}} + \frac{\partial E}{\partial z_3^{(4)}} \cdot \frac{\partial z_3^{(4)}}{\partial a_j^{(3)}} \\
&amp;= \sum_{k=1}^{3}\frac{\partial E}{\partial z_k^{(4)}} \cdot \frac{\partial z_k^{(4)}}{\partial a_j^{(3)}}  
\end{align}\]</span> Se nu dukker der noget op, som vi har set før! Nemlig det fejlled, som vi definerede i (<a href="#eq-error_term_j_4" class="quarto-xref">27</a>), og som vi allerede har regnet ud, da vi opdaterede vægtene og biasene i lag <span class="math inline">\(4\)</span>. Tænk lige over det - det er faktisk ret fedt! Dvs. at vi kan skrive: <span id="eq-partial_E_a_j_3"><span class="math display">\[
\begin{aligned}
\frac{\partial E}{\partial a_j^{(3)}} &amp;= \sum_{k=1}^{3} \delta_k^{(4)} \cdot \frac{\partial z_k^{(4)}}{\partial a_j^{(3)}}  
\end{aligned}
\tag{30}\]</span></span> Så mangler vi kun lige at finde <span class="math inline">\(\frac{\partial z_k^{(4)}}{\partial a_j^{(3)}}\)</span>! Fra (<a href="#eq-lag4" class="quarto-xref">21</a>) har vi, at <span class="math display">\[
z_k^{(4)} = \sum_i w_{ki}^{(4)} a_i^{(3)}+b_k^{(4)}
\]</span> så <span class="math display">\[
\frac{\partial z_k^{(4)}}{\partial a_j^{(3)}} = \frac{\partial}{\partial a_j^{(3)}} \left(\sum_i w_{ki}^{(4)} a_i^{(3)}+b_k^{(4)} \right)
\]</span> Når vi skal differentierer summen i ovenstående udtryk, får vi kun et led med, når <span class="math inline">\(i=j\)</span>, fordi i alle andre tilfælde, vil vi med hensyn til <span class="math inline">\(a_j^{(3)}\)</span> skulle differentiere en konstant. Og da <span class="math display">\[
\frac{\partial}{\partial a_j^{(3)}}\left ( w_{kj}^{(4)} a_j^{(3)} \right) = w_{kj}^{(4)}
\]</span> har vi altså, at <span class="math display">\[
\frac{\partial z_k^{(4)}}{\partial a_j^{(3)}} = w_{kj}^{(4)}
\]</span> Indsætter vi dette i (<a href="#eq-partial_E_a_j_3" class="quarto-xref">30</a>), har vi nu <span class="math display">\[\begin{align}
\frac{\partial E}{\partial a_j^{(3)}} = \sum_{k=1}^{3} \delta_k^{(4)} \cdot \frac{\partial z_k^{(4)}}{\partial a_j^{(3)}}  = \sum_{k=1}^{3} \delta_k^{(4)} \cdot w_{kj}^{(4)}
\end{align}\]</span></p>
<p>Nu skal vi i første omgang tilbage til (<a href="#eq-partial_E_z_j_3" class="quarto-xref">29</a>) og indsætte det vi netop er kommet frem til: <span class="math display">\[\begin{align}
\frac{\partial E}{\partial z_j^{(3)}}=\underbrace{\left ( \sum_{k=1}^{3} \delta_k^{(4)} \cdot w_{kj}^{(4)}\right )}_{\frac{\partial E}{\partial a_j^{(3)}}}
\cdot \underbrace{a_j^{(3)} \cdot (1-a_j^{(3)})}_{\frac{\partial a_j^{(3)}}{\partial z_j^{(3)}}}
\end{align}\]</span> Som vi gjorde i <a href="#sec-opdatering_lag4" class="quarto-xref">afsnit&nbsp;5.2.1</a>, vil vi også give dette lidt lange udtryk en særlig betegnelse, nemlig <span class="math display">\[\begin{align}
\delta_j^{(3)} = \frac{\partial E}{\partial z_j^{(3)}}=\left ( \sum_{k=1}^{3} \delta_k^{(4)} \cdot w_{kj}^{(4)}\right )
\cdot a_j^{(3)} \cdot (1-a_j^{(3)})
\end{align}\]</span> Det kan vist godt være lidt svært at bevare overblikket her, men nu er vi faktisk i mål! Vi indsætter i (<a href="#eq-partialE_w_ji_3" class="quarto-xref">28</a>) <span class="math display">\[\begin{align}
\frac{\partial E}{\partial w_{ji}^{(3)}} &amp;= \frac{\partial E}{\partial z_j^{(3)}} \cdot \frac{\partial z_j^{(3)}}{\partial w_{ji}^{(3)}} \\
&amp;= \delta_j^{(3)} \cdot a_i^{(2)}
\end{align}\]</span></p>
<p>Det er nu en smal sag at bestemme <span class="math inline">\(\frac{\partial E}{\partial b_j^{(3)}}\)</span>, da <span class="math display">\[\begin{align}
\frac{\partial E}{\partial b_j^{(3)}} &amp;= \frac{\partial E}{\partial z_j^{(3)}} \cdot \frac{\partial z_j^{(3)}}{\partial b_j^{(3)}} \\ &amp;= \delta_j^{(3)}\cdot \frac{\partial z_j^{(3)}}{\partial b_j^{(3)}}
\end{align}\]</span> Fra (<a href="#eq-lag3" class="quarto-xref">20</a>) har vi, at <span class="math display">\[
z_j^{(3)} = \sum_{i=1}^3 w_{ji}^{(3)} a_i^{(2)} + b_j^{(3)}
\]</span> og derfor er <span class="math display">\[
\frac{\partial z_j^{(3)}}{\partial b_j^{(3)}} = 1
\]</span> Altså får vi <span class="math display">\[\begin{align}
\frac{\partial E}{\partial b_j^{(3)}} = \delta_j^{(3)}
\end{align}\]</span> Glæden er stor, da vi nu har alle ingredienser til at opskrive opdateringsreglerne for det tredje lag!</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-12-contents" aria-controls="callout-12" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Opdateringsregler til vægte og bias i lag 3
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-12" class="callout-12-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Vægtene i outputlaget opdateres på denne måde: <span class="math display">\[
w_{ji}^{(3)} \leftarrow w_{ji}^{(3)} - \eta \cdot \delta_j^{(3)} \cdot a_i^{(2)}
\]</span> Biasene i outputlaget opdateres på denne måde: <span class="math display">\[
b_j^{(3)} \leftarrow b_j^{(3)} - \eta \cdot \delta_j^{(3)}
\]</span> hvor <span id="eq-error_term_j_3"><span class="math display">\[
\delta_j^{(3)} = \frac{\partial E}{\partial z_j^{(3)}}=\left( \sum_{k=1}^{3}\delta_k^{(4)} \cdot w_{kj}^{(4)}   \right) \cdot a_j^{(3)} \cdot (1-a_j^{(3)})
\tag{31}\]</span></span></p>
</div>
</div>
</div>
<p>Bemærk, at udgangspunktet for ovenstående er, at vi først har lavet et feedforward i netværket, så vi har alle <span class="math inline">\(a_i^{(2)}\)</span>- og <span class="math inline">\(a_j^{(3)}\)</span>-værdier. Derudover har vi allerede opdateret vægtene og biasene i lag <span class="math inline">\(4\)</span>. Derfor kender vi også fejleddene <span class="math inline">\(\delta_k^{(4)}\)</span> fra lag <span class="math inline">\(4\)</span>, som indgår i beregningen af <span class="math inline">\(\delta_j^{(3)}\)</span> i (<a href="#eq-error_term_j_3" class="quarto-xref">31</a>). Altså er det muligt at foretage de beregninger, som opdateringsreglerne i lag <span class="math inline">\(3\)</span> kræver.</p>
</section>
<section id="sec-opdatering_lag2" class="level3">
<h3 class="anchored" data-anchor-id="sec-opdatering_lag2">Opdateringsregler for lag <span class="math inline">\(2\)</span></h3>
<p>Vi er nu fremme ved det sidste lag, hvor vi skal have opdateret vægte og bias (husk på at <span class="math inline">\(a_i^{(1)}\)</span>-værdierne jo ikke skal beregnes, men er inputværdierne til netværket). Den gode nyhed her er, at der absolut intet nyt er under solen! Vi vil derfor heller ikke gå i drabelige deltaljer med alle udregninger her, men blot skitsere idéen.</p>
<p>Vi er nu på jagt efter <span class="math display">\[
\frac{\partial E}{\partial w_{ji}^{(2)}} \quad \text{og} \quad \frac{\partial E}{\partial b_j^{(2)}}
\]</span> og kigger vi på vores netværk i <a href="#fig-netvaerk3" class="quarto-xref">figur&nbsp;7</a> kan vi se følgende afhængigheder: <span class="math display">\[
\begin{matrix}
&amp; &amp; &amp; &amp; z_1^{(3)}  &amp; &amp; \\
&amp; &amp; &amp; \nearrow  &amp; &amp;  \searrow &amp; \\
w_{ji}^{(2)} &amp; \rightarrow &amp; z_j^{(2)} \rightarrow a_j^{(2)} &amp;  &amp;  &amp;  &amp; E \\
&amp; &amp; &amp; \searrow &amp; &amp;  \nearrow &amp;  \\
&amp; &amp; &amp; &amp; z_2^{(3)} &amp; &amp; \\
\end{matrix}
\]</span> Vi kan nu igen skrive <span id="eq-partialE_w_ji_2"><span class="math display">\[
\frac{\partial E}{\partial w_{ji}^{(2)}} = \frac{\partial E}{\partial z_j^{(2)}} \cdot \frac{\partial z_j^{(2)}}{\partial w_{ji}^{(2)}}
\tag{32}\]</span></span> Helt analogt til tidligere ses det nemt, at <span class="math display">\[
\frac{\partial z_j^{(2)}}{\partial w_{ji}^{(2)}} = a_i^{(1)}
\]</span> og kædreglen giver igen, at <span id="eq-partial_E_z_j_2"><span class="math display">\[
\frac{\partial E}{\partial z_j^{(2)}}= \frac{\partial E}{\partial a_j^{(2)}} \cdot
\frac{\partial a_j^{(2)}}{\partial z_j^{(2)}}
\tag{33}\]</span></span> Her fås også uden problemer, at den sidste faktor kan skrives som <span class="math display">\[
\frac{\partial a_j^{(2)}}{\partial z_j^{(2)}} = a_j^{(2)} \cdot (1-a_j^{(2)})
\]</span> og bruger man kædereglen for funktioner af flere variable, kommer man frem til, at <span class="math display">\[\begin{align}
\frac{\partial E}{\partial a_j^{(2)}} &amp;= \sum_{k=1}^2 \frac{\partial E}{\partial z_k^{(3)}}
\cdot \frac{\partial  z_k^{(3)}}{\partial a_j^{(2)}} \\
&amp;= \sum_{k=1}^2  \delta_k^{(3)} w_{kj}^{(3)},
\end{align}\]</span> hvor vi allerede har udregnet <span class="math inline">\(\delta_k^{(3)}\)</span>, da vi opdaterede vægtene og biasene i lag <span class="math inline">\(3\)</span>.</p>
<p>Indsætter vi i (<a href="#eq-partial_E_z_j_2" class="quarto-xref">33</a>) og samtidig definerer fejlleddet <span class="math inline">\(\delta_j^{(2)}\)</span> for det andet lag, får vi <span class="math display">\[
\delta_j^{(2)} = \frac{\partial E}{\partial z_j^{(2)}} = \left ( \sum_{k=1}^2  \delta_k^{(3)} w_{kj}^{(3)} \right ) \cdot a_j^{(2)} \cdot (1-a_j^{(2)})
\]</span> Alt i alt ender vi med <span class="math display">\[\begin{align}
\frac{\partial E}{\partial w_{ji}^{(2)}} &amp;= \delta_j^{(2)} \cdot a_i^{(1)} \\
&amp;= \delta_j^{(2)} \cdot x_i
\end{align}\]</span> fordi alle <span class="math inline">\(a_i^{(1)}\)</span>-værdierne svarer til selve inputværdierne <span class="math inline">\(x_i\)</span> til netværket.</p>
<p>Det er nu ikke svært at se, at <span class="math display">\[
\frac{\partial E}{\partial b_j^{(2)}} = \delta_j^{(2)}
\]</span> og vi får derfor følgende opdateringsregler for lag 2:</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-13-contents" aria-controls="callout-13" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Opdateringsregler til vægte og bias i lag 2
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-13" class="callout-13-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Vægtene i outputlaget opdateres på denne måde: <span class="math display">\[\begin{align}
w_{ji}^{(2)} \leftarrow w_{ji}^{(2)} - \eta \cdot \delta_j^{(2)} \cdot a_i^{(1)}
\end{align}\]</span> Biasene i outputlaget opdateres på denne måde: <span class="math display">\[\begin{align}
b_j^{(2)} \leftarrow b_j^{(2)} - \eta \cdot \delta_j^{(2)}
\end{align}\]</span> hvor <span id="eq-error_term_j_2"><span class="math display">\[
\delta_j^{(2)} = \frac{\partial E}{\partial z_j^{(2)}}= \left ( \sum_{k=1}^2  \delta_k^{(3)} w_{kj}^{(3)} \right ) \cdot a_j^{(2)} \cdot (1-a_j^{(2)})
\tag{34}\]</span></span></p>
</div>
</div>
</div>
</section>
</section>
<section id="var-det-så-egentlig-smart-med-alle-de-indekser" class="level2">
<h2 class="anchored" data-anchor-id="var-det-så-egentlig-smart-med-alle-de-indekser">Var det så egentlig smart med alle de indekser?</h2>
<p>Hvis man er nået hertil, kan man godt følge sig en lille smule forpustet. Der har godt nok været mange indekser at holde styr på! Både nogle der var sænkede, og nogle der var hævede og sat i parenteser! Alligevel kan man måske godt se fidusen nu.</p>
<p>Hvis vi ser på de opdateringsregler, som vi lige har udledt, så kan man se, at selve opdateringsreglerne af vægte og bias følger <em>præcis</em> samme form. Faktisk kan man, hvis man sammenligner opdateringsreglerne for de tre lag se, at opdateringsreglerne er på denne form:</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-14-contents" aria-controls="callout-14" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Generelle opdateringsregler til vægte og bias
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-14" class="callout-14-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Vægtene opdateres generelt på denne måde: <span class="math display">\[\begin{align}
w_{ji}^{(\text{lag})} \leftarrow w_{ji}^{(\text{lag})} - \eta \cdot \delta_j^{(\text{lag})} \cdot a_i^{(\text{lag-1})}
\end{align}\]</span> Biasene i outputlaget opdateres på denne måde: <span class="math display">\[\begin{align}
b_j^{(\text{lag})} \leftarrow b_j^{(\text{lag})} - \eta \cdot \delta_j^{(\text{lag})}
\end{align}\]</span></p>
</div>
</div>
</div>
<p>Bemærk her, at da vi allerede har lavet en feedforward i netværket, så kender vi outputværdierne <span class="math inline">\(a_i^{(\text{lag})}\)</span> i alle lag. Det vil sige, at vi kan opdatere vægtene og biasene, når blot vi kan beregne fejlleddene.</p>
<p>Den eneste reelle forskel på opdateringsreglerne er, at fejlleddene udregnes lidt forskelligt, alt efter om der er tale om outputlaget eller et skjult lag:</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-15-contents" aria-controls="callout-15" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Beregning af fejlleddene
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-15" class="callout-15-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Fejlleddene i outputlaget beregnes på denne måde: <span class="math display">\[\begin{align}
\delta_j^{(\text{outputlag})} = -(t_j-y_j) \cdot y_j \cdot (1-y_j),
\end{align}\]</span> idet outputværdierne fra netværket netop er <span class="math inline">\(y_1, y_2, \dots\)</span>.</p>
<p>Fejlleddene i et skjult lag beregnes på denne måde: <span class="math display">\[\begin{align}
\delta_j^{(\text{lag})} = \left ( \sum_{k}  \delta_k^{(\text{lag+1})} w_{kj}^{(\text{lag+1})} \right ) \cdot a_j^{(\text{lag})} \cdot (1-a_j^{(\text{lag})})
\end{align}\]</span></p>
</div>
</div>
</div>
<p>Bemærk her, at fejlleddene fra outputlaget uden videre kan beregnes, da vi kender target-værdierne <span class="math inline">\(t_j\)</span> og outputværdierne <span class="math inline">\(y_j\)</span> fra netværket (fordi vi allerede har lavet en feedforward). Vi kan også beregne fejlleddene i alle skjulte lag, idet vi hele tiden arbejder bagud i netværket (<em>backpropagation</em>). Det vil sige, at vi hele tiden har adgang til fejlleddene i laget længere fremme (lag+1), hvor (lag+1) første gang vil svare til outputlaget. Desuden kender vi pga. feedforward alle outputværdier <span class="math inline">\(a_j^{(\text{(lag)})}\)</span> og alle vægte <span class="math inline">\(w_{kj}^{(\text{(lag+1)})}\)</span>. Derfor kan vi også beregne fejlleddene i alle de skjulte lag.</p>
<p>Denne indsigt og den generelle overordnede struktur på opdateringsreglerne, var meget svær at indse med fremgangsmåde i <a href="#sec-backpropagation_bogstaver" class="quarto-xref">afsnit&nbsp;4</a>. Her druknede alt bare i et sandt bogstavshelvede!</p>
<p>Der er et par andre interessante ting at sige om beregningen af fejlleddene. Lad os først se på outputlaget: <span class="math display">\[
\delta_j^{(\text{outputlag})} = -(t_j-y_j) \cdot y_j \cdot (1-y_j)
\]</span> Hvis der er stor forskel på target-værdien <span class="math inline">\(t_j\)</span> og outputværdien <span class="math inline">\(y_j\)</span>, så bliver forskellen <span class="math inline">\(t_j-y_j\)</span> numerisk stor. Altså vil en stor forskel på det, vi ønsker, og det vi får ud af netværket betyde, at fejlleddet bliver større og i sidste ende, at de vægte, som direkte påvirker outputtet, også vil blive opdateret meget. Endelig ser vi igen, at hvis outputneuronen er mættet (dvs. at <span class="math inline">\(y_j\)</span> enten er tæt på <span class="math inline">\(0\)</span> eller <span class="math inline">\(1\)</span>), så vil fejlleddet ikke blive opdateret i samme grad, som hvis outputneuronen ikke havde været mættet (fordi hvis <span class="math inline">\(y_j\)</span> enten er tæt på <span class="math inline">\(0\)</span> eller <span class="math inline">\(1\)</span>, så vil <span class="math inline">\(y_j \cdot (1-y_j)\)</span> være tæt på <span class="math inline">\(0\)</span>).</p>
<p>Vi ser altså, at fejlleddet fra det sidste lag direkte afhænger af hvor stor forskellen er på target-værdi og outputværdi.</p>
<p>Ser vi så på fejlleddene fra de skjulte lag: <span class="math display">\[
\delta_j^{(\text{lag})} = \left ( \sum_{k}  \delta_k^{(\text{lag+1})} w_{kj}^{(\text{lag+1})} \right ) \cdot a_j^{(\text{lag})} \cdot (1-a_j^{(\text{lag})})
\]</span> Så kan vi igen se, at hvis den tilhørende outputneuron, som fyrer værdien <span class="math inline">\(a_j^{(\text{lag})}\)</span>, er mættet, så vil fejlleddet være tættere på <span class="math inline">\(0\)</span>, end hvis neuronen ikke havde været mættet. Samtidig kan vi også se, at der i fejlleddet indgår en vægtet sum af alle fejlleddene fra laget længere fremme: <span class="math display">\[
\sum_{k}  \delta_k^{(\text{lag+1})} w_{kj}^{(\text{lag+1})}
\]</span> På den måde vil store fejl i laget længere fremme også få indflydelse på fejlleddet i det nuværende lag.</p>
</section>
</section>
<section id="sec-NN_generelt" class="level1 page-columns page-full">
<h1>Kunstige neurale netværk helt generelt</h1>
<p>Med det benarbejde vi lige har været igennem, ligger det faktisk lige til højrebenet at generalisere overstående til et vilkårligt kunstigt neuralt netværk.</p>
<p>Vi forestiller os nu, at vi har <span class="math inline">\(K\)</span> lag i netværket, som det er illustreret på <a href="#fig-generelt_netvaerk" class="quarto-xref">figur&nbsp;10</a>.</p>
<div id="fig-generelt_netvaerk" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-generelt_netvaerk-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/generelt_netvaerk.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-generelt_netvaerk-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figur&nbsp;10: Generelt kunstigt neuralt netværk med <span class="math inline">\(K\)</span> lag.
</figcaption>
</figure>
</div>
<p>Det vil sige ét inputlag, ét outputlag og <span class="math inline">\(K-2\)</span> skjulte lag. Antallet af neuroner i hvert lag kan variere og behøver ikke at være det samme. Så lad os navngive antallet af neuroner i de <span class="math inline">\(K\)</span> lag på denne måde: <span class="math display">\[
n_1, n_2, \dots, n_k, \dots, n_K
\]</span> Inputværdierne til netværket betegner vi: <span class="math display">\[
a_1^{(1)}, a_2^{(1)}, \dots, a_{n_1}^{(1)}
\]</span> Feedforward ligningerne er nu helt identiske med dem vi opstillede i <a href="#sec-feedforward_indekser" class="quarto-xref">afsnit&nbsp;5.1</a>:</p>
<div class="callout callout-style-simple callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-16-contents" aria-controls="callout-16" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Feedforwardligninger - helt generelt
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-16" class="callout-16-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Beregn først: <span id="eq-z_j_k_generelt"><span class="math display">\[
z_j^{(k)} = \sum_{i} w_{ji}^{(k)} a_i^{(k-1)} +  b_j^{(k)}
\tag{35}\]</span></span> Outputværdierne for neuroner i det <span class="math inline">\(k\)</span>’te lag udregnes dernæst på denne måde: <span id="eq-a_j_k_generelt"><span class="math display">\[
a_j^{(k)} = \sigma(z_j^{(k)})
\tag{36}\]</span></span> for <span class="math inline">\(k \in \{2, 3, \dots, K \}\)</span>.</p>
</div>
</div>
</div>
<p>Hvis vi også kalder outputværdierne fra netværket for <span class="math display">\[
y_1, y_2, \dots, y_{n_K}
\]</span> så beregnes disse værdier altså ved <span class="math display">\[\begin{align}
y_j = a_j^{(K)} &amp;= \sigma(z_j^{(K)})
\end{align}\]</span> for <span class="math inline">\(j \in \{1, 2, \dots, n_K \}\)</span>.</p>
<section id="backpropagation---generelt" class="level2">
<h2 class="anchored" data-anchor-id="backpropagation---generelt">Backpropagation - generelt</h2>
<p>Lad os så se på backpropagation. Vi ved fra det foregående, at der reelt set kun er to ting, vi skal gøre:</p>
<ol type="1">
<li><p>Finde opdateringsreglerne for vægte og bias i outputlaget.</p></li>
<li><p>Finde opdateringsreglerne for vægte og bias i et vilkårligt skjult lag.</p></li>
</ol>
<section id="opdateringsregler-i-outputlaget" class="level3">
<h3 class="anchored" data-anchor-id="opdateringsregler-i-outputlaget">Opdateringsregler i outputlaget</h3>
<p>Vores tabsfunktion er stadig <span class="math display">\[
E= \frac{1}{2} \sum_{i=1}^{n_K} \left ( t_i - a_i^{(K)} \right )^2,
\]</span> hvor <span class="math inline">\(t_i\)</span> igen er targetværdierne. Vi skal bestemme <span class="math display">\[
\frac{\partial E}{\partial w_{ji}^{(K)}} \quad \text{og} \quad \frac{\partial E}{\partial b_j^{(K)}}
\]</span> Vi gør præcis som i <a href="#sec-opdatering_lag4" class="quarto-xref">afsnit&nbsp;5.2.1</a>. Vi indser først, at vi har denne direkte afhængighed fra <span class="math inline">\(w_{ji}^{(K)}\)</span> til <span class="math inline">\(E\)</span>: <span class="math display">\[
w_{ji}^{(K)} \rightarrow z_j^{(K)} \rightarrow a_j^{(K)} \rightarrow E
\]</span> Derfor får vi <span id="eq-partialE_w_ji_K"><span class="math display">\[
\frac{\partial E}{\partial w_{ji}^{(K)}} = \frac{\partial E}{\partial z_j^{(K)}} \cdot \frac{\partial z_j^{(K)}}{\partial w_{ji}^{(K)}}
\tag{37}\]</span></span> På grund af feedforwardligningen i (<a href="#eq-z_j_k_generelt" class="quarto-xref">35</a>) får vi for det første, at <span id="eq-partial_z_j_K_w_ji_K"><span class="math display">\[
\frac{\partial z_j^{(K)}}{\partial w_{ji}^{(K)}} = a_i^{(K-1)}
\tag{38}\]</span></span> Nu bruger vi kædereglen til at bestemme <span id="eq-partial_E_z_j_K_generelt"><span class="math display">\[
\frac{\partial E}{\partial z_j^{(K)}} = \frac{\partial E}{\partial a_j^{(K)}} \cdot  \frac{\partial a_j^{(K)}}{\partial z_j^{(K)}}
\tag{39}\]</span></span> På grund af feedforwardligningen i (<a href="#eq-a_j_k_generelt" class="quarto-xref">36</a>) og <a href="#thm-sigmoid_diff" class="quarto-xref">sætning&nbsp;1</a> får vi sidste faktor til <span class="math display">\[
\frac{\partial a_j^{(K)}}{\partial z_j^{(K)}}  =  a_j^{(K)}\cdot (1-a_j^{(K)})
\]</span> Endelig får vi, ved at differentiere tabsfunktionen med hensyn til <span class="math inline">\(a_j^{(K)}\)</span> <span class="math display">\[
\frac{\partial E}{\partial a_j^{(K)}} = -(t_j-a_j^{(K)})
\]</span> Vi definerer nu igen fejlleddet for outputlaget <span class="math inline">\(\delta_j^{(K)}\)</span>, som tidligere <span class="math display">\[
\delta_j^{(K)} = \frac{\partial E}{\partial z_j^{(K)}}
\]</span> og indsætter vi det, vi netop har udledt, i (<a href="#eq-partial_E_z_j_K_generelt" class="quarto-xref">39</a>) får vi <span class="math display">\[
\delta_j^{(K)} =  -(t_j-a_j^{(K)}) \cdot a_j^{(K)} \cdot (1-a_j^{(K)})
\]</span> Indsætter vi nu det hele i (<a href="#eq-partialE_w_ji_K" class="quarto-xref">37</a>), har vi altså: <span class="math display">\[
\frac{\partial E}{\partial w_{ji}^{(K)}} = \delta_j^{(K)}  \cdot a_i^{(K-1)}
\]</span> Det er ikke svært at overbevise sig selv om, at <span class="math display">\[
\frac{\partial E}{\partial b_j^{(K)}} = \delta_j^{(K)}
\]</span> og derfor har vi:</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-17-contents" aria-controls="callout-17" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Generelle opdateringsregler til vægte og bias i outputlaget (lag <span class="math inline">\(K\)</span>)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-17" class="callout-17-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Vægtene i outputlaget opdateres på denne måde: <span class="math display">\[\begin{align}
w_{ji}^{(K)} \leftarrow w_{ji}^{(K)} - \eta \cdot \delta_j^{(K)} \cdot a_i^{(K-1)}
\end{align}\]</span> Biasene i outputlaget opdateres på denne måde: <span class="math display">\[\begin{align}
b_j^{(K)} \leftarrow b_j^{(K)} - \eta \cdot \delta_j^{(K)}
\end{align}\]</span> hvor <span class="math display">\[\begin{align}
\delta_j^{(K)} = \frac{\partial E}{\partial z_j^{(K)}}= -(t_j-a_j^{(K)}) \cdot a_j^{(K)} \cdot (1-a_j^{(K)})
\end{align}\]</span></p>
</div>
</div>
</div>
</section>
<section id="opdateringsregler-i-et-vilkårligt-skjult-lag" class="level3">
<h3 class="anchored" data-anchor-id="opdateringsregler-i-et-vilkårligt-skjult-lag">Opdateringsregler i et vilkårligt skjult lag</h3>
<p>Vi ser nu på et vilkårligt skjult lag <span class="math inline">\(k\)</span>, som hverken er inputlaget eller outputlaget. Det vil sige, at <span class="math inline">\(k \in \{2, 3, \dots, K-1 \}\)</span>. Vi antager, at vi har kørt backpropagation på alle lag, der ligger længere fremme i netværket, og specielt har vi altså beregnet fejlleddene i lag <span class="math inline">\(k+1:\)</span> <span class="math display">\[
\delta_j^{(k+1)} = \frac{\partial E}{\partial z_j^{(k+1)}}
\]</span> Vi indser først, at vi har denne afhængighed fra <span class="math inline">\(w_{ji}^{(k)}\)</span> til tabsfunktionen <span class="math inline">\(E\)</span>: <span id="eq-dep_E_w_ji_k"><span class="math display">\[
\begin{matrix}
&amp; &amp; &amp; &amp; z_1^{(k+1)}  &amp; &amp; \\
&amp; &amp; &amp; \nearrow  &amp; \vdots &amp;  \searrow &amp; \\
w_{ji}^{(k)} &amp; \rightarrow &amp; z_j^{(k)} \rightarrow a_j^{(k)} &amp; \rightarrow  &amp;  z_j^{(k+1)} &amp; \rightarrow  &amp; E \\
&amp; &amp; &amp; \searrow &amp; \vdots &amp;  \nearrow &amp;  \\
&amp; &amp; &amp; &amp; z_{n_{k+1}}^{(k+1)} &amp; &amp; \\
\end{matrix}
\tag{40}\]</span></span> Vi starter som tidligere med at bruge kædereglen én gang: <span id="eq-partialE_w_ji_k"><span class="math display">\[
\frac{\partial E}{\partial w_{ji}^{(k)}} = \frac{\partial E}{\partial z_j^{(k)}} \cdot \frac{\partial z_j^{(k)}}{\partial w_{ji}^{(k)}}
\tag{41}\]</span></span> Fra feedforwardligningen i (<a href="#eq-z_j_k_generelt" class="quarto-xref">35</a>) får vi for det første, at <span class="math display">\[
\frac{\partial z_j^{(k)}}{\partial w_{ji}^{(k)}} = a_i^{(k-1)}
\]</span> Endnu en anvendelse af kædereglen, og hvor vi også i samme hug definerer fejlleddet <span class="math inline">\(\delta_j^{(k)}\)</span> for det <span class="math inline">\(k\)</span>’te skjulte lag, giver: <span id="eq-partial_E_z_j_k"><span class="math display">\[
\delta_j^{(k)} = \frac{\partial E}{\partial z_j^{(k)}}= \frac{\partial E}{\partial a_j^{(k)}} \cdot
\frac{\partial a_j^{(k)}}{\partial z_j^{(k)}}
\tag{42}\]</span></span> Den sidste partielle afledede kan vi udlede fra feedforwardligningen (<a href="#eq-a_j_k_generelt" class="quarto-xref">36</a>) og <a href="#thm-sigmoid_diff" class="quarto-xref">sætning&nbsp;1</a>: <span class="math display">\[
\frac{\partial a_j^{(k)}}{\partial z_j^{(k)}} = a_j^{(k)} \cdot (1-a_j^{(k)})
\]</span> For at beregne <span class="math inline">\(\frac{\partial E}{\partial a_j^{(k)}}\)</span> må vi have fat i kædereglen for funktioner af flere variable (se illustrationen i (<a href="#eq-dep_E_w_ji_k" class="quarto-xref">40</a>): <span class="math display">\[\begin{align}
\frac{\partial E}{\partial a_j^{(k)}} = \sum_{i=1}^{n_{k+1}} \frac{\partial E}{\partial z_i^{(k+1)}}
\cdot \frac{\partial  z_i^{(k+1)}}{\partial a_j^{(k)}}
\end{align}\]</span> Vi udnytter nu, at vi allerede kender fejlleddene fra lag <span class="math inline">\(k+1\)</span> og kan derfor omskrive til</p>
<p><span id="eq-partialE_aj_k"><span class="math display">\[
\frac{\partial E}{\partial a_j^{(k)}} = \sum_{i=1}^{n_{k+1}} \delta_i^{(k+1)}
\cdot \frac{\partial  z_i^{(k+1)}}{\partial a_j^{(k)}}
\tag{43}\]</span></span></p>
<p>Fra feedforwardligningen i (<a href="#eq-z_j_k_generelt" class="quarto-xref">35</a>) får vi, at <span class="math inline">\(z_i^{(k+1)}\)</span> kan skrives som <span class="math display">\[
z_i^{(k+1)} = \sum_{j} w_{ij}^{(k+1)} a_j^{(k)} +  b_i^{(k+1)}
\]</span> og derfor er <span class="math display">\[\begin{align}
\frac{\partial  z_i^{(k+1)}}{\partial a_j^{(k)}} = w_{ij}^{(k+1)}
\end{align}\]</span> Indsætter vi i (<a href="#eq-partialE_aj_k" class="quarto-xref">43</a>) fås <span class="math display">\[\begin{align}
\frac{\partial E}{\partial a_j^{(k)}} = \sum_{i=1}^{n_{k+1}} \delta_i^{(k+1)}
\cdot w_{ij}^{(k+1)}
\end{align}\]</span> og ved indsættelse i (<a href="#eq-partial_E_z_j_k" class="quarto-xref">42</a>) får vi nu fejlleddet i det <span class="math inline">\(k\)</span>’te lag <span class="math display">\[
\delta_j^{(k)} = \frac{\partial E}{\partial z_j^{(k)}}=  \left ( \sum_{i=1}^{n_{k+1}} \delta_i^{(k+1)} \cdot w_{ij}^{(k+1)} \right) \cdot a_j^{(k)} \cdot (1-a_j^{(k)})
\]</span> Vi bruger nu udtrykket for <span class="math inline">\(\frac{\partial E}{\partial w_{ji}^{(k)}}\)</span> i (<a href="#eq-partialE_w_ji_k" class="quarto-xref">41</a>) og ender med <span class="math display">\[\begin{align}
\frac{\partial E}{\partial w_{ji}^{(k)}} = \delta_j^{(k)} \cdot a_i^{(k-1)}
\end{align}\]</span> og tilsvarende får vi også, at <span class="math display">\[
\frac{\partial E}{\partial b_j^{(k)}} = \delta_j^{(k)}
\]</span> Opdateringsreglerne for et vilkårligt skjult lag bliver så:</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-18-contents" aria-controls="callout-18" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Opdateringsregler til vægte og bias i et vilkårligt skjult lag <span class="math inline">\(k\)</span>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-18" class="callout-18-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Vægtene i outputlaget opdateres på denne måde: <span class="math display">\[\begin{align}
w_{ji}^{(k)} \leftarrow w_{ji}^{(k)} - \eta \cdot \delta_j^{(k)} \cdot a_i^{(k-1)}
\end{align}\]</span> Biasene i outputlaget opdateres på denne måde: <span class="math display">\[\begin{align}
b_j^{(k)} \leftarrow b_j^{(k)} - \eta \cdot \delta_j^{(k)}
\end{align}\]</span> hvor <span class="math display">\[\begin{align}
\delta_j^{(k)} = \frac{\partial E}{\partial z_j^{(k)}}=  \left ( \sum_{i=1}^{n_{k+1}} \delta_i^{(k+1)} \cdot w_{ij}^{(k+1)} \right) \cdot a_j^{(k)} \cdot (1-a_j^{(k)})
\end{align}\]</span></p>
</div>
</div>
</div>
</section>
</section>
<section id="stokastisk-gradientnedstigning" class="level2">
<h2 class="anchored" data-anchor-id="stokastisk-gradientnedstigning">Stokastisk gradientnedstigning</h2>
<p>Vi har faktisk snydt lidt… Okay – indrømmet – det er lidt træls at komme at sige nu! Men i alt hvad vi har lavet indtil nu, har vi kun kigget på ét træningseksempel. Vi har ladet inputværdierne for det ene træningseksempel "kører igennem" netværket (feedforward), beregnet tabsfunktionen og brugt resultatet herfra til at opdatere alle vægtene (backpropagation). Men vi har jo ikke kun ét træningseksempel. Vi har faktisk rigtig mange! Måske ligefrem tusindvis af træningsdata. Men hvad gør man så?</p>
<p>Lad os lige genopfriske den tabsfunktion, som vi endte med i det helt generelle tilfælde: <span id="eq-E_singletraining"><span class="math display">\[
E= \frac{1}{2} \sum_{i=1}^{n_K} \left ( t_i - a_i^{(K)} \right )^2.
\tag{44}\]</span></span> Her er <span class="math inline">\(t_i\)</span> target-værdien for den <span class="math inline">\(i\)</span>’te outputneuron for lige præcis det træningseksempel vi står med. Husk på at et givet træningseksempel består af inputværdierne <span class="math display">\[
x_1, x_2, \dots, x_{n_1}
\]</span> <em>og</em> de ønskede target-værdier <span class="math display">\[
t_1, t_2, \dots, t_{n_K}.
\]</span> Når vi kører disse inputværdier igennem netværket, får de selvfølgelig i sidste ende direkte betydning for outputværdierne i det sidste lag (<span class="math inline">\(K\)</span>): <span class="math display">\[
a_1^{(K)}, a_2^{(K)}, \cdots, a_{n_K}^{(K)}.
\]</span> Det vil sige, at i vores tabsfunktion i (<a href="#eq-E_singletraining" class="quarto-xref">44</a>), så afhænger både <span class="math inline">\(t_i\)</span>’erne og <span class="math inline">\(a_i^{(K)}\)</span>’erne af træningseksemplet. Hvis vi sådan lidt generelt benævner vores træningseksempel med <span class="math inline">\(x\)</span>, så vil det kunne udtrykkes sådan her: <span class="math display">\[
E_x= \frac{1}{2} \sum_{i=1}^{n_K} \left ( t_{x,i} - a_{x,i}^{(K)} \right )^2,
\]</span> hvor så <span class="math inline">\(t_{x,i}\)</span> er target-værdien for den <span class="math inline">\(i\)</span>’te outputneuron fra træningsdata <span class="math inline">\(x\)</span> og <span class="math inline">\(a_{x,i}^{(K)}\)</span> er outputværdien for den <span class="math inline">\(i\)</span>’te outputneuron, som er beregnet på baggrund af inputværdierne fra træningsdata <span class="math inline">\(x\)</span>.</p>
<p>Den samlede tabsfunktion, som er den, vi i virkeligheden ønsker at minimere, bliver så gennemsnittet af tabsfunktionerne hørende til de enkelte træningsdata: <span id="eq-E_generel"><span class="math display">\[
E = \frac{1}{n} \sum_x E_x= \frac{1}{n} \sum_x \left ( \frac{1}{2} \sum_{i=1}^{n_K} \left ( t_{x,i} - a_{x,i}^{(K)} \right )^2 \right ).
\tag{45}\]</span></span> Husk på at vi er ude efter <span class="math display">\[
\frac{\partial E}{\partial w_{ji}^{(k)}} \quad \text{og} \quad \frac{\partial E}{\partial b_j^{(k)}}
\]</span> for <span class="math inline">\(k \in \{2, 3, \dots, K\}\)</span> og hvor <span class="math inline">\(E\)</span> nu er summen i (<a href="#eq-E_generel" class="quarto-xref">45</a>). Heldigvis kan vi differentiere ledvis, og der gælder derfor <span class="math display">\[
\frac{\partial E}{\partial w_{ji}^{(k)}} = \frac{1}{n} \sum_x \frac{\partial E_x}{\partial w_{ji}^{(k)}}
\]</span> og tilsvarende <span class="math display">\[
\frac{\partial E}{\partial b_j^{(k)}} = \frac{1}{n} \sum_x \frac{\partial E_x}{\partial b_j^{(k)}}
\]</span> Det kommer så til at betyde, at opdateringsreglerne nu generelt bliver på formen <span id="eq-opdatering_w_ji_alledata"><span class="math display">\[
w_{ji}^{(k)} \leftarrow w_{ji}^{(k)}-\eta \cdot \frac{\partial E}{\partial w_{ji}^{(k)}}  =
w_{ji}^{(k)}-\eta \cdot \frac{1}{n} \sum_x \frac{\partial E_x}{\partial w_{ji}^{(k)}}
\tag{46}\]</span></span> og tilsvarende for biasene <span id="eq-opdatering_b_j_alledata"><span class="math display">\[
b_j^{(k)} \leftarrow b_j^{(k)} -\eta \cdot \frac{\partial E}{\partial b_j^{(k)}}  =
b_j^{(k)}-\eta \cdot \frac{1}{n} \sum_x \frac{\partial E_x}{\partial b_j^{(k)}}
\tag{47}\]</span></span> Alle leddene <span class="math inline">\(\frac{\partial E_x}{\partial w_{ji}^{(k)}}\)</span> og <span class="math inline">\(\frac{\partial E_x}{\partial b_j^{(k)}}\)</span>, som indgår i opdateringsreglerne, svarer netop til hvad vi har udledt i de foregående afsnit, fordi vi jo netop her kun så på ét træningseksempel ad gangen. Hvis vi overfører dette til opdateringsreglerne i outputlaget, så vil vi f.eks. få</p>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-19-contents" aria-controls="callout-19" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Generelle opdateringsregler til vægte og bias i outputlaget (lag <span class="math inline">\(K\)</span>) med brug af alle træningsdata
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-19" class="callout-19-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Vægtene i outputlaget opdateres på denne måde: <span class="math display">\[\begin{align}
w_{ji}^{(K)} \leftarrow w_{ji}^{(K)} - \eta \cdot \frac{1}{n} \sum_x \left ( \delta_{x,j}^{(K)} \cdot a_{x,i}^{(K-1)} \right )
\end{align}\]</span> Biasene i outputlaget opdateres på denne måde: <span class="math display">\[\begin{align}
b_j^{(K)} \leftarrow b_j^{(K)} - \eta \cdot \frac{1}{n} \sum_x \left ( \delta_{x,j}^{(K)} \right )
\end{align}\]</span> hvor <span class="math display">\[\begin{align}
\delta_{x,j}^{(K)} = \frac{\partial E_x}{\partial z_j^{(K)}}= -(t_{x,j}-a_{x,j}^{(K)}) \cdot a_{x,j}^{(K)} \cdot (1-a_{x,j}^{(K)})
\end{align}\]</span></p>
</div>
</div>
</div>
<p>Og helt tilsvarende vil det se ud for opdateringsreglerne i de skjulte lag.</p>
<p>Lad os lige dvæle lidt ved, hvad det her, det egentlig betyder. Lad os sige at vi har <span class="math inline">\(1000\)</span> træningsdata. Så skal vi lade de <span class="math inline">\(1000\)</span> træningsdata kører igennem netværket, så vi kan beregne de <span class="math inline">\(1000\)</span> led, som indgår i de ovenstående summer. Herefter kan vi opdatere alle vægte og bias én gang. Det vil blot være ét lille skridt på vej ned i dalen mod det lokale minimum, som vi er på jagt efter. Dette lille skridt skal gentages rigtig mange gange, indtil værdien af tabsfunktionen ser ud til at begynde at konvergere – svarende til at vi har ramt det lokale minimum.</p>
<p>Så selvom gradientnedstigning kan bruges til at finde et lokalt minimum for tabsfunktionen <span class="math inline">\(E\)</span>, så er det faktisk også en beregningsmæssig stor og tung opgave! Derfor er der forsket meget videre i at gøre det endnu bedre og endnu hurtigere. I algoritmer som disse er der ofte et trade-off: Man kan gøre noget hurtigere ved at bruge mere hukommelse – eller bruge mindre hukommelse ved at gøre det en smule langsommere. En af de teknikker, der er kommet ud af den forskning, er, at man kan bruge mindre hukommelse ved i hvert opdateringsskridt kun at bruge en tilfældigt udvalgt del af træningsdata – det kunne f.eks. være <span class="math inline">\(10\%\)</span> af alle træningsdata. Så vil man i hvert skridt stadig bruge opdateringsreglerne i (<a href="#eq-opdatering_w_ji_alledata" class="quarto-xref">46</a>) og (<a href="#eq-opdatering_b_j_alledata" class="quarto-xref">47</a>), men hvor der nu kun summeres over de <span class="math inline">\(10 \%\)</span> af træningsdatene. Hver gang man laver et nyt opdateringsskridt, vil man tage en ny tilfældigt udvalgt del af træningsdata. Denne teknik kalder man <em>stokastisk gradientnedstigning</em> (stochastic gradient descent). Og der er endnu flere af sådanne små ændringer, der enten gør algoritmen hurtigere eller, at den bruger mindre hukommelse. Det vil komme an på den enkelte anvendelse, hvad der er vigtigst her.</p>
</section>
</section>
<section id="valg-af-tabsfunktion" class="level1 page-columns page-full">
<h1>Valg af tabsfunktion</h1>
<p>I <a href="#sec-backpropagation_bogstaver" class="quarto-xref">afsnit&nbsp;4</a> definerede vi tabsfunktionen ved <span class="math display">\[
E = \frac{1}{2}(t-o)^2
\]</span> mens vi <a href="#sec-bogstaver_til_indekser" class="quarto-xref">afsnit&nbsp;5</a> og <a href="#sec-NN_generelt" class="quarto-xref">afsnit&nbsp;6</a> så, hvordan denne tabsfunktionen kan generaliseres, når outputlaget har mere end én neuron. I alle tilfælde er der tale om en <em>kvadratisk</em> tabsfunktion, fordi vi ser på den kvadrerede forskel på target-værdi <span class="math inline">\(t\)</span> og outputværdi <span class="math inline">\(o\)</span>. Men det er et <em>valg</em> at definere tabsfunktionen på denne måde, man kunne have defineret mange andre tabsfunktioner i stedet for. Egentlig ønsker vi blot en tabsfunktion <span class="math inline">\(E\)</span> med følgende egenskaber:</p>
<ul>
<li><p><span class="math inline">\(E&gt;0\)</span> - fordi det giver bedst mening at tale om et positivt tab.</p></li>
<li><p>Hvis vi har et netværk, som klassificerer godt, så er <span class="math inline">\(E\)</span> tæt på <span class="math inline">\(0\)</span>, og omvendt hvis netværket er dårligt til at klassificere, så er <span class="math inline">\(E\)</span> langt væk fra <span class="math inline">\(0\)</span>.</p></li>
</ul>
<p>Har en tabsfunktion disse egenskaber, så giver det mening at bestemme vægtene i netværket, så tabsfunktionen minimeres.</p>
<p>Faktisk viser det sig, at valget af den kvadratiske tabsfunktion kombineret med sigmoid aktiveringsfunktionen har nogle ulemper. For at forstå det, skal vi se på opdateringsreglerne for vægtene tættest på outputlaget. Men den notation, som vi anvendte i <a href="#sec-backpropagation_bogstaver" class="quarto-xref">afsnit&nbsp;4</a>, fik vi f.eks. at <span class="math display">\[
w_1 \leftarrow w_1 + \eta  \cdot (t-o) \cdot o \cdot (1-o) \cdot z_1
\]</span> Når vi træner netværket, ved vi jo ikke, hvilke værdier vægtene skal have - så vi starter med at vælge nogle mere eller mindre tilfældige værdier. Det betyder også, at indtil netværket er trænet, så vil den andel af træningseksemplerne, som klassificeres korrekt, ikke nødvendigvis være så stor. Det gør ikke så meget, hvis bare netværket lærer hurtigt - det vil sige, at netværket hurtigt får opdateret vægtene så andelen af træningseksemplerne, som klassificeres korrekt, bliver stor. Problemet med den kvadratiske tabsfunktion er, at man i nogle tilfælde kan komme ud for at dette ikke sker, men derimod at netværket lærer langsomt.</p>
<p>Problemet opstår, hvis startvægtene fejlagtigt kommer til at give en outputværdi <span class="math inline">\(o\)</span>, som enten er tæt på <span class="math inline">\(0\)</span> eller <span class="math inline">\(1\)</span>. Hvis det sker, vil <span class="math inline">\(t-o\)</span> være "stor" (fordi outputværdien er fejlagtig), men samtidig vil faktoren <span class="math inline">\(o \cdot (1-o)\)</span> være tæt på <span class="math inline">\(0\)</span> (fordi <span class="math inline">\(o\)</span> enten er tæt på <span class="math inline">\(0\)</span> eller på <span class="math inline">\(1\)</span>). Derfor kan vi risikere, at <span class="math inline">\(w_1\)</span>-vægten ikke bliver opdateret særlig meget, fordi <span class="math inline">\(t-o\)</span> bliver ganget med et tal, som er tæt på <span class="math inline">\(0\)</span>. Sker dette kalder man det for <em>slow learning</em>.</p>
<p>Nu kunne man måske godt tænke, at det da ikke har noget med tabsfunktionen at gøre, men det har lige præcis noget med tabsfunktionen <em>i kombination</em> med sigmoid-funktionen at gøre. For at se det må vi genkalde os, hvor ovenstående opdateringsregel kom fra. Faktisk svarede <span class="math inline">\(t-o\)</span> til <span class="math inline">\(-dE/do\)</span> og <span class="math inline">\(o \cdot (1-o)\)</span> var sigmoid-funktionen <span class="math inline">\(\sigma(w_0+w_1 \cdot z_1 + w_2 \cdot z_2)\)</span> differentieret. Det vil sige: <span id="eq-opdatering_w1_med_forklaring"><span class="math display">\[
w_1 \leftarrow w_1 + \eta  \cdot \underbrace{(t-o)}_{-dE/do} \cdot \underbrace{o \cdot (1-o)}_{\sigma'(\cdots)} \cdot z_1
\tag{48}\]</span></span> Hvis man derimod kunne vælge en tabsfunktion, som passer bedre sammen med sigmoid-funktionen, på den måde at forstå at faktoren <span class="math inline">\(o \cdot (1-o)\)</span> vil forkorte ud i ovenstående udtryk, så vil man slippe af med problemet omkring langsom læring.</p>
<p>Nok ikke helt overraskende så kan man faktisk godt diske op med en sådan tabsfunktion! Den tabsfunktion, som passer godt sammen med sigmoid-funktionen, kaldes for <em>cross-entropy</em> tabsfunktionen og er defineret sådan her <span id="eq-cross_entropy"><span class="math display">\[
E = - \left ( t \cdot \ln(o)+(1-t) \cdot \ln(1-o) \right )
\tag{49}\]</span></span> Det ser jo ikke umiddelbart videre behageligt ud, og det er slet ikke oplagt, at det overhovedet er en tabsfunktion. Det vil sige, opfylder cross-entropy tabsfunktionen betingelserne listet ovenfor? Lad os starte med at undersøge om <span class="math inline">\(E&gt;0\)</span>. For det første er target-værdien <span class="math inline">\(t\)</span> altid enten <span class="math inline">\(0\)</span> eller <span class="math inline">\(1\)</span>. Derfor er der følgende to muligheder: <span class="math display">\[\begin{align}
t=0: &amp; \quad  E=- \ln(1-o)\\
t=1: &amp; \quad E=- \ln(o)
\end{align}\]</span> Vi ved også, at outputværdien <span class="math inline">\(o\)</span> ligger mellem <span class="math inline">\(0\)</span> og <span class="math inline">\(1\)</span>. Altså <span class="math inline">\(0&lt;o&lt;1\)</span>. Derfor vil også <span class="math inline">\(1-o\)</span> ligge mellem <span class="math inline">\(0\)</span> og <span class="math inline">\(1\)</span>. På <a href="#fig-graf_ln" class="quarto-xref">figur&nbsp;11</a> ses grafen for den naturlige logaritmefunktion <span class="math inline">\(\ln(x)\)</span>. Her ser vi, at hvis <span class="math inline">\(0&lt;x&lt;1\)</span>, så vil <span class="math inline">\(\ln(x)\)</span> være negativ. Derfor kan vi fra ovenstående udtryk se, at <span class="math inline">\(E\)</span> vil være positiv (fordi både <span class="math inline">\(\ln (1-o)\)</span> og <span class="math inline">\(\ln(o)\)</span> vil være negative).</p>
<div class="cell page-columns page-full">
<div class="cell-output-display page-columns page-full">
<div id="fig-graf_ln" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-graf_ln-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="neurale_net_files/figure-html/fig-graf_ln-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-graf_ln-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figur&nbsp;11: Grafen for den naturlige logaritmefunktion <span class="math inline">\(\ln(x)\)</span>.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Vi mangler nu at redegøre for, at <span class="math inline">\(E \thickapprox 0\)</span>, hvis netværket er god til at klassificere. Der er igen to muligheder alt efter om <span class="math inline">\(t=0\)</span> eller om <span class="math inline">\(t=1\)</span>. Hvis <span class="math inline">\(t=0\)</span> og netværket er godt, så vil <span class="math inline">\(o\)</span> også være tæt på <span class="math inline">\(0\)</span>, og <span class="math inline">\(1-o\)</span> vil være tæt på <span class="math inline">\(1\)</span>. I det tilfælde får vi <span class="math display">\[
E = - \left ( \underbrace{t}_{=0} \cdot \ln(o)+\underbrace{(1-t)}_{= 1} \cdot \underbrace{\ln(1-o)}_{\thickapprox 0} \right ),
\]</span> hvor vi bruger, at <span class="math inline">\(\ln(x) \thickapprox 0\)</span>, hvis <span class="math inline">\(x \thickapprox 1\)</span> (se <a href="#fig-graf_ln" class="quarto-xref">figur&nbsp;11</a>). Alt i alt får vi i dette tilfælde, at <span class="math inline">\(E\)</span> er tæt på <span class="math inline">\(0\)</span>. Hvis derimod <span class="math inline">\(t=1\)</span> og netværket er godt, så <span class="math inline">\(o\)</span> er tæt på <span class="math inline">\(1\)</span>, så får vi: <span class="math display">\[
E = - \left ( \underbrace{t}_{=1} \cdot \underbrace{\ln(o)}_{\thickapprox 0}+\underbrace{(1-t)}_{=0} \cdot \ln(1-o) \right )
\]</span> Igen får vi også i dette tilfælde, at <span class="math inline">\(E\)</span> er tæt på <span class="math inline">\(0\)</span>. På tilsvarende vis kan man argumentere for, at hvis netværket er dårligt, så enten <span class="math inline">\(t=0\)</span> og <span class="math inline">\(o \thickapprox  1\)</span> eller <span class="math inline">\(t=1\)</span> og <span class="math inline">\(o \thickapprox 0\)</span>, så vil <span class="math inline">\(E\)</span> blive stor.</p>
<p>Alt i alt er vi altså kommet frem til, at cross-entropy tabsfunktionen opfylder betingelserne ovenfor og dermed, at cross-entropy tabsfunktionen rent faktisk <em>er</em> en tabsfunktion! Så langt så godt! Nu mangler vi at vise, at cross-entropy tabsfunktionen løser det potentielle problem omkring langsom læring. Det gør vi ved at finde et nyt udtryk for opdatering af <span class="math inline">\(w_1\)</span>-vægten. Hvis vi ser på udtrykket i (<a href="#eq-opdatering_w1_med_forklaring" class="quarto-xref">48</a>), så skal vi bare have fundet et nyt udtryk for <span class="math inline">\(dE/do\)</span>, da vi holder fast i sigmoid aktiveringsfunktionen. Så lad os differentiere cross-entropy tabsfunktionen defineret i (<a href="#eq-cross_entropy" class="quarto-xref">49</a>) med hensyn til <span class="math inline">\(o\)</span>: <span class="math display">\[
\frac{dE}{do}= - \left ( t \cdot \frac{1}{o}-(1-t) \cdot \frac{1}{1-o} \right ),
\]</span> hvor vi har husket, at <span class="math inline">\(\ln(1-o)\)</span> er en sammensat funktion. Vi sætter nu på fælles brøkstreg <span class="math display">\[\begin{align}
\frac{dE}{do} &amp;= -  \frac{t \cdot (1-o) - o \cdot (1-t)}{o \cdot (1-o)}  \\
&amp; = -\frac{t-t \cdot o - o + t \cdot o}{o \cdot (1-o)} \\
&amp; = -\frac{t-o}{o \cdot (1-o)}
\end{align}\]</span> Og derfor er <span class="math display">\[
- \frac{dE}{do}=\frac{t-o}{o \cdot (1-o)}
\]</span> som ved indsættelse i (<a href="#eq-opdatering_w1_med_forklaring" class="quarto-xref">48</a>) giver <span class="math display">\[
w_1 \leftarrow w_1 + \eta  \cdot \underbrace{\frac{t-o}{o \cdot (1-o)}}_{-dE/do} \cdot \underbrace{o \cdot (1-o)}_{\sigma'(\cdots)} \cdot z_1
\]</span> Vi ser nu, at udtrykket <span class="math inline">\(o \cdot (1-o)\)</span>, som var den faktor, der kunne give anledning til langsom læring, forkorter ud, og vi får i stedet <span class="math display">\[
w_1 \leftarrow w_1 + \eta  \cdot (t-o) \cdot  z_1
\]</span> Her ses det tydeligt, at hvis der er stor forskel på target-værdi <span class="math inline">\(t\)</span> og outputværdi <span class="math inline">\(o\)</span>, så vil det give anledning til en stor opdatering af <span class="math inline">\(w_1\)</span>-vægten<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> - også selvom <span class="math inline">\(o\)</span> er tæt på <span class="math inline">\(0\)</span> eller <span class="math inline">\(1\)</span>. På den måde passer cross-entropy tabsfunktionen bedre sammen med sigmoid aktiveringsfunktionen, end den kvadratiske tabsfunktion gør. Simpelthen fordi det potentielle problem omkring langsom læring undgås.</p>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;Med mindre selvfølgelig at <span class="math inline">\(z_1\)</span> er tæt på <span class="math inline">\(0\)</span>, men i det tilfælde vil <span class="math inline">\(w_1\)</span> alligevel ikke have særlig stor indflydelse på outputværdien <span class="math inline">\(o\)</span>.</p></div></div></section>
<section id="billedgenkendelse-og-kunstige-neurale-netværk" class="level1 page-columns page-full">
<h1>Billedgenkendelse og kunstige neurale netværk</h1>
<p>Vi startede egentlig med at sige, at vi godt kunne tænke os at træne et kunstigt neuralt netværk, så det kan bruges til at afgøre, om der er en hund på et billede eller ej. Og egentlig kan det godt lade sig gøre, med det vi har lært indtil nu. Der er bare én afgørende ting ved billedgenkendelse, som vi ikke har taget højde for. I <a href="#sec-hvordanFunktion" class="quarto-xref">afsnit&nbsp;2</a> forklarede vi, hvordan man kan repræsentere et sort/hvidt billede ved hjælp af en vektor. F.eks. vil et billede på <span class="math inline">\(10 \times 10\)</span> pixels kunne repræsenteres ved en <span class="math inline">\(100\)</span> dimensional vektor. Vi kan så lave et kunstigt neuralt netværk med <span class="math inline">\(100\)</span> input neuroner, et antal skjulte lag og en outputneuron. Men gør vi det, så tillægger vi det ingen som helst betydning, at nogle af de <span class="math inline">\(100\)</span> pixels i billedet er tætte på hinanden, mens andre igen er langt væk fra hinanden. I stedet behandler vi alle pixels fuldstændig ens uden at tage højde for den indbyrdes placering, de enkelte pixels har i forhold til hinanden. Det giver ikke ret meget mening, når man behandler billeder. Det vil med andre ord sige, at vi faktisk smider værdifuld information ud med badevandet!</p>
<p>Det faktum tages der højde for i de såkaldte <em>convolutional neural networks</em>. Som illustration ser vi på et <span class="math inline">\(10 \times 10\)</span> pixels billede, hvis pixelværdier vi vil repræsentere på denne måde:</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: left;"><span class="math inline">\(x_{1,1}\)</span></th>
<th style="text-align: left;"><span class="math inline">\(x_{1,2}\)</span></th>
<th style="text-align: left;"><span class="math inline">\(x_{1,3}\)</span></th>
<th style="text-align: left;"><span class="math inline">\(x_{1,4}\)</span></th>
<th style="text-align: left;"><span class="math inline">\(x_{1,5}\)</span></th>
<th style="text-align: left;"><span class="math inline">\(x_{1,6}\)</span></th>
<th style="text-align: left;"><span class="math inline">\(x_{1,7}\)</span></th>
<th style="text-align: left;"><span class="math inline">\(x_{1,8}\)</span></th>
<th style="text-align: left;"><span class="math inline">\(x_{1,9}\)</span></th>
<th style="text-align: left;"><span class="math inline">\(x_{1,10}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(x_{2,1}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{2,2}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{2,3}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{2,4}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{2,5}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{2,6}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{2,7}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{2,8}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{2,9}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{2,10}\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(x_{3,1}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{3,2}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{3,3}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{3,4}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{3,5}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{3,6}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{3,7}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{3,8}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{3,9}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{3,10}\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(x_{4,1}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{4,2}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{4,3}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{4,4}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{4,5}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{4,6}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{4,7}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{4,8}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{4,9}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{4,10}\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(x_{5,1}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{5,2}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{5,3}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{5,4}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{5,5}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{5,6}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{5,7}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{5,8}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{5,9}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{5,10}\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(x_{6,1}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{6,2}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{6,3}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{6,4}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{6,5}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{6,6}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{6,7}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{6,8}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{6,9}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{6,10}\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(x_{7,1}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{7,2}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{7,3}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{7,4}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{7,5}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{7,6}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{7,7}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{7,8}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{7,9}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{7,10}\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(x_{8,1}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{8,2}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{8,3}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{8,4}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{8,5}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{8,6}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{8,7}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{8,8}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{8,9}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{8,10}\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(x_{9,1}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{9,2}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{9,3}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{9,4}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{9,5}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{9,6}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{9,7}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{9,8}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{9,9}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{9,10}\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(x_{10,1}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{10,2}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{10,3}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{10,4}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{10,5}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{10,6}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{10,7}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{10,8}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{10,9}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(x_{10,10}\)</span></td>
</tr>
</tbody>
</table>
<p>Det vil sige, at <span class="math inline">\(x_{5,8}\)</span> er pixelværdien i række <span class="math inline">\(5\)</span> og kolonne <span class="math inline">\(8\)</span> i billedet. Husk at når billedet er sort/hvidt, er denne værdi et heltal mellem <span class="math inline">\(0\)</span> og <span class="math inline">\(255\)</span>.</p>
<p>Vi forestiller os nu, at vi lader et vindue på <span class="math inline">\(3 \times 3\)</span> pixels kører henover billedet, som vist på <a href="#fig-sliding_window" class="quarto-xref">figur&nbsp;12</a>.</p>
<div id="fig-sliding_window" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-sliding_window-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/sliding_window1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-sliding_window-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figur&nbsp;12: Illustration af vindue på <span class="math inline">\(3 \times 3\)</span> pixels, som glider henover billedet.
</figcaption>
</figure>
</div>
<p>Hvis man tæller efter, vil der i alt kunne glide <span class="math inline">\(8\)</span> vinduer vandret og <span class="math inline">\(8\)</span> vinduer lodret. Det giver i alt <span class="math inline">\(64\)</span> vinduer. Pixelværdierne i hvert af disse vinduer sendes nu frem til en skjult neuron i et nyt lag i netværket. Dette er illustreret på <a href="#fig-local_receptive_fields" class="quarto-xref">figur&nbsp;13</a>.</p>
<div id="fig-local_receptive_fields" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-local_receptive_fields-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/local_receptive_fields.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-local_receptive_fields-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figur&nbsp;13: Local receptive fields for de skjulte neuroner.
</figcaption>
</figure>
</div>
<p>Bemærk, at neuronerne i det første skjulte lag er repræsenteret som et <span class="math inline">\(8 \times 8\)</span> pixels billede (i stedet for neuroner i en vertikal søjle som vi har gjort tidligere). Hvert af vinduerne til venstre i <a href="#fig-local_receptive_fields" class="quarto-xref">figur&nbsp;13</a> kalder man for et <em>local receptive field</em> for den tilhørende skjulte neuron til højre i figuren. For at beregne den værdi som den første skjulte neuron sender videre i netværket, gør vi som tidligere - men med den vigtige undtagelse, at vi kun vægter de <span class="math inline">\(9\)</span> værdi fra det tilhørende <em>local receptive field</em>. Hvis vi kalder den værdi, som den første skjulte neuron sender videre, for <span class="math inline">\(y_{1,1}\)</span>, så kommer det til se sådan her ud: <span class="math display">\[\begin{align}
y_{1,1}&amp;=\sigma(v_0 + v_1 \cdot x_{1,1} + v_2 \cdot x_{1,2} + v_3 \cdot x_{1,3} \\ &amp;\quad \quad \quad \quad + v_4 \cdot x_{2,1} + v_5 \cdot x_{2,2}+\cdots+ v_{9} \cdot x_{3,3}),
\end{align}\]</span> her er <span class="math inline">\(v_0\)</span> en bias, <span class="math inline">\(v_1, v_2, \dots, v_9\)</span> er vægte og <span class="math inline">\(\sigma\)</span> er igen sigmoid-funktionen.</p>
<p>Det vil altså sige, at hver neuron i det første skjulte lag <em>kun</em> afhænger af <span class="math inline">\(9\)</span> af de i alt <span class="math inline">\(100\)</span> input-neuroner. På den måde får vi konstrueret et netværk, hvor vi eksplicit indbygger i netværket, at pixels som ligger tæt på hinanden, skal have noget med hinanden at gøre. Og omvendt hvis to pixels ligger langt væk fra hinanden, skal de ikke have noget med hinanden at gøre (fordi de ikke kommer til at indgå i den samme vægtede sum).</p>
<p>En anden ting, der er ny, er, at vi for alle <span class="math inline">\(64\)</span> vinduer bruger de <em>samme</em> <span class="math inline">\(10\)</span> vægte: <span class="math inline">\(v_0, v_1, \dots, v_9\)</span>. Det vil sige, at når vi f.eks. skal udregne den sidste værdi, så bliver det <span class="math display">\[\begin{align}
y_{8,8}&amp; =\sigma(v_0 + v_1 \cdot x_{8,8} + v_2 \cdot x_{8,9} + v_3 \cdot x_{8,10}
\\ &amp; \quad \quad \quad \quad + v_4 \cdot x_{9,8} + v_5 \cdot x_{9,9}+\cdots+ v_9 \cdot x_{10,10})
\end{align}\]</span> Resultatet bliver <span class="math inline">\(8 \times 8\)</span> skjulte neuroner, som er vist til højre på billedet i <a href="#fig-local_receptive_fields" class="quarto-xref">figur&nbsp;13</a>. Dette lag i netværket kalder man for et <em>convolutional layer</em>. De i alt <span class="math inline">\(10\)</span> vægte kaldes for et <em>feature map</em>, og idéen er, at de bruges til at finde en bestemt egenskab (feature) i billedet. Lad os se på et eksempel. Nedenfor er illustreret et <span class="math inline">\(10 \times 10\)</span> pixels billede med en vertikal mørk linje i midten. Værdierne i hver celle er egentlig ikke en del af billedet, men blot den tilhørende gråskalaværdi.</p>
<div class="cell">
<div class="cell-output-display">
<table class="huxtable" data-quarto-disable-processing="true" style="border-collapse: collapse; border: 0px; margin-bottom: 2em; margin-top: 2em; ; margin-left: auto; margin-right: auto;  ">
<colgroup><col><col><col><col><col><col><col><col><col><col></colgroup><tbody><tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">150</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">100</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">100</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">150</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td></tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">150</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">100</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">100</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">150</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td></tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">150</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">100</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">100</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">150</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td></tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">150</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">100</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">100</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">150</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td></tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">150</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">100</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">100</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">150</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td></tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">150</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">100</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">100</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">150</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td></tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">150</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">100</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">100</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">150</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td></tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">150</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">100</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">100</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">150</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td></tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">150</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">100</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">100</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">150</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td></tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">150</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">100</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">100</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">150</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">240</td></tr>
</tbody></table>

</div>
</div>
<p>Den vertikale linje opstår, fordi der på hver række er store forskelle i gråskalaværdierne (fra høje værdier til lavere værdier og igen tilbage til høje værdier). Omvendt er der ingen horisontale linjer, fordi gråskalaværdierne i hver kolonne ikke ændrer sig. Som input til et convolutional neural netværk vil man som regel standardisere inputværdierne, så de alle ligger mellem <span class="math inline">\(0\)</span> og <span class="math inline">\(1\)</span>. Det gør man, fordi det viser sig, at backpropagation algoritmen konvergerer hurtigere. Vi standardiserer blot ved at dividere ovenstående værdier med <span class="math inline">\(255\)</span> og får</p>
<div class="cell">
<div class="cell-output-display">
<table class="huxtable" data-quarto-disable-processing="true" style="border-collapse: collapse; border: 0px; margin-bottom: 2em; margin-top: 2em; ; margin-left: auto; margin-right: auto;  ">
<colgroup><col><col><col><col><col><col><col><col><col><col></colgroup><tbody><tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">0.59</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">0.39</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">0.39</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">0.59</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td></tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">0.59</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">0.39</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">0.39</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">0.59</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td></tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">0.59</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">0.39</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">0.39</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">0.59</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td></tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">0.59</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">0.39</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">0.39</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">0.59</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td></tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">0.59</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">0.39</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">0.39</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">0.59</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td></tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">0.59</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">0.39</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">0.39</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">0.59</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td></tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">0.59</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">0.39</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">0.39</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">0.59</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td></tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">0.59</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">0.39</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">0.39</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">0.59</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td></tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">0.59</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">0.39</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">0.39</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">0.59</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td></tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">0.59</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">0.39</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(99, 99, 99); font-weight: normal;">0.39</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(150, 150, 150); font-weight: normal;">0.59</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(240, 240, 240); font-weight: normal;">0.94</td></tr>
</tbody></table>

</div>
</div>
<p>Et feature map, som kan bruges til at finde henholdsvis lodrette og vandrette linjer i et billede er vist i <a href="#fig-feature1_maps" class="quarto-xref">figur&nbsp;14</a> og <a href="#fig-feature2_maps" class="quarto-xref">figur&nbsp;15</a>.</p>
<div class="cell page-columns page-full">
<div id="fig-feature1_maps" class="cell-output-display quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-feature1_maps-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="huxtable" data-quarto-disable-processing="true" style="border-collapse: collapse; border: 0px; margin-bottom: 2em; margin-top: 2em; ; margin-left: auto; margin-right: auto;  " id="tab:fig-feature1_maps">
<colgroup><col><col><col></colgroup><tbody><tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">1</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">1</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">1</td></tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">0</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">0</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">0</td></tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">-1</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">-1</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">-1</td></tr>
</tbody></table>

</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-feature1_maps-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figur&nbsp;14: Et feature map <span class="math inline">\(f_1\)</span>, som kan finde vandrette linjer i billeder.
</figcaption>
</figure>
</div>
</div>
<div class="cell page-columns page-full">
<div id="fig-feature2_maps" class="cell-output-display quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-feature2_maps-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="huxtable" data-quarto-disable-processing="true" style="border-collapse: collapse; border: 0px; margin-bottom: 2em; margin-top: 2em; ; margin-left: auto; margin-right: auto;  " id="tab:fig-feature2_maps">
<colgroup><col><col><col></colgroup><tbody><tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">1</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">0</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">-1</td></tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">1</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">0</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">-1</td></tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">1</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">0</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; font-weight: normal;">-1</td></tr>
</tbody></table>

</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-feature2_maps-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figur&nbsp;15: Et feature map <span class="math inline">\(f_2\)</span>, som kan finde lodrette linjer i billeder.
</figcaption>
</figure>
</div>
</div>
<p>Det ses hurtigt, at hvis vi anvender feature map <span class="math inline">\(f_1\)</span> til at vægte værdierne i et vilkårligt <span class="math inline">\(9 \times 9\)</span> vindue i det originale billede, så får man <span class="math inline">\(0\)</span> (såfremt vi sætter biasværdien <span class="math inline">\(v_0=0\)</span>). Anvender vi f.eks. <span class="math inline">\(f_1\)</span> på det tredje vindue fås <span class="math display">\[\begin{align}
&amp;0+ 1 \cdot 0.94 + 1 \cdot 0.59  + 1 \cdot 0.39 + 0 \cdot 0.94 \\
&amp; \quad \quad \quad \quad + 0 \cdot 0.59 + 0 \cdot 0.39 -1 \cdot 0.94 - 1 \cdot 0.59 - 1 \cdot 0.39 =0
\end{align}\]</span> Da <span class="math inline">\(\sigma(0)=0.5\)</span> ender vi altså med et skjult lag, hvor alle <span class="math inline">\(64\)</span> skjulte neuroner sender <span class="math inline">\(0.5\)</span> frem i netværket. Det svarer til, at dette feature map ikke har fundet nogle vandrette linjer i billedet.</p>
<p>Bruger vi nu derimod <span class="math inline">\(f_2\)</span> på det samme vindue, så får vi <span class="math display">\[\begin{align*}
&amp;0+ 1 \cdot 0.94 + 0 \cdot 0.59  - 1 \cdot 0.39 + 1 \cdot 0.94
\\ &amp; \quad \quad \quad \quad + 0 \cdot 0.59 -1 \cdot 0.39 +1 \cdot 0.94 +0 \cdot 0.59 - 1 \cdot 0.39 = 1.65
\end{align*}\]</span> Anvendes sigmoid-funktionen fås <span class="math inline">\(\sigma(1.65)=0.84\)</span>. Sådan fortsættes for alle <span class="math inline">\(64\)</span> vinduer (local receptive fields), og man ender med nedenstående convolutional lag, hvor værdierne også er vist med de tilhørende farver (i den allermørkeste søjle står der <span class="math inline">\(0.16\)</span> - det er bare lidt svært at se!):</p>
<div class="cell">
<div class="cell-output-display">
<table class="huxtable" data-quarto-disable-processing="true" style="border-collapse: collapse; border: 0px; margin-bottom: 2em; margin-top: 2em; ; margin-left: auto; margin-right: auto;  ">
<colgroup><col><col><col><col><col><col><col><col></colgroup><tbody><tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(128, 128, 128); font-weight: normal;">0.5</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(189, 189, 189); font-weight: normal;">0.74</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(214, 214, 214); font-weight: normal;">0.84</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(166, 166, 166); font-weight: normal;">0.65</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(89, 89, 89); font-weight: normal;">0.35</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(41, 41, 41); font-weight: normal;">0.16</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(66, 66, 66); font-weight: normal;">0.26</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(128, 128, 128); font-weight: normal;">0.5</td></tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(128, 128, 128); font-weight: normal;">0.5</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(189, 189, 189); font-weight: normal;">0.74</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(214, 214, 214); font-weight: normal;">0.84</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(166, 166, 166); font-weight: normal;">0.65</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(89, 89, 89); font-weight: normal;">0.35</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(41, 41, 41); font-weight: normal;">0.16</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(66, 66, 66); font-weight: normal;">0.26</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(128, 128, 128); font-weight: normal;">0.5</td></tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(128, 128, 128); font-weight: normal;">0.5</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(189, 189, 189); font-weight: normal;">0.74</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(214, 214, 214); font-weight: normal;">0.84</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(166, 166, 166); font-weight: normal;">0.65</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(89, 89, 89); font-weight: normal;">0.35</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(41, 41, 41); font-weight: normal;">0.16</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(66, 66, 66); font-weight: normal;">0.26</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(128, 128, 128); font-weight: normal;">0.5</td></tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(128, 128, 128); font-weight: normal;">0.5</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(189, 189, 189); font-weight: normal;">0.74</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(214, 214, 214); font-weight: normal;">0.84</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(166, 166, 166); font-weight: normal;">0.65</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(89, 89, 89); font-weight: normal;">0.35</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(41, 41, 41); font-weight: normal;">0.16</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(66, 66, 66); font-weight: normal;">0.26</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(128, 128, 128); font-weight: normal;">0.5</td></tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(128, 128, 128); font-weight: normal;">0.5</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(189, 189, 189); font-weight: normal;">0.74</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(214, 214, 214); font-weight: normal;">0.84</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(166, 166, 166); font-weight: normal;">0.65</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(89, 89, 89); font-weight: normal;">0.35</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(41, 41, 41); font-weight: normal;">0.16</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(66, 66, 66); font-weight: normal;">0.26</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(128, 128, 128); font-weight: normal;">0.5</td></tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(128, 128, 128); font-weight: normal;">0.5</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(189, 189, 189); font-weight: normal;">0.74</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(214, 214, 214); font-weight: normal;">0.84</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(166, 166, 166); font-weight: normal;">0.65</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(89, 89, 89); font-weight: normal;">0.35</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(41, 41, 41); font-weight: normal;">0.16</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(66, 66, 66); font-weight: normal;">0.26</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(128, 128, 128); font-weight: normal;">0.5</td></tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(128, 128, 128); font-weight: normal;">0.5</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(189, 189, 189); font-weight: normal;">0.74</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(214, 214, 214); font-weight: normal;">0.84</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(166, 166, 166); font-weight: normal;">0.65</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(89, 89, 89); font-weight: normal;">0.35</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(41, 41, 41); font-weight: normal;">0.16</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(66, 66, 66); font-weight: normal;">0.26</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(128, 128, 128); font-weight: normal;">0.5</td></tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(128, 128, 128); font-weight: normal;">0.5</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(189, 189, 189); font-weight: normal;">0.74</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(214, 214, 214); font-weight: normal;">0.84</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(166, 166, 166); font-weight: normal;">0.65</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(89, 89, 89); font-weight: normal;">0.35</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(41, 41, 41); font-weight: normal;">0.16</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(66, 66, 66); font-weight: normal;">0.26</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(128, 128, 128); font-weight: normal;">0.5</td></tr>
</tbody></table>

</div>
</div>
<p>Den lodrette linje i det oprindelige billede kommer her til udtryk som henholdsvis en lysegrå og en mørkegrå lodret stribe. Den lysegrå stribe viser, at der på det oprindelige billeder har været en overgang fra lys til mørk og omvendt viser den mørkegrå stribe, at der på det oprindelige billede har været en overgang fra mørk til lys.</p>
<p>Herefter kondenseres billedet yderligere i det man kalder for et <em>pooling layer</em>. Det gør man ved at inddele ovenstående billede i f.eks. <span class="math inline">\(2 \times 2\)</span> pixels vinduer, som <em>ikke</em> overlapper hinanden. Herefter kan man gøre forskellige ting - en simpel mulighed er at tage maksimumsværdien af de <span class="math inline">\(4\)</span> pixels i hvert billede. Dette kaldes for <em>max pooling</em>. Gør man det får man følgende <span class="math inline">\(4 \times 4\)</span> pixels billede (igen vist med de tilhørende farver):</p>
<div class="cell">
<div class="cell-output-display">
<table class="huxtable" data-quarto-disable-processing="true" style="border-collapse: collapse; border: 0px; margin-bottom: 2em; margin-top: 2em; ; margin-left: auto; margin-right: auto;  ">
<colgroup><col><col><col><col></colgroup><tbody><tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(189, 189, 189); font-weight: normal;">0.74</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(214, 214, 214); font-weight: normal;">0.84</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(89, 89, 89); font-weight: normal;">0.35</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(128, 128, 128); font-weight: normal;">0.5</td></tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(189, 189, 189); font-weight: normal;">0.74</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(214, 214, 214); font-weight: normal;">0.84</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(89, 89, 89); font-weight: normal;">0.35</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(128, 128, 128); font-weight: normal;">0.5</td></tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(189, 189, 189); font-weight: normal;">0.74</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(214, 214, 214); font-weight: normal;">0.84</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(89, 89, 89); font-weight: normal;">0.35</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(128, 128, 128); font-weight: normal;">0.5</td></tr>
<tr>
<td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(189, 189, 189); font-weight: normal;">0.74</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(214, 214, 214); font-weight: normal;">0.84</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(89, 89, 89); font-weight: normal;">0.35</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0.4pt 0.4pt 0.4pt;    padding: 6pt 6pt 6pt 6pt; background-color: rgb(128, 128, 128); font-weight: normal;">0.5</td></tr>
</tbody></table>

</div>
</div>
<p>Læg mærke til hvordan man på dette kondenserede billede tydeligt kan se den lodrette stribe, som var i det oprindelige billede.</p>
<p>Så dette er den overordnede idé, men der er flere ting at bemærke. For det første bruges et feature map til at finde egenskaber på et billede som vist ovenfor, men man vil typisk ikke kun lede efter én egenskab men flere. Det vil sige, at der ikke kun er ét convolutional lag, men måske <span class="math inline">\(5\)</span> eller <span class="math inline">\(20\)</span> lag. For hvert af disse lag fås et tilhørende pooling lag. Dette er illustreret på <a href="#fig-CNN" class="quarto-xref">figur&nbsp;16</a>.</p>
<div id="fig-CNN" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-CNN-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/CNN.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-CNN-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figur&nbsp;16: Convolutional neural network.
</figcaption>
</figure>
</div>
<p><em>Alle</em> neuroner i pooling lagene forbindes nu til outputneuronen. Igen udregnes sigmoid-funktionen taget på en vægtet sum af alle neuronerne fra pooling lagene. Der er også mulighed for at indlægge flere convolutional og pooling lag i netværket. Ligesom der også kan indlægges flere "almindelige" neuroner (som vi tidligere har set det) efter pooling lagene.</p>
<p>For det andet vil man ikke anvende feature maps som på forhånd er defineret (som vi gjorde det i eksemplet ovenfor). For hvert convolutional layer trænes i stedet for de fælles vægte, som skal benyttes i det pågældende feature map. Selve træningen af netværket foregår igen ved hjælp af backpropagation, men nu justeret til de begrænsninger der er lagt ind i netværket.</p>
<p>For det tredje bliver antallet af vægte, som skal fittes, drastiske reduceret i et convolutional neuralt netværk sammenlignet med et almindelig neuralt netværk. Lad os som eksempel se på klassifikation af et <span class="math inline">\(10 \times 10\)</span> pixels billede. Antag, at vi anvender et local receptive field (vindue) på <span class="math inline">\(3 \times 3\)</span> pixels. Det vil sige, at hvert convolutional lag vil bestå af <span class="math inline">\(8 \times 8\)</span> neuroner. Da vægtene er delte, vil vi for hvert convolutional lag få bruge for <span class="math inline">\(3 \cdot 3 + 1=10\)</span> vægte. Antag, at vi har <span class="math inline">\(5\)</span> convolutional lag (bestående af <span class="math inline">\(5 \cdot 8 \cdot 8=320\)</span> neuroner), så får vi i alt brug for <span class="math inline">\(5 \cdot 10=50\)</span> vægte. For at komme til pooling laget anvendes ingen vægte. Men pooling laget vil bestå af <span class="math inline">\(5\)</span> pooling lag med i alt <span class="math inline">\(4 \times 4\)</span> neuroner. Det giver <span class="math inline">\(80\)</span> neuroner i alt. Forbindes disse til én outputneuron skal vi bruge <span class="math inline">\(81\)</span> vægte (én for hver neuron plus en bias). Alt i alt ender vi med <span class="math inline">\(131\)</span> vægte.</p>
<p>Havde vi i stedet lavet et fuldt forbundet kunstigt neuralt netværk med <span class="math inline">\(100\)</span> input neuroner, ét skjult lag med <span class="math inline">\(64\)</span> neuroner samt én outputneuron, så skulle vi først have bruge <span class="math inline">\(101 \cdot
64=6464\)</span> vægte for at forbinde input neuronerne med samtlige neuroner i det første skjulte lag. Herefter har vi brug for <span class="math inline">\(65\)</span> vægte for at forbinde det skjulte lag med outputneuronen. Alt i alt giver det <span class="math inline">\(6529\)</span> vægte! Der er altså en voldsom forskel i antallet af vægte, som skal læres. For at undgå overfitting må vi have mange flere træningsdata, end vi har vægte. Det betyder, at vi typisk vil kunne nøjes med færre træningseksempler i et convolutional neural netværk sammenlignet med et klassisk fuldt forbundet kunstigt neuralt netværk. Ydermere viser det sig, at convolutional neurale netværk kan trænes til at klassificere billeder langt bedre end et almindeligt kunstigt neuralt netværk. Netop fordi at de forskellige pixels placeringer i forhold til hinanden tages i betragtning, når et convolutional neuralt netværk konstrueres.</p>
</section>
<section id="videre-læsning" class="level1">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">Videre læsning</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-baktoft" class="csl-entry" role="listitem">
Baktoft, Allan. 2014. <em>Matematik i Virkeligheden. Bind 2</em>. Forlaget Natskyggen.
</div>
<div id="ref-bishop" class="csl-entry" role="listitem">
Bishop, Christopher M. 2006. <em>Pattern Recognition and Machine Learning</em>. Springer.
</div>
<div id="ref-james" class="csl-entry" role="listitem">
James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2021. <em>An Introduction to Statistical Learning with Applications in r. Second Edition</em>. Springer.
</div>
<div id="ref-mitchell" class="csl-entry" role="listitem">
Mitchell, Tom M. 1997. <em>Machine Learning</em>. The McGraw-Hill Companies, Inc.
</div>
<div id="ref-nielsen" class="csl-entry" role="listitem">
Nielsen, Michael A. 2015. <em>Neural Networks and Deep Learning</em>. Determination Press. <a href="http://neuralnetworksanddeeplearning.com/index.html">http://neuralnetworksanddeeplearning.com/index.html</a>.
</div>
<div id="ref-videnskabsteori" class="csl-entry" role="listitem">
Sørensen, Henrik Kragh, and Mikkel Willum Johansen. 2020. <em>"Invitation Til de Datalogiske Fags Videnskabsteori". Lærebog Til Brug for Undervisning Ved Institut for Naturfagenes Didaktik, Københavns Universitet</em>. Under udarbejdelse.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/aimat\.dk");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>