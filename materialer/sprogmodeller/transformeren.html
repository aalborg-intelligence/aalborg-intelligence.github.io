<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="De kraftige sprogmodeller, der indgår i de nyeste former for sproglig kunstig intelligens, benytter ikke helt den tilgang, vi hidtil har beskrevet, hvor man først laver Word2Vec og derefter træner et neuralt netværk til at prædiktere ord. I stedet bruges en videreudvikling, kaldet <em>transformeren</em>, der kombinerer de to trin i én algoritme. I denne note vil vi prøve at give en intuition for, hvad transformeren gør.">

<title>Transformeren – AI MAT - matematikken bag magien</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../logo/SVG/Bomaerke_05_AIMAT_2024.svg" rel="icon" type="image/svg+xml">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-ece03592d64235babf60c362785df9bd.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-Y219BCPS45"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
 
  gtag('consent', 'default', {
    'ad_storage': 'denied',
    'analytics_storage': 'denied'
  });
gtag('config', 'G-Y219BCPS45', { 'anonymize_ip': true});
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="floating nav-fixed slimcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../logo/PNG/Logo_multi_AIMAT_RGB_2024.png" alt="" class="navbar-logo light-content">
    <img src="../../logo/PNG/Logo_multi_AIMAT_RGB_2024.png" alt="" class="navbar-logo dark-content">
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../undervisningsforlob/index.html"> 
<span class="menu-text">Undervisningsforløb</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../materialer/index.html"> 
<span class="menu-text">Materialer</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../srp/index.html"> 
<span class="menu-text">SRP</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../apps/index.html"> 
<span class="menu-text">Apps</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">Om os</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://www.youtube.com/@ai-mat"> 
<span class="menu-text"><img src="../../logo/YouTube/youtube-color-darkblue-icon.svg" style="height:2em"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Indhold</h2>
   
  <ul>
  <li><a href="#opmærksomhed" id="toc-opmærksomhed" class="nav-link active" data-scroll-target="#opmærksomhed">Opmærksomhed</a></li>
  <li><a href="#vektorregning" id="toc-vektorregning" class="nav-link" data-scroll-target="#vektorregning">Vektorregning</a></li>
  <li><a href="#et-opmærksomhedslag" id="toc-et-opmærksomhedslag" class="nav-link" data-scroll-target="#et-opmærksomhedslag">Et opmærksomhedslag</a></li>
  <li><a href="#en-transformerblok" id="toc-en-transformerblok" class="nav-link" data-scroll-target="#en-transformerblok">En transformerblok</a></li>
  <li><a href="#transformernetværket" id="toc-transformernetværket" class="nav-link" data-scroll-target="#transformernetværket">Transformernetværket</a></li>
  <li><a href="#træning-af-netværket" id="toc-træning-af-netværket" class="nav-link" data-scroll-target="#træning-af-netværket">Træning af netværket</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Transformeren</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>De kraftige sprogmodeller, der indgår i de nyeste former for sproglig kunstig intelligens, benytter ikke helt den tilgang, vi hidtil har beskrevet, hvor man først laver Word2Vec og derefter træner et neuralt netværk til at prædiktere ord. I stedet bruges en videreudvikling, kaldet <em>transformeren</em>, der kombinerer de to trin i én algoritme. I Chat-GPT står GPT for eksempel for "Generative Pre-trained Transformer". Nedenfor beskriver vi nogle af de centrale dele af transformeren<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. Bemærk, at selv om vi prøver at give en intuition for, hvad transformeren gør, så er der ingen, der helt forstår i detaljer, hvorfor den virker.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;Den version af transformeneren, der beskrives her er en <em>decoder-only transformer</em>, som er den, der indgår i GPT teknologien.</p></div></div><section id="opmærksomhed" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="opmærksomhed">Opmærksomhed</h2>
<p>Vi er ude på at lave en algoritme, der genererer ny tekst ét ord ad gangen. Hvis vi for eksempel har genereret teksten</p>
<p><span class="math display">\[
\text{"Min hund er sulten, så jeg fodrer den med ---"}
\]</span></p>
<p>så skal vi lave en algoritme, der gætter næste ord. Både <span class="math inline">\(N\)</span>-gram modeller og neurale netværk tager de seneste <span class="math inline">\(N-1\)</span> ord i betragtning for at gætte det næste. Hvis <span class="math inline">\(N=4\)</span> skal vi altså gætte næste ord efter "fodrer den med". Det skal nok være en form for dyremad, men der kunne stå mange forskellige ting, for eksempel "hø" eller "fuglefrø". I dette tilfælde er vi nødt til at gå helt tilbage til ordet "hund" for at vide, hvilket dyr der er tale om og dermed hvilken slags mad, den skal have. Det smarte ved transformeren er, at den tager alle de hidtidige ord i betragtning. Dog lægger den mest vægt på de nærmeste ord.</p>
<p>Husk på, at da vi lavede Word2Vec, lod vi vektoren <span class="math inline">\(\vec{v}_{\text{ord}}\)</span> repræsentere betydningen af ordet. For at gætte næste ord i en sætning blev vektorerne for de <span class="math inline">\(N-1\)</span> foregående ord brugt som input til et neuralt netværk. Hver vektor <span class="math inline">\(\vec{v}_{\text{ord}}\)</span> blev brugt som en fast vektor uanset hvilke ord, der stod i nærheden af det. Men betydningen af et ord kan ændre sig alt efter konteksten. Se for eksempel på <span class="math display">\[\text{"Orkesteret skal spille ---"}\]</span> Kigger vi udelukkende på ordet "spille", kan der stå mange ting bagefter, for eksempel "ludo", "tennis" eller "koncert". Men når vi ser, at ordet "orkesteret" optræder inden, så ved vi, at der nok er tale om en slags musik. Det kunne derfor give mening at lade ordet "spille" repræsentere ved forskellige vektorer, alt efter om det indgår i en musikkontekst, en sportskontekst eller en brætspilskontekst. Det er netop idéen i transformeren: Vi vil lade vektorrepræsentationen af et ord afhænge af konteksten. Vi er altså <em>opmærksomme på</em> konteksten når vi laver vektorrepræsentationen. Derfor siges transformeren at have <em>opmærksomhed på sig selv</em><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>.</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;På engelsk siges transformeren at have <em>self-attention</em>.</p></div></div><p>Når transformeren skal bruges til at generere tekst, beregner den både nye vektorrepræsentationer og bruger dem til at gætte næste ord. Da vi kun har adgang til de forudgående ord, når vi genererer tekst, er det vigtigt, at vektorrepræsentationerne også kun dannes ud fra den forudgående tekst. Dette er anderledes end Word2Vec, hvor vektorrepræsentationerne blev beregnet én gang for alle på baggrund af træningsdata, hvor vi havde kendskab både til ordene før og efter fokusordet.</p>
</section>
<section id="vektorregning" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="vektorregning">Vektorregning</h2>
<p>Som udgangspunkt lader vi ordet "spille" være repræsenteret af en fast vektor <span class="math inline">\(\vec{v}_{\text{spille}}\)</span>. Vi modificerer derefter vores vektorrepræsentation <span class="math inline">\(\vec{v}_{\text{spille}}\)</span> til en ny vektor <span class="math inline">\(\vec{w}_{\text{spille}}\)</span> afhængigt af hvilke ord, der kommer før. Hvis ordet "orkesteret" kommer inden, så kan man forestille sig, at det trækker <span class="math inline">\(\vec{v}_{\text{spille}}\)</span> i en musikretning, mens hvis ordet havde været "landsholdet", så ville det trække <span class="math inline">\(\vec{v}_{\text{spille}}\)</span> i en sportsretning.</p>
<p>Vi vil modificere <span class="math inline">\(\vec{v}_{\text{spille}}\)</span> ved hjælp af vektoraddition og skalarmultiplikation. Husk på, at man lægger to 2-dimensionale vektorer sammen koordinatvis:</p>
<p><span class="math display">\[
\begin{pmatrix}a_1\\
a_2\end{pmatrix} + \begin{pmatrix}b_1\\
b_2\end{pmatrix} = \begin{pmatrix}a_1+b_1\\
a_2+b_2\end{pmatrix}
\]</span></p>
<p>Geometrisk lægger man vektorerne <span class="math inline">\(\vec{a}\)</span> og <span class="math inline">\(\vec{b}\)</span> sammen ved først at tegne <span class="math inline">\(\vec{a}\)</span> og derefter tegne <span class="math inline">\(\vec{b}\)</span> med udgangspunkt, der hvor <span class="math inline">\(\vec{a}\)</span> slutter. Vektoren <span class="math inline">\(\vec{a} + \vec{b}\)</span> er så den vektor, der starter samme sted som <span class="math inline">\(\vec{a}\)</span> og slutter, der hvor <span class="math inline">\(\vec{b}\)</span> slutter.</p>
<div class="cell page-columns page-full">
<div class="cell-output-display page-columns page-full">
<div id="fig-vektor_add" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-vektor_add-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="transformeren_files/figure-html/fig-vektor_add-1.png" class="img-fluid figure-img" style="width:25.0%">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-vektor_add-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figur&nbsp;1: Illustration af vektoraddition.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Dette kan vi nu benytte til at opdatere vektoren for "spille", når vi ved, at "orkesteret" står inden. Hvis vi har vektorerne <span class="math inline">\(\vec{v}_{\text{spille}}\)</span> og <span class="math inline">\(\vec{v}_{\text{orkesteret}}\)</span>, så kunne vi opdatere <span class="math inline">\(\vec{v}_{\text{spille}}\)</span> til</p>
<p><span class="math display">\[
\vec{w}_{\text{spille}} = \vec{v}_{\text{orkesteret}}+\vec{v}_{\text{spille}}
\]</span></p>
<p>Det er illustreret på <a href="#fig-spille" class="quarto-xref">figur&nbsp;2</a>. Det ses, at retningen på <span class="math inline">\(\vec{w}_{\text{spille}}\)</span> er blevet trukket over mod <span class="math inline">\(\vec{v}_{\text{orkesteret}}\)</span> og væk fra <span class="math inline">\(\vec{v}_{\text{landsholdet}}\)</span>.</p>
<div class="cell page-columns page-full">
<div class="cell-output-display page-columns page-full">
<div id="fig-spille" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-spille-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="transformeren_files/figure-html/fig-spille-1.png" class="img-fluid figure-img" style="width:40.0%">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-spille-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figur&nbsp;2: Illustration som viser, at <span class="math inline">\(\vec{w}_{\text{spille}} = \vec{v}_{\text{orkesteret}}+\vec{v}_{\text{spille}}\)</span>.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Der er dog et andet problem: Den nye vektor <span class="math inline">\(\vec{w}_{\text{spille}}\)</span> er meget lang i forhold til de oprindelige. Det løser vi ved at skalere de to vektorer ned, inden vi lægger dem sammen. Man kan skalere en vektor med et tal <span class="math inline">\(c\in \mathbb{R}\)</span> ved at gange hver koordinat med <span class="math inline">\(c\)</span>:</p>
<p><span class="math display">\[
c\begin{pmatrix}
    a_1\\a_2
\end{pmatrix} = \begin{pmatrix}
    ca_1\\ca_2
\end{pmatrix}
\]</span></p>
<p>Hvis <span class="math inline">\(c&gt;0\)</span>, er <span class="math inline">\(c\vec{a}\)</span> en vektor, der peger i samme retning som <span class="math inline">\(\vec{a}\)</span>, men er <span class="math inline">\(c\)</span> gange så lang. Hvis <span class="math inline">\(c&lt;0\)</span>, er vektoren <span class="math inline">\(|c|\)</span> gange så lang som <span class="math inline">\(\vec{a}\)</span>, men peger i modsat retning.</p>
<div class="cell page-columns page-full">
<div class="cell-output-display page-columns page-full">
<div id="fig-skalar" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-skalar-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="transformeren_files/figure-html/fig-skalar-1.png" class="img-fluid figure-img" style="width:40.0%">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-skalar-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figur&nbsp;3: Illustration af <span class="math inline">\(\vec v\)</span> ganget med henholdsvis <span class="math inline">\(2\)</span> og <span class="math inline">\(-2\)</span>.
</figcaption>
</figure>
</div>
</div>
</div>
<p>I vores eksempel kunne man skalere begge vektorer med en faktor <span class="math inline">\(\frac{1}{2}\)</span>, inden man lægger dem sammen, således at</p>
<p><span class="math display">\[
\vec{w}_{\text{spille}} = \frac{1}{2}\cdot \vec{v}_{\text{orkesteret}}+\frac{1}{2}\cdot \vec{v}_{\text{spille}}
\]</span></p>
<p>Dette er skitseret i <a href="#fig-spille2" class="quarto-xref">figur&nbsp;4</a>.</p>
<div class="cell page-columns page-full">
<div class="cell-output-display page-columns page-full">
<div id="fig-spille2" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-spille2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="transformeren_files/figure-html/fig-spille2-1.png" class="img-fluid figure-img" style="width:50.0%">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-spille2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figur&nbsp;4: Illustration af <span class="math inline">\(\vec{w}_{\text{spille}} = \frac{1}{2}\cdot \vec{v}_{\text{orkesteret}}+\frac{1}{2}\cdot \vec{v}_{\text{spille}}\)</span>.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Den nye vektor <span class="math inline">\(\vec{w}_{\text{spille}}\)</span> er mere sammenlignelig med den oprindelige <span class="math inline">\(\vec{v}_{\text{spille}}\)</span> i <a href="#fig-spille" class="quarto-xref">figur&nbsp;2</a>. Vi kunne have gjort noget tilsvarende hvis der havde stået</p>
<p><span class="math display">\[
\text{Landsholdet skal spille ---}
\]</span></p>
<p>Så ville <span class="math inline">\(\vec{w}_{\text{spille}}\)</span> blive trukket i retning af <span class="math inline">\(\vec{v}_{\text{landsholdet}}\)</span> i stedet. Men hvad nu, hvis der havde stået</p>
<p><span class="math display">\[
\text{Manden skal spille ---}
\]</span></p>
<p>Her bliver vi ikke rigtig klogere på, om der er tale om sport eller musik. Vi får altså ikke megen ny viden om betydningen af "spille". Her ville det derfor give mere mening at vælge</p>
<p><span class="math display">\[
\vec{w}_{\text{spille}} = \vec{v}_{\text{spille}} = 0\cdot \vec{v}_{\text{manden}}+1\cdot \vec{v}_{\text{spille}}
\]</span></p>
<p>Helt generelt, hvis der i stedet for "orkesteret" havde stået et ord med vektorrepræsentation <span class="math inline">\(\vec{v}_{\text{ord}}\)</span> ville vi sætte</p>
<p><span class="math display">\[
\vec{w}_{\text{spille}} = c_1 \cdot \vec{v}_{\text{ord}}+c_2 \cdot \vec{v}_{\text{spille}}
\]</span></p>
<p>hvor <span class="math inline">\(c_1\)</span> og <span class="math inline">\(c_2\)</span> er ikke-negative konstanter med <span class="math inline">\(c_1+c_2=1\)</span>. Hvis kontekstordet er meget relevant for at forstå betydningen af "spille", vælges <span class="math inline">\(c_1\)</span> stor, mens <span class="math inline">\(c_1\)</span> vælges tæt på 0, hvis kontekstordet ikke giver megen ny information om betydningen. Hvordan vi mere præcist vælger <span class="math inline">\(c_1\)</span> og <span class="math inline">\(c_2\)</span>, vender vi tilbage til i næste afsnit, hvor vi også skal se på, hvordan man kan inddrage information fra mere end et af de foregående ord.</p>
<p>Inden vi afslutter dette afsnit, minder vi om, at det normalt er for lidt at repræsentere ord ved 2-dimensionale vektorer. I stedet repræsenterer vi dem ved <span class="math inline">\(m\)</span>-dimensionale vektorer. Man kan lægge <span class="math inline">\(m\)</span>-dimensionale vektorer sammen og skalere dem med en konstant ligesom i to dimensioner:</p>
<p><span class="math display">\[
\begin{pmatrix}a_1\\ a_2 \\ \vdots\\a_m\end{pmatrix} + \begin{pmatrix}b_1\\ b_2\\ \vdots\\b_m\end{pmatrix} =  \begin{pmatrix}a_1+b_1\\ a_2+b_2\\ \vdots\\a_m+b_m\end{pmatrix}
\]</span></p>
<p>og</p>
<p><span class="math display">\[
c\begin{pmatrix}
    a_1\\a_2\\ \vdots\\a_m
\end{pmatrix} = \begin{pmatrix}
    ca_1\\ca_2\\ \vdots\\ca_m
\end{pmatrix}
\]</span></p>
<p>I tre dimensioner kan vektoraddition visualiseres på samme måde som i det 2-dimensionale tilfælde, men i højere dimensioner er det ikke muligt at visualisere hvad der foregår.</p>
</section>
<section id="et-opmærksomhedslag" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="et-opmærksomhedslag">Et opmærksomhedslag</h2>
<p>Lad os sige, at vi har et stykke tekst, og at det <span class="math inline">\(i\)</span>te ord i teksten er vores fokusord, som vi gerne vil finde en vektorrepræsentation for. Som udgangspunkt er betydningen af det <span class="math inline">\(i\)</span>te ord repræsenteret af vektoren <span class="math inline">\(\vec{v}_i\)</span>. Transformeren opdaterer vektoren <span class="math inline">\(\vec{v}_{i}\)</span> til <span class="math inline">\(\vec{w}_{i}\)</span> på baggrund af alle de ord, der går forud. Man kan forstille sig, at vi trækker vektoren <span class="math inline">\(\vec{v}_{i}\)</span> lidt i retning af alle vektorerne <span class="math inline">\(\vec{v}_{j}\)</span> med <span class="math inline">\(j&lt;i\)</span> svarende til alle de ord, der går forud i teksten. Hvor meget hvert ord trækker, afhænger af, hvor meget det siger om betydningen af det <span class="math inline">\(i\)</span>te ord. Vi opdaterer således <span class="math inline">\(\vec{v}_i\)</span> til</p>
<p><span class="math display">\[
\vec{w}_{i} = c_{1,i}\vec{v}_1 +c_{2,i}\vec{v}_2 + \dotsm + c_{i,i} \vec{v}_i
\]</span></p>
<p>hvor <span class="math inline">\(\vec{v}_1,\ldots,\vec{v}_{i-1}\)</span> er vektorrepræsentationerne for de <span class="math inline">\(i-1\)</span> ord, der går forud for det <span class="math inline">\(i\)</span>te ord. Desuden indgår nogle konstanter <span class="math inline">\(c_{j,i}\geq 0\)</span>, som er valgt, således at</p>
<p><span id="eq-sum_1"><span class="math display">\[
c_{1,i} + c_{2,i} + \dotsm + c_{i,i}=1
\tag{1}\]</span></span></p>
<p>Denne betingelse sikrer, at vi ikke risikerer at få meget lange vektorer ud. Konstanten <span class="math inline">\(c_{j,i}\)</span> bestemmer, hvor meget <span class="math inline">\(\vec{v}_i\)</span> bliver trukket i retning af <span class="math inline">\(\vec{v}_j\)</span>. Hvis det <span class="math inline">\(j\)</span>te ord har stor indflydelse på betydningen af det <span class="math inline">\(i\)</span>te ord, skal <span class="math inline">\(c_{j,i}\)</span> være stor, så <span class="math inline">\(\vec{v}_i\)</span> bliver trukket forholdsvis langt over mod <span class="math inline">\(\vec{v}_j\)</span>. Hvis omvendt det <span class="math inline">\(j\)</span>te ord ikke indeholder nogen information om betydningen af det <span class="math inline">\(i\)</span>te ord, skal <span class="math inline">\(c_{j,i}\)</span> være 0. Dermed bliver <span class="math inline">\(\vec{v}_i\)</span> ikke trukket i retning af <span class="math inline">\(\vec{v}_j\)</span>. I sætningen</p>
<p><span class="math display">\[
\text{"Orkesteret skal spille ---"}
\]</span></p>
<p>ville <span class="math inline">\(c_{1,3}\)</span> være stor, fordi ordet "orkesteret" er vigtigt for at forstå betydningen af "spille", mens <span class="math inline">\(c_{2,3}\)</span> ville være mindre, fordi ordet "skal" ikke fortæller så meget om betydningen af "spille". Desuden vil <span class="math inline">\(c_{3,3}\)</span> være stor, da ordet "spille" selvfølgelig indeholder megen information om sin egen betydning. Hvordan bestemmer vi så konstanterne <span class="math inline">\(c_{j,i}\)</span>? Jo, i stedet for at lade hvert ord repræsentere ved to vektorer som i Word2Vec<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>, lader transformeren hvert ord svare til hele tre vektorer<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> <span class="math inline">\(\vec{v}_{\text{ord}}\)</span>, <span class="math inline">\(\vec{k}_{\text{ord}}\)</span> og <span class="math inline">\(\vec{q}_{\text{ord}}\)</span>. Som i Word2Vec repræsenterer <span class="math inline">\(\vec{v}_{\text{ord}}\)</span> fokusordets betydning, og <span class="math inline">\(\vec{k}_{\text{ord}}\)</span> repræsenterer ordet, når det optræder som kontekst (da vi er ude på at gætte næste ord, består konteksten til et ord af alle de ord, der står før i teksten). Den ekstra vektor <span class="math inline">\(\vec{q}_{\text{ord}}\)</span> repræsenterer også fokusordet, men bruges til at afgøre, hvilke ord der er vigtige for at forstå fokusordets betydning. Vektorerne <span class="math inline">\(\vec{k}_{\text{ord}}\)</span> og <span class="math inline">\(\vec{q}_{\text{ord}}\)</span> skal have samme dimension, mens <span class="math inline">\(\vec{v}_{\text{ord}}\)</span> godt kan have en anden dimension. Alle vektorerne <span class="math inline">\(\vec{v}_{\text{ord}}\)</span>, <span class="math inline">\(\vec{k}_{\text{ord}}\)</span> og <span class="math inline">\(\vec{q}_{\text{ord}}\)</span> bliver bestemt, når vi træner transformeren.</p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;Hvor hvert ord blev repræsenteret ved en fokus- og en kontekstvektor.</p></div><div id="fn4"><p><sup>4</sup>&nbsp;I litteraturen kaldes de tre vektorer <span class="math inline">\(\vec{k}_{\text{ord}}\)</span>, <span class="math inline">\(\vec{q}_{\text{ord}}\)</span> og <span class="math inline">\(\vec{v}_{\text{ord}}\)</span> for key, query og value.</p></div></div><p>Lad os igen fokusere på det <span class="math inline">\(i\)</span>te ord. Vi bruger vektorerne <span class="math inline">\(\vec{k}_{j}\)</span> og <span class="math inline">\(\vec{q}_{i}\)</span> til at måle, hvor meget det <span class="math inline">\(j\)</span>te kontekstord fortæller om betydningen af det <span class="math inline">\(i\)</span>te ord. Mere præcist bruger vi skalarproduktet</p>
<p><span class="math display">\[
\vec{k}_j \cdot \vec{q}_i
\]</span></p>
<p>Store værdier af <span class="math inline">\(\vec{k}_j \cdot \vec{q}_i\)</span> svarer til, at det <span class="math inline">\(j\)</span>te ord indeholder megen information om betydningen af det <span class="math inline">\(i\)</span>te ord, mens meget negative værdier betyder, at det <span class="math inline">\(j\)</span>te kontekstord ikke fortæller ret meget om betydningen af det <span class="math inline">\(i\)</span>te ord. For at sikre at betingelsen i (<a href="#eq-sum_1" class="quarto-xref">1</a>) er overholdt, transformerer vi skalarprodukterne med en softmax funktion (se <a href="../../materialer/sprogmodeller/word2vec.html">noten om Word2Vec</a>). Vi laver derfor en vektor</p>
<p><span class="math display">\[
\vec{c}_i = \text{Softmax}({\vec{k}_1 \cdot \vec{q}_i},  {\vec{k}_2 \cdot \vec{q}_i},\ldots,  {\vec{k}_i \cdot \vec{q}_i} )
\]</span></p>
<p>hvis <span class="math inline">\(j\)</span>te koordinat er</p>
<p><span class="math display">\[
c_{j,i} = \frac{e^{\vec{k}_j \cdot \vec{q}_i}}{ e^{\vec{k}_1 \cdot \vec{q}_i}+e^{\vec{k}_2 \cdot \vec{q}_i}+\dotsm +e^{\vec{k}_i \cdot \vec{q}_i}}
\]</span> Dette sikrer, at <span class="math inline">\(c_{j,i}\)</span>’erne er tal mellem 0 og 1, som opfylder ligning (<a href="#eq-sum_1" class="quarto-xref">1</a>). Hvis <span class="math inline">\(\vec{k}_j \cdot \vec{q}_i\)</span> er meget stor bliver <span class="math inline">\(c_{j,i}\)</span> tæt på 1, mens meget negative <span class="math inline">\(\vec{k}_j \cdot \vec{q}_i\)</span> svarer til <span class="math inline">\(c_{j,i}\)</span> tæt på 0.</p>
<p>Processen, der opdaterer vektorrepræsentationen af et ord på baggrund af de foregående ord, kaldes et <em>opmærksomhedslag</em><a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> og udgør den centrale del af transformeren. I <a href="#fig-attention" class="quarto-xref">figur&nbsp;5</a> ses skematisk, hvordan de forskellige vektorer bruges i beregningen af <span class="math inline">\(\vec{w}_i\)</span>. Bemærk, at vi ikke har taget højde for, at betydningen af det <span class="math inline">\(i\)</span>te ord afhænger mest af de ord, der står lige i nærheden af det, og i mindre grad af ord langt væk. Derfor modificerer transformeren vektorerne for hvert ord afhængigt af ordets position i sætningen. Vi vil ikke gå i dybden med, hvordan det gøres.</p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;På engelsk <em>attention head</em>.</p></div></div><div class="cell page-columns page-full">
<div class="cell-output-display page-columns page-full">
<div id="fig-attention" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-attention-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="transformeren_files/figure-html/fig-attention-1.png" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-attention-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figur&nbsp;5: Opdatering af vektorrepræsentationen for <span class="math inline">\(\text{ord}_{i}\)</span> ved hjælp af opmærksomhed på forudgående ord. Bemærk, at kun <span class="math inline">\(\vec{q}_i\)</span> benyttes når <span class="math inline">\(\vec{v}_i\)</span> opdateres, mens <span class="math inline">\(\vec{q}_1,\ldots,\vec{q}_{i-1}\)</span> ikke benyttes.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Lad os se på et eksempel.</p>
<div id="exm-eks1" class="theorem example page-columns page-full">
<p><span class="theorem-title"><strong>Eksempel 1</strong></span> Betragt igen sætningen "Orkesteret skal spille". Lad os sige, at de tre ord har følgende vektorrepræsentationer.</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\text{orkesteret:} &amp;&amp;\vec{q}_1 = \begin{pmatrix}4\\-1\end{pmatrix}, &amp;&amp;\vec{k}_1=\begin{pmatrix}0\\1\end{pmatrix},
&amp;&amp;\vec{v}_1= \begin{pmatrix} -1\\ 1\end{pmatrix}\\
&amp;\text{skal:}&amp;&amp;\vec{q}_2 = \begin{pmatrix}0\\3\end{pmatrix}, &amp;&amp;\vec{k}_2=\begin{pmatrix}2\\-1\end{pmatrix},
&amp;&amp;\vec{v}_2= \begin{pmatrix} 0.5\\ -1\end{pmatrix}\\
&amp;\text{spille:}&amp;&amp;\vec{q}_3 = \begin{pmatrix}1\\2\end{pmatrix}, &amp;&amp;\vec{k}_3=\begin{pmatrix}1\\1\end{pmatrix},
&amp;&amp;\vec{v}_3= \begin{pmatrix} 1\\ 1\end{pmatrix}\\
\end{aligned}
\]</span></p>
<p>Lad os nu beregne den opdaterede vektor <span class="math inline">\(\vec{w}_3\)</span> for "spille". Først regnes skalarprodukterne</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\vec{k}_1\cdot \vec{q}_3=\begin{pmatrix}0\\1\end{pmatrix}  \cdot \begin{pmatrix}1\\2\end{pmatrix} =0\cdot 1 + 1\cdot 2 = 2  \\
&amp;\vec{k}_2\cdot \vec{q}_3=\begin{pmatrix}2\\-1\end{pmatrix}\cdot  \begin{pmatrix}1\\2\end{pmatrix} = 2\cdot 1 + (-1)\cdot 2 =0\\
&amp;\vec{k}_3\cdot \vec{q}_3= \begin{pmatrix}1 \\1\end{pmatrix} \cdot  \begin{pmatrix}1\\2\end{pmatrix} = 1\cdot 1 + 1 \cdot 2=3
\end{aligned}
\]</span></p>
<p>På <a href="#fig-ekskq" class="quarto-xref">figur&nbsp;6</a> er vektorerne <span class="math inline">\(\vec{k}_{\text{orkesteret}}\)</span>, <span class="math inline">\(\vec{k}_{\text{skal}}\)</span>, <span class="math inline">\(\vec{k}_{\text{spille}}\)</span> og <span class="math inline">\(\vec{q}_{\text{spille}}\)</span> indtegnet i et koordinatsystem. Det ses, at <span class="math inline">\(\vec{k}_{\text{spille}}\)</span> er den vektor, der peger mest i retning af <span class="math inline">\(\vec{q}_{\text{spille}}\)</span> svarende til største skalarprodukt, mens <span class="math inline">\(\vec{k}_{\text{skal}}\)</span> peger mindst i retning af <span class="math inline">\(\vec{q}_{\text{spille}}\)</span> svarende til det mindste skalarprodukt. Det svarer til, at "spille" har meget at sige om sin egen betydning, mens "skal" ikke har meget at sige om betydningen af "spille". Vektorerne <span class="math inline">\(\vec{q}_{\text{orkesteret}}\)</span> og <span class="math inline">\(\vec{q}_{\text{skal}}\)</span> bliver ikke brugt.</p>
<div class="cell page-columns page-full">
<div class="cell-output-display page-columns page-full">
<div id="fig-ekskq" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-ekskq-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="transformeren_files/figure-html/fig-ekskq-1.png" class="img-fluid figure-img" style="width:40.0%">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-ekskq-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figur&nbsp;6: Vektorerne <span class="math inline">\(\vec{k}_{\text{orkesteret}}\)</span>, <span class="math inline">\(\vec{k}_{\text{skal}}\)</span>, <span class="math inline">\(\vec{k}_{\text{spille}}\)</span> og <span class="math inline">\(\vec{q}_{\text{spille}}\)</span>.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Vi bruger softmax på skalarprodukterne for at finde konstanterne <span class="math inline">\(c_{1,3}\)</span>, <span class="math inline">\(c_{2,3}\)</span> og <span class="math inline">\(c_{3,3}\)</span>.</p>
<p><span class="math display">\[
\begin{aligned}
c_{1,3} = \frac{e^{\vec{k}_1\cdot \vec{q}_3}}{e^{\vec{k}_1\cdot \vec{q}_3}+e^{\vec{k}_2\cdot \vec{q}_3}+e^{\vec{k}_3\cdot \vec{q}_3}} = \frac{e^{2}}{e^{2}+e^{0}+e^{3} }\approx 0.259\\
c_{2,3} = \frac{e^{\vec{k}_2\cdot \vec{q}_3}}{e^{\vec{k}_1\cdot \vec{q}_3}+e^{\vec{k}_2\cdot \vec{q}_3}+e^{\vec{k}_3\cdot \vec{q}_3}} = \frac{e^{0}}{e^{2}+e^{0}+e^{3} }\approx 0.035\\
c_{3,3} = \frac{e^{\vec{k}_3\cdot \vec{q}_3}}{e^{\vec{k}_1\cdot \vec{q}_3}+e^{\vec{k}_2\cdot \vec{q}_3}+e^{\vec{k}_3\cdot \vec{q}_3}} = \frac{e^{3}}{e^{2}+e^{0}+e^{3} }\approx 0.705\\
\end{aligned}
\]</span> Bemærk (bortset fra afrunding), at</p>
<p><span class="math display">\[
c_{1,3} + c_{2,3} + c_{3,3} = 1
\]</span></p>
<p>Nu kan vi beregne</p>
<p><span class="math display">\[
\begin{aligned}
\vec{w}_3 &amp; =c_{1,3}\vec{v}_1 + c_{2,3}\vec{v}_2 + c_{3,3}\vec{v}_3  \\
&amp; = 0.259\begin{pmatrix} -1\\ 1\end{pmatrix} + 0.035\begin{pmatrix} 0.5\\ -1\end{pmatrix} + 0.705\begin{pmatrix} 1\\ 1\end{pmatrix} \\
&amp; =\begin{pmatrix} -0.259\\ 0.259\end{pmatrix} + \begin{pmatrix} 0.0175\\ -0.035\end{pmatrix} + \begin{pmatrix} 0.705\\ 0.705\end{pmatrix} \\
&amp; = \begin{pmatrix} -0.259 +  0.0175 + 0.705\\ 0.259-0.035+0.705 \end{pmatrix}\\
&amp;=\begin{pmatrix} 0.464\\ 0.929 \end{pmatrix}
\end{aligned}
\]</span></p>
<p>På <a href="#fig-eks1" class="quarto-xref">figur&nbsp;7</a> er vektorerne <span class="math inline">\(\vec{v}_{\text{orkesteret}}\)</span>, <span class="math inline">\(\vec{v}_{\text{skal}}\)</span>, <span class="math inline">\(\vec{v}_{\text{spille}}\)</span> og <span class="math inline">\(\vec{w}_{\text{spille}}\)</span> indtegnet i et koordinatsystem. Det ses, at <span class="math inline">\(\vec{w}_{\text{spille}}\)</span> er blevet trukket i retning af <span class="math inline">\(\vec{v}_{\text{orkesteret}}\)</span> i forhold til <span class="math inline">\(\vec{v}_{\text{spille}}\)</span>.</p>
<div class="cell page-columns page-full">
<div class="cell-output-display page-columns page-full">
<div id="fig-eks1" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-eks1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="transformeren_files/figure-html/fig-eks1-1.png" class="img-fluid figure-img" style="width:40.0%">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-eks1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figur&nbsp;7: Vektorerne <span class="math inline">\(\vec{v}_{\text{orkesteret}}\)</span>, <span class="math inline">\(\vec{v}_{\text{skal}}\)</span>, <span class="math inline">\(\vec{v}_{\text{spille}}\)</span> og <span class="math inline">\(\vec{w}_{\text{spille}}\)</span> indtegnet i et koordinatsystem.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
</section>
<section id="en-transformerblok" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="en-transformerblok">En transformerblok</h2>
<p>Opmærksomhedslaget er det centrale element i tranformeren. Vi skitserer nu, hvordan resten af transformernetværket er opbygget for at give et indtryk af algoritmens kompleksitet, men en del detaljer er udeladt.</p>
<p>Man kan lave flere opmærksomhedslag parallelt. Hvis der er <span class="math inline">\(K\)</span> parallelle opmærksomhedslag, så oversætter det <span class="math inline">\(k\)</span>te lag det <span class="math inline">\(i\)</span>te ord til tre vektorer <span class="math inline">\(\vec{q}^{k}_{i}\)</span>, <span class="math inline">\(\vec{k}^{k}_{i}\)</span> og <span class="math inline">\(\vec{v}^{k}_{i}\)</span> og beregner en ny vektor <span class="math inline">\(\vec{w}^{k}_{i}\)</span>, hvor <span class="math inline">\(k=1,\ldots,K\)</span>. Man kan forestille sig, at de forskellige opmærksomhedslag indfanger forskellige aspekter ved sætningen. Et holder måske styr på grammatikken, mens et andet fokuserer på betydningen af ordene. Men i stedet for at lægge os fast på, hvad hvert lag skal gøre, lader vi det være op til algoritmen selv at vælge nogle passende vektorer. I praksis er det derfor umuligt at gå ind og se præcis, hvad hvert lag gør.</p>
<p>Indtil videre er <span class="math inline">\(\vec{w}_i^k\)</span> dannet ud fra de oprindelige <span class="math inline">\(\vec{v}_i^k\)</span> ved hjælp af simple operationer som addition og skalering. Det viser sig dog at være for simpelt til at fungere godt i praksis. Derfor transformeres outputet fra opmærksomhedslagene med et neuralt netværk. Mere præcist sættes outputvektorerne <span class="math inline">\(\vec{w}^{k}_i\)</span> fra de forskellige lag i forlængelse af hinanden til en samlet outputvektor <span class="math inline">\(\vec{x}_i\)</span> af længde <span class="math inline">\(Km\)</span>. Koordinaterne i den lange vektor <span class="math inline">\(\vec{x}_i\)</span> bruges som input til et neuralt netværk, ligesom vi så i <a href="../../materialer/sprogmodeller/tekstgenerering.html">noten om neurale netværk til tekstgenerering</a>, bortset fra at vi ikke bruger softmax til sidst. Outputtet bliver en ny vektor <span class="math inline">\(\vec{y}_i\)</span>.</p>
<p>Tilsammen udgør de parallelle opmærksomhedslag og det efterfølgende neurale netværk en <em>transformerblok</em>. Strukturen er skitseret på <a href="#fig-transformerblok" class="quarto-xref">figur&nbsp;8</a>. Undervejs sker der forskellige transformationer af vektorerne, som viser sig at gøre de numeriske beregninger mere stabile. Vi vil ikke beskrive disse i detaljer, da de ikke er centrale for forståelsen.</p>
<div class="cell page-columns page-full">
<div class="cell-output-display page-columns page-full">
<div id="fig-transformerblok" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-transformerblok-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="transformeren_files/figure-html/fig-transformerblok-1.png" class="img-fluid figure-img" style="width:60.0%">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-transformerblok-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figur&nbsp;8: En transformerblok.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="transformernetværket" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="transformernetværket">Transformernetværket</h2>
<p>Når vi så har beregnet outputvektorerne <span class="math inline">\(\vec{y}_i\)</span> fra en transformerblok for alle positioner <span class="math inline">\(i\)</span>, kan vi bruge dem som input til en ny transformerblok. I hvert opmærksomhedslag inden for den næste transformerblok oversættes vektoren <span class="math inline">\(\vec{y}_i\)</span> (ikke det oprindelige ord) til tre nye vektorer. Så beregner transformerblokken en ny <span class="math inline">\(\vec{y}_i\)</span>, som kan bruges som input til endnu en transformerblok og så videre. Tilsammen udgør disse transformerblokke et <em>transformernetværk</em>, som er skitseret på <a href="#fig-transformer" class="quarto-xref">figur&nbsp;9</a>.</p>
<div class="cell page-columns page-full">
<div class="cell-output-display page-columns page-full">
<div id="fig-transformer" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-transformer-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="transformeren_files/figure-html/fig-transformer-1.png" class="img-fluid figure-img" style="width:25.0%">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-transformer-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figur&nbsp;9: Transformernetværket.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Egentlig var vi jo ude på at lave en algoritme, der kan gætte det næste ord, altså det <span class="math inline">\((i+1)\)</span>te ord. Det sker i den sidste prædiktionsblok i transformernetværket, se <a href="#fig-transformer" class="quarto-xref">figur&nbsp;9</a>. Vektoren <span class="math inline">\(\vec{y}_i\)</span>, der kommer ud fra den sidste transformerblok, indeholder information om betydningen af <span class="math inline">\(i\)</span>te ord samt alle de ord, der går forud. I prædiktionslaget omregnes <span class="math inline">\(\vec{y}_i\)</span> til sandsynligheder for næste ord.</p>
<p>For hvert ord i ordforrådet udregner vi først en score <span class="math inline">\(s_{\text{ord}}\)</span>, der måler, hvor sandsynligt det er, at ordet er det næste. Store værdier betyder, at ordet er sandsynligt som næste ord. Til at beregne scoren bruger vi en fast vektor <span class="math inline">\(\vec{a}_{\text{ord}}\)</span> for hvert ord og omregner <span class="math inline">\(\vec{y}_i\)</span> til scoren</p>
<p><span class="math display">\[
s_{\text{ord}} = \vec{a}_{\text{ord}}\cdot \vec{y}_i
\]</span></p>
<p>Disse scores samles i en vektor <span class="math inline">\(\vec{s}\)</span> med <span class="math inline">\(V\)</span> koordinater, hvor <span class="math inline">\(V\)</span> var antallet af ord i ordforrådet. Endelig omdannes <span class="math inline">\(\vec{s}\)</span> til en vektor af sandsynligheder ved endnu engang at bruge softmax-funktionen (se <a href="../../materialer/sprogmodeller/tekstgenerering.html">noten om neurale netværk til tekstgenerering</a>):</p>
<p><span class="math display">\[
\vec{p} = \text{Softmax}(\vec{s})
\]</span></p>
<p>Når man har disse sandsynligheder, kan man begynde at generere tekst, for eksempel ved hele tiden at vælge blandt de mest sandsynlige næste ord.</p>
</section>
<section id="træning-af-netværket" class="level2">
<h2 class="anchored" data-anchor-id="træning-af-netværket">Træning af netværket</h2>
<p>I alt indeholder transformernetværket rigtig mange vægte, der skal bestemmes, før vi kan begynde at generere tekst. Hvert opmærksomhedslag skal bruge vægte til at lave koordinaterne i de tre forskellige vektorer. Hver transformerblok indeholder desuden et neuralt netværk, som skal bruge et sæt af vægte. Endelig skal der i det sidste trin bruges <span class="math inline">\(V\)</span> vektorer på formen <span class="math inline">\(\vec{a}_{\text{ord}}\)</span>.</p>
<p>Den præcise struktur af GPT-4 netværket, som er fundamentet for Chat-GPT, er en forretningshemmelighed. En tidligere version, GPT-2, brugte 12 transformerblokke med 12 parallelle opmærksomhedslag i hvert, altså 144 opmærksomhedslag i alt. I alt havde GPT-2 omkring 1,5 milliarder vægte. Det er dog intet mod GPT-4, der vurderes at have omkring 1 billion vægte.</p>
<p>For at bestemme så mange vægte skal der bruges enorme mængder træningsdata. Til at træne GPT-2 blev der for eksempel brugt 8 millioner dokumenter. I træningsdata kender vi hele tiden det næste ord. For at måle hvor godt det passer med de sandsynligheder for næste ord, som transformeren giver, beregnes en cross-entropy tabsfunktion (se <a href="../../materialer/tabsfunktioner/tabsfunktioner.html">noten om tabsfunktioner</a>). Transformeren trænes til at minimere denne cross-entropy, således at den er god til at forudsige næste ord i træningsdata. Når transformeren er trænet, bliver den som regel fintunet til den opgave, den skal udføre, for eksempel at oversætte en tekst eller besvare et spørgsmål.</p>


</section>


</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/aimat\.dk");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>