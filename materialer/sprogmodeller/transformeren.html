<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>transformeren – AI MAT - matematikken bag magien</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../logo/SVG/Bomaerke_05_AIMAT_2024.svg" rel="icon" type="image/svg+xml">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-5f396f0d7eb5b5756f9d659d452ebaa5.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-Y219BCPS45"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
 
  gtag('consent', 'default', {
    'ad_storage': 'denied',
    'analytics_storage': 'denied'
  });
gtag('config', 'G-Y219BCPS45', { 'anonymize_ip': true});
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="floating nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../logo/PNG/Logo_multi_AIMAT_RGB_2024.png" alt="" class="navbar-logo">
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../undervisningsforlob.html"> 
<span class="menu-text">Undervisningsforløb</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../materialer.html"> 
<span class="menu-text">Materialer</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../sro.html"> 
<span class="menu-text">SRO</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../srp.html"> 
<span class="menu-text">SRP</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../apps.html"> 
<span class="menu-text">Apps</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../referencer.html"> 
<span class="menu-text">Referencer</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">Om os</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://www.youtube.com/@ai-mat"> 
<span class="menu-text"><img src="../../logo/YouTube/youtube-color-darkblue-icon.svg" style="height:2em"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Indhold</h2>
   
  <ul>
  <li><a href="#transformeren" id="toc-transformeren" class="nav-link active" data-scroll-target="#transformeren">Transformeren</a>
  <ul class="collapse">
  <li><a href="#opmærksomhed" id="toc-opmærksomhed" class="nav-link" data-scroll-target="#opmærksomhed">Opmærksomhed</a></li>
  <li><a href="#vektorregning" id="toc-vektorregning" class="nav-link" data-scroll-target="#vektorregning">Vektorregning</a>
  <ul class="collapse">
  <li><a href="#opgaver" id="toc-opgaver" class="nav-link" data-scroll-target="#opgaver">Opgaver</a></li>
  </ul></li>
  <li><a href="#et-opmærksomhedslag" id="toc-et-opmærksomhedslag" class="nav-link" data-scroll-target="#et-opmærksomhedslag">Et opmærksomhedslag</a>
  <ul class="collapse">
  <li><a href="#eksempel" id="toc-eksempel" class="nav-link" data-scroll-target="#eksempel">Eksempel</a></li>
  <li><a href="#opgave" id="toc-opgave" class="nav-link" data-scroll-target="#opgave">Opgave</a></li>
  <li><a href="#en-transformerblok" id="toc-en-transformerblok" class="nav-link" data-scroll-target="#en-transformerblok">En transformerblok</a></li>
  <li><a href="#transformernetværket" id="toc-transformernetværket" class="nav-link" data-scroll-target="#transformernetværket">Transformernetværket</a></li>
  </ul></li>
  <li><a href="#træning-af-netværket" id="toc-træning-af-netværket" class="nav-link" data-scroll-target="#træning-af-netværket">Træning af netværket</a></li>
  </ul></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="transformeren" class="level1 unnumbered">
<h1 class="unnumbered">Transformeren</h1>
<p>De kraftige sprogmodeller, der indgår i de nyeste former for sproglig kunstig intelligens, benytter ikke helt den tilgang, vi hidtil har beskrevet, hvor man først laver Word2Vec og derefter træner et neuralt netværk til at prædiktere ord. I stedet bruges en videreudvikling, kaldet <em>transformeren</em>, der kombinerer de to trin i én algoritme. I Chat-GPT står GPT fx for "Generative Pre-trained Transformer". Nedenfor beskriver vi nogle af de centrale dele af transformeren. (Fodnote: Den version af transformeneren, der beskrives her er en <em>decoder-only transformer</em>, som er den, der indgår i GPT teknologien.) Bemærk, at selv om vi prøver at give en intuition for, hvad transformeren gør, så er der ingen, der helt forstår i detaljer, hvorfor den virker.</p>
<section id="opmærksomhed" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="opmærksomhed">Opmærksomhed</h2>
<p>Vi er ude på at lave en algoritme, der genererer ny tekst ét ord ad gangen. Hvis vi fx har genereret teksten <span class="math display">\[\text{"Min hund er sulten, så jeg fodrer den med ---"}\]</span> så skal vi lave en algoritme, der gætter næste ord. Både <span class="math inline">\(N\)</span>-gram modeller og neurale netværk tager de seneste <span class="math inline">\(N-1\)</span> ord i betragtning for at gætte det næste. Hvis <span class="math inline">\(N=4\)</span> skal vi altså gætte næste ord efter "fodrer den med". Det skal nok være en form for dyremad, men der kunne stå mange forskellige ting, fx "hø" eller "fuglefrø". I dette tilfælde er vi nødt til at gå helt tilbage til ordet "hund" for at vide, hvilket dyr der er tale om og dermed hvilken slags mad, den skal have. Det smarte ved transformeren er, at den tager alle de hidtidige ord i betragtning. Dog lægger den mest vægt på de nærmeste ord.</p>
<p>Husk på, at da vi lavede Word2Vec, lod vi vektoren <span class="math inline">\(\overrightarrow{v}_{\text{ord}}\)</span> repræsentere betydningen af ordet. For at gætte næste ord i en sætning blev vektorerne for de <span class="math inline">\(N-1\)</span> foregående ord brugt som input til et neuralt netværk. Hver vektor <span class="math inline">\(\overrightarrow{v}_{\text{ord}}\)</span> blev brugt som en fast vektor uanset hvilke ord, der stod i nærheden af det. Men betydningen af et ord kan ændre sig alt efter konteksten. Se fx på <span class="math display">\[\text{"Orkesteret skal spille ---"}\]</span> Kigger vi udelukkende på ordet "spille", kan der stå mange ting bagefter, fx "ludo", "tennis" eller "koncert". Men når vi ser, at ordet "orkesteret" optræder inden, så ved vi, at der nok er tale om en slags musik. Det kunne derfor give mening at lade ordet "spille" repræsentere ved forskellige vektorer, alt efter om det indgår i en musikkontekst, en sportskontekst eller en brætspilskontekst. Det er netop idéen i transformeren: Vi vil lade vektorrepræsentationen af et ord afhænge af konteksten. Vi er altså <em>opmærksomme på</em>, hvilke ord der går forud, når vi laver vektorrepræsentationen. Derfor siges transformeren at have <em>opmærksomhed på sig selv</em>. (fodnote: på engelsk siges transformeren at have <em>self-attention</em>.)</p>
</section>
<section id="vektorregning" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="vektorregning">Vektorregning</h2>
<p>Som udgangspunkt lader vi ordet "spille" være repræsenteret af en fast vektor <span class="math inline">\(\overrightarrow{v}_{\text{spille}}\)</span>. Vi modificerer derefter vores vektorrepræsentation <span class="math inline">\(\overrightarrow{v}_{\text{spille}}\)</span> til en ny vektor <span class="math inline">\(\overrightarrow{w}_{\text{spille}}\)</span> afhængigt af hvilke ord, der kommer før. Hvis ordet "orkesteret" kommer inden, så kan man forestille sig, at det trækker <span class="math inline">\(\overrightarrow{v}_{\text{spille}}\)</span> i en musikretning, mens hvis ordet havde været "landsholdet", så ville det trække <span class="math inline">\(\overrightarrow{v}_{\text{spille}}\)</span> i en sportsretning.</p>
<p>Vi vil modificere <span class="math inline">\(\overrightarrow{v}_{\text{spille}}\)</span> ved hjælp af vektoraddition og skalarmultiplikation. Husk på, at man lægger to 2-dimensionale vektorer sammen koordinatvis: <span class="math display">\[\begin{pmatrix}a_1\\ a_2\end{pmatrix} + \begin{pmatrix}b_1\\ b_2\end{pmatrix} = \begin{pmatrix}a_1+b_1\\ a_2+b_2\end{pmatrix}\]</span> Geometrisk lægger man vektorerne <span class="math inline">\(\overrightarrow{a}\)</span> og <span class="math inline">\(\overrightarrow{b}\)</span> sammen ved først at tegne <span class="math inline">\(\overrightarrow{a}\)</span> og derefter tegne <span class="math inline">\(\overrightarrow{b}\)</span> med udgangspunkt, der hvor <span class="math inline">\(\overrightarrow{a}\)</span> slutter. Vektoren <span class="math inline">\(\overrightarrow{a} + \overrightarrow{b}\)</span> er så den vektor, der starter samme sted som <span class="math inline">\(\overrightarrow{a}\)</span> og slutter der hvor <span class="math inline">\(\overrightarrow{b}\)</span> slutter.</p>
<p>Dette kan vi nu benytte til at opdatere vektoren for "spille", når vi ved, at "orkesteret" står inden. Hvis vi har vektorerne <span class="math inline">\(\overrightarrow{v}_{\text{spille}}\)</span> og <span class="math inline">\(\overrightarrow{v}_{\text{orkesteret}}\)</span>, så kunne vi opdatere <span class="math inline">\(\overrightarrow{v}_{\text{spille}}\)</span> til <span class="math display">\[\overrightarrow{w}_{\text{spille}} = \overrightarrow{v}_{\text{orkesteret}}+\overrightarrow{v}_{\text{spille}}\]</span> Det er illustreret på Figur <a href="#fig:spille" data-reference-type="ref" data-reference="fig:spille">[fig:spille]</a>. Det ses, at retningen på <span class="math inline">\(\overrightarrow{v}_{\text{spille}}\)</span> er blevet trukket over mod <span class="math inline">\(\overrightarrow{v}_{\text{orkesteret}}\)</span> og væk fra <span class="math inline">\(\overrightarrow{v}_{\text{landsholdet}}\)</span>.</p>
<p>Der er dog et andet problem: Den nye vektor <span class="math inline">\(\overrightarrow{w}_{\text{spille}}\)</span> er meget lang i forhold til de oprindelige. Det løser vi ved at skalere de to vektorer ned, inden vi lægger dem sammen. Man kan skalere en vektor med et tal <span class="math inline">\(c\in \mathbb{R}\)</span> ved at gange hver koordinat med <span class="math inline">\(c\)</span>: <span class="math display">\[c\begin{pmatrix}
    a_1\\a_2
\end{pmatrix} = \begin{pmatrix}
    ca_1\\ca_2
\end{pmatrix}\]</span> Hvis <span class="math inline">\(c&gt;0\)</span>, er <span class="math inline">\(c\overrightarrow{a}\)</span> en vektor, der peger i samme retning som <span class="math inline">\(\overrightarrow{a}\)</span>, men er <span class="math inline">\(c\)</span> gange så lang. Hvis <span class="math inline">\(c&lt;0\)</span>, er vektoren <span class="math inline">\(|c|\)</span> gange så lang som <span class="math inline">\(\overrightarrow{a}\)</span>, men peger i modsat retning.</p>
<p>I vores eksempel kunne man skalere begge vektorer med en faktor <span class="math inline">\(\frac{1}{2}\)</span> inden man lægger dem sammen, således at <span class="math display">\[\overrightarrow{w}_{\text{spille}} = \frac{1}{2}\cdot \overrightarrow{v}_{\text{orkesteret}}+\frac{1}{2}\cdot \overrightarrow{v}_{\text{spille}}\]</span> Dette er skitseret i Figur <a href="#fig:spille2" data-reference-type="ref" data-reference="fig:spille2">[fig:spille2]</a>.</p>
<p>Den nye vektor <span class="math inline">\(\overrightarrow{w}_{\text{spille}}\)</span> er mere sammenlignelig med den oprindelige <span class="math inline">\(\overrightarrow{v}_{\text{spille}}\)</span> i Figur <a href="#fig:spille" data-reference-type="ref" data-reference="fig:spille">[fig:spille]</a>. Vi kunne have gjort noget tilsvarende hvis der havde stået <span class="math display">\[\text{Landsholdet skal spille ---}\]</span> Så ville <span class="math inline">\(\overrightarrow{w}_{\text{spille}}\)</span> blive trukket i retning af <span class="math inline">\(\overrightarrow{v}_{\text{landsholdet}}\)</span> i stedet. Men hvad nu, hvis der havde stået <span class="math display">\[\text{Manden skal spille ---}\]</span> Her bliver vi ikke rigtig klogere på, om der er tale om sport eller musik. Vi får altså ikke megen ny viden om betydningen af "spille". Her ville det derfor give mere mening at vælge <span class="math display">\[\overrightarrow{w}_{\text{spille}} = \overrightarrow{v}_{\text{spille}} = 0\cdot \overrightarrow{v}_{\text{orkesteret}}+1\cdot \overrightarrow{v}_{\text{spille}}\]</span> Helt generelt, hvis der i stedet for "orkesteret" havde stået et ord med vektorrepræsentation <span class="math inline">\(\overrightarrow{v}_{\text{ord}}\)</span> ville vi sætte <span class="math display">\[\overrightarrow{w}_{\text{spille}} = c_1 \cdot \overrightarrow{v}_{\text{ord}}+c_2 \cdot \overrightarrow{v}_{\text{spille}}\]</span> hvor <span class="math inline">\(c_1\)</span> og <span class="math inline">\(c_2\)</span> er ikke-negative konstanter med <span class="math inline">\(c_1+c_2=1\)</span>. Hvis kontekstordet er meget relevant for at forstå betydningen af "spille", vælges <span class="math inline">\(c_1\)</span> stor, mens <span class="math inline">\(c_1\)</span> vælges tæt på 0, hvis kontekstordet ikke giver megen ny information om betydningen. Hvordan vi mere præcist vælger <span class="math inline">\(c_1\)</span> og <span class="math inline">\(c_2\)</span>, vender vi tilbage til i næste afsnit, hvor vi også skal se på, hvordan man kan inddrage information fra mere end et af de foregående ord.</p>
<p>Inden vi afslutter dette afsnit, minder vi om, at det normalt er for lidt at repræsentere ord ved 2-dimensionale vektorer. I stedet repræsenterer vi dem ved <span class="math inline">\(m\)</span>-dimensionale vektorer. Man kan lægge <span class="math inline">\(m\)</span>-dimensionale vektorer sammen og skalere dem med en konstant ligesom i to dimensioner: <span class="math display">\[\begin{pmatrix}a_1\\ a_2 \\ \vdots\\a_m\end{pmatrix} + \begin{pmatrix}b_1\\ b_2\\ \vdots\\b_m\end{pmatrix} =  \begin{pmatrix}a_1+b_1\\ a_2+b_2\\ \vdots\\a_m+b_m\end{pmatrix}\]</span> og <span class="math display">\[c\begin{pmatrix}
    a_1\\a_2\\ \vdots\\a_m
\end{pmatrix} = \begin{pmatrix}
    ca_1\\ca_2\\ \vdots\\ca_m
\end{pmatrix}\]</span> I tre dimensioner kan vektoraddition visualiseres på samme måde som i det 2-dimensionale tilfælde, men i højere dimensioner er det ikke muligt at visualisere hvad der foregår.</p>
<section id="opgaver" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="opgaver">Opgaver</h3>
<ul>
<li><p>Lad <span class="math inline">\(\overrightarrow{v}_1 = \begin{pmatrix} 1\\ 3\end{pmatrix}\)</span> og <span class="math inline">\(\overrightarrow{v}_2 = \begin{pmatrix} 3\\1\end{pmatrix}\)</span>.</p>
<ul>
<li><p>Beregn vektorerne <span class="math display">\[\begin{aligned}
\overrightarrow{w}_1 = \frac{1}{3} \overrightarrow{v}_1 + \frac{2}{3} \overrightarrow{v}_2 \\
\overrightarrow{w}_2 = \frac{1}{2} \overrightarrow{v}_1 + \frac{1}{2} \overrightarrow{v}_2 \\
\overrightarrow{w}_3 = \frac{2}{3} \overrightarrow{v}_1 + \frac{1}{3} \overrightarrow{v}_2 \\\end{aligned}\]</span></p></li>
<li><p>Indtegn <span class="math inline">\(\overrightarrow{w}_1\)</span>, <span class="math inline">\(\overrightarrow{w}_2\)</span> og <span class="math inline">\(\overrightarrow{w}_3\)</span> i et koordinatsystem sammen med <span class="math inline">\(\overrightarrow{v}_1\)</span> og <span class="math inline">\(\overrightarrow{v}_2\)</span>.</p></li>
<li><p>Passer resultatet med, at vektoren <span class="math display">\[c_1\overrightarrow{v}_1 + c_2\overrightarrow{v}_2\]</span> med <span class="math inline">\(c_1,c_2\geq 0\)</span> ligger tættere på <span class="math inline">\(\overrightarrow{v}_1\)</span> jo større <span class="math inline">\(c_1\)</span> er?</p></li>
</ul></li>
<li><p>Lad <span class="math inline">\(\overrightarrow{v}_1 = \begin{pmatrix} 1\\ 2\\ 0\end{pmatrix}\)</span>, <span class="math inline">\(\overrightarrow{v}_2 = \begin{pmatrix} 1\\-1\\2\end{pmatrix}\)</span> og <span class="math inline">\(\overrightarrow{v}_3 = \begin{pmatrix} 0\\0\\1\end{pmatrix}\)</span>. Beregn <span class="math display">\[2\overrightarrow{v}_1+\overrightarrow{v}_2-2\overrightarrow{v}_3\]</span></p></li>
</ul>
</section>
</section>
<section id="et-opmærksomhedslag" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="et-opmærksomhedslag">Et opmærksomhedslag</h2>
<p>Lad os sige, at vi har et stykke tekst, og at det <span class="math inline">\(i\)</span>te ord i teksten er vores fokusord, som vi gerne vil finde en vektorrepræsentation for. Som udgangspunkt er betydningen af det <span class="math inline">\(i\)</span>te ord repræsenteret af vektoren <span class="math inline">\(\overrightarrow{v}_i\)</span>. Transformeren opdaterer vektoren <span class="math inline">\(\overrightarrow{v}_{i}\)</span> til <span class="math inline">\(\overrightarrow{w}_{i}\)</span> på baggrund af alle de ord, der går forud. Man kan forstille sig, at vi trækker vektoren <span class="math inline">\(\overrightarrow{v}_{i}\)</span> lidt i retning af alle vektorerne <span class="math inline">\(\overrightarrow{v}_{j}\)</span> med <span class="math inline">\(j&lt;i\)</span> svarende til alle de ord, der går forud i teksten. Hvor meget hvert ord trækker, afhænger af, hvor meget det siger om betydningen af det <span class="math inline">\(i\)</span>te ord. Vi opdaterer således <span class="math inline">\(\overrightarrow{v}_i\)</span> til <span class="math display">\[\overrightarrow{w}_{i} = c_{1,i}\overrightarrow{v}_1 +c_{2,i}\overrightarrow{v}_2 + \dotsm + c_{i,i} \overrightarrow{v}_i\]</span> hvor <span class="math inline">\(\overrightarrow{v}_1,\ldots,\overrightarrow{v}_{i-1}\)</span> er vektorrepræsentationerne for de <span class="math inline">\(i-1\)</span> ord, der går forud for det <span class="math inline">\(i\)</span>te ord. Desuden indgår nogle konstanter <span class="math inline">\(c_{j,i}\geq 0\)</span>, som er valgt, således at <span class="math display">\[\label{sum_1}
   c_{1,i} + c_{2,i} + \dotsm + c_{i,i}=1\]</span> Denne betingelse sikrer, at vi ikke risikerer at få meget lange vektorer ud. Konstanten <span class="math inline">\(c_{j,i}\)</span> bestemmer, hvor meget <span class="math inline">\(\overrightarrow{v}_i\)</span> bliver trukket i retning af <span class="math inline">\(\overrightarrow{v}_j\)</span>. Hvis <span class="math inline">\(j\)</span>te ord har stor indflydelse på betydningen af <span class="math inline">\(i\)</span>te ord, skal <span class="math inline">\(c_{j,i}\)</span> være stor, så <span class="math inline">\(\overrightarrow{v}_i\)</span> bliver trukket forholdsvis langt over mod <span class="math inline">\(\overrightarrow{v}_j\)</span>. Hvis omvendt det <span class="math inline">\(j\)</span>te ord ikke indeholder nogen information om betydningen af <span class="math inline">\(i\)</span>te ord, skal <span class="math inline">\(c_{j,i}\)</span> være 0. Dermed bliver <span class="math inline">\(\overrightarrow{v}_i\)</span> ikke trukket i retning af <span class="math inline">\(\overrightarrow{v}_j\)</span>. I sætningen <span class="math display">\[\text{"Orkesteret skal spille ---"}\]</span> ville <span class="math inline">\(c_{1,3}\)</span> være stor, fordi ordet "orkesteret" er vigtigt for at forstå betydningen af "spille", mens <span class="math inline">\(c_{2,3}\)</span> ville være mindre, fordi ordet "skal" ikke fortæller så meget om betydningen af "spille". Desuden vil <span class="math inline">\(c_{3,3}\)</span> være stor, da ordet "spille" selvfølgelig indeholder megen information om sin egen betydning.</p>
<p>Hvordan bestemmer vi så konstanterne <span class="math inline">\(c_{j,i}\)</span>? Jo, i stedet for at lade hvert ord repræsentere ved to vektorer som i Word2Vec (fodnote: nemlig fokus- og kontekstvektoren), lader transformeren hvert ord svare til hele tre vektorer <span class="math inline">\(\overrightarrow{v}_{\text{ord}}\)</span>, <span class="math inline">\(\overrightarrow{k}_{\text{ord}}\)</span> og <span class="math inline">\(\overrightarrow{q}_{\text{ord}}\)</span>. (Fodnote: I litteraturen kaldes de tre vektorer <span class="math inline">\(\overrightarrow{k}_{\text{ord}}\)</span>, <span class="math inline">\(\overrightarrow{q}_{\text{ord}}\)</span> og <span class="math inline">\(\overrightarrow{v}_{\text{ord}}\)</span> for key, query og value.) Som i Word2Vec repræsenterer <span class="math inline">\(\overrightarrow{v}_{\text{ord}}\)</span> fokusordets betydning, og <span class="math inline">\(\overrightarrow{k}_{\text{ord}}\)</span> repræsenterer ordet når det optræder som kontekst. (Da vi er ude på at gætte næste ord, består konteksten til et ord af alle de ord, der står før i teksten). Den ekstra vektor <span class="math inline">\(\overrightarrow{q}_{\text{ord}}\)</span> repræsenterer også fokusordet, men bruges til at afgøre, hvilke ord der er er vigtige for at forstå fokusordets betydning. Vektorerne <span class="math inline">\(\overrightarrow{k}_{\text{ord}}\)</span> og <span class="math inline">\(\overrightarrow{q}_{\text{ord}}\)</span> skal have samme dimension, mens <span class="math inline">\(\overrightarrow{v}_{\text{ord}}\)</span> godt kan have en anden dimension.</p>
<p>Lad os igen fokusere på det <span class="math inline">\(i\)</span>te ord. Vi bruger vektorerne <span class="math inline">\(\overrightarrow{k}_{j}\)</span> og <span class="math inline">\(\overrightarrow{q}_{i}\)</span> til at måle, hvor meget det <span class="math inline">\(j\)</span>te kontekstord fortæller om betydningen af det <span class="math inline">\(i\)</span>te ord. Mere præcist bruger vi skalarproduktet <span class="math display">\[\overrightarrow{k}_j \cdot \overrightarrow{q}_i\]</span> Store værdier af <span class="math inline">\(\overrightarrow{k}_j \cdot \overrightarrow{q}_i\)</span> svarer til, at det <span class="math inline">\(j\)</span>te ord indeholder megen information om betydningen af det <span class="math inline">\(i\)</span>te ord, mens meget negative værdier betyder, at det <span class="math inline">\(j\)</span>te kontekstord ikke fortæller ret meget om betydningen af det <span class="math inline">\(i\)</span>te ord. For at sikre at betingelsen <a href="#sum_1" data-reference-type="eqref" data-reference="sum_1">[sum_1]</a> er overholdt, transformerer vi skalarprodukterne med en softmax funktion, se (LINK TIL Word2Vec). Vi laver derfor en vektor <span class="math display">\[\overrightarrow{c}_i = \text{Softmax}({\overrightarrow{k}_1 \cdot \overrightarrow{q}_i},  {\overrightarrow{k}_2 \cdot \overrightarrow{q}_i},\ldots,  {\overrightarrow{k}_i \cdot \overrightarrow{q}_i} )\]</span> hvis <span class="math inline">\(j\)</span>te koordinat er <span class="math display">\[c_{j,i} = \frac{e^{\overrightarrow{k}_j \cdot \overrightarrow{q}_i}}{ e^{\overrightarrow{k}_1 \cdot \overrightarrow{q}_i}+e^{\overrightarrow{k}_2 \cdot \overrightarrow{q}_i}+\dotsm +e^{\overrightarrow{k}_i \cdot \overrightarrow{q}_i}}\]</span> Dette sikrer, at <span class="math inline">\(c_{j,i}\)</span>’erne er tal mellem 0 og 1, som opfylder Ligning <a href="#sum_1" data-reference-type="eqref" data-reference="sum_1">[sum_1]</a>. Hvis <span class="math inline">\(\overrightarrow{k}_j \cdot \overrightarrow{q}_i\)</span> er meget stor bliver <span class="math inline">\(c_{j,i}\)</span> tæt på 1, mens meget negative <span class="math inline">\(\overrightarrow{k}_j \cdot \overrightarrow{q}_i\)</span> svarer til <span class="math inline">\(c_{j,i}\)</span> tæt på 0.</p>
<p>Processen, der opdaterer vektorrepræsentationen af et ord på baggrund af de foregående ord, kaldes et <em>opmærksomhedslag</em> (Fodnote: På engelsk <em>attention head</em>) og udgør den centrale del af transformeren. Figur <a href="#fig:attention" data-reference-type="ref" data-reference="fig:attention">[fig:attention]</a> viser skematisk, hvordan de forskellige vektorer bruges i beregningen af <span class="math inline">\(\overrightarrow{w}_i\)</span>. Bemærk at vi ikke har taget højde for, at betydningen af det <span class="math inline">\(i\)</span>te ord afhænger mest af de ord, der står lige i nærheden af det, og i mindre grad af ord langt væk. Derfor modificerer transformeren vektorerne for hvert ord afhængigt af ordets position i sætningen. Vi vil ikke gå i dybden med, hvordan det gøres.</p>
<section id="eksempel" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="eksempel">Eksempel</h3>
<p>Betragt igen sætningen "Orkesteret skal spille". Lad os sige, at de tre ord har følgende vektorrepræsentationer. <span class="math display">\[\begin{aligned}
&amp;\text{orkesteret:} &amp;&amp;\overrightarrow{q}_1 = \begin{pmatrix}4\\-1\end{pmatrix}, &amp;&amp;\overrightarrow{k}_1=\begin{pmatrix}0\\1\end{pmatrix},
&amp;&amp;\overrightarrow{v}_1= \begin{pmatrix} -1\\ 1\end{pmatrix}\\
&amp;\text{skal:}&amp;&amp;\overrightarrow{q}_2 = \begin{pmatrix}0\\3\end{pmatrix}, &amp;&amp;\overrightarrow{k}_2=\begin{pmatrix}2\\-1\end{pmatrix},
&amp;&amp;\overrightarrow{v}_2= \begin{pmatrix} 0.5\\ -1\end{pmatrix}\\
&amp;\text{spille:}&amp;&amp;\overrightarrow{q}_3 = \begin{pmatrix}1\\2\end{pmatrix}, &amp;&amp;\overrightarrow{k}_3=\begin{pmatrix}2\\0.5\end{pmatrix},
&amp;&amp;\overrightarrow{v}_3= \begin{pmatrix} 1\\ 1\end{pmatrix}\\\end{aligned}\]</span> Lad os nu beregne den opdaterede vektor <span class="math inline">\(\overrightarrow{w}_3\)</span> for "spille". Først regnes skalarprodukterne <span class="math display">\[\begin{aligned}
&amp;\overrightarrow{k}_1\cdot \overrightarrow{q}_3=\begin{pmatrix}0\\1\end{pmatrix}  \cdot \begin{pmatrix}1\\2\end{pmatrix} =0\cdot 1 + 1\cdot 2 = 2  \\
&amp;\overrightarrow{k}_2\cdot \overrightarrow{q}_3=\begin{pmatrix}2\\-1\end{pmatrix}\cdot  \begin{pmatrix}1\\2\end{pmatrix} = 2\cdot 1 + (-1)\cdot 2 =0\\
&amp;\overrightarrow{k}_3\cdot \overrightarrow{q}_3= \begin{pmatrix}2\\0.5\end{pmatrix} \cdot  \begin{pmatrix}1\\2\end{pmatrix} = 2\cdot 1 + 0.5 \cdot 2=3\end{aligned}\]</span> Vi bruger softmax på skalarprodukterne for at finde konstanterne <span class="math inline">\(c_{1,3}\)</span>, <span class="math inline">\(c_{2,3}\)</span> og <span class="math inline">\(c_{3,3}\)</span>. <span class="math display">\[\begin{aligned}
c_{1,3} = \frac{e^{\overrightarrow{k}_1\cdot \overrightarrow{q}_3}}{e^{\overrightarrow{k}_1\cdot \overrightarrow{q}_3}+e^{\overrightarrow{k}_2\cdot \overrightarrow{q}_3}+e^{\overrightarrow{k}_3\cdot \overrightarrow{q}_3}} = \frac{e^{2}}{e^{2}+e^{0}+e^{3} }\approx 0.259\\
c_{2,3} = \frac{e^{\overrightarrow{k}_2\cdot \overrightarrow{q}_3}}{e^{\overrightarrow{k}_1\cdot \overrightarrow{q}_3}+e^{\overrightarrow{k}_2\cdot \overrightarrow{q}_3}+e^{\overrightarrow{k}_3\cdot \overrightarrow{q}_3}} = \frac{e^{0}}{e^{2}+e^{0}+e^{3} }\approx 0.035\\
c_{3,3} = \frac{e^{\overrightarrow{k}_3\cdot \overrightarrow{q}_3}}{e^{\overrightarrow{k}_1\cdot \overrightarrow{q}_3}+e^{\overrightarrow{k}_2\cdot \overrightarrow{q}_3}+e^{\overrightarrow{k}_3\cdot \overrightarrow{q}_3}} = \frac{e^{3}}{e^{2}+e^{0}+e^{3} }\approx 0.705\\\end{aligned}\]</span> Nu kan vi beregne <span class="math display">\[\begin{aligned}
\overrightarrow{w}_3 &amp; =c_{1,3}\overrightarrow{v}_1 + c_{2,3}\overrightarrow{v}_2 + c_{3,3}\overrightarrow{v}_3  \\
&amp; = 0.259\begin{pmatrix} -1\\ 1\end{pmatrix} + 0.035\begin{pmatrix} 0.5\\ -1\end{pmatrix} + 0.705\begin{pmatrix} 1\\ 1\end{pmatrix} \\
&amp; =\begin{pmatrix} -0.259\\ 0.259\end{pmatrix} + \begin{pmatrix} 0.0175\\ -0.035\end{pmatrix} + \begin{pmatrix} 0.705\\ 0.705\end{pmatrix} \\
&amp; = \begin{pmatrix} -0.259 +  0.0175 + 0.705\\ 0.259-0.035+0.705 \end{pmatrix}\\
&amp;=\begin{pmatrix} 0.464\\ 0.929 \end{pmatrix}\end{aligned}\]</span> Nedenfor er vektorerne <span class="math inline">\(\overrightarrow{v}_{\text{orkesteret}}\)</span>, <span class="math inline">\(\overrightarrow{v}_{\text{skal}}\)</span>, <span class="math inline">\(\overrightarrow{v}_{\text{spille}}\)</span> og <span class="math inline">\(\overrightarrow{w}_{\text{spille}}\)</span> indtegnet i et koordinatsystem. Det ses at <span class="math inline">\(\overrightarrow{w}_{\text{spille}}\)</span> er blevet trukket i retning af <span class="math inline">\(\overrightarrow{v}_{\text{orkesteret}}\)</span> i forhold til <span class="math inline">\(\overrightarrow{v}_{\text{spille}}\)</span>.</p>
</section>
<section id="opgave" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="opgave">Opgave</h3>
<p>Betragt sætningen "Der svømmer marsvinet". Her har "svømmer" stor betydning for vores opfattelse af ordet "marsvinet", mens "der" ikke giver os ret meget ny information. Lad os sige, at de tre ord har vektorrepræsentationerne <span class="math display">\[\begin{aligned}
&amp;\text{der}&amp;&amp;
\overrightarrow{q}_1 = \begin{pmatrix}0\\-5\end{pmatrix},&amp;&amp; \overrightarrow{k}_1=\begin{pmatrix}4\\-1\end{pmatrix},&amp;&amp;\overrightarrow{v}_1= \begin{pmatrix} -1\\ -1\end{pmatrix}\\
&amp;\text{svømmer}&amp;&amp;
\overrightarrow{q}_2 = \begin{pmatrix}3\\-7\end{pmatrix},&amp;&amp; \overrightarrow{k}_2=\begin{pmatrix}1\\2\end{pmatrix},&amp;&amp;\overrightarrow{v}_2= \begin{pmatrix} -2\\ 2\end{pmatrix}\\
&amp;\text{marsvinet}&amp;&amp;
\overrightarrow{q}_3 = \begin{pmatrix}0\\1\end{pmatrix}, &amp;&amp;\overrightarrow{k}_3=\begin{pmatrix}-1\\2\end{pmatrix},&amp;&amp;\overrightarrow{v}_3= \begin{pmatrix} 1\\ 2\end{pmatrix}\\\end{aligned}\]</span> Vi vil nu se, at den opdaterede vektor <span class="math inline">\(\overrightarrow{w}_3\)</span> for "marsvinet" bliver trukket meget i retning af "svømmer", men i mindre grad i retning af "der".</p>
<ul>
<li><p>Beregn <span class="math inline">\(\overrightarrow{w}_3\)</span> ved at følge nedenstående skridt:</p>
<ul>
<li><p>Beregn skalarprodukterne <span class="math inline">\(\overrightarrow{k}_1\cdot \overrightarrow{q}_3\)</span>, <span class="math inline">\(\overrightarrow{k}_2\cdot \overrightarrow{q}_3\)</span> og <span class="math inline">\(\overrightarrow{k}_3\cdot \overrightarrow{q}_3\)</span>.</p></li>
<li><p>Brug softmax til at beregne konstanterne <span class="math inline">\(c_{1,3}\)</span>, <span class="math inline">\(c_{2,3}\)</span> og <span class="math inline">\(c_{3,3}\)</span>.</p></li>
<li><p>Beregn <span class="math display">\[\overrightarrow{w}_3 = c_{1,3}\overrightarrow{v}_1 + c_{2,3}\overrightarrow{v}_2 + c_{3,3}\overrightarrow{v}_3\]</span></p></li>
</ul></li>
<li><p>Tegn vektorerne <span class="math inline">\(\overrightarrow{v}_1\)</span>, <span class="math inline">\(\overrightarrow{v}_2\)</span>, <span class="math inline">\(\overrightarrow{v}_3\)</span> og <span class="math inline">\(\overrightarrow{w}_3\)</span> ind i et koordinatsystem og overvej, hvordan <span class="math inline">\(\overrightarrow{w}_3\)</span> ligger i forhold til <span class="math inline">\(\overrightarrow{v}_1\)</span>, <span class="math inline">\(\overrightarrow{v}_2\)</span>, <span class="math inline">\(\overrightarrow{v}_3\)</span> og <span class="math inline">\(\overrightarrow{w}_3\)</span>.</p></li>
<li><p>Tegn vektorerne <span class="math inline">\(\overrightarrow{k}_1\)</span>, <span class="math inline">\(\overrightarrow{k}_2\)</span>, <span class="math inline">\(\overrightarrow{k}_3\)</span> og <span class="math inline">\(\overrightarrow{q}_3\)</span> ind i et koordinatsystem. Passer det med, at kontekstvektoren for de ord, der har mest at sige om betydningen af ordet "marsvinet", peger mest i retning af <span class="math inline">\(\overrightarrow{q}_3\)</span>?</p></li>
</ul>
</section>
<section id="en-transformerblok" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="en-transformerblok">En transformerblok</h3>
<p>Man kan lave flere opmærksomhedslag parallelt. Hvis der er <span class="math inline">\(K\)</span> parallelle opmærksomhedslag, så oversætter det <span class="math inline">\(k\)</span>te lag det <span class="math inline">\(i\)</span>te ord til tre vektorer <span class="math inline">\(\overrightarrow{q}^{k}_{i}\)</span>, <span class="math inline">\(\overrightarrow{k}^{k}_{i}\)</span> og <span class="math inline">\(\overrightarrow{v}^{k}_{i}\)</span> og beregner en ny vektor <span class="math inline">\(\overrightarrow{w}^{k}_{i}\)</span>, hvor <span class="math inline">\(k=1,\ldots,K\)</span>. Man kan forestille sig, at de forskellige opmærksomhedslag indfanger forskellige aspekter ved sætningen. Et holder måske styr på grammatikken, mens et andet fokuserer på betydningen af ordene. Men i stedet for at lægge os fast på, hvad hvert lag skal gøre, lader vi det være op til algoritmen selv at vælge nogle passende vektorer. I praksis er det derfor umuligt at gå ind og se præcis, hvad hvert lag gør.</p>
<p>Outputvektorerne <span class="math inline">\(\overrightarrow{w}^{k}_i\)</span> fra de forskellige lag sættes i forlængelse af hinanden til en samlet outputvektor <span class="math inline">\(\overrightarrow{x}_i\)</span> af længde <span class="math inline">\(Km\)</span>. Som det næste køres <span class="math inline">\(\overrightarrow{x}_i\)</span> gennem et neuralt netværk, ligesom vi så i noten "Tekstgenerering med neurale netværk", bortset fra at vi ikke bruger softmax til sidst. Det vil sige, at koordinaterne i <span class="math inline">\(\overrightarrow{x}_i\)</span> bruges som input i det neurale netværk. Outputtet bliver en ny vektor <span class="math inline">\(\overrightarrow{y}_i\)</span>.</p>
<p>Tilsammen udgør de parallelle opmærksomhedslag og det efterfølgende neurale netværk en <em>transformerblok</em>. Strukturen er skitseret på Figur <a href="#fig:transformerblok" data-reference-type="ref" data-reference="fig:transformerblok">[fig:transformerblok]</a>. Undervejs sker der forskellige transformationer af vektorerne, som viser sig at gøre de numeriske beregninger mere stabile. Vi vil ikke beskrive disse i detaljer, da de ikke er centrale for forståelsen.</p>
</section>
<section id="transformernetværket" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="transformernetværket">Transformernetværket</h3>
<p>Når vi så har beregnet outputvektorerne <span class="math inline">\(\overrightarrow{y}_i\)</span> fra en transformerblok for alle positioner <span class="math inline">\(i\)</span>, kan vi bruge dem som input til en ny transformerblok. I hvert opmærksomhedslag inden for den næste transformerblok oversættes vektoren <span class="math inline">\(\overrightarrow{y}_i\)</span> (ikke det oprindelige ord) til tre nye vektorer. Så beregner transformerblokken en ny <span class="math inline">\(\overrightarrow{y}_i\)</span>, som kan bruges som input til endnu en transformerblok og så videre. Tilsammen udgør disse transformerblokke et <em>transformernetværk</em>, som er skitseret på Figur <a href="#fig:transformer" data-reference-type="ref" data-reference="fig:transformer">[fig:transformer]</a>.</p>
<p>Egentlig var vi jo ude på at lave en algoritme, der kan gætte det næste ord, altså det <span class="math inline">\((i+1)\)</span>ste ord. Det sker i den sidste prædiktionsblok i transformernetværket, se Figur <a href="#fig:transformer" data-reference-type="ref" data-reference="fig:transformer">[fig:transformer]</a>. Den tager vektoren <span class="math inline">\(\overrightarrow{y}_i\)</span>, der kommer ud fra den sidste transformerblok, og omregner den for hvert ord i ordforrådet til en sandsynlighed for, at det ord er det næste.</p>
<p>For hvert ord i ordforrådet udregner vi først en score <span class="math inline">\(s_{\text{ord}}\)</span>, der måler, hvor sandsynligt det er, at ordet er det næste. Store værdier betyder, at ordet er sandsynligt som næste ord. Til at beregne scoren bruger vi en fast vektor <span class="math inline">\(\overrightarrow{a}_{\text{ord}}\)</span> for hvert ord og omregner <span class="math inline">\(\overrightarrow{y}_i\)</span> til scoren <span class="math display">\[s_{\text{ord}} = \overrightarrow{a}_{\text{ord}}\cdot \overrightarrow{y}_i\]</span> Disse scores samles i en vektor <span class="math inline">\(\overrightarrow{s}\)</span> med <span class="math inline">\(V\)</span> koordinater, hvor <span class="math inline">\(V\)</span> var antallet af ord i ordforrådet. Endelig omdannes <span class="math inline">\(\overrightarrow{s}\)</span> til en vektor af sandsynligheder ved endnu engang at bruge softmax-funktionen (se "Tekstgenerering med neurale netværk" LINK). <span class="math display">\[\overrightarrow{p} = \text{Softmax}(\overrightarrow{s})\]</span> Når man har disse sandsynligheder, kan man begynde at generere tekst, fx ved hele tiden at vælge det mest sandsynlige næste ord.</p>
</section>
</section>
<section id="træning-af-netværket" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="træning-af-netværket">Træning af netværket</h2>
<p>I alt indeholder transformernetværket rigtig mange vægte, der skal bestemmes, før vi kan begynde at generere tekst. Hvert opmærksomhedslag skal bruge vægte til at lave koordinaterne i de tre forskellige vektorer. Hver transformerblok indeholder desuden et neuralt netværk, som skal bruge et sæt af vægte. Endelig skal der i det sidste trin bruges <span class="math inline">\(V\)</span> vektorer på formen <span class="math inline">\(\overrightarrow{a}_{\text{ord}}\)</span>.</p>
<p>Den præcise struktur af GPT-4 netværket, som er fundamentet for Chat-GPT, er en forretningshemmelighed. En tidligere version, GPT-2, brugte 12 transformerblokke med 12 parallelle opmærksomhedslag i hvert, altså 144 opmærksomhedslag i alt. I alt havde GPT-2 omkring 1,5 milliarder vægte. Det er dog intet mod GPT-4, der vurderes at have omkring 1 billion vægte.</p>
<p>For at bestemme så mange vægte skal der bruges enorme mængder træningsdata. Til at træne GPT-2 blev der fx brugt 8 millioner dokumenter. I træningsdata kender vi hele tiden det næste ord. For at måle hvor godt det passer med de sandsynligheder for næste ord, som transformeren giver, beregnes en cross-entropy tabsfunktion, se (LINK). Transformeren trænes til at minimere denne cross-entropy, således at den er god til at forudsige næste ord i træningsdata. Når transformeren er trænet, bliver den som regel fintunet til den opgave, den skal udføre, fx at oversætte en tekst eller besvare et spørgsmål.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/aimat\.dk");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>