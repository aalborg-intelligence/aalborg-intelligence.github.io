<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.33">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="Denne note handler om, hvordan de vektorer, som repræsenterer hvert enkelt ord i vores ordforråd, kan bruges som input i et kunstigt neuralt netværk, der kan bruges til at prædiktere det næste ord i en sætning.">

<title>Tekstgenerering med neurale netværk – AI MAT - matematikken bag magien</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../logo/SVG/Bomaerke_05_AIMAT_2024.svg" rel="icon" type="image/svg+xml">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-ea385d0e468b0dd5ea5bf0780b1290d9.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-1e0da696844436e9ae95f09da2421ece.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-Y219BCPS45"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
 
  gtag('consent', 'default', {
    'ad_storage': 'denied',
    'analytics_storage': 'denied'
  });
gtag('config', 'G-Y219BCPS45', { 'anonymize_ip': true});
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="floating nav-fixed slimcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../logo/PNG/Logo_multi_AIMAT_RGB_2024.png" alt="" class="navbar-logo">
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../undervisningsforlob/index.html"> 
<span class="menu-text">Undervisningsforløb</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../materialer/index.html"> 
<span class="menu-text">Materialer</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../sro/index.html"> 
<span class="menu-text">SRO</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../srp/index.html"> 
<span class="menu-text">SRP</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../apps/index.html"> 
<span class="menu-text">Apps</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../referencer/index.html"> 
<span class="menu-text">Referencer</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">Om os</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://www.youtube.com/@ai-mat"> 
<span class="menu-text"><img src="../../logo/YouTube/youtube-color-darkblue-icon.svg" style="height:2em"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Indhold</h2>
   
  <ul>
  <li><a href="#træning-af-netværket" id="toc-træning-af-netværket" class="nav-link active" data-scroll-target="#træning-af-netværket">Træning af netværket</a></li>
  <li><a href="#tekstgenerering" id="toc-tekstgenerering" class="nav-link" data-scroll-target="#tekstgenerering">Tekstgenerering</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Tekstgenerering med neurale netværk</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Vi har set, hvordan man kan få repræsenteret alle ord i ordforrådet som vektorer med <a href="../../materialer/sprogmodeller/word2vec.html">Word2Vec</a>. Næste skridt er at bruge disse vektorer til at generere tekst. I denne note ser vi på, hvordan det for eksempel kan gøres ved hjælp af <em>neurale netværk</em>. I praksis foretages tekstgenerering som regel ved hjælp af en særlig smart algoritme kaldet <em>transformeren</em>, der i en vis forstand laver Word2Vec og neurale netværk på én gang. Når du har læst denne note, kan du læse videre om <a href="">tranformeren her</a>.</p>
<p>Vi vil gerne kunne generere en tekst ét ord ad gangen. Lad os som eksempel sige, at vi har fået lavet sætningen</p>
<div class="llm_saetninger">
<p>"En hund og en kat —"</p>
</div>
<p>og skal generere næste ord. Lige som med <a href="../../materialer/sprogmodeller/simple.html#n-gram-sprogmodeller"><span class="math inline">\(N\)</span>-grams</a> gør vi det lidt simplere ved kun at kigge på de sidste <span class="math inline">\(N-1\)</span> ord i sætningen. Vi vil sætte <span class="math inline">\(N=4\)</span> i denne note, så vi gætter næste ord på baggrund af de 3 foregående. I praksis ville man bruge et større <span class="math inline">\(N\)</span>. I eksemplet skal vi så gætte næste ord efter "og en kat". Til det bruger vi et neuralt netværk, som er en slags funktion, der tager de tre seneste ord som input. Som output giver netværket for hvert ord i ordforrådet en sandsynlighed for, at det er det næste ord.</p>
<p>I eksemplet er vores input til det neurale netværk altså "og en kat". For hvert af de tre ord, har vi lavet en vektorrepræsentation med <a href="../../materialer/sprogmodeller/word2vec.html">Word2Vec</a>. Hvis vektorerne fra Word2Vec har <span class="math inline">\(m\)</span> koordinater, samler vi de tre vektorer i én vektor <span class="math inline">\(\vec{x}\)</span> med <span class="math inline">\(3m\)</span> koordinater, hvor de første <span class="math inline">\(m\)</span> koordinater er vektoren for "og", de næste <span class="math inline">\(m\)</span> koordinater er vektoren for "en", og de sidste <span class="math inline">\(m\)</span> koordinater er vektoren for "kat". Hvis for eksempel vores vektorer for "og", "en" og "kat" er <span class="math display">\[
\vec{v}_{\text{og}}=\begin{pmatrix} 2\\1 \end{pmatrix}, \quad \vec{v}_{\text{en}}=\begin{pmatrix} -1\\3 \end{pmatrix}, \quad \vec{v}_{\text{kat}}=\begin{pmatrix} 7\\-4 \end{pmatrix}
\]</span> så er vores input til det neurale netværk vektoren <span class="math display">\[
\vec{x} =\begin{pmatrix} 2\\1 \\-1\\ 3\\ 7\\ -4 \end{pmatrix}
\]</span> Denne vektor indeholder både informationen fra Word2Vec og information om rækkefølgen af de tre ord, som svarer til rækkefølgen, de tre vektorer er sat ind i <span class="math inline">\(\vec{x}\)</span>.</p>
<p>Output fra det neurale netværk skal være en vektor <span class="math display">\[
\vec{z}=\begin{pmatrix} z_1\\ \vdots \\ z_V\end{pmatrix}
\]</span> med <span class="math inline">\(V\)</span> koordinater, hvor <span class="math inline">\(V\)</span> er antallet af ord i vores ordforråd. Vi forestiller os, at vi har nummereret alle ord i ordforrådet. Den <span class="math inline">\(i\)</span>’te koordinat i <span class="math inline">\(\vec{z}\)</span> hører sammen med det <span class="math inline">\(i\)</span>’te ord, som vi vil kalde "ord<span class="math inline">\(_i\)</span>". Den <span class="math inline">\(i\)</span>’te koordinat i <span class="math inline">\(\vec{z}\)</span> skal give sandsynligheden for, at "ord<span class="math inline">\(_i\)</span>" er det næste ord efter "og en kat". Med andre ord, <span class="math display">\[
z_i=P(\text{ord}_i \text{ } |\text{ "og en kat" })
\]</span></p>
<p>En god outputvektor <span class="math inline">\(\vec{z}\)</span> skal opfylde følgende:</p>
<div class="highlight2">
<ul>
<li><p>Alle koordinater skal være sandsynligheder, så <span id="eq-betingelse1"><span class="math display">\[0\leq z_i\leq 1 \tag{1}\]</span></span> for alle <span class="math inline">\(i\)</span>.</p></li>
<li><p>Summen af alle sandsynlighederne skal give 1, altså <span id="eq-betingelse2"><span class="math display">\[z_1+\dotsm + z_V=1 \tag{2}\]</span></span><br>
da det er den samlede sandsynlighed for at få et af de mulige ord.</p></li>
<li><p>Hvis "ord<span class="math inline">\(_i\)</span>" er et godt bud på et ord, der følger efter "og en kat", skal <span class="math inline">\(z_i\)</span> være tæt på <span class="math inline">\(1\)</span> (der er i praksis mange ord, som er gode bud og summen af sandsynlighederne skal give <span class="math inline">\(1\)</span>, så <span class="math inline">\(z_i\)</span> bliver ikke <span class="math inline">\(1\)</span>).</p></li>
<li><p>Hvis ord<span class="math inline">\(_i\)</span> er et dårligt bud på næste ord, skal <span class="math inline">\(z_i\)</span> være tæt på <span class="math inline">\(0\)</span>.</p></li>
</ul>
</div>
<p>&nbsp;</p>
<p>Vores neurale netværk skal altså være en funktion, der tager vektoren <span class="math inline">\(\vec{x}\)</span> som input og giver vektoren <span class="math inline">\(\vec{z}\)</span> som output. Funktionen dannes ved at sammensætte en masse simplere funktioner. For at holde overblik kan man skitsere det neurale netværk som i <a href="#fig-NN_tekst" class="quarto-xref">figur&nbsp;1</a>.</p>
<div id="fig-NN_tekst" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-NN_tekst-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/NN_tekstgenerering.png" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-NN_tekst-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figur&nbsp;1: Kunstigt neuralt netværk som kan bruges til tekstgenerering.
</figcaption>
</figure>
</div>
<p>Vores input er vektoren <span class="math inline">\(\vec{x}\)</span>, der har <span class="math inline">\(3m\)</span> koordinater. Disse koordinater svarer til de grønne cirkler i venstre side af figuren kaldet <em>inputlaget</em>. De lyserøde cirkler i midten angiver <em>det skjulte lag</em><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. Her omregnes <span class="math inline">\(\vec{x}\)</span> til en ny vektor <span class="math inline">\(\vec{h}\)</span> med <span class="math inline">\(d\)</span> koordinater, hvor <span class="math inline">\(d\)</span> er et tal, vi har valgt. Hver koordinat i <span class="math inline">\(\vec{h}\)</span> svarer til en af de lyserøde cirkler i midten, og pilene i venstre side angiver, at hver koordinat i <span class="math inline">\(\vec{h}\)</span> er en funktion af koordinaterne i <span class="math inline">\(\vec{x}\)</span>. Mere præcist beregnes koordinaterne i <span class="math inline">\(\vec{h}\)</span> ved: <span class="math display">\[
\begin{aligned}
h_1&amp;=f(w_{1,0}+w_{1,1}x_1+w_{1,2}x_2+\ldots +w_{1,3m}x_{3m})\\
&amp;\vdots\\
h_j&amp;=f(w_{j,0}+w_{j,1}x_1+w_{j,2}x_2+\ldots +w_{j,3m}x_{3m})\\
&amp;\vdots\\
h_{d}&amp;=f(w_{d,0}+w_{d,1}x_1+w_{d,2}x_2+\ldots +w_{d,3m}x_{3m})\\\end{aligned}
\]</span></p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;Man kan gøre sit neurale netværk mere fleksibelt ved at have flere skjulte lag. For at holde forklaringen simpel vil vi dog kun gennemgå tilfældet med ét skjult lag her.</p></div></div><p>Funktionen <span class="math inline">\(f\)</span>, der indgår, er en <em>aktiveringsfunktion</em>. Man kan for eksempel bruge sigmoid-funktionen <span class="math display">\[
f(x)=\frac{1}{1+\mathrm{e}^{-x}}
\]</span> Du kan læse mere om <a href="../../undervisningsforlob/aktiveringsfunktioner.html">aktiveringsfunktioner her</a>. Desuden indgår der <span class="math inline">\(d \cdot (3m+1)\)</span> <em>vægte</em> på formen <span class="math inline">\(w_{j,k}\)</span>. Vægtene er reelle konstanter. Når vi om lidt træner det neurale netværk, forsøger vi at bestemme værdien af disse vægte.</p>
<p>De mørkeblå cirkler til højre i <a href="#fig-NN_tekst" class="quarto-xref">figur&nbsp;1</a> udgør <em>outputlaget</em>. I outputlaget laves vektoren <span class="math inline">\(\vec{h}\)</span> om til outputvektoren <span class="math inline">\(\vec{z}\)</span> med <span class="math inline">\(V\)</span> koordinater svarende til cirklerne til højre. Igen viser pilene, at hver koordinat i <span class="math inline">\(\vec{z}\)</span> er en funktion af koordinaterne i <span class="math inline">\(\vec{h}\)</span>. Funktionen udregnes i to trin:</p>
<ul>
<li><p>Først udregner vi en vektor <span class="math inline">\(\vec{y}\)</span> med <span class="math inline">\(V\)</span> koordinater, hvor <span class="math inline">\(i\)</span>’te koordinat er <span class="math display">\[
y_i=u_{i,0}+u_{i,1}h_1+u_{i,2}h_2+\ldots + u_{i,d}h_{d}
\]</span> Igen indgår der nogle vægte <span class="math inline">\(u_{i,j}\)</span>. Dem er der i alt <span class="math inline">\((d+1)\cdot V\)</span> af.</p></li>
<li><p>Derefter laver vi <span class="math inline">\(\vec{y}\)</span> om til sandsynligheder. Det gør vi ved at bruge softmax-funktionen, som blev introduceret i <a href="../../materialer/sprogmodeller/word2vec.html">noten om Word2Vec</a>. Softmax-funktionen tager en <span class="math inline">\(V\)</span>-dimensional vektor <span class="math inline">\(\vec{y}\)</span> som input og giver en ny <span class="math inline">\(V\)</span>-dimensional vektor <span class="math inline">\(\vec{z}=\text{Softmax}(\vec{y})\)</span> som output. Den <span class="math inline">\(i\)</span>’te koordinat i <span class="math inline">\(\vec{z}\)</span> udregnes som <span class="math display">\[
z_i=\frac{\mathrm{e}^{y_i}}{\mathrm{e}^{y_1} + \dotsm + \mathrm{e}^{y_V}}
\]</span> Vi så i <a href="../../materialer/sprogmodeller/word2vec.html">Word2Vec-noten</a>, at <span class="math inline">\(\vec{z}\)</span> opfylder (<a href="#eq-betingelse1" class="quarto-xref">1</a>) og (<a href="#eq-betingelse2" class="quarto-xref">2</a>), således at det giver mening at tænke på <span class="math inline">\(\vec{z}\)</span> som en vektor af sandsynligheder. Dette <span class="math inline">\(\vec{z}\)</span> er vores outputvektor.</p></li>
</ul>
<p>Samlet set er der ret mange vægte i modellen. Der er <span class="math inline">\(d\cdot (3m+1)\)</span> vægte i det skjulte lag og <span class="math inline">\((d+1)\cdot V\)</span> vægte i ouputlaget. I alt bliver det <span class="math inline">\(d\cdot(1+3m +V) +V\)</span> vægte.</p>
<p>Hvis vi tager et meget simpelt eksempel, hvor alle ord repræsenteres ved en 3-dimensional vektor (<span class="math inline">\(m=3\)</span>), vi har et ordforråd på <span class="math inline">\(V=2000\)</span> ord og vi vælger, at der skal være <span class="math inline">\(d=50\)</span> neuroner i det skjulte lag, så får vi i alt</p>
<p><span class="math display">\[
d\cdot(1+3m +V) +V = 50 \cdot (1 + 3 \cdot 3+2000) + 2000 =102500
\]</span></p>
<p>vægte! Det samlede antal vægte bliver altså hurtigt meget, meget stort.</p>
<p>Læg mærke til, at valget af <span class="math inline">\(d\)</span> er det, der bestemmer antallet af vægte: <span class="math inline">\(m\)</span> var fastlagt da vi lavede Word2Vec, <span class="math inline">\(V\)</span> er antallet af ord i vores ordforråd, og 3-tallet er antal ord, vi prædikterer udfra. Valget af <span class="math inline">\(d\)</span> er i praksis et kompromis. Jo større <span class="math inline">\(d\)</span> er, des mere præcis en model kan vi lave. Omvendt bliver der også flere vægte, der skal bestemmes. Det kræver stor regnekraft. Desuden kræver det meget træningsdata, hvis man vil undgå overfitting - et problem, som du kan læse mere om <a href="../../materialer/krydsvalidering/krydsvalidering.html">i noten om krydsvalidering</a>.</p>
<p><br>
</p>
<section id="træning-af-netværket" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="træning-af-netværket">Træning af netværket</h2>
<p>Som sagt indgår der ret mange vægte i modellen. Indtil nu har vi ikke sagt, hvilken værdi disse vægte skal have. Husk på, at vores neurale netværk skal give os sandsynligheden for, at et ord er næste ord i en sætning, når vi kender de 3 foregående ord. For at lære, hvilket ord der typisk kommer efter tre givne ord i virkelige tekster, får vi endnu engang brug for noget træningsdata i form af vores store tekstkorpus. Ud fra dette tekstkorpus laver vi et datasæt bestående af alle 4-gram, det vil sige alle sekvenser på 4 ord, der forekommer i teksten. De tre første ord kalder vi input, og det sidste kalder vi <em>target</em>.</p>
<p>Hvis for eksempel vores træningsdata består af sætningen</p>
<div class="llm_saetninger">
<p>"Solen skinner, og en kat løber på græsplænen."</p>
</div>
<p>så laver vi en datatabel<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> som i <a href="#tbl-data" class="quarto-xref">tabel&nbsp;1</a>.</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;Vi ignorerer tegnsætning.</p></div></div><div id="tbl-data" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-tbl figure page-columns page-full">
<div aria-describedby="tbl-data-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Input 1</th>
<th style="text-align: center;">Input 2</th>
<th style="text-align: center;">Input 3</th>
<th style="text-align: center;">Target</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\vdots\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\vdots\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\vdots\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\vdots\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: center;">Solen</td>
<td style="text-align: center;">skinner</td>
<td style="text-align: center;">og</td>
</tr>
<tr class="odd">
<td style="text-align: center;">skinner</td>
<td style="text-align: center;">og</td>
<td style="text-align: center;">en</td>
<td style="text-align: center;">kat</td>
</tr>
<tr class="even">
<td style="text-align: center;">og</td>
<td style="text-align: center;">en</td>
<td style="text-align: center;">kat</td>
<td style="text-align: center;">løber</td>
</tr>
<tr class="odd">
<td style="text-align: center;">en</td>
<td style="text-align: center;">kat</td>
<td style="text-align: center;">løber</td>
<td style="text-align: center;">på</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\vdots\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\vdots\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\vdots\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\vdots\)</span></td>
</tr>
</tbody>
</table>
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-tbl margin-caption" id="tbl-data-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tabel&nbsp;1: Træningsdata.
</figcaption>
</figure>
</div>
<p>Hvis vores neurale netværk er valgt godt, skal det gerne give en høj sandsynlighed for targetordet, når vi giver de tre inputord som input. Vi forsøger derfor at vælge vægtene i det neurale netværk, så netværket giver en høj sandsynlighed for targetordet. Når vi bestemmer vægtene, så de passer til træningsdata, siger vi, at vi <em>træner</em> det neurale netværk.</p>
<p>Lad os se på en enkelt række i datasættet, for eksempel den der svarer til sekvensen "og en kat løber". Vores inputord er "og", "en" og "kat". Dem oversætter vi til vektoren <span class="math inline">\(\vec{x}\)</span> ved at bruge ordenes Word2Vec-vektorer som beskrevet ovenfor. Output fra det neurale netværk er en vektor <span class="math inline">\(\vec{z}\)</span>, hvis <span class="math inline">\(i\)</span>’te koordinat giver sandsynligheden for, at det <span class="math inline">\(i\)</span>’te ord i ordforrådet er det næste ord. Hvis vi udelukkende ser på sekvensen "og en kat løber", og ignorerer alle de andre sekvenser i træningsdata, så skal "løber" have sandsynligheden 1, og alle andre ord skal have sandsynligheden 0. Vektoren med <span class="math inline">\(1\)</span> i den koordinat, der svarer til det korrekte ord, og <span class="math inline">\(0\)</span> i alle andre koordinater kaldes <em>targetvektoren</em> <span class="math inline">\(\vec{t}\)</span>.</p>
<p>I praksis rammer vores sandsynlighedsvektor <span class="math inline">\(\vec{z}\)</span> aldrig target <span class="math inline">\(\vec{t}\)</span> præcist, fordi der også skal tages højde for de andre sekvenser i datasættet. Det kunne for eksempel være, at sekvensen "og en kat spiser" også forekommer et sted i træningsdata. I så fald skal "spiser" også have høj sandsynlighed.</p>
<p>I det mindste vil vi gerne have, at <span class="math inline">\(\vec{z}\)</span> kommer tæt på targetvektoren <span class="math inline">\(\vec{t}\)</span>. Vi måler, hvor langt vi er fra target med en <a href="../../materialer/tabsfunktioner/tabsfunktioner.html">tabsfunktion</a>. Den tabsfunktion, vi vil bruge her, kaldes <em>cross-entropy</em>. Med output <span class="math inline">\(\vec{z}\)</span> og targetvektor <span class="math inline">\(\vec{t}\)</span>, er cross-entropy givet ved</p>
<p><span class="math display">\[
CE(\vec{z},\vec{t})=-t_1\ln(z_1)-t_2\ln(z_2)- \cdots  -t_V\ln(z_V)
\]</span></p>
<p>Targetvektoren er <span class="math inline">\(0\)</span> på alle koordinater undtagen den, der svarer til det korrekte ord, så alle andre led i summen er 0. Lad os sige, det korrekte ord har nummeret <span class="math inline">\(c\)</span> i vores ordforråd, så <span class="math inline">\(t_c=1\)</span> og <span class="math inline">\(t_j=0\)</span> for alle <span class="math inline">\(j\neq c\)</span>. Så er <span class="math inline">\(CE(\vec{z},\vec{t})=-\ln(z_c)\)</span>. Da <span class="math inline">\(z_c\)</span> er sandsynligheden for, at vores targetord er det næste, vil vi gerne have, at <span class="math inline">\(z_c\)</span> er så stor som muligt. Da den naturlige logaritme er en voksende funktion, svarer det til, at <span class="math inline">\(CE(\vec{z},\vec{t})=-\ln(z_c)\)</span> skal være så lille som muligt. Dette er illustreret i <a href="#fig-natural_ln" class="quarto-xref">figur&nbsp;2</a>, hvor vi tegnet grafen for den naturlige logaritme-funktion samt grafen for minus den naturlige logartime-funktion (husk på at <span class="math inline">\(0&lt;z_c&lt;1\)</span>):</p>
<div id="fig-natural_ln" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-natural_ln-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../softmax/images/natural_ln.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:50.0%">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-natural_ln-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figur&nbsp;2: Grafen for <span class="math inline">\(\ln(x)\)</span> og <span class="math inline">\(-\ln(x)\)</span>.
</figcaption>
</figure>
</div>
<p>Dette gentager vi nu for hver eneste række i vores træningsdata. Vi beregner en cross-entropy for hver. Til sidst lægger vi alle disse cross-entropy sammen til en samlet tabsfunktion <span class="math inline">\(L\)</span>, som helst skal være så lille som muligt. Vi har udregnet <span class="math inline">\(L\)</span> udfra vores træningsdata og vægtene. Træningsdata er det, vi går ud fra, vi ved, så det kan vi ikke lave om på for at minimere <span class="math inline">\(L\)</span>. Derfor betragter vi nu <span class="math inline">\(L\)</span> som en funktion af vægtene <span class="math inline">\(w_{j,k}\)</span> og <span class="math inline">\(u_{i,j}\)</span>. Vi ønsker at bestemme vægtene således, at <span class="math inline">\(L\)</span> bliver mindst mulig svarende til, at vores sandsynligheder kommer så tæt på target som muligt. Vi skal altså finde minimum for en funktion af mange variable. Det kan man for eksempel gøre ved hjælp af <a href="../../materialer/gradientnedstigning/gradientnedstigning.html">gradientnedstigning</a>. For at lave gradientnedstigning er det vigtigt at kunne finde de partielt afledte af <span class="math inline">\(L\)</span>. En smart måde at lave gradientnedstigning på kaldes <em>backpropagation</em>. Et simpelt eksempel på backpropagation findes i noten om <a href="../../materialer/simple_neurale_net/simple_neurale_net.html">simple neurale net</a>.</p>
</section>
<section id="tekstgenerering" class="level2">
<h2 class="anchored" data-anchor-id="tekstgenerering">Tekstgenerering</h2>
<p>Las os sige, at vi har fået trænet vores neurale netværk. Det vil sige, at vi har bestemt de vægte, der skal indgå. Så er vores neurale netværk en fastlagt funktion. Når vi giver netværket en inputvektor <span class="math inline">\(\vec{x}\)</span>, beregner det en outputvektor <span class="math inline">\(\vec{z}\)</span> af sandsynligheder ved brug af de valgte vægte.</p>
<p>Vi kan nu gå i gang med at generere tekst. Lad os sige, at vi har dannet de første ord i en sætning. Det kunne være</p>
<div class="llm_saetninger">
<p>"En hund og en kat —"</p>
</div>
<p>Vi tager de <span class="math inline">\(3\)</span> sidste ord "og", "en" og "kat" og oversætter dem til en vektor <span class="math inline">\(\vec{x}\)</span>. Denne vektor giver vi som input til det neurale netværk. For hvert ord i ordforrådet beregner det neurale netværk sandsynligheden for, at det er det næste ord. Det kan være, at "løber" får sandsynligheden <span class="math inline">\(1/2\)</span>, "spiser" får sandsynligheden <span class="math inline">\(1/3\)</span>, mens alle andre ord får meget små sandsynligheder. En mulighed er så at vælge det mest sandsynlige ord som det næste. Det ville være "løber" i vores eksempel. Det viser sig dog, at det giver for lidt variation i de sætninger, der dannes. I stedet kan man vælge et tilfældigt næste ord ud fra deres sandsynligheder. I vores eksempel ville vi vælge "løber" med sandsynlighed <span class="math inline">\(1/2\)</span>, "spiser" med sandsynlighed <span class="math inline">\(1/3\)</span>, og så videre.</p>


</section>


</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/aimat\.dk");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>