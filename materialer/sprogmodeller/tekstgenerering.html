<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.43">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>tekstgenerering – AI MAT - matematikken bag magien</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../logo/SVG/Bomaerke_05_AIMAT_2024.svg" rel="icon" type="image/svg+xml">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-d4d76bf8491c20bad77d141916dc28e1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-f566325cf577907e9eaf893566fd6138.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-Y219BCPS45"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
 
  gtag('consent', 'default', {
    'ad_storage': 'denied',
    'analytics_storage': 'denied'
  });
gtag('config', 'G-Y219BCPS45', { 'anonymize_ip': true});
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../logo/PNG/Logo_multi_AIMAT_RGB_2024.png" alt="" class="navbar-logo">
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../undervisningsforlob.html"> 
<span class="menu-text">Undervisningsforløb</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../materialer.html"> 
<span class="menu-text">Materialer</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../sro.html"> 
<span class="menu-text">SRO</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../srp.html"> 
<span class="menu-text">SRP</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../apps.html"> 
<span class="menu-text">Apps</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../referencer.html"> 
<span class="menu-text">Referencer</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">Om os</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://www.youtube.com/@ai-mat"> 
<span class="menu-text"><img src="../../logo/YouTube/youtube-color-darkblue-icon.svg" style="height:2em"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Indhold</h2>
   
  <ul>
  <li><a href="#tekstgenerering-med-neurale-netværk" id="toc-tekstgenerering-med-neurale-netværk" class="nav-link active" data-scroll-target="#tekstgenerering-med-neurale-netværk">Tekstgenerering med neurale netværk</a>
  <ul class="collapse">
  <li><a href="#træning-af-netværket" id="toc-træning-af-netværket" class="nav-link" data-scroll-target="#træning-af-netværket">Træning af netværket</a></li>
  <li><a href="#tekstgenerering" id="toc-tekstgenerering" class="nav-link" data-scroll-target="#tekstgenerering">Tekstgenerering</a></li>
  </ul></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="tekstgenerering-med-neurale-netværk" class="level1 unnumbered">
<h1 class="unnumbered">Tekstgenerering med neurale netværk</h1>
<p>Vi har set, hvordan man kan få repræsenteret alle ord i ordforrådet som vektorer med Word2Vec. Næste skridt er at bruge disse vektorer til at generere tekst. I denne note ser vi på, hvordan det for eksempel kan gøres ved hjælp af <em>neurale netværk</em>. I praksis foretages tekstgenerering som regel ved hjælp af en særlig smart algoritme kaldet <em>transformeren</em>, der i en vis forstand laver Word2Vec og neurale netværk på én gang. Når du har læst denne note, kan du læse videre om tranformeren her LINK.</p>
<p>Vi vil gerne kunne generere en tekst ét ord ad gangen. Lad os som eksempel sige, at vi har fået lavet sætningen <span class="math display">\[
\text{"En hund og en kat ---"}
\]</span> og skal generere næste ord. Lige som med <span class="math inline">\(N\)</span>-grams LINK gør vi det lidt simplere ved kun at kigge på de sidste <span class="math inline">\(N-1\)</span> ord i sætningen. Vi vil sætte <span class="math inline">\(N=4\)</span> i denne note, så vi gætter næste ord på baggrund af de 3 foregående. I praksis ville man bruge et større <span class="math inline">\(N\)</span>. I eksemplet skal vi så gætte næste ord efter "og en kat". Til det bruger vi et neuralt netværk, som er en slags funktion, der tager de tre seneste ord som input. Som output giver netværket for hvert ord i ordforrådet en sandsynlighed for, at det er det næste ord.</p>
<p>I eksemplet er vores input til det neurale netværk altså "og en kat". For hvert af de tre ord, har vi lavet en vektorrepræsentation med Word2Vec. Hvis vektorerne fra Word2Vec har <span class="math inline">\(m\)</span> koordinater, samler vi de tre vektorer i én vektor <span class="math inline">\(\overrightarrow{x}\)</span> med <span class="math inline">\(3m\)</span> koordinater, hvor de første <span class="math inline">\(m\)</span> koordinater er vektoren for "og", de næste <span class="math inline">\(m\)</span> koordinater er vektoren for "en", og de sidste <span class="math inline">\(m\)</span> koordinater er vektoren for "kat". Hvis fx vores vektorer for "og", "en" og "kat" er <span class="math display">\[
\overrightarrow{v}_{\text{og}}=\begin{pmatrix} 2\\1 \end{pmatrix}, \quad \overrightarrow{v}_{\text{en}}=\begin{pmatrix} -1\\3 \end{pmatrix}, \quad \overrightarrow{v}_{\text{kat}}=\begin{pmatrix} 7\\-4 \end{pmatrix}
\]</span> så er vores input til det neurale netværk vektoren <span class="math display">\[
\overrightarrow{x} =\begin{pmatrix} 2\\1 \\-1\\ 3\\ 7\\ -4 \end{pmatrix}
\]</span> Denne vektor indeholder både informationen fra Word2Vec og information om rækkefølgen af de tre ord, som svarer til rækkefølgen, de tre vektorer er sat ind i <span class="math inline">\(\overrightarrow{x}\)</span>.</p>
<p>Output fra det neurale netværk skal være en vektor <span class="math display">\[
\overrightarrow{z}=\begin{pmatrix} z_1\\ \vdots \\ z_V\end{pmatrix}
\]</span> med <span class="math inline">\(V\)</span> koordinater, hvor <span class="math inline">\(V\)</span> er antallet af ord i vores ordforråd. Vi forestiller os, at vi har nummereret alle ord i ordforrådet. Den <span class="math inline">\(i\)</span>te koordinat i <span class="math inline">\(\overrightarrow{z}\)</span> hører sammen med det <span class="math inline">\(i\)</span>te ord, som vi vil kalde "ord<span class="math inline">\(_i\)</span>". Den <span class="math inline">\(i\)</span>te koordinat i <span class="math inline">\(\overrightarrow{z}\)</span> skal give sandsynligheden for, at "ord<span class="math inline">\(_i\)</span>" er det næste ord efter "og en kat". Med andre ord, <span class="math display">\[
z_i=P(\text{ord}_i|\text{ "og en kat" })
\]</span></p>
<p>En god outputvektor <span class="math inline">\(\overrightarrow{z}\)</span> skal opfylde følgende.</p>
<ul>
<li><p>Alle koordinater skal være sandsynligheder, så <span class="math inline">\(0\leq z_i\leq 1\)</span> for alle <span class="math inline">\(i\)</span>.</p></li>
<li><p>Summen af alle sandsynlighederne skal give 1, altså <span class="math inline">\(z_1+\dotsm + z_V=1\)</span>, da det er den samlede sandsynlighed for at få et af de mulige ord.</p></li>
<li><p>Hvis "ord<span class="math inline">\(_i\)</span>" er et godt bud på et ord, der følger efter "og en kat", skal <span class="math inline">\(z_i\)</span> være tæt på <span class="math inline">\(1\)</span>. FODNOTE: Der er i praksis mange ord, som er gode bud og summen af sandsynlighederne skal give <span class="math inline">\(1\)</span>, så <span class="math inline">\(z_i\)</span> bliver ikke <span class="math inline">\(1\)</span>.</p></li>
<li><p>Hvis ord<span class="math inline">\(_i\)</span> er et dårligt bud på næste ord, skal <span class="math inline">\(z_i\)</span> være tæt på <span class="math inline">\(0\)</span>.</p></li>
</ul>
<p>Vores neurale netværk skal altså være en funktion, der tager vektoren <span class="math inline">\(\overrightarrow{x}\)</span> som input og giver vektoren <span class="math inline">\(\overrightarrow{z}\)</span> som output. Funktionen dannes ved at sammensætte en masse simplere funktioner. For at holde overblik kan man skitsere det neurale netværk som i Figur ?.</p>
<p>FLOT FIGUR MED NETVÆRKET</p>
<p>Vores input er vektoren <span class="math inline">\(\overrightarrow{x}\)</span>, der har <span class="math inline">\(3m\)</span> koordinater. Disse koordinater svarer til cirklerne i venstre side af figuren kaldet <em>inputlaget</em>. Cirklerne i midten angiver <em>det skjulte lag</em>. (FODNOTE: Man kan gøre sit neurale netværk mere fleksibelt ved at have flere skjulte lag. For at holde forklaringen simpel vil vi dog kun gennemgå tilfældet med et skjult lag her.) Her omregnes <span class="math inline">\(\overrightarrow{x}\)</span> til en ny vektor <span class="math inline">\(\overrightarrow{h}\)</span> med <span class="math inline">\(d\)</span> koordinater, hvor <span class="math inline">\(d\)</span> er et tal, vi har valgt. Hver koordinat i <span class="math inline">\(\overrightarrow{h}\)</span> svarer til en af cirklerne i midten, og pilene i venstre side angiver, at hver koordinat i <span class="math inline">\(\overrightarrow{h}\)</span> er en funktion af koordinaterne i <span class="math inline">\(\overrightarrow{x}\)</span>. Mere præcist beregnes koordinaterne i <span class="math inline">\(\overrightarrow{h}\)</span> ved: <span class="math display">\[
\begin{aligned}
h_1&amp;=f(w_{1,0}+w_{1,1}x_1+w_{1,2}x_2+\ldots +w_{1,3m}x_{3m})\\
&amp;\vdots\\
h_j&amp;=f(w_{j,0}+w_{j,1}x_1+w_{j,2}x_2+\ldots +w_{j,3m}x_{3m})\\
&amp;\vdots\\
h_{d}&amp;=f(w_{d,0}+w_{d,1}x_1+w_{d,2}x_2+\ldots +w_{d,3m}x_{3m})\\\end{aligned}
\]</span> Funktionen <span class="math inline">\(f\)</span>, der indgår, er en <em>aktiveringsfunktion</em>. Man kan fx bruge sigmoid-funktionen <span class="math display">\[
f(x)=\frac{1}{1+e^{-x}}
\]</span> Du kan læse mere om aktiveringsfunktioner her LINK. Desuden indgår der <span class="math inline">\(d \cdot (3m+1)\)</span> <em>vægte</em> på formen <span class="math inline">\(w_{j,k}\)</span>. Vægtene er reelle konstanter. Når vi om lidt træner det neurale netværk, forsøger vi at bestemme værdien af disse vægte.</p>
<p>Cirklerne til højre i Figur ? udgør <em>outputlaget</em>. I outputlaget laves vektoren <span class="math inline">\(\overrightarrow{h}\)</span> om til outputvektoren <span class="math inline">\(\overrightarrow{z}\)</span> med <span class="math inline">\(V\)</span> koordinater svarende til cirklerne til højre. Igen viser pilene, at hver koordinat i <span class="math inline">\(\overrightarrow{z}\)</span> er en funktion af koordinaterne i <span class="math inline">\(\overrightarrow{h}\)</span>. Funktionen udregnes i to trin:</p>
<ul>
<li><p>Først udregner vi en vektor <span class="math inline">\(\overrightarrow{y}\)</span> med <span class="math inline">\(V\)</span> koordinater, hvor <span class="math inline">\(i\)</span>te koordinat er <span class="math display">\[
y_i=u_{i,0}+u_{i,1}h_1+u_{i,2}h_2+\ldots + u_{i,d}h_{d}
\]</span> Igen indgår der nogle vægte <span class="math inline">\(u_{i,j}\)</span>. Dem er der i alt <span class="math inline">\((d+1)\cdot V\)</span> af.</p></li>
<li><p>Derefter laver vi <span class="math inline">\(\overrightarrow{y}\)</span> om til sandsynligheder. Det gør vi ved at bruge softmax-funktionen, som blev introduceret i noten Word2Vec LINK. Softmax-funktionen tager en <span class="math inline">\(V\)</span>-dimensional vektor <span class="math inline">\(\overrightarrow{y}\)</span> som input og giver en ny <span class="math inline">\(V\)</span>-dimensional vektor <span class="math inline">\(\overrightarrow{z}=\text{Softmax}(\overrightarrow{y})\)</span> som output. Den <span class="math inline">\(i\)</span>te koordinat i <span class="math inline">\(\overrightarrow{z}\)</span> udregnes som <span class="math display">\[
z_i=\frac{e^{y_i}}{e^{y_1} + \dotsm + e^{y_V}}
\]</span> Vi så i Word2Vec-noten, at <span class="math inline">\(\overrightarrow{z}\)</span> opfylder 1.–2. i LINK TILBAGE I DENNE TEKST, således at det giver mening at tænke på <span class="math inline">\(\overrightarrow{z}\)</span> som en vektor af sandsynligheder. Dette <span class="math inline">\(\overrightarrow{z}\)</span> er vores outputvektor.</p></li>
</ul>
<p>Samlet set er der ret mange vægte i modellen. Der er <span class="math inline">\(d\cdot (3m+1)\)</span> vægte i det skjulte lag og <span class="math inline">\((d+1)\cdot V\)</span> vægte i ouputlaget. I alt bliver det <span class="math inline">\(d\cdot(1+3m +V) +V\)</span> vægte. Læg mærke til, at valget af <span class="math inline">\(d\)</span> er det, der bestemmer antallet af vægte: <span class="math inline">\(m\)</span> var fastlagt da vi lavede Word2Vec, <span class="math inline">\(V\)</span> er antallet af ord i vores ordforråd, og 3-tallet er antal ord, vi prædikterer udfra. Valget af <span class="math inline">\(d\)</span> er i praksis et kompromis. Jo større <span class="math inline">\(d\)</span> er, des mere præcis en model kan vi lave. Omvendt bliver der også flere vægte, der skal bestemmes. Det kræver stor regnekraft. Desuden kræver det meget træningsdata, hvis man vil undgå overfitting - et problem, som du kan læse mere om her LINK.</p>
<section id="træning-af-netværket" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="træning-af-netværket">Træning af netværket</h2>
<p>Som sagt indgår der ret mange vægte i modellen. Indtil nu har vi ikke sagt, hvilken værdi disse vægte skal have. Husk på, at vores neurale netværk skal give os sandsynligheden for, at et ord er næste ord i en sætning, når vi kender de 3 foregående ord. For at lære, hvilket ord der typisk kommer efter tre givne ord i virkelige tekster, får vi endnu engang brug for noget træningsdata i form af vores store tekstkorpus. Ud fra dette tekstkorpus laver vi et datasæt bestående af alle 4-gram, det vil sige alle sekvenser på 4 ord, der forekommer i teksten. De tre første ord kalder vi input, og det sidste kalder vi <em>target</em>.</p>
<p>Hvis fx vores træningsdata består af sætningen <span class="math display">\[
\text{"Solen skinner, og en kat løber på græsplænen."}
\]</span> så laver vi en datatabel som i Tabel <a href="#fig:data" data-reference-type="ref" data-reference="fig:data">[fig:data]</a>. (FODNOTE: Vi ignorerer tegnsætning.)</p>
<table class="table">
<caption>Træningsdata<span data-label="fig:data"></span></caption>
<thead>
<tr class="header">
<th style="text-align: center;">Input 1</th>
<th style="text-align: center;">Input 2</th>
<th style="text-align: center;">Input 3</th>
<th style="text-align: center;">Target</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">⋮</td>
<td style="text-align: center;">⋮</td>
<td style="text-align: center;">⋮</td>
<td style="text-align: center;">⋮</td>
</tr>
<tr class="even">
<td style="text-align: center;"></td>
<td style="text-align: center;">Solen</td>
<td style="text-align: center;">skinner</td>
<td style="text-align: center;">og</td>
</tr>
<tr class="odd">
<td style="text-align: center;">skinner</td>
<td style="text-align: center;">og</td>
<td style="text-align: center;">en</td>
<td style="text-align: center;">kat</td>
</tr>
<tr class="even">
<td style="text-align: center;">og</td>
<td style="text-align: center;">en</td>
<td style="text-align: center;">kat</td>
<td style="text-align: center;">løber</td>
</tr>
<tr class="odd">
<td style="text-align: center;">en</td>
<td style="text-align: center;">kat</td>
<td style="text-align: center;">løber</td>
<td style="text-align: center;">på</td>
</tr>
<tr class="even">
<td style="text-align: center;">⋮</td>
<td style="text-align: center;">⋮</td>
<td style="text-align: center;">⋮</td>
<td style="text-align: center;">⋮</td>
</tr>
</tbody>
</table>
<p>Hvis vores neurale netværk er valgt godt, skal det gerne give en høj sandsynlighed for targetordet, når vi giver de tre inputord som input. Vi forsøger derfor at vælge vægtene i det neurale netværk, så netværket giver en høj sandsynlighed for targetordet. Når vi bestemmer vægtene, så de passer til træningsdata, siger vi, at vi <em>træner</em> det neurale netværk.</p>
<p>Lad os se på en enkelt række i datasættet, fx den der svarer til sekvensen "og en kat løber". Vores inputord er "og", "en" og "kat". Dem oversætter vi til vektoren <span class="math inline">\(\overrightarrow{x}\)</span> ved at bruge ordenes Word2Vec-vektorer som beskrevet ovenfor. Output fra det neurale netværk er en vektor <span class="math inline">\(\overrightarrow{z}\)</span>, hvis <span class="math inline">\(i\)</span>te koordinat giver sandsynligheden for, at det <span class="math inline">\(i\)</span>te ord i ordforrådet er det næste ord. Hvis vi udelukkende ser på sekvensen "og en kat løber", og ignorerer alle de andre sekvenser i træningsdata, så skal "løber" have sandsynligheden 1, og alle andre ord skal have sandsynligheden 0. Vektoren med <span class="math inline">\(1\)</span> i den koordinat, der svarer til det korrekte ord, og <span class="math inline">\(0\)</span> i alle andre koordinater kaldes <em>targetvektoren</em> <span class="math inline">\(\overrightarrow{t}\)</span>.</p>
<p>I praksis rammer vores sandsynlighedsvektor <span class="math inline">\(\overrightarrow{z}\)</span> aldrig target <span class="math inline">\(\overrightarrow{t}\)</span> præcist, fordi der også skal tages højde for de andre sekvenser i datasættet. Det kunne fx være, at sekvensen "og en kat spiser" også forekommer et sted i træningsdata. I så fald skal "spiser" også have høj sandsynlighed.</p>
<p>I det mindste vil vi gerne have, at <span class="math inline">\(\overrightarrow{z}\)</span> kommer tæt på targetvektoren <span class="math inline">\(\overrightarrow{t}\)</span>. Vi måler, hvor langt vi er fra target med en <em>tabsfunktion</em> LINK. Den tabsfunktion, vi vil bruge her, kaldes <em>cross-entropy</em>. Med output <span class="math inline">\(\overrightarrow{z}\)</span> og targetvektor <span class="math inline">\(\overrightarrow{t}\)</span>, er cross-entropy givet ved <span class="math display">\[
CE(\overrightarrow{z},\overrightarrow{t})=-t_1\ln(z_1)-t_2\ln(z_2)- \cdots  -t_V\ln(z_V)
\]</span> Targetvektoren er <span class="math inline">\(0\)</span> på alle koordinater undtagen den, der svarer til det korrekte ord, så alle andre led i summen er 0. Lad os sige, det korrekte ord har nummeret <span class="math inline">\(c\)</span> i vores ordforråd, så <span class="math inline">\(t_c=1\)</span> og <span class="math inline">\(t_j=0\)</span> for alle <span class="math inline">\(j\neq c\)</span>. Så er <span class="math inline">\(CE(\overrightarrow{z},\overrightarrow{t})=-\ln(z_c)\)</span>. Da <span class="math inline">\(z_c\)</span> er sandsynligheden for, at vores targetord er det næste, vil vi gerne have, at <span class="math inline">\(z_c\)</span> er så stor som muligt. Da den naturlige logaritme er en voksende funktion, svarer det til, at <span class="math inline">\(CE(\overrightarrow{z},\overrightarrow{t})=-\ln(z_c)\)</span> skal være så lille som muligt.GRAF FOR LN</p>
<p>Dette gentager vi nu for hver eneste række i vores træningsdata. Vi beregner en cross-entropy for hver. Til sidst lægger vi alle disse cross-entropy sammen til en samlet tabsfunktion <span class="math inline">\(L\)</span>, som helst skal være så lille som muligt. Vi har udregnet <span class="math inline">\(L\)</span> udfra vores træningsdata og vægtene. Træningsdata er det, vi går ud fra, vi ved, så det kan vi ikke lave om på for at minimere <span class="math inline">\(L\)</span>. Derfor betragter vi nu <span class="math inline">\(L\)</span> som en funktion af vægtene <span class="math inline">\(w_{j,k}\)</span> og <span class="math inline">\(u_{i,j}\)</span>. Vi ønsker at bestemme vægtene således, at <span class="math inline">\(L\)</span> bliver mindst mulig svarende til, at vores sandsynligheder kommer så tæt på target som muligt. Vi skal altså finde minimum for en funktion af mange variable. Det kan man fx gøre ved hjælp af <em>gradientnedstigning</em>, som du kan læse mere om HER. For at lave gradientnedstigning er det vigtigt at kunne finde de partielt afledte af <span class="math inline">\(L\)</span>. En smart måde at lave gradientnedstigning på kaldes <em>backpropagation</em>. Se mere om backpropagation HER.</p>
</section>
<section id="tekstgenerering" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="tekstgenerering">Tekstgenerering</h2>
<p>Las os sige, at vi har fået trænet vores neurale netværk. Det vil sige, at vi har bestemt de vægte, der skal indgå. Så er vores neurale netværk en fastlagt funktion. Når vi giver netværket en inputvektor <span class="math inline">\(\overrightarrow{x}\)</span>, beregner det en outputvektor <span class="math inline">\(\overrightarrow{z}\)</span> af sandsynligheder ved brug af de valgte vægte.</p>
<p>Vi kan nu gå i gang med at generere tekst. Lad os sige, at vi har dannet de første ord i en sætning. Det kunne være <span class="math display">\[
\text{"En hund og en kat ---"}
\]</span> Vi tager de <span class="math inline">\(3\)</span> sidste ord "og", "en" og "kat" og oversætter dem til en vektor <span class="math inline">\(\overrightarrow{x}\)</span>. Denne vektor giver vi som input til det neurale netværk. For hvert ord i ordforrådet beregner det neurale netværk sandsynligheden for, at det er det næste ord. Det kan være at "løber" får sandsynligheden 1/2, "spiser" får sandsynligheden 1/3, mens alle andre ord får meget små sandsynligheder. En mulighed er så at vælge det mest sandsynlige ord som det næste. Det ville være "løber" i vores eksempel. Det viser sig dog, at det giver for lidt variation i de sætninger, der dannes. I stedet kan man vælge et tilfældigt næste ord ud fra deres sandsynligheder. I vores eksempel ville vi vælge "løber" med sandsynlighed 1/2, "spiser" med sandsynlighed 1/3, osv.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/aimat\.dk");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>