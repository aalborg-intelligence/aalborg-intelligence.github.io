---
##title: "Materialer om sprogmodeller"
description: "Forskellige noter -- med forskelligt fokus og sværhedsgrad -- om sprogmodeller."
image: "sprogmodeller/images/eks1.png"
---

# Materialer om sprogmodeller

På denne side finder du forskellige noter om sprogmodeller. Noterne varierer i sværhedsgrad og i matematisk fokus. 

Noterne er skrevet til elever i gymnasiet og bør læses i den rækkefølge, som de er beskrevet nedenfor. Det er dog ikke nødvendigt at læse alle noterne for at få en forståelse for de store sprogmodeller. 

Sværhedsgraden af noterne er klassificeret fra \"forholdvis nem\" (\*) til \"svær\" (\*\*\*\*).




<!-- Start på clickable section -->

<a href="sprogmodeller/intro.html" class="quarto-grid-link">

::: {.boxed}

### Introduktion til sprogmodeller

![](sprogmodeller/images/sprog.jpg){style='float:right;'  width=40%}

Noten giver en en kort og letlæselig introduktion til sprogmodeller, som handler om, hvordan sprogmodeller i virkeligheden bare prøver at forudsige det næste ord i en sætning. Vi anbefaler, at man starter med at læse denne note.

[Sværhedsgrad: \*]{style="color: #8086F2"}

:::

<!-- Slut på clickable section -->
</a>




<!-- Start på clickable section -->

<a href="sprogmodeller/simple.html" class="quarto-grid-link">

::: {.boxed}

### Simple sprogmodeller

![](sprogmodeller/images/sprog2.jpg){style='float:right;'  width=30%}

I noten om simple sprogmodeller giver vi en \"blød\" introduktion til idéen bag sprogmodeller, men denne note er ikke en forudsætning for de efterfølgende noter, så man kan vælge at springe den over.


[Sværhedsgrad: \*\*]{style="color: #8086F2"}

:::

<!-- Slut på clickable section -->
</a>





<!-- Start på clickable section -->

<a href="sprogmodeller/word2vec.html" class="quarto-grid-link">

::: {.boxed}

### Word2Vec

![](sprogmodeller/images/eks1.png){style='float:right;'  width=40%}

Denne note handler om, hvordan ord kan repræsenteres som vektorer, hvor den semantiske betydning af ordet indgår i vektorrepræsentationen. Det gøres ved, at ord, som har nogenlunde samme betydning, bliver repræsenteret ved vektorer, som peger i nogenlunde samme retning. Denne note er central for at forstå de store sprogmodeller. 


[Sværhedsgrad: \*\*\*\*]{style="color: #8086F2"}

:::

<!-- Slut på clickable section -->
</a>



<!-- Start på clickable section -->

<a href="sprogmodeller/tekstgenerering.html" class="quarto-grid-link">

::: {.boxed}

### Neurale netværk til tekstgenerering

::: {.paddingleft}

![](sprogmodeller/images/NN_tekstgenerering.png){style='float:right;'  width=40%}
:::

Denne note handler om, hvordan de vektorer, som repræsenterer hvert enkelt ord i vores ordforråd, kan bruges som input i et kunstigt neuralt netværk, der kan trænes til at prædiktere det næste ord i en sætning. På den måde får vi bygget en stor (omend simpel) sprogmodel -- de store sprogmodeller, som anvendes i virkelighedens verden, er noget mere komplicerede!


[Sværhedsgrad: \*\*\*\*]{style="color: #8086F2"}

:::

<!-- Slut på clickable section -->
</a>


<!-- Start på clickable section -->

<a href="sprogmodeller/transformeren.html" class="quarto-grid-link">

::: {.boxed}

### Introduktion til sprogmodeller

![](sprogmodeller/images/fig-attention.png){style='float:right;'  width=40%}

De kraftige sprogmodeller, der indgår i de nyeste former for sproglig kunstig intelligens, benytter ikke helt den tilgang, vi hidtil har beskrevet, hvor man først laver Word2Vec og derefter træner et neuralt
netværk til at prædiktere ord. I stedet bruges en videreudvikling, kaldet *transformeren*, der kombinerer de to trin i én algoritme. I Chat-GPT står GPT for eksempel for \"Generative Pre-trained Transformer\".
I denne note beskriver vi nogle af de centrale dele af transformeren. Bemærk, at selv om vi prøver at give en intuition for, hvad transformeren gør, så er der ingen, der helt forstår i detaljer, hvorfor
den virker.

[Sværhedsgrad: \*\*\*\*]{style="color: #8086F2"}

:::

<!-- Slut på clickable section -->
</a>

