---
##title: "Øvrige AI materialer"
description: "Forskellige noter -- med forskelligt fokus og sværhedsgrad -- om forskellige andre AI materialer (end neurale net og sprogmodeller)."
image: "ROC/images/confusion_matrix.png"
---

# Øvrige AI materialer

På denne side finder du øvrige AI materialer, som ikke er dækket i de forskellige noter om neurale net og sprogmodeller. Noterne varierer i sværhedsgrad og i matematisk fokus. 
Noterne er skrevet til elever i gymnasiet og kan læses uafhængigt af hinanden.

Sværhedsgraden af noterne er klassificeret fra \"forholdvis nem\" (\*) til \"svær\" (\*\*\*\*).


<!-- Start på clickable section -->

<a href="logistisk/log-reg.html" class="quarto-grid-link">

::: {.boxed}

### Logistisk regression

![](logistisk/data/figur_til_www_files/figure-html/log_reg_www-1.png){style='float:right;'  width=40%}

Logistisk regression er en metode, som kan bruges til klassifikation, og metoden har faktisk fællestræk med simple neurale netværk. Logistisk regression er et helt andet emne end logistisk vækst, som vi kender fra gymnasieundervisningen. Det eneste, de to emner umiddelbart har til fælles, er, at den logistiske funktion spiller en rolle begge steder. I slutningen af noten vil vi dog se et eksempel, hvor der alligevel er en sammenhæng mellem logistisk regression og logistisk vækst.

[Sværhedsgrad: \*\*\*]{style="color: #8086F2"}

:::
<!-- Slut på clickable section -->
</a>




<!-- Start på clickable section -->

<a href="tabsfunktioner/tabsfunktioner.html" class="quarto-grid-link">

::: {.boxed}

### Tabsfunktioner

::: {.paddingleft}

![](tabsfunktioner/images/tabsfunktion.jpg){style='float:right;'  width=30%}
:::

I langt de fleste tilfælde sker træning af AI modeller ved at minimere en tabsfunktion. Lidt løst sagt kan man sige, at en tabsfunktion måler, hvor god en AI model er til at forudsige det, vi gerne vil have den til at sige noget om. I denne note forklarer vi, hvordan tabsfunktioner kan se ud, og hvad træningsdata er for en størrelse.

[Sværhedsgrad: \*\*\*]{style="color: #8086F2"}

:::

<!-- Slut på clickable section -->
</a>



<!-- Start på clickable section -->

<a href="krydsvalidering/krydsvalidering.html" class="quarto-grid-link">

::: {.boxed}

### Overfitting, modeludvælgelse og krydsvalidering

![](krydsvalidering/images/overfitting.png){style='float:right;'  width=30%}

I denne note forklarer vi, hvordan man vælger den bedste model til beskrivelse af data. Vi undersøger, om man bare skal vælge den mest komplicerede, eller om der kan gå noget galt, hvis man gør det. Det handler kort sagt om overfitting og krydsvalidering.

[Sværhedsgrad: \*\*\*]{style="color: #8086F2"}

:::

<!-- Slut på clickable section -->
</a>


<!-- Start på clickable section -->

<a href="ROC/ROC.html" class="quarto-grid-link">

::: {.boxed}

### Sensitivitet, specificitet, ROC-kurver og AUC

![](ROC/images/confusion_matrix.png){style='float:right;'  width=40%}

Når man skal vælge en god algoritme, som kan anvendes til en klassifikation, har man brug for at kunne sammenligne, hvor godt forskellige algoritmer prædikterer. Hvordan det kan gøres, handler denne note om.

[Sværhedsgrad: \*\*\*]{style="color: #8086F2"}

:::

<!-- Slut på clickable section -->
</a>



<!-- Start på clickable section -->

<a href="naivbayes/NaivBayes.html" class="quarto-grid-link">

::: {.boxed}

### Naiv Bayes klassifier

![](naivbayes/images/bayes_thm.png){style='float:right;'  width=40%}

Denne note handler om klassifikation ved hjælp af en metode, som kaldes for \"naiv Bayes\". Noten er baseret på sandsynlighedsregning -- herunder betingede sandsynligheder og uafhængige hændelser.

[Sværhedsgrad: \*\*\*]{style="color: #8086F2"}

:::

<!-- Slut på clickable section -->
</a>



<!-- Start på clickable section -->

<a href="kmeans/kmeans.html" class="quarto-grid-link">

::: {.boxed}

### Clustering med K-means

![](kmeans/images/kmeansbil.jpg){style='float:right;'  width=40%}
Clustering med K-means er en metode, som kan bruges til at opdele observationer i et antal grupper. Metoden er et eksempel på *unsupervised learning*, fordi vi ikke på forhånd har nogle observationer, hvor vi *ved* hvilken gruppe, hver observation tilhører.

[Sværhedsgrad: \*\*\*\*]{style="color: #8086F2"}

:::

<!-- Slut på clickable section -->
</a>
